{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from utils import *\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "try:\n",
    "    plt1.closeWindow()\n",
    "    print(\"closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt1 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "# settings.useParallelProjection = True #makes view orthographic\n",
    "\n",
    "## uncomment to use VOLPE dataset -----------------------------------------------------\n",
    "# location = 'C:/Users/Derm/2021-03-10-16-43-50_Velodyne-VLP-16-Data_garminSignage.txt'\n",
    "# cloud = np.loadtxt(open(location, \"rb\"), delimiter=\",\")\n",
    "# cloud = cloud[~np.isnan(cloud).any(axis=1)] #remove all rows with NaN elements\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "print(type(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "##-------------------------------------------------------------------------------------\n",
    "\n",
    "# f =np.array([200,200,40]) #fidelity in x, y, z #takes ~30s on my dsektop\n",
    "# lim = np.array([-50,50,-50,50,-10,10])\n",
    "\n",
    "f =np.array([25,25,4]) #fidelity in x, y, z # < 5s\n",
    "lim = np.array([-100,100,-100,100,-10,10])\n",
    "\n",
    "for _ in range(3):\n",
    "    E = subdivide_scan(cloud,plt1, bounds = lim, fid = f, draw_grid = False, show_pc = False) \n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "plt2 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "cloud_tensor = tf.convert_to_tensor(cloud, np.float32)\n",
    "# print(tf.shape(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# # make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "# #-------------------------------------------------------------------------------------\n",
    "\n",
    "f = tf.constant([25,25,4]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.])\n",
    "\n",
    "for _ in range(10):\n",
    "    E = subdivide_scan_tf(cloud,plt2, bounds = lim, fid = f, draw_grid = False, show_pc = False) \n",
    "#     print(tf.config.experimental.get_memory_info('GPU:0'))\n",
    "# ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test R() and Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hat = np.array([1,0,0])\n",
    "theta =  0.1 #np.pi/6 #rad\n",
    "\n",
    "rot_mat_simp = R_simp(n_hat, theta)\n",
    "print(rot_mat_simp)\n",
    "angs = np.array([theta,0 ,0])\n",
    "rot_mat = R(angs)\n",
    "print(rot_mat)\n",
    "\n",
    "print(R2Euler(rot_mat))\n",
    "\n",
    "p_point = np.array([1,1,1]).T\n",
    "\n",
    "J = jacobian(angs, p_point)\n",
    "\n",
    "d_rot_mat_simp = dR_simp(n_hat,theta)\n",
    "# print(d_rot_mat_simp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test R2Euler_tf and R_tf\n",
    "#### Works with single axis roation\n",
    "#### Works with vectoried input\n",
    "#### Solution becomes ambiguious with mutliple axis inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = tf.random.normal((3,1)) * tf.constant([[0.], [0.], [1.] ]) #single axis angle input\n",
    "# angs = tf.Variable([[0.],[ np.pi/2],[ 0.]]) #vector input, multiple axis rotation\n",
    "print(\"Input angs: \\n\", angs.numpy())\n",
    "# print(\"R(angs): \\n\", R_tf(angs).numpy())\n",
    "test1 = R2Euler_tf(R_tf(angs))\n",
    "print(\"R2Euler_tf(R(angs)): \\n\", test1.numpy())\n",
    "# test2 = R2Euler(R(angs[:,:2]))\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test tfp find bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.convert_to_tensor(cloud, np.float32)#[:100]\n",
    "# print(\"c: \\n\", c.numpy())\n",
    "startx = -100.\n",
    "stopx = 100.\n",
    "numx = 10\n",
    "edgesx = tf.linspace(startx, stopx, numx)\n",
    "xbins = tfp.stats.find_bins(c[:,0], edgesx)\n",
    "print(xbins)\n",
    "starty = -100.\n",
    "stopy = 100.\n",
    "numy = 10\n",
    "edgesy = tf.linspace(starty, stopy, numy)\n",
    "ybins = tfp.stats.find_bins(c[:,1], edgesy)\n",
    "print(ybins)\n",
    "\n",
    "min_num_pts = 1000\n",
    "\n",
    "count = 0\n",
    "E = []\n",
    "\n",
    "for x in range(numx):\n",
    "    for y in range(numy):\n",
    "        #only do calculations if there are a sufficicently high number of points in the bin\n",
    "        xin = tf.where(xbins == x)\n",
    "        if tf.shape(xin)[0] > min_num_pts:\n",
    "            if tf.shape(tf.where(tf.gather(ybins, xin) == y))[0] > min_num_pts: #repeat for y points at x coord\n",
    "#                 print(\"working\", x, y)\n",
    "                count += 1\n",
    "# print(xin)\n",
    "# print(ybins)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.linspace(1,5,5)\n",
    "print(test)\n",
    "ans = tf.where(test < 4)\n",
    "print(\"ans: \\n\",ans)\n",
    "print(\"\\n\", tf.gather(test, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inline volumetric rendering using ipyvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple demo\n",
    "import ipyvolume\n",
    "ds = ipyvolume.datasets.aquariusA2.fetch()\n",
    "short = ds.data[:,:,:]\n",
    "ipyvolume.quickvolshow(short, lighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.linspace(1,12,8)\n",
    "ans[2] = 0\n",
    "print(ans)\n",
    "\n",
    "test = ans[ans < 10]\n",
    "print(test)\n",
    "np.shape(test)[0]\n",
    "\n",
    "print(np.median(test[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = tf.random.normal([3,3])\n",
    "print(tes)\n",
    "print(tf.reverse(tes, axis = [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.reshape([10.,10.,2.], (3,1))\n",
    "# print(type(a))\n",
    "# t = tf.Tensor(a, dtype = \"float32\")\n",
    "\n",
    "a = tf.constant([2.1,2.,3.])\n",
    "b = tf.constant([1.,2.,3.])\n",
    "tf.tensordot(a,b, axes = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = tf.eye(3)\n",
    "# print(j)\n",
    "Jx = tf.constant([[1.], [2.], [3.]])\n",
    "J = tf.concat([eye, Jx], axis = 1)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.sin(1.))\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs  = np.array([1.,0.1,0.1])\n",
    "p_point = np.array([1.,2.,3.])\n",
    "for _ in range(numiter):\n",
    "    J = jacobian(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on CPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF is slower if we do them one by one BUT is waaay faster if we send them in all at once\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs = tf.random.normal((3,numiter))\n",
    "p_point = tf.random.normal((3,numiter))\n",
    "J = jacobian_tf(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on GPU\")\n",
    "print(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing subdividing cells without loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: given input tensor \"cloud\" and \"bins\" which contains all og and binned coordinates\n",
    "#      subdivide and perform ops on \"cloud\" wihtout using any loops \n",
    "\n",
    "bins = tf.transpose(tf.constant([[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.],\n",
    "                                 [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                 [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]))\n",
    "cloud = bins + tf.random.normal(tf.shape(bins))*0.1\n",
    "print(\"binned coordinate values: \\n\", bins)\n",
    "# print(cloud)\n",
    "\n",
    "#1d case (easy)\n",
    "# q = tf.constant([1., 1., 2.]) \n",
    "# print(tf.squeeze(tf.gather(bins, ans))) #works for 1d, unsure of utility in 2d\n",
    "#2d case (hard)\n",
    "q = tf.constant([[[1., 1., 2.]],\n",
    "                 [[0., 9., 9.]],\n",
    "                 [[2., 0., 1.]],\n",
    "                 [[7., 8., 9.]]])\n",
    "print(\"\\n cells of interest: \\n\",q)\n",
    "\n",
    "idx = tf.equal(bins, q)\n",
    "print(idx)\n",
    "#ans outputs tensor of shape [N,2], where:\n",
    "#  [[voxel number, index of [x,y,z] in cloud that corresponds to bin #],\n",
    "#   [voxel number,index of [x,y,z] in cloud that corresponds to bin #]] ... \n",
    "ans = tf.where(tf.math.reduce_all(idx, axis = 2) == True)\n",
    "print(\"ans: \\n\", ans)\n",
    "\n",
    "#Need to \"ungroup\" so that we can fit_gaussian_tf() to each individual voxel...\n",
    "s = tf.shape(ans)\n",
    "group_ids, group_idx = tf.unique(ans[:, 0], out_idx=s.dtype)\n",
    "num_groups = tf.reduce_max(group_idx) + 1\n",
    "# print(group_ids, group_idx, num_groups)\n",
    "sizes = tf.math.bincount(group_idx)\n",
    "# print(sizes)\n",
    "\n",
    "#replace <bins> here with <cloud> when done debugging\n",
    "rag = tf.RaggedTensor.from_row_lengths(tf.gather(cloud, ans[:,1]), sizes) \n",
    "# print(\"ragged: \\n\", rag)\n",
    "\n",
    "#Run on GPU as vectorized operation (WAAAAAY Faster) --\n",
    "reg = tf.RaggedTensor.to_tensor(rag)\n",
    "print(\"\\n regular tensor: \\n\", reg)\n",
    "mu, sigma = fit_gaussian_tf(reg)\n",
    "print(\"mu: \\n\", mu)\n",
    "print(\"sigma: \\n\", sigma)\n",
    "#------------------------------------------------------- \n",
    "\n",
    "# # works but uses loop (runs on CPU -> slow) -----------\n",
    "# A =  tf.data.Dataset.from_tensor_slices(rag)\n",
    "# mus = []\n",
    "# sigmas = []\n",
    "# for i in range(len(A)):\n",
    "#     mu, sigma = fit_gaussian_tf(rag[i])\n",
    "#     mus.append(mu)\n",
    "#     sigmas.append(sigma)\n",
    "# print(mus, sigmas)\n",
    "# #------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove zero rows from 3d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins2 = tf.transpose(tf.constant([[[2., 9., 3., 0., 2., 2., 3., 1., 0., 2.], #x\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]], \n",
    "                                  \n",
    "                                  [[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.], #y\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]],\n",
    "                                  \n",
    "                                  [[2., 1., 3., 1., 2., 2., 3., 1., 0., 2.], #z\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]]))\n",
    "\n",
    "print(bins2[:2])\n",
    "print(bins2[:,:,0])\n",
    "#need to AVERAGE point locations PER AXIS, PER BIN\n",
    "#   Ignore SPECIFIC POINTS where XYZ are ALL ZERO\n",
    "idx = tf.math.not_equal(bins2[:,:,0], tf.constant([0.,0.,0.]))\n",
    "print(idx[:2])\n",
    "mask = tf.where(tf.math.reduce_any(idx, axis = 2) == True)\n",
    "print(\"\\n mask: \\n\", mask[:6]) #correct(?)\n",
    "# print(tf.gather(bins,mask))\n",
    "\n",
    "nonzero = tf.gather(bins,[0,0,0])\n",
    "print(\"\\n nonzero elements: \\n\", nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2D tensor with all permutations (:n1, :n2, :n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fida = 100 \n",
    "fidb = 100\n",
    "fidc = 20\n",
    "\n",
    "a = tf.linspace(1,fida,fida)[:,None]\n",
    "b = tf.linspace(1,fidb,fidb)[:,None]\n",
    "c = tf.linspace(1,fidc,fidc)[:,None]\n",
    "\n",
    "ansa = tf.tile(a, [fidb*fidc, 1])\n",
    "ansb = tf.tile(tf.reshape(tf.tile(b, [1,fida]), [-1,1] ), [(fidc), 1])\n",
    "ansc = tf.reshape(tf.tile(c, [1,fida*fidb]), [-1,1] )\n",
    "\n",
    "ans = tf.squeeze(tf.transpose(tf.Variable([ansa,ansb,ansc])))\n",
    "# print(ans)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.array_ops.where_v2(\n",
    "        math_ops.not_equal(tensor, array_ops.constant(0, tensor.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
