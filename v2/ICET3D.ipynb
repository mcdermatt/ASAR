{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from utils import *\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "# from numba import cuda #gpu library used to clear gpu memory after each trial\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "took 3.1033310890197754 seconds with numpy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94aeb0a7b4442eab2290435ca8aa7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "try:\n",
    "    plt1.closeWindow()\n",
    "    print(\"closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt1 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "# settings.useParallelProjection = True #makes view orthographic\n",
    "\n",
    "## uncomment to use VOLPE dataset -----------------------------------------------------\n",
    "# location = 'C:/Users/Derm/2021-03-10-16-43-50_Velodyne-VLP-16-Data_garminSignage.txt'\n",
    "# cloud = np.loadtxt(open(location, \"rb\"), delimiter=\",\")\n",
    "# cloud = cloud[~np.isnan(cloud).any(axis=1)] #remove all rows with NaN elements\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "print(type(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "##-------------------------------------------------------------------------------------\n",
    "\n",
    "# f =np.array([200,200,40]) #fidelity in x, y, z #takes ~30s on my dsektop\n",
    "# lim = np.array([-50,50,-50,50,-10,10])\n",
    "\n",
    "f =np.array([50,50,1]) #fidelity in x, y, z # < 5s\n",
    "lim = np.array([-100,100,-100,100,-10,10])\n",
    "\n",
    "for _ in range(1):\n",
    "    E = subdivide_scan(cloud,plt1, bounds = lim, fid = f, draw_grid = False, show_pc = True) \n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.07901787757873535 seconds with tensorflow\n"
     ]
    }
   ],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "#bad vibes\n",
    "# dev = cuda.get_current_device()\n",
    "# dev.reset()\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "plt2 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "cloud_tensor = tf.convert_to_tensor(cloud, np.float32)\n",
    "# print(tf.shape(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# # make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "# #-------------------------------------------------------------------------------------\n",
    "\n",
    "f = tf.constant([100,100,20]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.])\n",
    "\n",
    "for _ in range(1):\n",
    "    E = subdivide_scan_tf(cloud, plt2, bounds = lim, fid = f, draw_grid = False, show_pc = False) \n",
    "# ViewInteractiveWidget(plt2.window)\n",
    "# print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test R() and Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hat = np.array([1,0,0])\n",
    "theta =  0.1 #np.pi/6 #rad\n",
    "\n",
    "rot_mat_simp = R_simp(n_hat, theta)\n",
    "print(rot_mat_simp)\n",
    "angs = np.array([theta,0 ,0])\n",
    "rot_mat = R(angs)\n",
    "print(rot_mat)\n",
    "\n",
    "print(R2Euler(rot_mat))\n",
    "\n",
    "p_point = np.array([1,1,1]).T\n",
    "\n",
    "J = jacobian(angs, p_point)\n",
    "\n",
    "d_rot_mat_simp = dR_simp(n_hat,theta)\n",
    "# print(d_rot_mat_simp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test R2Euler_tf and R_tf\n",
    "#### Works with single axis roation\n",
    "#### Works with vectoried input\n",
    "#### Solution becomes ambiguious with mutliple axis inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = tf.random.normal((3,1)) * tf.constant([[0.], [0.], [1.] ]) #single axis angle input\n",
    "# angs = tf.Variable([[0.],[ np.pi/2],[ 0.]]) #vector input, multiple axis rotation\n",
    "print(\"Input angs: \\n\", angs.numpy())\n",
    "# print(\"R(angs): \\n\", R_tf(angs).numpy())\n",
    "test1 = R2Euler_tf(R_tf(angs))\n",
    "print(\"R2Euler_tf(R(angs)): \\n\", test1.numpy())\n",
    "# test2 = R2Euler(R(angs[:,:2]))\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test tfp find bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.convert_to_tensor(cloud, np.float32)#[:100]\n",
    "# print(\"c: \\n\", c.numpy())\n",
    "startx = -100.\n",
    "stopx = 100.\n",
    "numx = 10\n",
    "edgesx = tf.linspace(startx, stopx, numx)\n",
    "xbins = tfp.stats.find_bins(c[:,0], edgesx)\n",
    "print(xbins)\n",
    "starty = -100.\n",
    "stopy = 100.\n",
    "numy = 10\n",
    "edgesy = tf.linspace(starty, stopy, numy)\n",
    "ybins = tfp.stats.find_bins(c[:,1], edgesy)\n",
    "print(ybins)\n",
    "\n",
    "min_num_pts = 1000\n",
    "\n",
    "count = 0\n",
    "E = []\n",
    "\n",
    "for x in range(numx):\n",
    "    for y in range(numy):\n",
    "        #only do calculations if there are a sufficicently high number of points in the bin\n",
    "        xin = tf.where(xbins == x)\n",
    "        if tf.shape(xin)[0] > min_num_pts:\n",
    "            if tf.shape(tf.where(tf.gather(ybins, xin) == y))[0] > min_num_pts: #repeat for y points at x coord\n",
    "#                 print(\"working\", x, y)\n",
    "                count += 1\n",
    "# print(xin)\n",
    "# print(ybins)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.linspace(1,5,5)\n",
    "print(test)\n",
    "ans = tf.where(test < 4)\n",
    "print(\"ans: \\n\",ans)\n",
    "print(\"\\n\", tf.gather(test, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inline volumetric rendering using ipyvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple demo\n",
    "import ipyvolume\n",
    "ds = ipyvolume.datasets.aquariusA2.fetch()\n",
    "short = ds.data[:,:,:]\n",
    "ipyvolume.quickvolshow(short, lighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.linspace(1,12,8)\n",
    "ans[2] = 0\n",
    "print(ans)\n",
    "\n",
    "test = ans[ans < 10]\n",
    "print(test)\n",
    "np.shape(test)[0]\n",
    "\n",
    "print(np.median(test[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = tf.random.normal([3,3])\n",
    "print(tes)\n",
    "print(tf.reverse(tes, axis = [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.reshape([10.,10.,2.], (3,1))\n",
    "# print(type(a))\n",
    "# t = tf.Tensor(a, dtype = \"float32\")\n",
    "\n",
    "a = tf.constant([2.1,2.,3.])\n",
    "b = tf.constant([1.,2.,3.])\n",
    "tf.tensordot(a,b, axes = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = tf.eye(3)\n",
    "# print(j)\n",
    "Jx = tf.constant([[1.], [2.], [3.]])\n",
    "J = tf.concat([eye, Jx], axis = 1)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.sin(1.))\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs  = np.array([1.,0.1,0.1])\n",
    "p_point = np.array([1.,2.,3.])\n",
    "for _ in range(numiter):\n",
    "    J = jacobian(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on CPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF is slower if we do them one by one BUT is waaay faster if we send them in all at once\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs = tf.random.normal((3,numiter))\n",
    "p_point = tf.random.normal((3,numiter))\n",
    "J = jacobian_tf(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on GPU\")\n",
    "print(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing subdividing cells without loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binned coordinate values: \n",
      " tf.Tensor(\n",
      "[[2. 0. 1.]\n",
      " [1. 1. 2.]\n",
      " [3. 0. 3.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]\n",
      " [2. 0. 1.]\n",
      " [3. 3. 3.]\n",
      " [1. 1. 2.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]], shape=(10, 3), dtype=float32)\n",
      "\n",
      " cells of interest: \n",
      " tf.Tensor(\n",
      "[[[1. 1. 2.]]\n",
      "\n",
      " [[0. 9. 9.]]\n",
      "\n",
      " [[2. 0. 1.]]\n",
      "\n",
      " [[7. 8. 9.]]], shape=(4, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[False False False]\n",
      "  [ True  True  True]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [ True  True  True]\n",
      "  [False False False]\n",
      "  [False False False]]\n",
      "\n",
      " [[False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [ True False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [ True False False]\n",
      "  [False False False]]\n",
      "\n",
      " [[ True  True  True]\n",
      "  [False False False]\n",
      "  [False  True False]\n",
      "  [False  True False]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False  True False]\n",
      "  [ True  True  True]]\n",
      "\n",
      " [[False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]]], shape=(4, 10, 3), dtype=bool)\n",
      "\n",
      " loc: \n",
      " tf.Tensor(\n",
      "[[0 1]\n",
      " [0 7]\n",
      " [2 0]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [2 9]], shape=(6, 2), dtype=int64)\n",
      "\n",
      " regular tensor: \n",
      " tf.Tensor(\n",
      "[[[ 1.0326307   1.0779016   2.1562457 ]\n",
      "  [ 0.96885943  0.97136784  1.9056185 ]\n",
      "  [ 0.          0.          0.        ]\n",
      "  [ 0.          0.          0.        ]]\n",
      "\n",
      " [[ 2.2705162  -0.11964648  1.069912  ]\n",
      "  [ 1.9428284  -0.08928128  0.9844919 ]\n",
      "  [ 1.9720027   0.03824694  1.0199641 ]\n",
      "  [ 2.0882204   0.02896799  0.8352577 ]]], shape=(2, 4, 3), dtype=float32)\n",
      "mu: \n",
      " tf.Tensor(\n",
      "[[ 0.5003725   0.51231736  1.0154661 ]\n",
      " [ 2.0683918  -0.03542821  0.9774064 ]], shape=(2, 3), dtype=float32)\n",
      "sigma: \n",
      " <tf.Variable 'Variable:0' shape=(3, 3, 2) dtype=float32, numpy=\n",
      "array([[[ 0.50176203,  0.03315222],\n",
      "        [ 0.25719878, -0.0040213 ],\n",
      "        [ 0.5101092 ,  0.00272181]],\n",
      "\n",
      "       [[ 0.25719878, -0.0040213 ],\n",
      "        [ 0.5277755 ,  0.00978388],\n",
      "        [ 0.5235784 , -0.00354766]],\n",
      "\n",
      "       [[ 0.5101092 ,  0.00272181],\n",
      "        [ 0.5235784 , -0.00354766],\n",
      "        [ 2.078046  ,  0.01531244]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#Goal: given input tensor \"cloud\" and \"bins\" which contains all og and binned coordinates\n",
    "#      subdivide and perform ops on \"cloud\" wihtout using any loops \n",
    "\n",
    "bins = tf.transpose(tf.constant([[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.],\n",
    "                                 [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                 [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]))\n",
    "cloud = bins + tf.random.normal(tf.shape(bins))*0.1\n",
    "print(\"binned coordinate values: \\n\", bins)\n",
    "# print(cloud)\n",
    "\n",
    "#1d case (easy)\n",
    "# q = tf.constant([1., 1., 2.]) \n",
    "# print(tf.squeeze(tf.gather(bins, ans))) #works for 1d, unsure of utility in 2d\n",
    "#2d case (hard)\n",
    "q = tf.constant([[[1., 1., 2.]],\n",
    "                 [[0., 9., 9.]],\n",
    "                 [[2., 0., 1.]],\n",
    "                 [[7., 8., 9.]]])\n",
    "print(\"\\n cells of interest: \\n\",q)\n",
    "\n",
    "idx = tf.equal(bins, q)\n",
    "print(idx)\n",
    "#ans outputs tensor of shape [N,2], where:\n",
    "#  [[voxel number, index of [x,y,z] in cloud that corresponds to bin #],\n",
    "#   [voxel number,index of [x,y,z] in cloud that corresponds to bin #]] ... \n",
    "loc = tf.where(tf.math.reduce_all(idx, axis = 2) == True)\n",
    "print(\"\\n loc: \\n\", loc)\n",
    "\n",
    "#Need to \"ungroup\" so that we can fit_gaussian_tf() to each individual voxel...\n",
    "s = tf.shape(loc)\n",
    "group_ids, group_idx = tf.unique(loc[:, 0], out_idx=s.dtype)\n",
    "num_groups = tf.reduce_max(group_idx) + 1\n",
    "# print(group_ids, group_idx, num_groups)\n",
    "sizes = tf.math.bincount(group_idx)\n",
    "# print(sizes)\n",
    "\n",
    "#replace <bins> here with <cloud> when done debugging\n",
    "rag = tf.RaggedTensor.from_row_lengths(tf.gather(cloud, loc[:,1]), sizes) \n",
    "# print(\"ragged: \\n\", rag)\n",
    "\n",
    "#Run on GPU as vectorized operation (WAAAAAY Faster) --\n",
    "reg = tf.RaggedTensor.to_tensor(rag)\n",
    "print(\"\\n regular tensor: \\n\", reg)\n",
    "mu, sigma = fit_gaussian_tf(reg)\n",
    "print(\"mu: \\n\", mu)\n",
    "print(\"sigma: \\n\", sigma)\n",
    "#------------------------------------------------------- \n",
    "\n",
    "# # works but uses loop (runs on CPU -> slow) -----------\n",
    "# A =  tf.data.Dataset.from_tensor_slices(rag)\n",
    "# mus = []\n",
    "# sigmas = []\n",
    "# for i in range(len(A)):\n",
    "#     mu, sigma = fit_gaussian_tf(rag[i])\n",
    "#     mus.append(mu)\n",
    "#     sigmas.append(sigma)\n",
    "# print(mus, sigmas)\n",
    "# #------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find \"loc\" more efficiently than using tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binned points: \n",
      " tf.Tensor(\n",
      "[[2. 0. 1.]\n",
      " [1. 1. 2.]\n",
      " [3. 0. 3.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]\n",
      " [2. 0. 1.]\n",
      " [3. 3. 3.]\n",
      " [1. 1. 2.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]], shape=(10, 3), dtype=float32)\n",
      "\n",
      "bins to place them: \n",
      " tf.Tensor(\n",
      "[[[1. 1. 2.]]\n",
      "\n",
      " [[0. 9. 9.]]\n",
      "\n",
      " [[2. 0. 1.]]\n",
      "\n",
      " [[7. 8. 9.]]], shape=(4, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3 0]\n",
      " [8 0]], shape=(2, 2), dtype=int64)\n",
      "\n",
      " goal is to get this: \n",
      " tf.Tensor(\n",
      "[[0 1]\n",
      " [0 7]\n",
      " [2 0]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [2 9]], shape=(6, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"binned points: \\n\", bins)\n",
    "print(\"\\nbins to place them: \\n\",q)\n",
    "\n",
    "# #SUPER inefficient \n",
    "# for i in range(tf.shape(bins)[0]):\n",
    "#     for j in range(tf.shape(q)[0]):\n",
    "#         if tf.reduce_all(bins[i] == q[j]):\n",
    "#             print(j,i)\n",
    "#             try:\n",
    "#                 loc2 = tf.concat((loc2, tf.constant([[j,i]])), axis = 0)\n",
    "#             except:\n",
    "#                 loc2 = tf.constant([[j,i]])\n",
    "# print(\"\\n loc \\n\",loc2)\n",
    "# loc2 = None\n",
    "\n",
    "testidx = tf.where(bins == q[1])\n",
    "print(testidx)\n",
    "    \n",
    "print(\"\\n goal is to get this: \\n\",loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove zero rows from 3d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[2. 2. 2.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[9. 1. 1.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 1. 1.]\n",
      "  [2. 2. 2.]]], shape=(2, 4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2. 0. 0. 1.]\n",
      " [9. 0. 1. 2.]\n",
      " [3. 0. 0. 3.]\n",
      " [0. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]\n",
      " [2. 0. 0. 1.]\n",
      " [3. 3. 3. 3.]\n",
      " [1. 1. 1. 2.]\n",
      " [0. 0. 0. 0.]\n",
      " [2. 0. 0. 1.]], shape=(10, 4), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:NotEqual]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-2eba47198321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#need to AVERAGE point locations PER AXIS, PER BIN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#   Ignore SPECIFIC POINTS where XYZ are ALL ZERO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mnot_equal\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mincompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m   \"\"\"\n\u001b[1;32m-> 1900\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mnot_equal\u001b[1;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[0;32m   6561\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6562\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6563\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6564\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6565\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:NotEqual]"
     ]
    }
   ],
   "source": [
    "bins2 = tf.transpose(tf.constant([[[2., 9., 3., 0., 2., 2., 3., 1., 0., 2.], #x\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]], \n",
    "                                  \n",
    "                                  [[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.], #y\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]],\n",
    "                                  \n",
    "                                  [[2., 1., 3., 1., 2., 2., 3., 1., 0., 2.], #z\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]]))\n",
    "\n",
    "print(bins2[:2])\n",
    "print(bins2[:,:,0])\n",
    "#need to AVERAGE point locations PER AXIS, PER BIN\n",
    "#   Ignore SPECIFIC POINTS where XYZ are ALL ZERO\n",
    "idx = tf.math.not_equal(bins2[:,:,0], tf.constant([0.,0.,0.]))\n",
    "print(idx[:2])\n",
    "mask = tf.where(tf.math.reduce_any(idx, axis = 2) == True)\n",
    "print(\"\\n mask: \\n\", mask[:6]) #correct(?)\n",
    "# print(tf.gather(bins,mask))\n",
    "\n",
    "nonzero = tf.gather(bins,[0,0,0])\n",
    "print(\"\\n nonzero elements: \\n\", nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2D tensor with all permutations (:n1, :n2, :n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [2. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [2. 1. 0.]\n",
      " [0. 2. 0.]\n",
      " [1. 2. 0.]\n",
      " [2. 2. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [2. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [2. 1. 1.]\n",
      " [0. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [2. 2. 1.]\n",
      " [0. 0. 2.]\n",
      " [1. 0. 2.]\n",
      " [2. 0. 2.]\n",
      " [0. 1. 2.]\n",
      " [1. 1. 2.]\n",
      " [2. 1. 2.]\n",
      " [0. 2. 2.]\n",
      " [1. 2. 2.]\n",
      " [2. 2. 2.]], shape=(27, 3), dtype=float64)\n",
      "\n",
      " pt: tf.Tensor(\n",
      "[[2. 0. 1.]\n",
      " [1. 1. 2.]\n",
      " [3. 0. 3.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]\n",
      " [2. 0. 1.]\n",
      " [3. 3. 3.]\n",
      " [1. 1. 2.]\n",
      " [0. 0. 0.]\n",
      " [2. 0. 1.]], shape=(10, 3), dtype=float32) \n",
      "\n",
      "\n",
      " tf.Tensor([11 22 30  0 11 11 39 22  0 11], shape=(10,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[11  0]\n",
      " [22  1]\n",
      " [30  2]\n",
      " [ 0  3]\n",
      " [11  4]\n",
      " [11  5]\n",
      " [39  6]\n",
      " [22  7]\n",
      " [ 0  8]\n",
      " [11 10]], shape=(10, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "fida = 3 \n",
    "fidb = 3\n",
    "fidc = 3\n",
    "\n",
    "a = tf.linspace(0,fida-1,fida)[:,None]\n",
    "b = tf.linspace(0,fidb-1,fidb)[:,None]\n",
    "c = tf.linspace(0,fidc-1,fidc)[:,None]\n",
    "\n",
    "ansa = tf.tile(a, [fidb*fidc, 1])\n",
    "ansb = tf.tile(tf.reshape(tf.tile(b, [1,fida]), [-1,1] ), [(fidc), 1])\n",
    "ansc = tf.reshape(tf.tile(c, [1,fida*fidb]), [-1,1] )\n",
    "\n",
    "q = tf.squeeze(tf.transpose(tf.Variable([ansa,ansb,ansc])))\n",
    "print(q)\n",
    "\n",
    "#GOAL- determine which voxel pt belongs in based on its coords\n",
    "# pt = tf.constant([2,1,0])\n",
    "pt = bins\n",
    "print(\"\\n pt:\", pt, \"\\n\")\n",
    "num = tf.cast( ( pt[:,0] + fida*pt[:,1] + (fida*fidb)*pt[:,2] ), tf.int32)\n",
    "print(\"\\n\", num, \"\\n\")\n",
    "# print(q[num])\n",
    "\n",
    "ans = tf.concat((num[:,None], tf.cast(tf.linspace(0, tf.shape(pt)[0], tf.shape(pt)[0]  )[:,None],\n",
    "                                      dtype = tf.int32) ), axis = 1 )\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate covariance of 3d tensors with multiple voxels. Ignore zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.8948956   2.2362711  -0.43921176]\n",
      " [-0.35083345 -3.1048205  -0.10731926]\n",
      " [-0.5755011  -2.7571492   0.9450426 ]\n",
      " [ 0.8119266  -3.7354808   1.0391369 ]\n",
      " [-0.46134612  4.5810437   0.01974574]\n",
      " [-1.6642511   0.83993524  0.26953086]\n",
      " [ 0.19249603  6.0262723   0.7527277 ]\n",
      " [-1.1216501  -1.4189025  -0.02843553]\n",
      " [-1.6132956   0.6021511  -1.7156568 ]\n",
      " [-0.24320705 -3.1648061  -0.13676174]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]], shape=(20, 3), dtype=float32)\n",
      "\n",
      " Sparse Identity: \n",
      " SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([10  3], shape=(2,), dtype=int64))\n",
      "\n",
      " covariance matrices: \n",
      " tf.Tensor(\n",
      "[[ 0.35506487 -0.16443588  0.17140147]\n",
      " [-0.16443588  5.3297634  -0.14231727]\n",
      " [ 0.17140147 -0.14231727  0.2881017 ]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor([2 4], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(10, 2, 1))\n",
    "b = tf.random.normal(shape=(10, 2, 1))*4\n",
    "c = tf.random.normal(shape=(10, 2, 1))\n",
    "\n",
    "d = tf.concat((a,b,c), axis = 2)\n",
    "d = tf.concat((d, tf.zeros((10,2,3))), axis = 0)\n",
    "print(d[:,1])\n",
    "\n",
    "I = tf.sparse.eye(10,3)\n",
    "print(\"\\n Sparse Identity: \\n\", I)\n",
    "\n",
    "cov = tfp.stats.covariance(d, sample_axis = 0, event_axis = 2)\n",
    "print(\"\\n covariance matrices: \\n\", cov[1])\n",
    "\n",
    "print(sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
