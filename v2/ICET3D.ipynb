{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from utils import *\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "# from numba import cuda #gpu library used to clear gpu memory after each trial\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICET3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([18130     3], shape=(2,), dtype=int32)\n",
      "took 0.0779886245727539 seconds with tensorflow\n",
      "\n",
      " shapes \n",
      " tf.Tensor([2215    3], shape=(2,), dtype=int32) tf.Tensor([2215    3    3], shape=(3,), dtype=int32) tf.Tensor([136], shape=(1,), dtype=int32)\n",
      "\n",
      " L \n",
      " tf.Tensor(\n",
      "[[[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(136, 3, 3), dtype=float32)\n",
      "0 -----------------\n",
      "took 0.06501460075378418 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor(\n",
      "[ 2.7552457e+00 -3.0925930e-03 -3.3517886e-06 -1.6743934e-02\n",
      "  1.1456142e-01 -2.7698968e-02], shape=(6,), dtype=float32)\n",
      "took 5.180672645568848 seconds total\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e174656c78764671ac3e58681c566bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ICET3D import ICET3D\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True)\n",
    "\n",
    "plt = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud1 = velo1[:,:3]\n",
    "cloud1_tensor = tf.convert_to_tensor(cloud1, np.float32)\n",
    "velo2 = dataset.get_velo(2) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud2 = velo2[:,:3]\n",
    "cloud2_tensor = tf.convert_to_tensor(cloud2, np.float32)\n",
    "\n",
    "f = tf.constant([10,10,1]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.]) #needs to encompass every point\n",
    "nc = 1\n",
    "mnp = 5\n",
    "npts = 100000\n",
    "D = True #draw sim\n",
    "DG = False #draw grid\n",
    "DE = True #draw ellipsoids\n",
    "DC = True #draw correspondences\n",
    "TD = True #use test dataset\n",
    "\n",
    "start = time.time()\n",
    "# #use whole point set\n",
    "# #---------------------------------------------------------------------------------\n",
    "# f = tf.constant([50,50,2]) #fidelity in x, y, z # < 5s\n",
    "# lim = tf.constant([-100.,100.,-100.,100.,-10.,10.]) #needs to encompass every point\n",
    "# Q, x_hist = ICET3D(cloud1_tensor[:npts], cloud2_tensor[:npts], plt, bounds = lim, \n",
    "#            fid = f, num_cycles = nc , min_num_pts = mnp, draw = D, draw_grid = DG, \n",
    "#            draw_ell = DE, draw_corr = DC)\n",
    "# #---------------------------------------------------------------------------------\n",
    "\n",
    "#just consider small section of image where there are easily identifiable features:\n",
    "#----------------------------------------------------------------------------------\n",
    "limtest = tf.constant([-20.,0.,-20.,0.,-1.5,1.5])\n",
    "f = tf.constant([15,15,15])\n",
    "# cloud1_tensor = tf.squeeze(tf.gather(cloud1_tensor, tf.where( (cloud1_tensor[:,0] > limtest[0]))))\t#only works one cond at a time\n",
    "cloud1_tensor = tf.squeeze(tf.gather(cloud1_tensor, tf.where( tf.math.reduce_all(tf.concat( (\n",
    "\t(cloud1_tensor[:,0] > limtest[0])[:,None], \n",
    "\t(cloud1_tensor[:,0] < limtest[1])[:,None], \n",
    "\t(cloud1_tensor[:,1] > limtest[2])[:,None], \n",
    "\t(cloud1_tensor[:,1] < limtest[3])[:,None],\n",
    "\t(cloud1_tensor[:,2] > limtest[4])[:,None], \n",
    "\t(cloud1_tensor[:,2] < limtest[5])[:,None],\n",
    "\t), axis = 1 ), axis = 1))))\n",
    "cloud2_tensor = tf.squeeze(tf.gather(cloud2_tensor, tf.where( tf.math.reduce_all(tf.concat( (\n",
    "\t(cloud2_tensor[:,0] > limtest[0])[:,None], \n",
    "\t(cloud2_tensor[:,0] < limtest[1])[:,None], \n",
    "\t(cloud2_tensor[:,1] > limtest[2])[:,None], \n",
    "\t(cloud2_tensor[:,1] < limtest[3])[:,None],\n",
    "\t(cloud2_tensor[:,2] > limtest[4])[:,None], \n",
    "\t(cloud2_tensor[:,2] < limtest[5])[:,None],), axis = 1 ), axis = 1))))\n",
    "Q, x_hist = ICET3D(cloud1_tensor, cloud2_tensor, plt, bounds = limtest, \n",
    "           fid = f, num_cycles = nc , min_num_pts = mnp, draw = D, draw_grid = DG,\n",
    "           draw_ell = DE, draw_corr = DC, test_dataset = TD)\n",
    "#----------------------------------------------------------------------------------\n",
    "#NOTE: Out of Memory Error comes from too high fidelity/ pts in cloud tensor --> 100x100x2x120,000 > 2gb\n",
    "\n",
    "print(\"took\", time.time() - start, \"seconds total\")\n",
    "\n",
    "# print(tf.sqrt(tf.math.abs(Q)))\n",
    "# ans = np.sqrt(Q.numpy())\n",
    "# print(ans[0,0], ans[1,1], ans[2,2])\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display progression of solution values\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot()\n",
    "ax1.set_xlabel(\"iteration\")\n",
    "ax1.set_ylabel(\"value\")\n",
    "ax1.plot(x_hist.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test - multiply a [6,6] tensor with a [N, 6, 3] tensor\n",
    "# A = tf.eye(6)        #[6, 6]\n",
    "# B = tf.ones([2,6,3]) #[2, 6, 3]\n",
    "# print(tf.shape(tf.matmul(A,B))) #[2, 6, 3]\n",
    "\n",
    "C = tf.ones([164, 6,3])\n",
    "D = tf.ones([164,3])[:,:,None]\n",
    "print(tf.shape(tf.matmul(C,D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.greater(tf.ones(3), tf.constant([-1.,2.,3.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivide scan using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "try:\n",
    "    plt1.closeWindow()\n",
    "    print(\"closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt1 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "# settings.useParallelProjection = True #makes view orthographic\n",
    "\n",
    "## uncomment to use VOLPE dataset -----------------------------------------------------\n",
    "# location = 'C:/Users/Derm/2021-03-10-16-43-50_Velodyne-VLP-16-Data_garminSignage.txt'\n",
    "# cloud = np.loadtxt(open(location, \"rb\"), delimiter=\",\")\n",
    "# cloud = cloud[~np.isnan(cloud).any(axis=1)] #remove all rows with NaN elements\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# make 2D sinusioal pattern (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "##-------------------------------------------------------------------------------------\n",
    "\n",
    "# f =np.array([200,200,40]) #fidelity in x, y, z #takes ~30s on my dsektop\n",
    "# lim = np.array([-50,50,-50,50,-10,10])\n",
    "\n",
    "f =np.array([100,100,2]) #fidelity in x, y, z # < 5s\n",
    "lim = np.array([-100,100,-100,100,-10,10])\n",
    "\n",
    "for _ in range(1):\n",
    "#     cloud_partial = tf.gather(cloud,tf.cast((tf.linspace(1,100000,100)), tf.int32))\n",
    "    cloud_partial = cloud\n",
    "    mus, sigmas, sizes = subdivide_scan(cloud_partial,plt1, bounds = lim, fid = f, draw_grid = False, show_pc = True) \n",
    "\n",
    "# print(\"\\n mus: \\n\", mus)\n",
    "# print(\"\\n sigmas: \\n\", sigmas, np.shape(sigmas))\n",
    "    \n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivide scan using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "plt2 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "cloud_tensor = tf.convert_to_tensor(cloud, np.float32)\n",
    "# print(tf.shape(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# # make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "# #-------------------------------------------------------------------------------------\n",
    "\n",
    "f = tf.constant([100,100,2]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.])\n",
    "DRAW = True\n",
    "\n",
    "for _ in range(1):\n",
    "#     cloud_partial = tf.gather(cloud,tf.cast((tf.linspace(1,100000,30)), tf.int32))\n",
    "    cloud_partial = cloud\n",
    "    E = subdivide_scan_tf(cloud_partial, plt2, bounds = lim, fid = f, draw=DRAW, draw_grid = False, show_pc = 1) \n",
    "# print(\"\\n points: \\n\", cloud_partial)\n",
    "\n",
    "# mu = E[0]\n",
    "# print(\"\\n mu: \\n\",mu)\n",
    "\n",
    "# sigma = E[1]\n",
    "# print(\"\\n sigma: \\n\", sigma)\n",
    "\n",
    "# print(tf.transpose(sigma))\n",
    "# print(\"\\n sigma[:,:,1] \\n\", sigma[:,:,0])\n",
    "\n",
    "# sig2 = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "# print(\"reshaped sigma \\n\", sig2)\n",
    "\n",
    "# shapes = E[2]\n",
    "# print(\"\\n shapes: \\n\", shapes)\n",
    "\n",
    "# sigma = E[1]\n",
    "# print(tf.shape(sigma),sigma[:,:,1])\n",
    "\n",
    "# if DRAW:\n",
    "ViewInteractiveWidget(plt2.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.constant([1.,1.,1.]) #works ------------------------------\n",
    "# print(\"\\n a \\n\", a)\n",
    "\n",
    "# b = tf.random.normal([10,3])\n",
    "# print(\"\\n b \\n\", b)\n",
    "\n",
    "# dist = tf.reduce_sum(tf.math.squared_difference(a,b), axis = 1)\n",
    "# ans = tf.where(dist == tf.math.reduce_min(dist))[0,0]\n",
    "# print(\"\\n ans \\n\", b[ans])\n",
    "## -----------------------------------------------------------------\n",
    "\n",
    "# batch input - not working yet ------------------------------------\n",
    "a = tf.constant([[[1., 1., 1.]],\n",
    "                 [[0., 0., 0.]],\n",
    "                 [[0., 0., 0.]]])  \n",
    "print(\"\\n a \\n\", a)\n",
    "\n",
    "b = tf.random.normal([10,3])\n",
    "print(\"\\n b \\n\", b)\n",
    "\n",
    "# print(tf.gather(a,(0,1)))\n",
    "# print(tf.math.subtract(a, b))\n",
    "# print(tf.square(a-b))\n",
    "dist = tf.math.reduce_sum( (tf.square( tf.math.subtract(a, b) ))  , axis = 2)\n",
    "print(\"\\n dist \\n\", dist)\n",
    "\n",
    "ans = tf.where( tf.transpose(dist) ==tf.math.reduce_min(dist, axis = 1))\n",
    "print(\"\\n shortest dist \\n\", ans)\n",
    "\n",
    "reordered = tf.argsort(ans[:,1], axis = 0)\n",
    "print(\"\\n reordered \\n\", tf.gather(ans,reordered))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ragged tensor given row sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = tf.constant([1,2,8,4,5])\n",
    "\n",
    "# dummy_vals would be (points_x - mu_x)\n",
    "v = tf.random.uniform([tf.math.reduce_sum(sizes)])\n",
    "dummy_vals = tf.RaggedTensor.from_row_lengths(v ,sizes) \n",
    "print(dummy_vals.to_tensor() - 1)\n",
    "mask_test = tf.RaggedTensor.from_row_lengths(tf.ones(tf.math.reduce_sum(sizes)) ,sizes)\n",
    "print(tf.transpose(mask_test.to_tensor()))\n",
    "print((dummy_vals.to_tensor() -1) * mask_test.to_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test R() and Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hat = np.array([1,0,0])\n",
    "theta =  0.1 #np.pi/6 #rad\n",
    "\n",
    "rot_mat_simp = R_simp(n_hat, theta)\n",
    "print(rot_mat_simp)\n",
    "angs = np.array([theta,0 ,0])\n",
    "rot_mat = R(angs)\n",
    "print(rot_mat)\n",
    "\n",
    "print(R2Euler(rot_mat))\n",
    "\n",
    "p_point = np.array([1,1,1]).T\n",
    "\n",
    "J = jacobian(angs, p_point)\n",
    "\n",
    "d_rot_mat_simp = dR_simp(n_hat,theta)\n",
    "# print(d_rot_mat_simp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test R2Euler_tf and R_tf\n",
    "#### Works with single axis roation\n",
    "#### Works with vectoried input\n",
    "#### Solution becomes ambiguious with mutliple axis inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = tf.random.normal((3,1)) * tf.constant([[0.], [0.], [1.] ]) #single axis angle input\n",
    "# angs = tf.Variable([[0.],[ np.pi/2],[ 0.]]) #vector input, multiple axis rotation\n",
    "print(\"Input angs: \\n\", angs.numpy())\n",
    "# print(\"R(angs): \\n\", R_tf(angs).numpy())\n",
    "test1 = R2Euler_tf(R_tf(angs))\n",
    "print(\"R2Euler_tf(R(angs)): \\n\", test1.numpy())\n",
    "# test2 = R2Euler(R(angs[:,:2]))\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test tfp find bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.convert_to_tensor(cloud, np.float32)#[:100]\n",
    "# print(\"c: \\n\", c.numpy())\n",
    "startx = -100.\n",
    "stopx = 100.\n",
    "numx = 10\n",
    "edgesx = tf.linspace(startx, stopx, numx)\n",
    "xbins = tfp.stats.find_bins(c[:,0], edgesx)\n",
    "print(xbins)\n",
    "starty = -100.\n",
    "stopy = 100.\n",
    "numy = 10\n",
    "edgesy = tf.linspace(starty, stopy, numy)\n",
    "ybins = tfp.stats.find_bins(c[:,1], edgesy)\n",
    "print(ybins)\n",
    "\n",
    "min_num_pts = 1000\n",
    "\n",
    "count = 0\n",
    "E = []\n",
    "\n",
    "for x in range(numx):\n",
    "    for y in range(numy):\n",
    "        #only do calculations if there are a sufficicently high number of points in the bin\n",
    "        xin = tf.where(xbins == x)\n",
    "        if tf.shape(xin)[0] > min_num_pts:\n",
    "            if tf.shape(tf.where(tf.gather(ybins, xin) == y))[0] > min_num_pts: #repeat for y points at x coord\n",
    "#                 print(\"working\", x, y)\n",
    "                count += 1\n",
    "# print(xin)\n",
    "# print(ybins)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.linspace(1,5,5)\n",
    "print(test)\n",
    "ans = tf.where(test < 4)\n",
    "print(\"ans: \\n\",ans)\n",
    "print(\"\\n\", tf.gather(test, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inline volumetric rendering using ipyvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple demo\n",
    "import ipyvolume\n",
    "ds = ipyvolume.datasets.aquariusA2.fetch()\n",
    "short = ds.data[:,:,:]\n",
    "ipyvolume.quickvolshow(short, lighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.linspace(1,12,8)\n",
    "ans[2] = 0\n",
    "print(ans)\n",
    "\n",
    "test = ans[ans < 10]\n",
    "print(test)\n",
    "np.shape(test)[0]\n",
    "\n",
    "print(np.median(test[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = tf.random.normal([3,3])\n",
    "print(tes)\n",
    "print(tf.reverse(tes, axis = [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.reshape([10.,10.,2.], (3,1))\n",
    "# print(type(a))\n",
    "# t = tf.Tensor(a, dtype = \"float32\")\n",
    "\n",
    "a = tf.constant([2.1,2.,3.])\n",
    "b = tf.constant([1.,2.,3.])\n",
    "tf.tensordot(a,b, axes = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = tf.eye(3)\n",
    "# print(j)\n",
    "Jx = tf.constant([[1.], [2.], [3.]])\n",
    "J = tf.concat([eye, Jx], axis = 1)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare jacobian() and jacobian_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.sin(1.))\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs  = np.array([1.,0.1,0.1])\n",
    "p_point = np.array([1.,2.,3.])\n",
    "for _ in range(numiter):\n",
    "    J = jacobian(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on CPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF is slower if we do them one by one BUT is waaay faster if we send them in all at once\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "# angs = tf.random.normal((3,numiter))\n",
    "angs = tf.constant([1.,2.,3.])\n",
    "p_point = tf.random.normal((3,numiter))\n",
    "J = jacobian_tf(p_point, angs);\n",
    "print(\"took\", time.time()-start, \"seconds on GPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing subdividing cells without loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: given input tensor \"cloud\" and \"bins\" which contains all og and binned coordinates\n",
    "#      subdivide and perform ops on \"cloud\" wihtout using any loops \n",
    "\n",
    "bins = tf.transpose(tf.constant([[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.],\n",
    "                                 [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                 [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]))\n",
    "cloud = bins + tf.random.normal(tf.shape(bins))*0.1\n",
    "print(\"binned coordinate values: \\n\", bins)\n",
    "# print(cloud)\n",
    "\n",
    "#1d case (easy)\n",
    "# q = tf.constant([1., 1., 2.]) \n",
    "# print(tf.squeeze(tf.gather(bins, ans))) #works for 1d, unsure of utility in 2d\n",
    "#2d case (hard)\n",
    "q = tf.constant([[[1., 1., 2.]],\n",
    "                 [[0., 9., 9.]],\n",
    "                 [[2., 0., 1.]],\n",
    "                 [[7., 8., 9.]]])\n",
    "print(\"\\n cells of interest: \\n\",q)\n",
    "\n",
    "idx = tf.equal(bins, q)\n",
    "print(idx)\n",
    "#ans outputs tensor of shape [N,2], where:\n",
    "#  [[voxel number, index of [x,y,z] in cloud that corresponds to bin #],\n",
    "#   [voxel number,index of [x,y,z] in cloud that corresponds to bin #]] ... \n",
    "loc = tf.where(tf.math.reduce_all(idx, axis = 2) == True)\n",
    "print(\"\\n loc: \\n\", loc)\n",
    "\n",
    "#Need to \"ungroup\" so that we can fit_gaussian_tf() to each individual voxel...\n",
    "s = tf.shape(loc)\n",
    "group_ids, group_idx = tf.unique(loc[:, 0], out_idx=s.dtype)\n",
    "num_groups = tf.reduce_max(group_idx) + 1\n",
    "# print(group_ids, group_idx, num_groups)\n",
    "sizes = tf.math.bincount(group_idx)\n",
    "# print(sizes)\n",
    "\n",
    "#replace <bins> here with <cloud> when done debugging\n",
    "rag = tf.RaggedTensor.from_row_lengths(tf.gather(cloud, loc[:,1]), sizes) \n",
    "# print(\"ragged: \\n\", rag)\n",
    "\n",
    "#Run on GPU as vectorized operation (WAAAAAY Faster) --\n",
    "reg = tf.RaggedTensor.to_tensor(rag)\n",
    "print(\"\\n regular tensor: \\n\", reg)\n",
    "mu, sigma = fit_gaussian_tf(reg)\n",
    "print(\"mu: \\n\", mu)\n",
    "print(\"sigma: \\n\", sigma)\n",
    "#------------------------------------------------------- \n",
    "\n",
    "# # works but uses loop (runs on CPU -> slow) -----------\n",
    "# A =  tf.data.Dataset.from_tensor_slices(rag)\n",
    "# mus = []\n",
    "# sigmas = []\n",
    "# for i in range(len(A)):\n",
    "#     mu, sigma = fit_gaussian_tf(rag[i])\n",
    "#     mus.append(mu)\n",
    "#     sigmas.append(sigma)\n",
    "# print(mus, sigmas)\n",
    "# #------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find \"loc\" more efficiently than using tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"binned points: \\n\", bins)\n",
    "print(\"\\nbins to place them: \\n\",q)\n",
    "\n",
    "# #SUPER inefficient \n",
    "# for i in range(tf.shape(bins)[0]):\n",
    "#     for j in range(tf.shape(q)[0]):\n",
    "#         if tf.reduce_all(bins[i] == q[j]):\n",
    "#             print(j,i)\n",
    "#             try:\n",
    "#                 loc2 = tf.concat((loc2, tf.constant([[j,i]])), axis = 0)\n",
    "#             except:\n",
    "#                 loc2 = tf.constant([[j,i]])\n",
    "# print(\"\\n loc \\n\",loc2)\n",
    "# loc2 = None\n",
    "\n",
    "testidx = tf.where(bins == q[1])\n",
    "print(testidx)\n",
    "    \n",
    "print(\"\\n goal is to get this: \\n\",loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove zero rows from 3d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins2 = tf.transpose(tf.constant([[[2., 9., 3., 0., 2., 2., 3., 1., 0., 2.], #x\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]], \n",
    "                                  \n",
    "                                  [[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.], #y\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]],\n",
    "                                  \n",
    "                                  [[2., 1., 3., 1., 2., 2., 3., 1., 0., 2.], #z\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]]))\n",
    "\n",
    "print(bins2[:2])\n",
    "print(bins2[:,:,0])\n",
    "#need to AVERAGE point locations PER AXIS, PER BIN\n",
    "#   Ignore SPECIFIC POINTS where XYZ are ALL ZERO\n",
    "idx = tf.math.not_equal(bins2[:,:,0], tf.constant([0.,0.,0.]))\n",
    "print(idx[:2])\n",
    "mask = tf.where(tf.math.reduce_any(idx, axis = 2) == True)\n",
    "print(\"\\n mask: \\n\", mask[:6]) #correct(?)\n",
    "# print(tf.gather(bins,mask))\n",
    "\n",
    "nonzero = tf.gather(bins,[0,0,0])\n",
    "print(\"\\n nonzero elements: \\n\", nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2D tensor with all permutations (:n1, :n2, :n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fida = 2 \n",
    "fidb = 4\n",
    "fidc = 1\n",
    "\n",
    "a = tf.linspace(0,fida-1,fida)[:,None]\n",
    "b = tf.linspace(0,fidb-1,fidb)[:,None]\n",
    "c = tf.linspace(0,fidc-1,fidc)[:,None]\n",
    "\n",
    "ansa = tf.tile(a, [fidb*fidc, 1])\n",
    "ansb = tf.tile(tf.reshape(tf.tile(b, [1,fida]), [-1,1] ), [(fidc), 1])\n",
    "ansc = tf.reshape(tf.tile(c, [1,fida*fidb]), [-1,1] )\n",
    "\n",
    "q = tf.squeeze(tf.transpose(tf.Variable([ansa,ansb,ansc])))\n",
    "print(q)\n",
    "\n",
    "#GOAL- determine which voxel pt belongs in based on its coords\n",
    "# pt = tf.constant([2,1,0])\n",
    "pt = bins\n",
    "print(\"\\n pt:\", pt, \"\\n\")\n",
    "num = tf.cast( ( pt[:,0] + fida*pt[:,1] + (fida*fidb)*pt[:,2] ), tf.int32)\n",
    "print(\"\\n\", num, \"\\n\")\n",
    "# print(q[num])\n",
    "\n",
    "ans = tf.concat((num[:,None], tf.cast(tf.linspace(0, tf.shape(pt)[0], tf.shape(pt)[0]  )[:,None],\n",
    "                                      dtype = tf.int32) ), axis = 1 )\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate covariance of 3d tensors with multiple voxels. Ignore zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal(shape=(10, 2, 1))\n",
    "b = tf.random.normal(shape=(10, 2, 1))*4\n",
    "c = tf.random.normal(shape=(10, 2, 1))\n",
    "\n",
    "d = tf.concat((a,b,c), axis = 2)\n",
    "d = tf.concat((d, tf.zeros((10,2,3))), axis = 0)\n",
    "print(d[:,1])\n",
    "\n",
    "I = tf.sparse.eye(10,3)\n",
    "print(\"\\n Sparse Identity: \\n\", I)\n",
    "\n",
    "cov = tfp.stats.covariance(d, sample_axis = 0, event_axis = 2)\n",
    "print(\"\\n covariance matrices: \\n\", cov[1])\n",
    "\n",
    "print(sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.cast((tf.linspace(1,1000,100)), tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
