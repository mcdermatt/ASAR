{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from utils import *\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "# from numba import cuda #gpu library used to clear gpu memory after each trial\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICET3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([44130     3], shape=(2,), dtype=int32)\n",
      "took 0.14391541481018066 seconds with tensorflow\n",
      "\n",
      " shapes \n",
      " tf.Tensor([29212     3], shape=(2,), dtype=int32) tf.Tensor([29212     3     3], shape=(3,), dtype=int32) tf.Tensor([882], shape=(1,), dtype=int32)\n",
      "y0 tf.Tensor([116   3], shape=(2,), dtype=int32)\n",
      "\n",
      " U \n",
      " tf.Tensor([116   3   3], shape=(3,), dtype=int32)\n",
      "\n",
      " ext_idx \n",
      " tf.Tensor(\n",
      "[  0   3   6   9  12  15  18  21  24  27  30  33  36  39  42  45  48  51\n",
      "  54  57  60  63  66  69  72  75  81  84  90  93  96  99 102 105 108 111\n",
      " 112 114 117 120 123 126 129 132 135 138 141 144 147 150 153 156 159 162\n",
      " 165 168 171 174 177 180 183 186 189 192 195 198 201 204 207 210 213 216\n",
      " 219 222 225 228 231 234 237 240 243 246 249 252 255 256 258 259 261 262\n",
      " 264 265 267 268 269 270 271 273 274 276 277 279 280 282 283 285 286 288\n",
      " 289 291 292 294 295 297 298 300 301 303 304 306 307 309 310 312 313 315\n",
      " 316 318 319 321 322 324 325 327 328 330 331 333 334 336 337 339 340 341\n",
      " 342 343 344 345 346], shape=(149,), dtype=int64)\n",
      "\n",
      " L before \n",
      " tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]], shape=(149, 3), dtype=float32)\n",
      "L row lengths \n",
      " tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 3 3 2], shape=(114,), dtype=int32)\n",
      "\n",
      " L \n",
      " tf.Tensor(\n",
      "[[[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(116, 3, 3), dtype=float32)\n",
      "0 -----------------\n",
      "took 0.16203713417053223 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.2410264  -0.7989223   0.4161103  -0.01537346  0.04785228  0.11975083], shape=(6,), dtype=float32)\n",
      "1 -----------------\n",
      "took 0.14353466033935547 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24102496 -0.79915684  0.4160876  -0.00333835  0.04877403  0.11868697], shape=(6,), dtype=float32)\n",
      "2 -----------------\n",
      "took 0.14303326606750488 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24103726 -0.7991251   0.41608936 -0.00491619  0.04914884  0.1188783 ], shape=(6,), dtype=float32)\n",
      "3 -----------------\n",
      "took 0.14253902435302734 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24104042 -0.79916734  0.41608712 -0.00284007  0.04949729  0.11934835], shape=(6,), dtype=float32)\n",
      "4 -----------------\n",
      "took 0.14403343200683594 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24105416 -0.79912806  0.41608918 -0.00481468  0.04988564  0.1192831 ], shape=(6,), dtype=float32)\n",
      "5 -----------------\n",
      "took 0.14303302764892578 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24104825 -0.7991682   0.41608706 -0.00279922  0.04982826  0.11951132], shape=(6,), dtype=float32)\n",
      "6 -----------------\n",
      "took 0.14453887939453125 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24106161 -0.7991301   0.4160891  -0.00472364  0.05020256  0.11938988], shape=(6,), dtype=float32)\n",
      "7 -----------------\n",
      "took 0.14103388786315918 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24105592 -0.7991678   0.41608712 -0.00282691  0.05014263  0.11964167], shape=(6,), dtype=float32)\n",
      "8 -----------------\n",
      "took 0.14403367042541504 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.2410617  -0.79913086  0.41608912 -0.00465697  0.05019136  0.11940424], shape=(6,), dtype=float32)\n",
      "9 -----------------\n",
      "took 0.14403367042541504 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24105777 -0.7991665   0.41608724 -0.00287274  0.05019776  0.1196705 ], shape=(6,), dtype=float32)\n",
      "10 -----------------\n",
      "took 0.14103269577026367 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.2410659  -0.79913074  0.41608918 -0.00465924  0.050356    0.11946989], shape=(6,), dtype=float32)\n",
      "11 -----------------\n",
      "took 0.14603400230407715 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24105716 -0.79916674  0.4160873  -0.00283247  0.05015442  0.11965071], shape=(6,), dtype=float32)\n",
      "12 -----------------\n",
      "took 0.1450338363647461 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24106276 -0.79912996  0.4160893  -0.0046542   0.05019663  0.11940517], shape=(6,), dtype=float32)\n",
      "13 -----------------\n",
      "took 0.1440417766571045 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.2410587  -0.79916555  0.41608742 -0.00287225  0.05019745  0.1196705 ], shape=(6,), dtype=float32)\n",
      "14 -----------------\n",
      "took 0.1455378532409668 seconds with tensorflow\n",
      "\n",
      " x \n",
      " tf.Tensor([ 0.24106686 -0.7991297   0.41608936 -0.00465931  0.05035599  0.1194699 ], shape=(6,), dtype=float32)\n",
      "took 7.856208801269531 seconds total\n",
      "9.3358807e-07 1.0103279e-06 5.7446936e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0b57f5e0494ccf9d6d1e66e3a07022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ICET3D import ICET3D\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True)\n",
    "\n",
    "plt = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud1 = velo1[:,:3]\n",
    "cloud1_tensor = tf.convert_to_tensor(cloud1, np.float32)\n",
    "velo2 = dataset.get_velo(2) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud2 = velo2[:,:3]\n",
    "cloud2_tensor = tf.convert_to_tensor(cloud2, np.float32)\n",
    "\n",
    "f = tf.constant([10,10,1]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.]) #needs to encompass every point\n",
    "nc = 15\n",
    "mnp = 100\n",
    "npts = 100000\n",
    "D = False #draw sim\n",
    "DG = False #draw grid\n",
    "DE = True #draw ellipsoids\n",
    "DC = True #draw correspondences\n",
    "TD = True #use test dataset\n",
    "CM = \"NN\" #correspondence method, \"voxel\" or \"NN\"\n",
    "\n",
    "start = time.time()\n",
    "# #use whole point set\n",
    "# #---------------------------------------------------------------------------------\n",
    "# f = tf.constant([50,50,2]) #fidelity in x, y, z # < 5s\n",
    "# lim = tf.constant([-100.,100.,-100.,100.,-10.,10.]) #needs to encompass every point\n",
    "# Q, x_hist = ICET3D(cloud1_tensor[:npts], cloud2_tensor[:npts], plt, bounds = lim, \n",
    "#            fid = f, num_cycles = nc , min_num_pts = mnp, draw = D, draw_grid = DG, \n",
    "#            draw_ell = DE, draw_corr = DC)\n",
    "# #---------------------------------------------------------------------------------\n",
    "\n",
    "#just consider small section of image where there are easily identifiable features:\n",
    "#----------------------------------------------------------------------------------\n",
    "limtest = tf.constant([-20.,0.,-20.,0.,-1.5,1.5])\n",
    "f = tf.constant([35,35,35])\n",
    "# cloud1_tensor = tf.squeeze(tf.gather(cloud1_tensor, tf.where( (cloud1_tensor[:,0] > limtest[0]))))\t#only works one cond at a time\n",
    "cloud1_tensor = tf.squeeze(tf.gather(cloud1_tensor, tf.where( tf.math.reduce_all(tf.concat( (\n",
    "\t(cloud1_tensor[:,0] > limtest[0])[:,None], \n",
    "\t(cloud1_tensor[:,0] < limtest[1])[:,None], \n",
    "\t(cloud1_tensor[:,1] > limtest[2])[:,None], \n",
    "\t(cloud1_tensor[:,1] < limtest[3])[:,None],\n",
    "\t(cloud1_tensor[:,2] > limtest[4])[:,None], \n",
    "\t(cloud1_tensor[:,2] < limtest[5])[:,None],\n",
    "\t), axis = 1 ), axis = 1))))\n",
    "cloud2_tensor = tf.squeeze(tf.gather(cloud2_tensor, tf.where( tf.math.reduce_all(tf.concat( (\n",
    "\t(cloud2_tensor[:,0] > limtest[0])[:,None], \n",
    "\t(cloud2_tensor[:,0] < limtest[1])[:,None], \n",
    "\t(cloud2_tensor[:,1] > limtest[2])[:,None], \n",
    "\t(cloud2_tensor[:,1] < limtest[3])[:,None],\n",
    "\t(cloud2_tensor[:,2] > limtest[4])[:,None], \n",
    "\t(cloud2_tensor[:,2] < limtest[5])[:,None],), axis = 1 ), axis = 1))))\n",
    "Q, x_hist = ICET3D(cloud1_tensor, cloud2_tensor, plt, bounds = limtest, \n",
    "           fid = f, num_cycles = nc , min_num_pts = mnp, draw = D, draw_grid = DG,\n",
    "           draw_ell = DE, draw_corr = DC, test_dataset = TD, CM = CM)\n",
    "#----------------------------------------------------------------------------------\n",
    "#NOTE: Out of Memory Error comes from too high fidelity/ pts in cloud tensor --> 100x100x2x120,000 > 2gb\n",
    "\n",
    "print(\"took\", time.time() - start, \"seconds total\")\n",
    "\n",
    "# print(tf.sqrt(tf.math.abs(Q)))\n",
    "ans = np.sqrt(abs(Q.numpy()))\n",
    "print(ans[0,0], ans[1,1], ans[2,2])\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x155342f7508>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display progression of solution values\n",
    "from matplotlib import pyplot as plt\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot()\n",
    "ax1.set_xlabel(\"iteration\")\n",
    "ax1.set_ylabel(\"estimated rotation (rad)\")\n",
    "\n",
    "# ax1.plot(x_hist.numpy())\n",
    "# ax1.legend(['x','y','z','phi','theta','psi'])\n",
    "ax1.plot(x_hist[:,3:].numpy())\n",
    "ax1.legend(['phi','theta','psi'])\n",
    "\n",
    "ax1.plot(np.linspace(1,50,15), 0.12*np.ones(15), 'g--')\n",
    "ax1.plot(np.linspace(1,50,15), 0.05*np.ones(15), 'r--')\n",
    "ax1.plot(np.linspace(1,50,15), 0.02*np.ones(15), 'b--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15534254f48>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot()\n",
    "ax2.set_xlabel(\"iteration\")\n",
    "ax2.set_ylabel(\"estimated translation (cm)\")\n",
    "\n",
    "# ax1.plot(x_hist.numpy())\n",
    "# ax1.legend(['x','y','z','phi','theta','psi'])\n",
    "ax2.plot(x_hist[:,:3].numpy())\n",
    "ax2.legend(['x','y','z'])\n",
    "\n",
    "ax2.plot(np.linspace(1,15,15), .3*np.ones(15), 'g--')\n",
    "ax2.plot(np.linspace(1,15,15), .2*np.ones(15), 'r--')\n",
    "ax2.plot(np.linspace(1,15,15), .1*np.ones(15), 'b--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.linspace(1.,10.,10)\n",
    "print(a)\n",
    "mask = tf.cast(tf.math.less(a, 4), tf.float32)\n",
    "print(mask)\n",
    "a = a*mask\n",
    "print(a)\n",
    "print(tf.math.reduce_max(tf.constant([1.,2.,9.])))\n",
    "print(tf.math.abs([-1.,2.,3.,-0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOAL: Keep distribution axis for neighboring ellipses on the same surface pointing in the same direction\n",
    "#      if I don't do this, it will mess up my z-error??\n",
    "\n",
    "# if largest absolute value element in 3rd column of U[i] is less than 0, multiply U[i] by -1\n",
    "U = tf.constant([[[1., 2.,  4.],\n",
    "                  [0., 3., -1.],\n",
    "                  [1., 3., -6.]],\n",
    "                  \n",
    "                 [[3., 2.,  1.],\n",
    "                  [0., 2.,  -9.],\n",
    "                  [9., 1.,  6.]],\n",
    "                \n",
    "                 [[1., 1.,  -1.],\n",
    "                  [1., 1.,  3.],\n",
    "                  [1., 1.,  5.]]])\n",
    "\n",
    "print(U, \"\\n\")\n",
    "# #slow loopy way\n",
    "# print(\"slower way ----------------------------\")\n",
    "# for i in range(tf.shape(U)[0]):\n",
    "#     a = tf.math.reduce_max(tf.abs(U[i,:,2]))\n",
    "#     print(a)\n",
    "#     b = tf.where(tf.equal(tf.abs(U[i,:,2] ), a ))[0,0]\n",
    "#     print(b) \n",
    "#     print(U[i,b,2])\n",
    "#     if U[i,b,2] < 0:\n",
    "#         print(\"gotta reverse U \\n\")\n",
    "\n",
    "#faster vectorized way\n",
    "print(\"\\n faster way ---------------------\")\n",
    "a = tf.math.reduce_max(tf.abs(U[:,:,2]), axis = 1)[:,None]\n",
    "# print(a)\n",
    "b = tf.where( tf.math.equal(tf.abs(U[:,:,2]), a) )\n",
    "# print(b)\n",
    "# print(\"U[:,:,2] \\n\", U[:,:,2])\n",
    "absmax = tf.gather_nd(U[:,:,2], b)\n",
    "print(\"absmax: \\n\", absmax)\n",
    "\n",
    "#test: only look at one comonent of direction of largest ditribution axis\n",
    "# absmax = U[:,0,2]\n",
    "# print(absmax)\n",
    "\n",
    "mask = (-2.*tf.cast(tf.math.less(absmax, 0), tf.float32) + tf.ones(tf.shape(absmax)))[:,None][:,None]\n",
    "print(\"mask: \\n\", mask)\n",
    "\n",
    "# print(\"output: \", mask*U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test - multiply a [6,6] tensor with a [N, 6, 3] tensor\n",
    "# A = tf.eye(6)        #[6, 6]\n",
    "# B = tf.ones([2,6,3]) #[2, 6, 3]\n",
    "# print(tf.shape(tf.matmul(A,B))) #[2, 6, 3]\n",
    "\n",
    "C = tf.ones([164, 6,3])\n",
    "D = tf.ones([164,3])[:,:,None]\n",
    "print(tf.shape(tf.matmul(C,D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(15, 3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [3. 3. 3.]\n",
      "  [3. 3. 3.]]], shape=(15, 3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]\n",
      "\n",
      "\n",
      "   [[[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]\n",
      "\n",
      "    [[1. 1. 1.]\n",
      "     [1. 1. 1.]\n",
      "     [1. 1. 1.]]]]]], shape=(15, 3, 3, 15, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([15,3,3])\n",
    "b = tf.ones([15,3,3])\n",
    "# print(a, b)\n",
    "print(a * b)\n",
    "print(a @ b)\n",
    "# print(tf.tensordot(a,b, axes = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.81579804 0.07908082 0.8427702 ]\n",
      " [0.82890105 0.7560538  0.75865495]\n",
      " [0.62552524 0.00951374 0.8569366 ]\n",
      " [0.40709472 0.33734012 0.8656899 ]\n",
      " [0.57215416 0.08774686 0.71531796]\n",
      " [0.919863   0.8204982  0.28919268]\n",
      " [0.37577438 0.49524033 0.2079339 ]\n",
      " [0.8038533  0.91459525 0.47948086]\n",
      " [0.3899132  0.81449354 0.05697346]\n",
      " [0.5833684  0.7004868  0.7843642 ]], shape=(10, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape (2, 1) must have rank 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-eb5458b07e4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRaggedTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_row_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor.py\u001b[0m in \u001b[0;36mfrom_row_splits\u001b[1;34m(cls, values, row_splits, name, validate)\u001b[0m\n\u001b[0;32m    451\u001b[0m           \u001b[0mrow_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow_splits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m           \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m           preferred_dtype=_get_optional_partition_dtype(values))\n\u001b[0m\u001b[0;32m    454\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_row_partition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_partition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\row_partition.py\u001b[0m in \u001b[0;36mfrom_row_splits\u001b[1;34m(cls, row_splits, validate, preferred_dtype)\u001b[0m\n\u001b[0;32m    339\u001b[0m       row_splits = cls._convert_row_partition(row_splits, \"row_splits\",\n\u001b[0;32m    340\u001b[0m                                               preferred_dtype)\n\u001b[1;32m--> 341\u001b[1;33m       \u001b[0mrow_splits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_has_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\robot\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_has_rank\u001b[1;34m(self, rank)\u001b[0m\n\u001b[0;32m   1039\u001b[0m     \"\"\"\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape (2, 1) must have rank 1"
     ]
    }
   ],
   "source": [
    "t = tf.random.uniform([10,3])\n",
    "print(t)\n",
    "lims = [tf.constant([1]), tf.constant([2])]\n",
    "rag = tf.RaggedTensor.from_row_splits(t, lims)\n",
    "print(rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivide scan using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "try:\n",
    "    plt1.closeWindow()\n",
    "    print(\"closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt1 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "# settings.useParallelProjection = True #makes view orthographic\n",
    "\n",
    "## uncomment to use VOLPE dataset -----------------------------------------------------\n",
    "# location = 'C:/Users/Derm/2021-03-10-16-43-50_Velodyne-VLP-16-Data_garminSignage.txt'\n",
    "# cloud = np.loadtxt(open(location, \"rb\"), delimiter=\",\")\n",
    "# cloud = cloud[~np.isnan(cloud).any(axis=1)] #remove all rows with NaN elements\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# make 2D sinusioal pattern (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "##-------------------------------------------------------------------------------------\n",
    "\n",
    "# f =np.array([200,200,40]) #fidelity in x, y, z #takes ~30s on my dsektop\n",
    "# lim = np.array([-50,50,-50,50,-10,10])\n",
    "\n",
    "f =np.array([100,100,2]) #fidelity in x, y, z # < 5s\n",
    "lim = np.array([-100,100,-100,100,-10,10])\n",
    "\n",
    "for _ in range(1):\n",
    "#     cloud_partial = tf.gather(cloud,tf.cast((tf.linspace(1,100000,100)), tf.int32))\n",
    "    cloud_partial = cloud\n",
    "    mus, sigmas, sizes = subdivide_scan(cloud_partial,plt1, bounds = lim, fid = f, draw_grid = False, show_pc = True) \n",
    "\n",
    "# print(\"\\n mus: \\n\", mus)\n",
    "# print(\"\\n sigmas: \\n\", sigmas, np.shape(sigmas))\n",
    "    \n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivide scan using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "plt2 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "cloud_tensor = tf.convert_to_tensor(cloud, np.float32)\n",
    "# print(tf.shape(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# # make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "# #-------------------------------------------------------------------------------------\n",
    "\n",
    "f = tf.constant([100,100,2]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.])\n",
    "DRAW = True\n",
    "\n",
    "for _ in range(1):\n",
    "#     cloud_partial = tf.gather(cloud,tf.cast((tf.linspace(1,100000,30)), tf.int32))\n",
    "    cloud_partial = cloud\n",
    "    E = subdivide_scan_tf(cloud_partial, plt2, bounds = lim, fid = f, draw=DRAW, draw_grid = False, show_pc = 1) \n",
    "# print(\"\\n points: \\n\", cloud_partial)\n",
    "\n",
    "# mu = E[0]\n",
    "# print(\"\\n mu: \\n\",mu)\n",
    "\n",
    "# sigma = E[1]\n",
    "# print(\"\\n sigma: \\n\", sigma)\n",
    "\n",
    "# print(tf.transpose(sigma))\n",
    "# print(\"\\n sigma[:,:,1] \\n\", sigma[:,:,0])\n",
    "\n",
    "# sig2 = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "# print(\"reshaped sigma \\n\", sig2)\n",
    "\n",
    "# shapes = E[2]\n",
    "# print(\"\\n shapes: \\n\", shapes)\n",
    "\n",
    "# sigma = E[1]\n",
    "# print(tf.shape(sigma),sigma[:,:,1])\n",
    "\n",
    "# if DRAW:\n",
    "ViewInteractiveWidget(plt2.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.constant([1.,1.,1.]) #works ------------------------------\n",
    "# print(\"\\n a \\n\", a)\n",
    "\n",
    "# b = tf.random.normal([10,3])\n",
    "# print(\"\\n b \\n\", b)\n",
    "\n",
    "# dist = tf.reduce_sum(tf.math.squared_difference(a,b), axis = 1)\n",
    "# ans = tf.where(dist == tf.math.reduce_min(dist))[0,0]\n",
    "# print(\"\\n ans \\n\", b[ans])\n",
    "## -----------------------------------------------------------------\n",
    "\n",
    "# batch input - not working yet ------------------------------------\n",
    "a = tf.constant([[[1., 1., 1.]],\n",
    "                 [[0., 0., 0.]],\n",
    "                 [[0., 0., 0.]]])  \n",
    "print(\"\\n a \\n\", a)\n",
    "\n",
    "b = tf.random.normal([10,3])\n",
    "print(\"\\n b \\n\", b)\n",
    "\n",
    "# print(tf.gather(a,(0,1)))\n",
    "# print(tf.math.subtract(a, b))\n",
    "# print(tf.square(a-b))\n",
    "dist = tf.math.reduce_sum( (tf.square( tf.math.subtract(a, b) ))  , axis = 2)\n",
    "print(\"\\n dist \\n\", dist)\n",
    "\n",
    "ans = tf.where( tf.transpose(dist) ==tf.math.reduce_min(dist, axis = 1))\n",
    "print(\"\\n shortest dist \\n\", ans)\n",
    "\n",
    "reordered = tf.argsort(ans[:,1], axis = 0)\n",
    "print(\"\\n reordered \\n\", tf.gather(ans,reordered))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ragged tensor given row sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = tf.constant([1,2,8,4,5])\n",
    "\n",
    "# dummy_vals would be (points_x - mu_x)\n",
    "v = tf.random.uniform([tf.math.reduce_sum(sizes)])\n",
    "dummy_vals = tf.RaggedTensor.from_row_lengths(v ,sizes) \n",
    "print(dummy_vals.to_tensor() - 1)\n",
    "mask_test = tf.RaggedTensor.from_row_lengths(tf.ones(tf.math.reduce_sum(sizes)) ,sizes)\n",
    "print(tf.transpose(mask_test.to_tensor()))\n",
    "print((dummy_vals.to_tensor() -1) * mask_test.to_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test R() and Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hat = np.array([1,0,0])\n",
    "theta =  0.1 #np.pi/6 #rad\n",
    "\n",
    "rot_mat_simp = R_simp(n_hat, theta)\n",
    "print(rot_mat_simp)\n",
    "angs = np.array([theta,0 ,0])\n",
    "rot_mat = R(angs)\n",
    "print(rot_mat)\n",
    "\n",
    "print(R2Euler(rot_mat))\n",
    "\n",
    "p_point = np.array([1,1,1]).T\n",
    "\n",
    "J = jacobian(angs, p_point)\n",
    "\n",
    "d_rot_mat_simp = dR_simp(n_hat,theta)\n",
    "# print(d_rot_mat_simp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test R2Euler_tf and R_tf\n",
    "#### Works with single axis roation\n",
    "#### Works with vectoried input\n",
    "#### Solution becomes ambiguious with mutliple axis inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = tf.random.normal((3,1)) * tf.constant([[0.], [0.], [1.] ]) #single axis angle input\n",
    "# angs = tf.Variable([[0.],[ np.pi/2],[ 0.]]) #vector input, multiple axis rotation\n",
    "print(\"Input angs: \\n\", angs.numpy())\n",
    "# print(\"R(angs): \\n\", R_tf(angs).numpy())\n",
    "test1 = R2Euler_tf(R_tf(angs))\n",
    "print(\"R2Euler_tf(R(angs)): \\n\", test1.numpy())\n",
    "# test2 = R2Euler(R(angs[:,:2]))\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test tfp find bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.convert_to_tensor(cloud, np.float32)#[:100]\n",
    "# print(\"c: \\n\", c.numpy())\n",
    "startx = -100.\n",
    "stopx = 100.\n",
    "numx = 10\n",
    "edgesx = tf.linspace(startx, stopx, numx)\n",
    "xbins = tfp.stats.find_bins(c[:,0], edgesx)\n",
    "print(xbins)\n",
    "starty = -100.\n",
    "stopy = 100.\n",
    "numy = 10\n",
    "edgesy = tf.linspace(starty, stopy, numy)\n",
    "ybins = tfp.stats.find_bins(c[:,1], edgesy)\n",
    "print(ybins)\n",
    "\n",
    "min_num_pts = 1000\n",
    "\n",
    "count = 0\n",
    "E = []\n",
    "\n",
    "for x in range(numx):\n",
    "    for y in range(numy):\n",
    "        #only do calculations if there are a sufficicently high number of points in the bin\n",
    "        xin = tf.where(xbins == x)\n",
    "        if tf.shape(xin)[0] > min_num_pts:\n",
    "            if tf.shape(tf.where(tf.gather(ybins, xin) == y))[0] > min_num_pts: #repeat for y points at x coord\n",
    "#                 print(\"working\", x, y)\n",
    "                count += 1\n",
    "# print(xin)\n",
    "# print(ybins)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.linspace(1,5,5)\n",
    "print(test)\n",
    "ans = tf.where(test < 4)\n",
    "print(\"ans: \\n\",ans)\n",
    "print(\"\\n\", tf.gather(test, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inline volumetric rendering using ipyvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple demo\n",
    "import ipyvolume\n",
    "ds = ipyvolume.datasets.aquariusA2.fetch()\n",
    "short = ds.data[:,:,:]\n",
    "ipyvolume.quickvolshow(short, lighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.linspace(1,12,8)\n",
    "ans[2] = 0\n",
    "print(ans)\n",
    "\n",
    "test = ans[ans < 10]\n",
    "print(test)\n",
    "np.shape(test)[0]\n",
    "\n",
    "print(np.median(test[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = tf.random.normal([3,3])\n",
    "print(tes)\n",
    "print(tf.reverse(tes, axis = [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.reshape([10.,10.,2.], (3,1))\n",
    "# print(type(a))\n",
    "# t = tf.Tensor(a, dtype = \"float32\")\n",
    "\n",
    "a = tf.constant([2.1,2.,3.])\n",
    "b = tf.constant([1.,2.,3.])\n",
    "tf.tensordot(a,b, axes = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = tf.eye(3)\n",
    "# print(j)\n",
    "Jx = tf.constant([[1.], [2.], [3.]])\n",
    "J = tf.concat([eye, Jx], axis = 1)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare jacobian() and jacobian_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.sin(1.))\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs  = np.array([1.,0.1,0.1])\n",
    "p_point = np.array([1.,2.,3.])\n",
    "for _ in range(numiter):\n",
    "    J = jacobian(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on CPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF is slower if we do them one by one BUT is waaay faster if we send them in all at once\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "# angs = tf.random.normal((3,numiter))\n",
    "angs = tf.constant([1.,2.,3.])\n",
    "p_point = tf.random.normal((3,numiter))\n",
    "J = jacobian_tf(p_point, angs);\n",
    "print(\"took\", time.time()-start, \"seconds on GPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing subdividing cells without loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: given input tensor \"cloud\" and \"bins\" which contains all og and binned coordinates\n",
    "#      subdivide and perform ops on \"cloud\" wihtout using any loops \n",
    "\n",
    "bins = tf.transpose(tf.constant([[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.],\n",
    "                                 [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                 [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]))\n",
    "cloud = bins + tf.random.normal(tf.shape(bins))*0.1\n",
    "print(\"binned coordinate values: \\n\", bins)\n",
    "# print(cloud)\n",
    "\n",
    "#1d case (easy)\n",
    "# q = tf.constant([1., 1., 2.]) \n",
    "# print(tf.squeeze(tf.gather(bins, ans))) #works for 1d, unsure of utility in 2d\n",
    "#2d case (hard)\n",
    "q = tf.constant([[[1., 1., 2.]],\n",
    "                 [[0., 9., 9.]],\n",
    "                 [[2., 0., 1.]],\n",
    "                 [[7., 8., 9.]]])\n",
    "print(\"\\n cells of interest: \\n\",q)\n",
    "\n",
    "idx = tf.equal(bins, q)\n",
    "print(idx)\n",
    "#ans outputs tensor of shape [N,2], where:\n",
    "#  [[voxel number, index of [x,y,z] in cloud that corresponds to bin #],\n",
    "#   [voxel number,index of [x,y,z] in cloud that corresponds to bin #]] ... \n",
    "loc = tf.where(tf.math.reduce_all(idx, axis = 2) == True)\n",
    "print(\"\\n loc: \\n\", loc)\n",
    "\n",
    "#Need to \"ungroup\" so that we can fit_gaussian_tf() to each individual voxel...\n",
    "s = tf.shape(loc)\n",
    "group_ids, group_idx = tf.unique(loc[:, 0], out_idx=s.dtype)\n",
    "num_groups = tf.reduce_max(group_idx) + 1\n",
    "# print(group_ids, group_idx, num_groups)\n",
    "sizes = tf.math.bincount(group_idx)\n",
    "# print(sizes)\n",
    "\n",
    "#replace <bins> here with <cloud> when done debugging\n",
    "rag = tf.RaggedTensor.from_row_lengths(tf.gather(cloud, loc[:,1]), sizes) \n",
    "# print(\"ragged: \\n\", rag)\n",
    "\n",
    "#Run on GPU as vectorized operation (WAAAAAY Faster) --\n",
    "reg = tf.RaggedTensor.to_tensor(rag)\n",
    "print(\"\\n regular tensor: \\n\", reg)\n",
    "mu, sigma = fit_gaussian_tf(reg)\n",
    "print(\"mu: \\n\", mu)\n",
    "print(\"sigma: \\n\", sigma)\n",
    "#------------------------------------------------------- \n",
    "\n",
    "# # works but uses loop (runs on CPU -> slow) -----------\n",
    "# A =  tf.data.Dataset.from_tensor_slices(rag)\n",
    "# mus = []\n",
    "# sigmas = []\n",
    "# for i in range(len(A)):\n",
    "#     mu, sigma = fit_gaussian_tf(rag[i])\n",
    "#     mus.append(mu)\n",
    "#     sigmas.append(sigma)\n",
    "# print(mus, sigmas)\n",
    "# #------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find \"loc\" more efficiently than using tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"binned points: \\n\", bins)\n",
    "print(\"\\nbins to place them: \\n\",q)\n",
    "\n",
    "# #SUPER inefficient \n",
    "# for i in range(tf.shape(bins)[0]):\n",
    "#     for j in range(tf.shape(q)[0]):\n",
    "#         if tf.reduce_all(bins[i] == q[j]):\n",
    "#             print(j,i)\n",
    "#             try:\n",
    "#                 loc2 = tf.concat((loc2, tf.constant([[j,i]])), axis = 0)\n",
    "#             except:\n",
    "#                 loc2 = tf.constant([[j,i]])\n",
    "# print(\"\\n loc \\n\",loc2)\n",
    "# loc2 = None\n",
    "\n",
    "testidx = tf.where(bins == q[1])\n",
    "print(testidx)\n",
    "    \n",
    "print(\"\\n goal is to get this: \\n\",loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove zero rows from 3d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins2 = tf.transpose(tf.constant([[[2., 9., 3., 0., 2., 2., 3., 1., 0., 2.], #x\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]], \n",
    "                                  \n",
    "                                  [[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.], #y\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]],\n",
    "                                  \n",
    "                                  [[2., 1., 3., 1., 2., 2., 3., 1., 0., 2.], #z\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]]))\n",
    "\n",
    "print(bins2[:2])\n",
    "print(bins2[:,:,0])\n",
    "#need to AVERAGE point locations PER AXIS, PER BIN\n",
    "#   Ignore SPECIFIC POINTS where XYZ are ALL ZERO\n",
    "idx = tf.math.not_equal(bins2[:,:,0], tf.constant([0.,0.,0.]))\n",
    "print(idx[:2])\n",
    "mask = tf.where(tf.math.reduce_any(idx, axis = 2) == True)\n",
    "print(\"\\n mask: \\n\", mask[:6]) #correct(?)\n",
    "# print(tf.gather(bins,mask))\n",
    "\n",
    "nonzero = tf.gather(bins,[0,0,0])\n",
    "print(\"\\n nonzero elements: \\n\", nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2D tensor with all permutations (:n1, :n2, :n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fida = 2 \n",
    "fidb = 4\n",
    "fidc = 1\n",
    "\n",
    "a = tf.linspace(0,fida-1,fida)[:,None]\n",
    "b = tf.linspace(0,fidb-1,fidb)[:,None]\n",
    "c = tf.linspace(0,fidc-1,fidc)[:,None]\n",
    "\n",
    "ansa = tf.tile(a, [fidb*fidc, 1])\n",
    "ansb = tf.tile(tf.reshape(tf.tile(b, [1,fida]), [-1,1] ), [(fidc), 1])\n",
    "ansc = tf.reshape(tf.tile(c, [1,fida*fidb]), [-1,1] )\n",
    "\n",
    "q = tf.squeeze(tf.transpose(tf.Variable([ansa,ansb,ansc])))\n",
    "print(q)\n",
    "\n",
    "#GOAL- determine which voxel pt belongs in based on its coords\n",
    "# pt = tf.constant([2,1,0])\n",
    "pt = bins\n",
    "print(\"\\n pt:\", pt, \"\\n\")\n",
    "num = tf.cast( ( pt[:,0] + fida*pt[:,1] + (fida*fidb)*pt[:,2] ), tf.int32)\n",
    "print(\"\\n\", num, \"\\n\")\n",
    "# print(q[num])\n",
    "\n",
    "ans = tf.concat((num[:,None], tf.cast(tf.linspace(0, tf.shape(pt)[0], tf.shape(pt)[0]  )[:,None],\n",
    "                                      dtype = tf.int32) ), axis = 1 )\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate covariance of 3d tensors with multiple voxels. Ignore zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal(shape=(10, 2, 1))\n",
    "b = tf.random.normal(shape=(10, 2, 1))*4\n",
    "c = tf.random.normal(shape=(10, 2, 1))\n",
    "\n",
    "d = tf.concat((a,b,c), axis = 2)\n",
    "d = tf.concat((d, tf.zeros((10,2,3))), axis = 0)\n",
    "print(d[:,1])\n",
    "\n",
    "I = tf.sparse.eye(10,3)\n",
    "print(\"\\n Sparse Identity: \\n\", I)\n",
    "\n",
    "cov = tfp.stats.covariance(d, sample_axis = 0, event_axis = 2)\n",
    "print(\"\\n covariance matrices: \\n\", cov[1])\n",
    "\n",
    "print(sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.cast((tf.linspace(1,1000,100)), tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
