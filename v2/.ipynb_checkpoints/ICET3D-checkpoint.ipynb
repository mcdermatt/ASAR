{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from utils import *\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "# from numba import cuda #gpu library used to clear gpu memory after each trial\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICET3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.057013511657714844 seconds with tensorflow\n",
      "\n",
      " U \n",
      " tf.Tensor(\n",
      "[[[ 0.08315633 -0.7978918   0.59703755]\n",
      "  [ 0.0805341  -0.59177226 -0.8020722 ]\n",
      "  [ 0.9932771   0.11477919  0.01504786]]\n",
      "\n",
      " [[-0.06324871 -0.9532076   0.29562628]\n",
      "  [ 0.01789134 -0.29725483 -0.9546306 ]\n",
      "  [ 0.9978374  -0.05509002  0.03585512]]\n",
      "\n",
      " [[ 0.03640925 -0.81719947  0.5752039 ]\n",
      "  [-0.01272165 -0.5759179  -0.81740856]\n",
      "  [ 0.999256    0.02244367 -0.03136488]]\n",
      "\n",
      " [[ 0.02012786 -0.641264    0.7670563 ]\n",
      "  [ 0.02335847  0.76730394  0.6408582 ]\n",
      "  [-0.99952453  0.00501817  0.03042313]]], shape=(4, 3, 3), dtype=float32)\n",
      "\n",
      " axislen \n",
      " tf.Tensor(\n",
      "[[  0.3874464   22.96434     46.561485  ]\n",
      " [  0.31520817  48.58188    134.11145   ]\n",
      " [  0.56223774  67.689186   222.32457   ]\n",
      " [  0.57027346  44.96696    175.03154   ]], shape=(4, 3), dtype=float32)\n",
      "\n",
      " tf.math.abs(tf.linalg.matmul(axislen, U)) \n",
      " tf.Tensor(\n",
      "[[[ 48.130085   8.55451   17.48709 ]\n",
      "  [137.14853   13.607706  36.759895]\n",
      "  [226.32794   14.986954  50.61043 ]\n",
      "  [177.5236     6.975237  33.092426]]\n",
      "\n",
      " [[ 46.84715    9.760651  20.138454]\n",
      "  [134.67068   22.12986   41.475983]\n",
      "  [223.01927   32.90473   56.480484]\n",
      "  [175.42146   23.552727  36.482475]]\n",
      "\n",
      " [[ 46.248806  12.497185  20.008783]\n",
      "  [133.4051    25.226807  43.736324]\n",
      "  [221.31851   34.453094  61.9795  ]\n",
      "  [174.35004   22.434954  41.918198]]\n",
      "\n",
      " [[ 45.99514   17.605827  16.430624]\n",
      "  [132.90654   37.74793   35.455967]\n",
      "  [220.62642   52.6933    50.574245]\n",
      "  [173.88647   35.01597   34.579884]]], shape=(4, 4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]]\n",
      "\n",
      " [[False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]]\n",
      "\n",
      " [[False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]]\n",
      "\n",
      " [[False False False]\n",
      "  [False False False]\n",
      "  [False False False]\n",
      "  [False False False]]], shape=(4, 4, 3), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "from ICET3D import ICET3D\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True)\n",
    "\n",
    "plt = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud1 = velo1[:,:3]\n",
    "cloud1_tensor = tf.convert_to_tensor(cloud1, np.float32)\n",
    "velo2 = dataset.get_velo(1) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud2 = velo2[:,:3]\n",
    "cloud2_tensor = tf.convert_to_tensor(cloud2, np.float32)\n",
    "\n",
    "f = tf.constant([2,2,1]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.])\n",
    "\n",
    "E = ICET3D(cloud1_tensor, cloud2_tensor , plt, bounds = lim, fid = f)\n",
    "\n",
    "# print(E)\n",
    "# ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivide scan using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.46545934677124023 seconds with numpy\n",
      "\n",
      " mus: \n",
      " [array([-7.279544 , -7.506945 , -1.1749684], dtype=float32), array([-10.881932 ,  11.404407 ,  -1.2673018], dtype=float32), array([  9.635166 , -10.163892 ,  -1.2729832], dtype=float32), array([10.100568,  8.786581, -1.202917], dtype=float32)]\n",
      "\n",
      " sigmas: \n",
      " [array([[ 31.219512  , -11.45109463,  -1.65278876],\n",
      "       [-11.45109463,  37.99840039,  -2.09079027],\n",
      "       [ -1.65278876,  -2.09079027,   0.69533613]]), array([[118.76543521, -72.67969513,  -5.23231936],\n",
      "       [-72.67969513, 171.00035329,   4.81781292],\n",
      "       [ -5.23231936,   4.81781292,   0.81422825]]), array([[ 55.85986794, -24.08171272,   3.95338082],\n",
      "       [-24.08171272, 126.5145818 ,  -3.79017329],\n",
      "       [  3.95338082,  -3.79017329,   0.63372028]]), array([[121.48534699,  63.91976166,   3.93203425],\n",
      "       [ 63.91976166,  98.38098596,   3.57474923],\n",
      "       [  3.93203425,   3.57474923,   0.73286852]])] (4, 3, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558e72427ff44e849c2af4090305af65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "try:\n",
    "    plt1.closeWindow()\n",
    "    print(\"closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt1 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "# settings.useParallelProjection = True #makes view orthographic\n",
    "\n",
    "## uncomment to use VOLPE dataset -----------------------------------------------------\n",
    "# location = 'C:/Users/Derm/2021-03-10-16-43-50_Velodyne-VLP-16-Data_garminSignage.txt'\n",
    "# cloud = np.loadtxt(open(location, \"rb\"), delimiter=\",\")\n",
    "# cloud = cloud[~np.isnan(cloud).any(axis=1)] #remove all rows with NaN elements\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "##-------------------------------------------------------------------------------------\n",
    "\n",
    "# f =np.array([200,200,40]) #fidelity in x, y, z #takes ~30s on my dsektop\n",
    "# lim = np.array([-50,50,-50,50,-10,10])\n",
    "\n",
    "f =np.array([2,2,1]) #fidelity in x, y, z # < 5s\n",
    "lim = np.array([-100,100,-100,100,-10,10])\n",
    "\n",
    "for _ in range(1):\n",
    "#     cloud_partial = tf.gather(cloud,tf.cast((tf.linspace(1,100000,100)), tf.int32))\n",
    "    cloud_partial = cloud\n",
    "    mus, sigmas, sizes = subdivide_scan(cloud_partial,plt1, bounds = lim, fid = f, draw_grid = False, show_pc = True) \n",
    "\n",
    "print(\"\\n mus: \\n\", mus)\n",
    "print(\"\\n sigmas: \\n\", sigmas, np.shape(sigmas))\n",
    "    \n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivide scan using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.07118701934814453 seconds with tensorflow\n",
      "\n",
      " mu: \n",
      " tf.Tensor(\n",
      "[[ -7.2795615  -7.506899   -1.174968 ]\n",
      " [  9.634657  -10.163886   -1.2729071]\n",
      " [-10.882134   11.404009   -1.267325 ]\n",
      " [ 10.097389    8.784627   -1.2026961]], shape=(4, 3), dtype=float32)\n",
      "\n",
      " sigma: \n",
      " tf.Tensor(\n",
      "[[[ 31.219513   -11.451095    -1.6527888 ]\n",
      "  [-11.451095    37.998405    -2.0907903 ]\n",
      "  [ -1.6527888   -2.0907903    0.69533616]]\n",
      "\n",
      " [[ 55.863667   -24.08301      3.9527936 ]\n",
      "  [-24.08301    126.51124     -3.7892303 ]\n",
      "  [  3.9527936   -3.7892303    0.63370085]]\n",
      "\n",
      " [[118.76277    -72.674835    -5.232029  ]\n",
      "  [-72.674835   170.99898      4.817859  ]\n",
      "  [ -5.232029     4.817859     0.8142107 ]]\n",
      "\n",
      " [[121.47576     63.915535     3.928406  ]\n",
      "  [ 63.915535    98.36012      3.5724027 ]\n",
      "  [  3.928406     3.5724027    0.73286694]]], shape=(4, 3, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc2884f51794c1584509bf53ece51ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## from vedo import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "\n",
    "settings.embedWindow(backend='ipyvtk', verbose = True) #was this\n",
    "\n",
    "plt2 = Plotter(N=1, axes=1, bg = (0.1,0.1,0.1), bg2 = (0.3,0.3,0.3),  interactive=True)\n",
    "\n",
    "## uncomment to use KITTI dataset -----------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "frame_range = range(150, 151, 1)\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(0) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "cloud = velo1[:,:3]\n",
    "cloud_tensor = tf.convert_to_tensor(cloud, np.float32)\n",
    "# print(tf.shape(cloud))\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# # make 2D sinusioal motion (for debug) ------------------------------------------------\n",
    "# cloud = np.random.randn(10000,3)\n",
    "# cloud[:,0] += -50*cloud[:,1] + np.random.randn()*5\n",
    "# cloud[:,1] += 5\n",
    "# cloud[:,1] = cloud[:,1] * 3 + 10*np.random.randn() + np.sin(cloud[:,1]*5)*10\n",
    "# cloud[:,2] += 0.5*cloud[:,1] - 10\n",
    "# #-------------------------------------------------------------------------------------\n",
    "\n",
    "f = tf.constant([2,2,1]) #fidelity in x, y, z # < 5s\n",
    "lim = tf.constant([-100.,100.,-100.,100.,-10.,10.])\n",
    "DRAW = True\n",
    "\n",
    "for _ in range(1):\n",
    "#     cloud_partial = tf.gather(cloud,tf.cast((tf.linspace(1,100000,30)), tf.int32))\n",
    "    cloud_partial = cloud\n",
    "    E = subdivide_scan_tf(cloud_partial, plt2, bounds = lim, fid = f, draw=DRAW, draw_grid = False, show_pc = True) \n",
    "# print(\"\\n points: \\n\", cloud_partial)\n",
    "\n",
    "mu = E[0]\n",
    "print(\"\\n mu: \\n\",mu)\n",
    "\n",
    "sigma = E[1]\n",
    "print(\"\\n sigma: \\n\", sigma)\n",
    "\n",
    "# print(tf.transpose(sigma))\n",
    "# print(\"\\n sigma[:,:,1] \\n\", sigma[:,:,0])\n",
    "\n",
    "# sig2 = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "# print(\"reshaped sigma \\n\", sig2)\n",
    "\n",
    "# shapes = E[2]\n",
    "# print(\"\\n shapes: \\n\", shapes)\n",
    "\n",
    "# sigma = E[1]\n",
    "# print(tf.shape(sigma),sigma[:,:,1])\n",
    "\n",
    "# if DRAW:\n",
    "ViewInteractiveWidget(plt2.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ragged tensor given row sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = tf.constant([1,2,8,4,5])\n",
    "\n",
    "# dummy_vals would be (points_x - mu_x)\n",
    "v = tf.random.uniform([tf.math.reduce_sum(sizes)])\n",
    "dummy_vals = tf.RaggedTensor.from_row_lengths(v ,sizes) \n",
    "print(dummy_vals.to_tensor() - 1)\n",
    "mask_test = tf.RaggedTensor.from_row_lengths(tf.ones(tf.math.reduce_sum(sizes)) ,sizes)\n",
    "print(tf.transpose(mask_test.to_tensor()))\n",
    "print((dummy_vals.to_tensor() -1) * mask_test.to_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test R() and Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hat = np.array([1,0,0])\n",
    "theta =  0.1 #np.pi/6 #rad\n",
    "\n",
    "rot_mat_simp = R_simp(n_hat, theta)\n",
    "print(rot_mat_simp)\n",
    "angs = np.array([theta,0 ,0])\n",
    "rot_mat = R(angs)\n",
    "print(rot_mat)\n",
    "\n",
    "print(R2Euler(rot_mat))\n",
    "\n",
    "p_point = np.array([1,1,1]).T\n",
    "\n",
    "J = jacobian(angs, p_point)\n",
    "\n",
    "d_rot_mat_simp = dR_simp(n_hat,theta)\n",
    "# print(d_rot_mat_simp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test R2Euler_tf and R_tf\n",
    "#### Works with single axis roation\n",
    "#### Works with vectoried input\n",
    "#### Solution becomes ambiguious with mutliple axis inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = tf.random.normal((3,1)) * tf.constant([[0.], [0.], [1.] ]) #single axis angle input\n",
    "# angs = tf.Variable([[0.],[ np.pi/2],[ 0.]]) #vector input, multiple axis rotation\n",
    "print(\"Input angs: \\n\", angs.numpy())\n",
    "# print(\"R(angs): \\n\", R_tf(angs).numpy())\n",
    "test1 = R2Euler_tf(R_tf(angs))\n",
    "print(\"R2Euler_tf(R(angs)): \\n\", test1.numpy())\n",
    "# test2 = R2Euler(R(angs[:,:2]))\n",
    "# print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test tfp find bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.convert_to_tensor(cloud, np.float32)#[:100]\n",
    "# print(\"c: \\n\", c.numpy())\n",
    "startx = -100.\n",
    "stopx = 100.\n",
    "numx = 10\n",
    "edgesx = tf.linspace(startx, stopx, numx)\n",
    "xbins = tfp.stats.find_bins(c[:,0], edgesx)\n",
    "print(xbins)\n",
    "starty = -100.\n",
    "stopy = 100.\n",
    "numy = 10\n",
    "edgesy = tf.linspace(starty, stopy, numy)\n",
    "ybins = tfp.stats.find_bins(c[:,1], edgesy)\n",
    "print(ybins)\n",
    "\n",
    "min_num_pts = 1000\n",
    "\n",
    "count = 0\n",
    "E = []\n",
    "\n",
    "for x in range(numx):\n",
    "    for y in range(numy):\n",
    "        #only do calculations if there are a sufficicently high number of points in the bin\n",
    "        xin = tf.where(xbins == x)\n",
    "        if tf.shape(xin)[0] > min_num_pts:\n",
    "            if tf.shape(tf.where(tf.gather(ybins, xin) == y))[0] > min_num_pts: #repeat for y points at x coord\n",
    "#                 print(\"working\", x, y)\n",
    "                count += 1\n",
    "# print(xin)\n",
    "# print(ybins)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.linspace(1,5,5)\n",
    "print(test)\n",
    "ans = tf.where(test < 4)\n",
    "print(\"ans: \\n\",ans)\n",
    "print(\"\\n\", tf.gather(test, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inline volumetric rendering using ipyvolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple demo\n",
    "import ipyvolume\n",
    "ds = ipyvolume.datasets.aquariusA2.fetch()\n",
    "short = ds.data[:,:,:]\n",
    "ipyvolume.quickvolshow(short, lighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.linspace(1,12,8)\n",
    "ans[2] = 0\n",
    "print(ans)\n",
    "\n",
    "test = ans[ans < 10]\n",
    "print(test)\n",
    "np.shape(test)[0]\n",
    "\n",
    "print(np.median(test[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = tf.random.normal([3,3])\n",
    "print(tes)\n",
    "print(tf.reverse(tes, axis = [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.reshape([10.,10.,2.], (3,1))\n",
    "# print(type(a))\n",
    "# t = tf.Tensor(a, dtype = \"float32\")\n",
    "\n",
    "a = tf.constant([2.1,2.,3.])\n",
    "b = tf.constant([1.,2.,3.])\n",
    "tf.tensordot(a,b, axes = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = tf.eye(3)\n",
    "# print(j)\n",
    "Jx = tf.constant([[1.], [2.], [3.]])\n",
    "J = tf.concat([eye, Jx], axis = 1)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.sin(1.))\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs  = np.array([1.,0.1,0.1])\n",
    "p_point = np.array([1.,2.,3.])\n",
    "for _ in range(numiter):\n",
    "    J = jacobian(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on CPU\")\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF is slower if we do them one by one BUT is waaay faster if we send them in all at once\n",
    "start = time.time()\n",
    "numiter = 1000\n",
    "angs = tf.random.normal((3,numiter))\n",
    "p_point = tf.random.normal((3,numiter))\n",
    "J = jacobian_tf(angs, p_point);\n",
    "print(\"took\", time.time()-start, \"seconds on GPU\")\n",
    "print(J.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing subdividing cells without loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: given input tensor \"cloud\" and \"bins\" which contains all og and binned coordinates\n",
    "#      subdivide and perform ops on \"cloud\" wihtout using any loops \n",
    "\n",
    "bins = tf.transpose(tf.constant([[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.],\n",
    "                                 [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                 [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]))\n",
    "cloud = bins + tf.random.normal(tf.shape(bins))*0.1\n",
    "print(\"binned coordinate values: \\n\", bins)\n",
    "# print(cloud)\n",
    "\n",
    "#1d case (easy)\n",
    "# q = tf.constant([1., 1., 2.]) \n",
    "# print(tf.squeeze(tf.gather(bins, ans))) #works for 1d, unsure of utility in 2d\n",
    "#2d case (hard)\n",
    "q = tf.constant([[[1., 1., 2.]],\n",
    "                 [[0., 9., 9.]],\n",
    "                 [[2., 0., 1.]],\n",
    "                 [[7., 8., 9.]]])\n",
    "print(\"\\n cells of interest: \\n\",q)\n",
    "\n",
    "idx = tf.equal(bins, q)\n",
    "print(idx)\n",
    "#ans outputs tensor of shape [N,2], where:\n",
    "#  [[voxel number, index of [x,y,z] in cloud that corresponds to bin #],\n",
    "#   [voxel number,index of [x,y,z] in cloud that corresponds to bin #]] ... \n",
    "loc = tf.where(tf.math.reduce_all(idx, axis = 2) == True)\n",
    "print(\"\\n loc: \\n\", loc)\n",
    "\n",
    "#Need to \"ungroup\" so that we can fit_gaussian_tf() to each individual voxel...\n",
    "s = tf.shape(loc)\n",
    "group_ids, group_idx = tf.unique(loc[:, 0], out_idx=s.dtype)\n",
    "num_groups = tf.reduce_max(group_idx) + 1\n",
    "# print(group_ids, group_idx, num_groups)\n",
    "sizes = tf.math.bincount(group_idx)\n",
    "# print(sizes)\n",
    "\n",
    "#replace <bins> here with <cloud> when done debugging\n",
    "rag = tf.RaggedTensor.from_row_lengths(tf.gather(cloud, loc[:,1]), sizes) \n",
    "# print(\"ragged: \\n\", rag)\n",
    "\n",
    "#Run on GPU as vectorized operation (WAAAAAY Faster) --\n",
    "reg = tf.RaggedTensor.to_tensor(rag)\n",
    "print(\"\\n regular tensor: \\n\", reg)\n",
    "mu, sigma = fit_gaussian_tf(reg)\n",
    "print(\"mu: \\n\", mu)\n",
    "print(\"sigma: \\n\", sigma)\n",
    "#------------------------------------------------------- \n",
    "\n",
    "# # works but uses loop (runs on CPU -> slow) -----------\n",
    "# A =  tf.data.Dataset.from_tensor_slices(rag)\n",
    "# mus = []\n",
    "# sigmas = []\n",
    "# for i in range(len(A)):\n",
    "#     mu, sigma = fit_gaussian_tf(rag[i])\n",
    "#     mus.append(mu)\n",
    "#     sigmas.append(sigma)\n",
    "# print(mus, sigmas)\n",
    "# #------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find \"loc\" more efficiently than using tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"binned points: \\n\", bins)\n",
    "print(\"\\nbins to place them: \\n\",q)\n",
    "\n",
    "# #SUPER inefficient \n",
    "# for i in range(tf.shape(bins)[0]):\n",
    "#     for j in range(tf.shape(q)[0]):\n",
    "#         if tf.reduce_all(bins[i] == q[j]):\n",
    "#             print(j,i)\n",
    "#             try:\n",
    "#                 loc2 = tf.concat((loc2, tf.constant([[j,i]])), axis = 0)\n",
    "#             except:\n",
    "#                 loc2 = tf.constant([[j,i]])\n",
    "# print(\"\\n loc \\n\",loc2)\n",
    "# loc2 = None\n",
    "\n",
    "testidx = tf.where(bins == q[1])\n",
    "print(testidx)\n",
    "    \n",
    "print(\"\\n goal is to get this: \\n\",loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove zero rows from 3d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins2 = tf.transpose(tf.constant([[[2., 9., 3., 0., 2., 2., 3., 1., 0., 2.], #x\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]], \n",
    "                                  \n",
    "                                  [[2., 1., 3., 0., 2., 2., 3., 1., 0., 2.], #y\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]],\n",
    "                                  \n",
    "                                  [[2., 1., 3., 1., 2., 2., 3., 1., 0., 2.], #z\n",
    "                                  [0., 0., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [0., 1., 0., 0., 0., 0., 3., 1., 0., 0.],\n",
    "                                  [1., 2., 3., 0., 1., 1., 3., 2., 0., 1.]]]))\n",
    "\n",
    "print(bins2[:2])\n",
    "print(bins2[:,:,0])\n",
    "#need to AVERAGE point locations PER AXIS, PER BIN\n",
    "#   Ignore SPECIFIC POINTS where XYZ are ALL ZERO\n",
    "idx = tf.math.not_equal(bins2[:,:,0], tf.constant([0.,0.,0.]))\n",
    "print(idx[:2])\n",
    "mask = tf.where(tf.math.reduce_any(idx, axis = 2) == True)\n",
    "print(\"\\n mask: \\n\", mask[:6]) #correct(?)\n",
    "# print(tf.gather(bins,mask))\n",
    "\n",
    "nonzero = tf.gather(bins,[0,0,0])\n",
    "print(\"\\n nonzero elements: \\n\", nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2D tensor with all permutations (:n1, :n2, :n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fida = 2 \n",
    "fidb = 2\n",
    "fidc = 1\n",
    "\n",
    "a = tf.linspace(0,fida-1,fida)[:,None]\n",
    "b = tf.linspace(0,fidb-1,fidb)[:,None]\n",
    "c = tf.linspace(0,fidc-1,fidc)[:,None]\n",
    "\n",
    "ansa = tf.tile(a, [fidb*fidc, 1])\n",
    "ansb = tf.tile(tf.reshape(tf.tile(b, [1,fida]), [-1,1] ), [(fidc), 1])\n",
    "ansc = tf.reshape(tf.tile(c, [1,fida*fidb]), [-1,1] )\n",
    "\n",
    "q = tf.squeeze(tf.transpose(tf.Variable([ansa,ansb,ansc])))\n",
    "print(q)\n",
    "\n",
    "#GOAL- determine which voxel pt belongs in based on its coords\n",
    "# pt = tf.constant([2,1,0])\n",
    "pt = bins\n",
    "print(\"\\n pt:\", pt, \"\\n\")\n",
    "num = tf.cast( ( pt[:,0] + fida*pt[:,1] + (fida*fidb)*pt[:,2] ), tf.int32)\n",
    "print(\"\\n\", num, \"\\n\")\n",
    "# print(q[num])\n",
    "\n",
    "ans = tf.concat((num[:,None], tf.cast(tf.linspace(0, tf.shape(pt)[0], tf.shape(pt)[0]  )[:,None],\n",
    "                                      dtype = tf.int32) ), axis = 1 )\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate covariance of 3d tensors with multiple voxels. Ignore zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal(shape=(10, 2, 1))\n",
    "b = tf.random.normal(shape=(10, 2, 1))*4\n",
    "c = tf.random.normal(shape=(10, 2, 1))\n",
    "\n",
    "d = tf.concat((a,b,c), axis = 2)\n",
    "d = tf.concat((d, tf.zeros((10,2,3))), axis = 0)\n",
    "print(d[:,1])\n",
    "\n",
    "I = tf.sparse.eye(10,3)\n",
    "print(\"\\n Sparse Identity: \\n\", I)\n",
    "\n",
    "cov = tfp.stats.covariance(d, sample_axis = 0, event_axis = 2)\n",
    "print(\"\\n covariance matrices: \\n\", cov[1])\n",
    "\n",
    "print(sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.cast((tf.linspace(1,1000,100)), tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
