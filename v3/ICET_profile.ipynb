{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df034054",
   "metadata": {},
   "source": [
    "# Notebook for identifying and removing bottlenecks from ICET implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc1c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 09:31:16.403426: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 09:31:17.027722: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-21 09:31:18.019421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-21 09:31:18.019499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-21 09:31:18.019504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-21 09:31:19.407942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:19.526498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:19.526811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 09:31:19.833191: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 09:31:19.834829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:19.835099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:19.835518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:20.772013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:20.772278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:20.772446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-21 09:31:20.772559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "# tf.config.set_visible_devices([], 'GPU') #run on CPU only -- seems to actually execute main parts of code faster here...\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "from ICET_spherical import ICET\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook\n",
    "\n",
    "# %%bash\n",
    "# # python -m cProfile scan_match.py\n",
    "# python scan_match.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e4c23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth poses are not avaialble for sequence 09.\n",
      "\n",
      " loading model took 4.76837158203125e-07 \n",
      " total:  4.291534423828125e-06\n",
      "\n",
      " shuffling and converting to tensor took  0.030080080032348633 \n",
      " total:  0.0301055908203125\n",
      "\n",
      " converting to spherical took 0.015475988388061523 \n",
      " total:  0.04559779167175293\n",
      "\n",
      " fit_gaussian for scan 1 0.01750493049621582 \n",
      " total:  1.5329134464263916\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.0571894645690918 \n",
      " total:  1.64686918258667 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.33976105  0.0124645   0.00270582 -0.00057757  0.00145208 -0.00518778], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01694178581237793 \n",
      " total:  1.6638340950012207 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05123162269592285 \n",
      " total:  1.7153396606445312 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 6.9391894e-01 -1.3333373e-03  8.4738331e-03 -4.3932843e-04\n",
      "  1.7295798e-03  1.7378689e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.02149176597595215 \n",
      " total:  1.7368533611297607 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.04973173141479492 \n",
      " total:  1.7868638038635254 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 8.6956495e-01  7.7536013e-03  1.1438782e-02 -2.0870072e-04\n",
      "  2.0195167e-03  2.7316851e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.022151470184326172 \n",
      " total:  1.8090388774871826 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.050400495529174805 \n",
      " total:  1.8597173690795898 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.3425977e-01  1.1554695e-02  1.2139152e-02 -1.1373321e-04\n",
      "  2.1298896e-03  2.9621175e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01647210121154785 \n",
      " total:  1.8762094974517822 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.0493626594543457 \n",
      " total:  1.925842046737671 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.4640988e-01  1.3570282e-02  1.2417588e-02 -1.4131484e-04\n",
      "  2.1199298e-03  3.0437319e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016849279403686523 \n",
      " total:  1.9427087306976318 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05076742172241211 \n",
      " total:  1.9937529563903809 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.48595047e-01  1.39966328e-02  1.23860305e-02 -1.72005573e-04\n",
      "  2.08742195e-03  2.99663073e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01643514633178711 \n",
      " total:  2.0102105140686035 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.06578946113586426 \n",
      " total:  2.076265573501587 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.4891638e-01  1.4070975e-02  1.2412971e-02 -1.7335228e-04\n",
      "  2.0862166e-03  2.9891210e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01634955406188965 \n",
      " total:  2.0926353931427 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.050330162048339844 \n",
      " total:  2.1432301998138428 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.01717090606689453 \n",
      " total:  2.160428285598755 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.4829756e-01  1.4178301e-02  1.2265752e-02 -1.8662815e-04\n",
      "  2.0541376e-03  2.9722333e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01684856414794922 \n",
      " total:  2.177290916442871 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05096793174743652 \n",
      " total:  2.2285327911376953 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.011977434158325195 \n",
      " total:  2.2405290603637695 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.4820642e-01  1.4075846e-02  1.2280452e-02 -1.8605078e-04\n",
      "  2.0533421e-03  2.9566227e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016182899475097656 \n",
      " total:  2.256725788116455 \n",
      " ~~~~~~~~~~~~~~\n",
      "pred_stds: \n",
      " tf.Tensor(\n",
      "[1.18972105e-03 5.09139034e-04 1.05911626e-04 2.21342907e-05\n",
      " 1.67638482e-05 1.00752375e-04], shape=(6,), dtype=float32)\n",
      " L2: \n",
      " tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "basepath = '/media/derm/06EF-127D1/KITTI'\n",
    "# sequence = '03' #forest\n",
    "sequence = '09' #trees and small town\n",
    "dataset = pykitti.odometry(basepath, sequence)\n",
    "velo1 = dataset.get_velo(400)\n",
    "c1 = velo1[:,:3]\n",
    "velo2 = dataset.get_velo(401)\n",
    "c2 = velo2[:,:3]\n",
    "\n",
    "it = ICET(cloud1 = c1, cloud2 = c2, fid = 70, niter = 9, \n",
    "           draw = False, group = 2, RM = True, DNN_filter = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ff0c0",
   "metadata": {},
   "source": [
    "# get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "cebb9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt2(rads, thresh = 0.5, mnp = 100):\n",
    "    \"\"\"testing new method of finding radial bins for spherical voxels\"\"\"\n",
    "    \n",
    "    before = time.time()\n",
    "\n",
    "    max_buffer = 0.2 \n",
    "\n",
    "    if len(tf.shape(rads)) < 2:\n",
    "        rads = rads[:,None]\n",
    "\n",
    "    OG_rads = rads #hold on to OG rads\n",
    "    #replace all zeros in rads (result of converting ragged -> standard tensor) with some arbitrarily large value\n",
    "    mask = tf.cast(tf.math.equal(rads, 0), tf.float32)*1000\n",
    "    rads = rads + mask\n",
    "    # print(rads)\n",
    "\n",
    "    #sort in ascending order for each column in tensor\n",
    "    top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "#     print(\"\\n top_k \\n\", top_k[1])\n",
    "    rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "    rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "    print(\"rads \\n\", rads)\n",
    "\n",
    "    # calculate the forward difference between neighboring points\n",
    "    z = tf.zeros([1, tf.shape(rads)[1].numpy()])\n",
    "    shifted = tf.concat((rads[1:], z), axis = 0)\n",
    "    diff = shifted - rads\n",
    "    # diff = tf.math.abs(rads - shifted) #debug 6/9/22\n",
    "#     print(\"\\n diff \\n\", diff)\n",
    "\n",
    "    # #find where difference jumps\n",
    "    jumps = tf.where(diff > thresh)\n",
    "#     print(\"\\n jumps \\n\", jumps) #[idx of jump, which spike is jumping]\n",
    "\n",
    "    #----------------------------------------------------------------------\n",
    "    #not sure if actually needed...\n",
    "    #get indexes of all used spikes\n",
    "    used = jumps[:,1][None,:]\n",
    "    # print(\"used\", used)\n",
    "    biggest = tf.math.reduce_max(used, axis = 1).numpy()[0]\n",
    "    # print(\"biggest\", biggest)\n",
    "    all_spikes = tf.cast(tf.linspace(0,biggest,biggest+1), tf.int64)[None,:] #list all spikes total\n",
    "    # print(\"all_spikes\", all_spikes)\n",
    "\n",
    "    #find differnce\n",
    "    missing = tf.sets.difference(all_spikes, used).values[None,:]\n",
    "    # print(\"\\n missing\", missing)\n",
    "    # z = tf.zeros(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # z = 51*tf.ones(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    #z should be this...\n",
    "    # print(\"\\n OG_rads\", OG_rads)\n",
    "    # ends = tf.math.argmax(OG_rads, axis = 0) #wrong -> not max arg, last nonzero argument!!\n",
    "    zero = tf.constant(0, dtype = tf.float32)\n",
    "    ends = tf.math.reduce_sum(tf.cast(tf.not_equal(OG_rads, zero), tf.int64), axis = 0) #correct\n",
    "    # print(\"\\n ends\", ends)\n",
    "\n",
    "    test = tf.gather(ends, missing[0])  #get index of last element of missing jump section\n",
    "    # print(\"\\n test\", test)\n",
    "    z = test[None,:]\n",
    "    z -= 2 #fixes indexing bug\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    missing = tf.transpose(tf.concat((z, missing), axis = 0))\n",
    "    # print(missing)\n",
    "\n",
    "    jumps = tf.concat((jumps, missing), axis = 0) #concat missing stuff back at the end of jumps\n",
    "#     print(\"\\n jumps after fix\", jumps)\n",
    "    #----------------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n jumps: \\n\", jumps.numpy())\n",
    "    \n",
    "    #find where the first large cluster occurs in each spike\n",
    "   \n",
    "\n",
    "    \n",
    "    bounds = None\n",
    "\n",
    "    return(bounds, jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "0f50c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " took 1.0185918807983398  s with old method \n",
      "\n",
      "\n",
      " bounds_old: \n",
      " tf.Tensor(\n",
      "[[ 8.48445892 12.37514305]\n",
      " [ 7.32219505 10.72554016]\n",
      " [ 5.35522413  6.61872005]\n",
      " ...\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]], shape=(536, 2), dtype=float64)\n",
      "(536, 2)\n",
      "rads \n",
      " tf.Tensor(\n",
      "[[   8.449831     7.2839036    5.336023  ...   27.126928     3.7713213\n",
      "    54.913895 ]\n",
      " [   8.484459     7.322195     5.355224  ...   27.1396       3.779652\n",
      "  1000.       ]\n",
      " [   8.487444     7.3482585    5.3561454 ...   27.14838      3.8077207\n",
      "  1000.       ]\n",
      " ...\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]], shape=(506, 536), dtype=float32)\n",
      "\n",
      " jumps: \n",
      " [[  0  45]\n",
      " [  0 162]\n",
      " [  0 269]\n",
      " ...\n",
      " [501 102]\n",
      " [502 287]\n",
      " [504 287]]\n",
      " \n",
      " took 0.006579399108886719  s with new method\n"
     ]
    }
   ],
   "source": [
    "from utils import get_cluster\n",
    "# print(\"rads: \\n\", it.rads)\n",
    "\n",
    "s = time.time()\n",
    "bounds_old = get_cluster(it.rads, mnp = it.min_num_pts)\n",
    "print(\"\\n took\", time.time() - s, \" s with old method \\n\")\n",
    "print(\"\\n bounds_old: \\n\", bounds_old)\n",
    "print(np.shape(bounds_old))\n",
    "\n",
    "s = time.time()\n",
    "bounds_new, jumps = gt2(it.rads, mnp = it.min_num_pts)\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "b7756ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old slow soln shape: \n",
      " tf.Tensor([536   2], shape=(2,), dtype=int32)\n",
      "\n",
      " bounds_old: \n",
      " tf.Tensor(\n",
      "[[ 8.48445892 12.37514305]\n",
      " [ 7.32219505 10.72554016]\n",
      " [ 5.35522413  6.61872005]\n",
      " [ 5.20210648  6.24694252]\n",
      " [ 0.          0.        ]\n",
      " [ 4.89096785  5.85317039]\n",
      " [ 4.64766264  5.13235998]\n",
      " [ 4.55753613  5.00266695]\n",
      " [11.36053562 18.66326904]\n",
      " [11.01212311 18.64307213]\n",
      " [ 3.32399344  3.54074168]\n",
      " [ 3.50027776  5.51918268]\n",
      " [ 6.24643803  7.73354149]\n",
      " [ 8.13937759 10.06496334]\n",
      " [ 6.92522478  9.03021431]], shape=(15, 2), dtype=float64)\n",
      "\n",
      " jumps_rag \n",
      " <tf.RaggedTensor [[0, 45, 162, 269, 316, 376, 379, 448, 486, 500, 513, 524, 531, 535],\n",
      " [0, 13, 255, 349, 385, 389, 493, 500, 523], [0, 87, 242, 321, 384, 411],\n",
      " [0, 242, 269, 281, 427, 532, 534], [0, 269, 407, 425, 514],\n",
      " [0, 44, 329, 524, 529, 534], [0, 104, 164, 269, 517], [0, 426, 514],\n",
      " [0, 263, 444, 513], [0, 254, 269, 384, 481, 490, 528, 533],\n",
      " [0, 311, 456, 513, 520], [0, 349, 514], [0, 349, 437, 513, 516, 523],\n",
      " [0, 349, 384, 523, 530], [0, 271, 385]]>\n",
      "\n",
      " first_big_enough: \n",
      " tf.Tensor([1 1 1 0 0 1 0 0 0 0 0 0 0 0 0], shape=(15,), dtype=int64)\n",
      "\n",
      " inner: \n",
      " tf.Tensor([45 13 87  0  0 44  0  0  0  0], shape=(10,), dtype=int64)\n",
      "\n",
      " idx \n",
      " tf.Tensor([  0   0   0 ... 411 412 413], shape=(1404,), dtype=int32)\n",
      "\n",
      " inside_bound \n",
      " tf.Tensor(\n",
      "[ 9.0798     7.4419475  5.798274   5.199855   4.426507   5.0516624\n",
      "  4.638537   4.5574927 11.356775  11.01124    3.3216293  3.4876556\n",
      "  6.228087   5.7541857  6.9159107], shape=(15,), dtype=float32)\n",
      "\n",
      " outside_bound \n",
      " tf.Tensor(\n",
      "[  10.6182785   10.461407     6.6143994 1000.        1000.\n",
      " 1000.           4.9589157 1000.          15.567635    14.909887\n",
      " 1000.        1000.           7.221906  1000.        1000.       ], shape=(15,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#identifying location of jumps without looping\n",
    "print(\"old slow soln shape: \\n\", tf.shape(bounds_old)) #want to produce this same shape!!!\n",
    "print(\"\\n bounds_old: \\n\", bounds_old[:15])\n",
    "\n",
    "#get all radial measurements\n",
    "#(temp-- already done inside function)-----------------------------\n",
    "mask = tf.cast(tf.math.equal(it.rads, 0), tf.float32)*1000\n",
    "rads = it.rads + mask\n",
    "#sort in ascending order for each column in tensor\n",
    "top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "# print(\"\\n rads: \\n\", rads[:10])\n",
    "# print(\"\\n it.rads \\n\", it.rads)\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# print(\"\\n jumps: \\n\", tf.shape(jumps))\n",
    "# print(\"\\n jumps: \\n\",jumps[:30])\n",
    "\n",
    "y, idx = tf.unique(jumps[:,0])\n",
    "# print(\"\\n y \\n\", y, \"\\n \\n idx\", idx)\n",
    "# print(\"\\n jumps \\n\", jumps)\n",
    "\n",
    "# get ragged tensor containing indices where jumps occur in each wedge shaped voxel\n",
    "jumps_rag = tf.RaggedTensor.from_value_rowids(jumps[:,1], idx)\n",
    "# append 0 to beginning of each ragged elemet of jumps_rag\n",
    "jumps_rag = tf.concat([zeros.with_row_splits_dtype(tf.int64), jumps_rag.with_row_splits_dtype(tf.int64)], axis = 1)\n",
    "print(\"\\n jumps_rag \\n\", jumps_rag[:15])\n",
    "\n",
    "#get num points between each jump \n",
    "npts_between_jumps = tf.experimental.numpy.diff(jumps_rag.to_tensor())\n",
    "# print(\"\\n npts_between_jumps:\\n \",npts_between_jumps[:15])\n",
    "# print(\"\\n npts_between_jumps:\\n \",npts_between_jumps)\n",
    "\n",
    "#get idx within jumps_rag corresponding to first sufficiently large jump\n",
    "big_enough = tf.cast(tf.math.greater(npts_between_jumps, 100), tf.int32)\n",
    "# print(big_enough[:10])\n",
    "first_big_enough = tf.math.argmax(big_enough, axis = 1)\n",
    "print(\"\\n first_big_enough: \\n\", first_big_enough[:15])\n",
    "# print(\"\\n first_big_enough: \\n\", first_big_enough)\n",
    "\n",
    "#------------------\n",
    "#get inner and outer (temp simple way-- just use radial measurements of inner and outermost points in cluster)\n",
    "inner = tf.gather(jumps_rag.to_tensor(), first_big_enough, batch_dims = 1)\n",
    "print(\"\\n inner: \\n\", inner[:10])\n",
    "# print(\"\\n inner: \\n\", inner)\n",
    "\n",
    "#infill zero elements throughout (use tf.ragged.from_value_rowids keyed by y)\n",
    "inner = tf.RaggedTensor.from_value_rowids(inner, y).to_tensor()[:,0]\n",
    "#add zeros to end of bounds to get to same number of total voxels as OG_rads \n",
    "inner = tf.pad(inner, [[0,tf.shape(rads)[1]-len(inner)]]) #DEBUG-- make sure I'm using correct dimension of tf.shape(rads)\n",
    "# print(\"\\n inner \\n\", inner)\n",
    "# print(\"\\n inner \\n\", tf.shape(inner))\n",
    "\n",
    "#concat idx and y, use gather_nd instead of converting to ragged and back?? \n",
    "# idx = tf.concat((tf.cast(tf.range(len(inner))[:,None], tf.int64), inner[:,None]), axis = 1) #wrong?\n",
    "idx1 = tf.concat((inner[:,None], tf.cast(tf.range(len(inner))[:,None], tf.int64)), axis = 1) #test\n",
    "print(\"\\n idx \\n\", idx)\n",
    "inside_bound = tf.gather_nd(rads, idx1)\n",
    "print(\"\\n inside_bound \\n\", inside_bound[:15])\n",
    "\n",
    "\n",
    "#repeat for outside bound\n",
    "outer = tf.gather(jumps_rag.to_tensor(), first_big_enough +1, batch_dims = 1)\n",
    "outer = tf.RaggedTensor.from_value_rowids(outer, y).to_tensor()[:,0]\n",
    "outer = tf.pad(outer, [[0,tf.shape(rads)[1]-len(outer)]]) #DEBUG-- make sure I'm using correct dimension of tf.shape(rads)\n",
    "idx2 = tf.concat((outer[:,None], tf.cast(tf.range(len(outer))[:,None], tf.int64)), axis = 1) #test\n",
    "outside_bound = tf.gather_nd(rads, idx2)\n",
    "print(\"\\n outside_bound \\n\", outside_bound[:15])\n",
    "\n",
    "#------------------\n",
    "\n",
    "# #test-----------------\n",
    "# #infill zero elements throughout (use tf.ragged.from_value_rowids keyed by y)\n",
    "# first_big_enough = tf.RaggedTensor.from_value_rowids(first_big_enough, y).to_tensor()[:,0]\n",
    "# #add zeros to end of bounds to get to same number of total voxels as OG_rads \n",
    "# first_big_enough = tf.pad(first_big_enough, [[0,tf.shape(rads)[1]-len(first_big_enough)]])\n",
    "# print(\"\\n first_big_enough: \\n\", first_big_enough[:15])\n",
    "\n",
    "# # inner_idx = tf.gather(jumps_rag.to_tensor(), first_big_enough)\n",
    "# # idx = tf.concat((tf.cast(tf.range(len(inner))[:,None], tf.int64), inner[:,None]), axis = 1)\n",
    "# #--------------------\n",
    "\n",
    "#TODO add voxel length padding \n",
    "#  (max half distance betweeen last in cluster and first point outside cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "0ec14bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[0, 0, 45, 162, 269, 316, 376, 379, 448, 486, 500, 513, 524, 531, 535],\n",
      " [0, 0, 13, 255, 349, 385, 389, 493, 500, 523],\n",
      " [0, 0, 87, 242, 321, 384, 411], [0, 0, 242, 269, 281, 427, 532, 534],\n",
      " [0, 0, 269, 407, 425, 514], [0, 0, 44, 329, 524, 529, 534],\n",
      " [0, 0, 104, 164, 269, 517], [0, 0, 426, 514], [0, 0, 263, 444, 513],\n",
      " [0, 0, 254, 269, 384, 481, 490, 528, 533], [0, 0, 311, 456, 513, 520],\n",
      " [0, 0, 349, 514], [0, 0, 349, 437, 513, 516, 523],\n",
      " [0, 0, 349, 384, 523, 530], [0, 0, 271, 385], [0, 0, 172],\n",
      " [0, 0, 329, 426, 518, 526], [0, 0, 168, 417, 457, 491], [0, 0, 504],\n",
      " [0, 0, 278, 306], [0, 0, 168, 278, 385, 412, 481], [0, 0, 150],\n",
      " [0, 0, 199], [0, 0, 254, 278], [0, 0, 98, 136, 529],\n",
      " [0, 0, 278, 490, 508], [0, 0, 364, 384, 399],\n",
      " [0, 0, 254, 364, 384, 481, 521], [0, 0, 254, 278, 384, 433],\n",
      " [0, 0, 49, 147, 150, 239, 243, 384, 432, 481],\n",
      " [0, 0, 29, 58, 119, 228, 384, 412, 448, 513, 516, 522],\n",
      " [0, 0, 54, 84, 117, 272, 384, 385, 515], [0, 0, 270, 384, 498, 516, 519],\n",
      " [0, 0, 150, 205, 400, 458, 490], [0, 0, 184, 494, 516],\n",
      " [0, 0, 150, 184, 269, 458, 481, 515, 516], [0, 0, 269, 418, 516, 525],\n",
      " [0, 0, 400, 506], [0, 0, 269, 321], [0, 0, 269, 437],\n",
      " [0, 0, 247, 269, 451], [0, 0, 208, 457, 500, 504], [0, 0, 136],\n",
      " [0, 0, 208, 417], [0, 0, 507], [0, 0, 98, 106, 150],\n",
      " [0, 0, 98, 428, 500, 527], [0, 0, 142, 208], [0, 0, 108, 208, 500, 515],\n",
      " [0, 0, 150, 457], [0, 0, 417], [0, 0, 362, 432, 504], [0, 0, 136, 460],\n",
      " [0, 0, 136, 271], [0, 0, 4, 106, 136, 332, 441, 463],\n",
      " [0, 0, 136, 490, 529], [0, 0, 210, 446], [0, 0, 216, 239, 243, 414, 427],\n",
      " [0, 0, 124, 129, 145, 177, 207, 302],\n",
      " [0, 0, 29, 119, 141, 145, 150, 228, 318, 414, 427, 502],\n",
      " [0, 0, 117, 272, 360, 465, 504, 515], [0, 0, 249, 269, 509],\n",
      " [0, 0, 271, 360], [0, 0, 269, 275, 360, 475, 511], [0, 0, 150, 360],\n",
      " [0, 0, 269, 346, 458, 483], [0, 0, 269, 462], [0, 0, 269, 379, 464],\n",
      " [0, 0, 269, 364], [0, 0, 88, 150, 486], [0, 0, 428], [0, 0, 88, 269, 295],\n",
      " [0, 0, 139, 373, 404], [0, 0, 509], [0, 0, 114, 210, 352, 417, 518],\n",
      " [0, 0, 305, 309, 404, 417], [0, 0, 404, 428], [0, 0, 404],\n",
      " [0, 0, 114, 400], [0, 0, 214], [0, 0, 352, 373], [0, 0, 21],\n",
      " [0, 0, 58, 361, 499, 512, 518],\n",
      " [0, 0, 139, 247, 261, 315, 351, 403, 459, 467, 518],\n",
      " [0, 0, 150, 386, 433, 434, 484], [0, 0, 243, 274, 336, 353, 426, 518],\n",
      " [0, 0, 132, 336, 370], [0, 0, 167, 355, 494], [0, 0, 29, 119, 228],\n",
      " [0, 0, 117, 247], [0, 0, 352], [0, 0, 54, 116, 497],\n",
      " [0, 0, 39, 82, 84, 139, 157], [0, 0, 139], [0, 0, 139, 439, 474],\n",
      " [0, 0, 134, 139, 170, 321, 336, 460], [0, 0, 341, 352, 460], [0, 0, 315],\n",
      " [0, 0, 24, 86, 315, 460], [0, 0, 315], [0, 0, 166, 367], [0, 0, 478, 497],\n",
      " [0, 0, 170, 315, 360, 497], [0, 0, 170, 358, 416, 465, 497],\n",
      " [0, 0, 170, 460, 495, 497, 501], [0, 0, 24, 170], [0, 0, 170, 494],\n",
      " [0, 0, 24, 55, 98], [0, 0, 85, 501], [0, 0, 324], [0, 0, 176],\n",
      " [0, 0, 238, 320, 382, 505], [0, 0, 238, 426, 478],\n",
      " [0, 0, 15, 91, 204, 243, 279, 416, 433, 465],\n",
      " [0, 0, 29, 341, 416, 426, 465, 478, 494],\n",
      " [0, 0, 34, 86, 219, 220, 360, 426, 478, 494],\n",
      " [0, 0, 132, 189, 233, 320, 360, 416, 426],\n",
      " [0, 0, 44, 109, 239, 250, 353, 416, 480],\n",
      " [0, 0, 29, 51, 119, 203, 228, 416, 485],\n",
      " [0, 0, 61, 91, 114, 150, 367, 416], [0, 0, 117, 235, 292, 356],\n",
      " [0, 0, 78, 80, 91, 235, 471], [0, 0, 54, 102, 287], [0, 0, 84],\n",
      " [0, 0, 86, 102, 239, 415], [0, 0, 134, 183], [0, 0, 80], [0, 0, 444],\n",
      " [0, 0, 86, 98, 357, 444], [0, 0, 48, 357],\n",
      " [0, 0, 39, 98, 111, 188, 235, 329, 357], [0, 0, 203, 426],\n",
      " [0, 0, 86, 389, 426], [0, 0, 235, 410], [0, 0, 37],\n",
      " [0, 0, 48, 179, 329, 468], [0, 0, 170, 464], [0, 0, 58, 464],\n",
      " [0, 0, 203, 348], [0, 0, 18], [0, 0, 170, 419, 422, 461],\n",
      " [0, 0, 58, 419, 433, 469], [0, 0, 199, 316, 419], [0, 0, 392],\n",
      " [0, 0, 226, 390], [0, 0, 347, 487], [0, 0, 6, 59, 179, 469],\n",
      " [0, 0, 29, 31, 51, 119, 228], [0, 0, 425], [0, 0, 35, 117, 162],\n",
      " [0, 0, 99], [0, 0, 54, 239, 409], [0, 0, 84, 115, 182], [0, 0, 281, 357],\n",
      " [0, 0, 509], [0, 0, 235, 242, 509], [0, 0, 194, 287],\n",
      " [0, 0, 71, 162, 356, 482], [0, 0, 436], [0, 0, 229, 239], [0, 0, 58],\n",
      " [0, 0, 239], [0, 0, 150, 267, 468, 477], [0, 0, 49, 452, 476],\n",
      " [0, 0, 268], [0, 0, 316, 420], [0, 0, 227], [0, 0, 86, 438, 510],\n",
      " [0, 0, 468, 488, 503], [0, 0, 273, 468], [0, 0, 119, 228, 348],\n",
      " [0, 0, 29, 235], [0, 0, 86], [0, 0, 29, 113, 117], [0, 0, 224, 468],\n",
      " [0, 0, 72], [0, 0, 54, 77, 360], [0, 0, 11, 17, 84],\n",
      " [0, 0, 58, 150, 227, 387], [0, 0, 229, 327, 387], [0, 0, 43, 149, 412],\n",
      " [0, 0, 101, 113, 205], [0, 0, 68, 113, 185, 239, 350, 468],\n",
      " [0, 0, 62, 63, 147, 365, 436], [0, 0, 56], [0, 0, 56, 165, 170, 395, 468],\n",
      " [0, 0, 70, 113, 133, 468], [0, 0, 113, 468], [0, 0, 5, 69, 186, 259],\n",
      " [0, 0, 56, 452, 470, 479], [0, 0, 43, 46, 267],\n",
      " [0, 0, 46, 56, 75, 433, 472], [0, 0, 175, 199, 212, 423], [0, 0, 43, 243],\n",
      " [0, 0, 146, 397], [0, 0, 230], [0, 0, 56, 85], [0, 0, 409],\n",
      " [0, 0, 46, 58, 132], [0, 0, 43, 228, 251, 388, 503],\n",
      " [0, 0, 118, 131, 503], [0, 0, 58, 119], [0, 0, 231], [0, 0, 296, 426],\n",
      " [0, 0, 43, 63, 205, 423], [0, 0, 43, 205], [0, 0, 46, 130, 134, 344],\n",
      " [0, 0, 54, 327], [0, 0, 84], [0, 0, 158, 161, 304, 421], [0, 0, 368, 423],\n",
      " [0, 0, 76, 468], [0, 0, 46, 489], [0, 0, 164, 383, 468],\n",
      " [0, 0, 262, 263, 314, 347, 394], [0, 0, 26, 184, 347, 468],\n",
      " [0, 0, 85, 188], [0, 0, 23, 191, 218, 377, 420, 429],\n",
      " [0, 0, 27, 199, 363, 442], [0, 0, 20, 46, 92, 171, 180, 260, 374],\n",
      " [0, 0, 3, 64, 123, 199, 282, 337, 433],\n",
      " [0, 0, 127, 138, 156, 187, 284, 454],\n",
      " [0, 0, 42, 103, 155, 160, 195, 243, 322, 340, 396, 424],\n",
      " [0, 0, 126, 237, 430],\n",
      " [0, 0, 124, 188, 217, 312, 317, 321, 331, 348, 376, 496],\n",
      " [0, 0, 41, 53, 83, 97, 199, 222, 257, 263, 321, 342, 402, 440],\n",
      " [0, 0, 67, 378, 401, 438],\n",
      " [0, 0, 2, 81, 87, 148, 236, 255, 283, 301, 359, 371],\n",
      " [0, 0, 19, 132, 228, 348, 381], [0, 0, 156, 245, 431, 473, 492],\n",
      " [0, 0, 26, 51, 205, 290, 325, 405], [0, 0, 60, 325], [0, 0, 14, 192],\n",
      " [0, 0, 170, 201, 289, 319, 334], [0, 0, 7, 40, 46, 117, 294, 393],\n",
      " [0, 0, 314, 380, 466], [0, 0, 134, 265, 338, 455], [0, 0, 54, 142],\n",
      " [0, 0, 46, 47, 110, 288, 342], [0, 0, 84, 105, 342, 365],\n",
      " [0, 0, 204, 281], [0, 0, 17, 46, 108, 190], [0, 0, 17, 266],\n",
      " [0, 0, 17, 31, 46, 68, 101, 140, 204], [0, 0, 50, 170, 199],\n",
      " [0, 0, 61, 181, 204, 246, 378], [0, 0, 277, 300, 391],\n",
      " [0, 0, 10, 85, 120, 135, 170, 199, 227, 253], [0, 0, 199, 291, 328, 369],\n",
      " [0, 0, 63, 170, 200, 369, 413], [0, 0, 25, 38, 348, 433], [0, 0, 15],\n",
      " [0, 0, 1, 21, 30, 70, 85, 100, 211, 387], [0, 0, 303, 341, 450],\n",
      " [0, 0, 66, 71, 199, 219, 293, 335, 348, 409, 470],\n",
      " [0, 0, 200, 220, 233, 375], [0, 0, 34, 60, 257],\n",
      " [0, 0, 6, 58, 107, 148, 250], [0, 0, 58, 286, 301, 321, 407],\n",
      " [0, 0, 100, 107, 132, 228], [0, 0, 213, 286, 342], [0, 0, 51, 206],\n",
      " [0, 0, 89, 224], [0, 0, 89, 406], [0, 0, 224], [0, 0, 58, 117, 199, 209],\n",
      " [0, 0, 100, 398], [0, 0, 93, 134, 169], [0, 0, 119, 280, 349],\n",
      " [0, 0, 54, 174, 264], [0, 0, 58, 197, 221, 258, 297, 409],\n",
      " [0, 0, 84, 227, 241, 293], [0, 0, 13, 227, 234, 268, 281], [0, 0, 144],\n",
      " [0, 0, 18, 37, 199, 223, 314, 350], [0, 0, 153],\n",
      " [0, 0, 25, 221, 227, 308, 348, 357], [0, 0, 387], [0, 0, 167, 227],\n",
      " [0, 0, 0, 151, 153, 227, 349, 433, 443], [0, 0, 151, 366],\n",
      " [0, 0, 18, 223, 263], [0, 0, 25, 228, 308, 392], [0, 0, 29, 311, 348],\n",
      " [0, 0, 125, 228, 348, 447], [0, 0, 29, 52, 57, 221], [0, 0, 409],\n",
      " [0, 0, 29, 32, 57, 58, 108, 202, 214, 308], [0, 0, 52, 132],\n",
      " [0, 0, 57, 58, 189, 409], [0, 0, 378], [0, 0, 51, 57, 378],\n",
      " [0, 0, 32, 199], [0, 0, 86, 221, 223, 297, 308, 387], [0, 0, 227, 419],\n",
      " [0, 0, 86, 223, 348, 354], [0, 0, 57, 199, 263], [0, 0, 108, 198],\n",
      " [0, 0, 79, 134, 183, 199, 243, 308], [0, 0, 54, 348, 378],\n",
      " [0, 0, 56, 190], [0, 0, 412], [0, 0, 84, 302, 308, 387, 415],\n",
      " [0, 0, 0, 90, 348], [0, 0, 0, 56, 108, 309], [0, 0, 0, 56, 168],\n",
      " [0, 0, 0, 167, 308], [0, 0, 0, 167], [0, 0, 56, 86, 190, 302, 378, 433],\n",
      " [0, 0, 56, 86, 378, 445], [0, 0, 308, 309], [0, 0, 184, 243],\n",
      " [0, 0, 86, 209, 348], [0, 0, 86, 343, 408], [0, 0, 184, 348],\n",
      " [0, 0, 32, 348], [0, 0, 16, 29, 63, 96, 152, 223, 348, 378],\n",
      " [0, 0, 49, 302, 378, 449], [0, 0, 16, 29, 49, 95, 223, 226, 309],\n",
      " [0, 0, 142, 343], [0, 0, 85, 225, 309],\n",
      " [0, 0, 40, 63, 225, 299, 308, 309], [0, 0, 51],\n",
      " [0, 0, 40, 45, 96, 248, 299, 308, 349],\n",
      " [0, 0, 40, 49, 85, 95, 119, 176, 313, 339, 349, 408],\n",
      " [0, 0, 55, 85, 106, 193, 302], [0, 0, 33, 96, 154, 173, 299, 339, 349],\n",
      " [0, 0, 32, 33, 96, 117, 154, 176, 239, 252, 339],\n",
      " [0, 0, 33, 96, 239, 339], [0, 0, 32, 176, 346, 408, 449],\n",
      " [0, 0, 29, 54, 176, 299, 329, 354],\n",
      " [0, 0, 29, 119, 128, 176, 232, 239, 252, 346, 449],\n",
      " [0, 0, 25, 100, 115, 239, 346, 399], [0, 0, 63, 182, 349, 477],\n",
      " [0, 0, 25, 29, 84, 173, 239, 281, 298, 399],\n",
      " [0, 0, 25, 74, 119, 173, 477], [0, 0, 29, 298, 342],\n",
      " [0, 0, 25, 204, 313, 342], [0, 0, 313], [0, 0, 25, 272, 345],\n",
      " [0, 0, 74, 112, 115, 122, 163, 285, 354], [0, 0, 36, 285, 411],\n",
      " [0, 0, 36, 91, 99, 100, 122, 163, 172, 285, 302],\n",
      " [0, 0, 25, 36, 63, 88, 95, 285, 342], [0, 0, 12, 161, 346],\n",
      " [0, 0, 65, 88, 95, 159, 163, 276, 372], [0, 0, 12, 65, 73, 95, 276],\n",
      " [0, 0, 72, 107, 276], [0, 0, 137, 215], [0, 0, 63],\n",
      " [0, 0, 25, 114, 323, 330], [0, 0, 28, 272], [0, 0, 137, 244],\n",
      " [0, 0, 25, 121, 128, 137, 161, 399], [0, 0, 161, 411],\n",
      " [0, 0, 25, 161, 198], [0, 0, 32, 121, 161, 244, 333],\n",
      " [0, 0, 117, 333, 346], [0, 0, 32], [0, 0, 25, 346, 399],\n",
      " [0, 0, 25, 49, 54], [0, 0, 25, 99, 241, 411], [0, 0, 49, 143, 399],\n",
      " [0, 0, 28, 39, 124, 399, 411], [0, 0, 28, 84, 143, 247, 399],\n",
      " [0, 0, 25, 39, 72, 73, 119, 247, 307, 411], [0, 0, 141, 307],\n",
      " [0, 0, 141, 159, 196, 228, 247], [0, 0, 228, 240, 247],\n",
      " [0, 0, 9, 247, 326], [0, 0, 141, 159, 247], [0, 0, 178],\n",
      " [0, 0, 8, 94, 141, 310, 435], [0, 0, 310], [0, 0, 228, 453],\n",
      " [0, 0, 22, 99, 119, 228], [0, 0, 141, 204], [0, 0, 196], [0, 0, 159],\n",
      " [0, 0, 256], [0, 0, 43], [0, 0, 43], [0, 0, 477], [0, 0, 43], [0, 0, 31],\n",
      " [0, 0, 196], [0, 0, 196, 256], [0, 0, 256], [0, 0, 256], [0, 0, 256],\n",
      " [0, 0, 39], [0, 0, 35], [0, 0, 194], [0, 0, 194], [0, 0, 31, 39],\n",
      " [0, 0, 31], [0, 0, 111], [0, 0, 31], [0, 0, 111], [0, 0, 70, 111],\n",
      " [0, 0, 70, 80, 111], [0, 0, 70, 80], [0, 0, 70], [0, 0, 70], [0, 0, 111],\n",
      " [0, 0, 111], [0, 0, 111], [0, 0, 179], [0, 0, 179], [0, 0, 179],\n",
      " [0, 0, 18], [0, 0, 102], [0, 0, 287], [0, 0, 287]]>\n"
     ]
    }
   ],
   "source": [
    "#multi-dimensional indexing test\n",
    "# a = tf.random.uniform([3,3])\n",
    "# print(a)\n",
    "# idx = tf.constant([[1,1],[2,2]])\n",
    "# b = tf.gather_nd(a, idx)\n",
    "# print(b)\n",
    "\n",
    "#test adding zeros to start of each ragged tensor\n",
    "# print(tf.shape(jumps_rag))\n",
    "zeros = tf.zeros(tf.shape(jumps_rag)[0])[:,None]\n",
    "zeros = tf.cast(tf.RaggedTensor.from_tensor(zeros), tf.int64)\n",
    "# print(tf.shape(zeros))\n",
    "# print(tf.shape(jumps_rag))\n",
    "test = tf.concat([zeros.with_row_splits_dtype(tf.int64), jumps_rag.with_row_splits_dtype(tf.int64)], axis = 1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbe43f",
   "metadata": {},
   "source": [
    "# fit_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg2(cloud, rag, npts):\n",
    "    \"\"\"new method of fitting gaussian to better handle ragged input data\"\"\"\n",
    "    numSamples = 3\n",
    "    \n",
    "    coords = tf.gather(cloud, rag)\n",
    "    mu = tf.math.reduce_mean(coords, axis = 1)[:,None]\n",
    "#     mu = tf.math.reduce_mean(coords, axis = 1) #old\n",
    "#     print(mu)\n",
    "\n",
    "#   TODO: try randomly sampling 30 points from each ragged cell, use reduced num pts to calculate covariance\n",
    "#     subsampled = tf.map_fn(sample, it.inside2) #works but SLOW\n",
    "#     subsampled = tf.map_fn(sample, it.inside2, parallel_iterations=True)\n",
    "#     subsampled = tf.gather(rag,tf.range(tf.shape(rag)[0]))[:numSamples] #wrong\n",
    "#     print(subsampled)\n",
    "\n",
    "    xpos = tf.gather(cloud[:,0], rag)\n",
    "    ypos = tf.gather(cloud[:,1], rag)\n",
    "    zpos = tf.gather(cloud[:,2], rag)\n",
    "#     c = tfp.stats.covariance(xpos.to_tensor(), ypos.to_tensor())\n",
    "\n",
    "#     print(xpos)\n",
    "    idx = tf.range(30)\n",
    "    xpos = tf.gather(xpos, idx, axis = 1)\n",
    "    ypos = tf.gather(ypos, idx, axis = 1)\n",
    "    zpos = tf.gather(zpos, idx, axis = 1)\n",
    "    print(xpos)\n",
    "\n",
    "    xx = tf.math.reduce_sum(tf.math.square(xpos - mu[:,:,0] ), axis = 1)/npts\n",
    "    yy = tf.math.reduce_sum(tf.math.square(ypos - mu[:,:,1] ), axis = 1)/npts\n",
    "    zz = tf.math.reduce_sum(tf.math.square(zpos - mu[:,:,2] ), axis = 1)/npts\n",
    "    xy = tf.math.reduce_sum( (xpos - mu[:,:,0])*(ypos - mu[:,:,1]), axis = 1)/npts  #+\n",
    "    xz = tf.math.reduce_sum( (xpos - mu[:,:,0])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "    yz = tf.math.reduce_sum( (ypos - mu[:,:,1])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "\n",
    "    sigma = tf.Variable([xx, xy, xz,\n",
    "                        xy, yy, yz,\n",
    "                        xz, yz, zz]) \n",
    "    sigma = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "        \n",
    "#     mu = None\n",
    "    return(mu, sigma)\n",
    "\n",
    "@tf.function\n",
    "def sample(x, samples=3):\n",
    "  \"\"\"https://stackoverflow.com/questions/71073873/sample-from-ragged-tensor\"\"\"  \n",
    "  length = tf.shape(x)[0]\n",
    "#   was this\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.random.shuffle(tf.range(length))[:samples]))\n",
    " \n",
    "#   test\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.range(length))[:samples])\n",
    "  x = tf.gather(x,tf.range(length))[:samples]\n",
    "\n",
    "    \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "mu2, sigma2 = it.fit_gaussian(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\"\\n took\", time.time() - s, \" s with old method\")\n",
    "\n",
    "s = time.time()\n",
    "mu2, sigma2 = fg2(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")\n",
    "\n",
    "# print(it.npts2)\n",
    "# print(it.inside2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c39b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect <tf.RaggedTensor [[], [1, 2, 3, 4], [5, 4, 3, 2, 1], [6], [99], [7, 8, 9, 10, 11, 12, 13]]>\n",
      "\n",
      " idx tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "\n",
      " test tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 1  2  3]\n",
      " [ 5  4  3]\n",
      " [ 6 99  7]\n",
      " [99  7  8]\n",
      " [ 7  8  9]], shape=(6, 3), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: object of type 'RaggedTensor' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m test\u001b[39m\u001b[38;5;124m\"\u001b[39m, test) \u001b[38;5;66;03m#NOTE: indices with too few elements produce unexpected behavior\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                         \u001b[38;5;66;03m#that doesn't matter since they get suppressed anyways\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m vec2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'RaggedTensor' has no len()\n"
     ]
    }
   ],
   "source": [
    "# vect = it.inside2\n",
    "vect = tf.ragged.constant([[],[1,2,3,4],[5,4,3,2,1],[6],[99],[7,8,9,10,11,12,13]])\n",
    "# print(tf.shape(vect)[0])\n",
    "print(\"vect\", vect)\n",
    "c = tf.map_fn(sample, vect)\n",
    "# print(c)\n",
    "\n",
    "#wrong\n",
    "# test = tf.gather(vect,tf.range(tf.shape(vect)[0]))[:3]\n",
    "idx = tf.range(3)\n",
    "print(\"\\n idx\", idx)\n",
    "test = tf.gather(vect, idx , axis = 1)\n",
    "print(\"\\n test\", test) #NOTE: indices with too few elements produce unexpected behavior\n",
    "                        #that doesn't matter since they get suppressed anyways\n",
    "    \n",
    "vec2 = tf.random.categorical(vect, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608026c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
