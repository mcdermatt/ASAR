{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df034054",
   "metadata": {},
   "source": [
    "# Notebook for identifying and removing bottlenecks from ICET implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc1c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "# tf.config.set_visible_devices([], 'GPU') #run on CPU only -- seems to actually execute main parts of code faster here...\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "from ICET_spherical import ICET\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook\n",
    "\n",
    "# %%bash\n",
    "# # python -m cProfile scan_match.py\n",
    "# python scan_match.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74e4c23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loading model took 4.76837158203125e-07 \n",
      " total:  5.7220458984375e-06\n",
      "\n",
      " shuffling and converting to tensor took  0.006495237350463867 \n",
      " total:  0.006583690643310547\n",
      "\n",
      " converting to spherical took 0.0327756404876709 \n",
      " total:  0.03940153121948242\n",
      "\n",
      " getting cluster took 0.5056931972503662 seconds !!!\n",
      "\n",
      " fit_gaussian for scan 1 0.029498577117919922 \n",
      " total:  0.9042644500732422\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.25449275970458984 \n",
      " total:  1.2374465465545654 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.0480183e-09  3.4007790e-06  3.6277578e-07 -4.4495103e-08\n",
      " -4.2737582e-08  4.9248877e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.022118091583251953 \n",
      " total:  1.2596476078033447 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.27145862579345703 \n",
      " total:  1.5315909385681152 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.0503055e-09  4.1004641e-06  2.7179695e-07 -4.4458101e-08\n",
      " -3.6679204e-08  7.3638586e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.026779890060424805 \n",
      " total:  1.5584590435028076 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.28116488456726074 \n",
      " total:  1.840160608291626 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.0536676e-09  4.7694029e-06  3.9066163e-07 -4.5225089e-08\n",
      " -3.6148514e-08  7.6288694e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.022101879119873047 \n",
      " total:  1.8623394966125488 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.26233863830566406 \n",
      " total:  2.125152349472046 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.0529392e-09  4.5325919e-06  3.0030131e-07 -4.4427825e-08\n",
      " -3.6862769e-08  7.2746724e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.022084474563598633 \n",
      " total:  2.1473281383514404 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.24298667907714844 \n",
      " total:  2.390840530395508 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.0515675e-09  4.3148966e-06  3.7612685e-07 -4.8020794e-08\n",
      " -3.5025284e-08  7.3539741e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.021920204162597656 \n",
      " total:  2.4128479957580566 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.25667238235473633 \n",
      " total:  2.6700000762939453 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-9.8262309e-10  4.0909440e-06  2.8593797e-07 -4.5423278e-08\n",
      " -3.8008164e-08  7.4294064e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.024119138717651367 \n",
      " total:  2.6942100524902344 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.25780534744262695 \n",
      " total:  2.95249605178833 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.3596394e-09  4.7582612e-06  4.0675377e-07 -4.4751875e-08\n",
      " -3.6531446e-08  7.6964761e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.028441429138183594 \n",
      " total:  2.9810149669647217 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.2981107234954834 \n",
      " total:  3.2796080112457275 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.02202916145324707 \n",
      " total:  3.3017148971557617 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.3601326e-09  4.1781636e-06  3.1517445e-07 -4.4094254e-08\n",
      " -3.7051290e-08  5.1205973e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.030305147171020508 \n",
      " total:  3.3320558071136475 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.24715399742126465 \n",
      " total:  3.579697370529175 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.01575493812561035 \n",
      " total:  3.5955350399017334 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[-1.3619889e-09  4.5255624e-06  3.9173435e-07 -4.7351087e-08\n",
      " -3.5212558e-08  5.3099228e-07], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.021620750427246094 \n",
      " total:  3.617191791534424 \n",
      " ~~~~~~~~~~~~~~\n",
      "pred_stds: \n",
      " tf.Tensor(\n",
      "[8.0373923e-15 1.6810230e-06 1.9112875e-07 3.1596297e-08 3.4375930e-08\n",
      " 4.5698553e-07], shape=(6,), dtype=float32)\n",
      " L2: \n",
      " tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# basepath = '/media/derm/06EF-127D1/KITTI'\n",
    "# # sequence = '03' #forest\n",
    "# sequence = '09' #trees and small town\n",
    "# dataset = pykitti.odometry(basepath, sequence)\n",
    "# velo1 = dataset.get_velo(400)\n",
    "# c1 = velo1[:,:3]\n",
    "# velo2 = dataset.get_velo(401)\n",
    "# c2 = velo2[:,:3]\n",
    "\n",
    "fn1 = \"/home/derm/ASAR/v3/spherical_paper/MC_trajectories/scene1_scan13.txt\"\n",
    "c1 = np.loadtxt(fn1)\n",
    "fn2 = \"/home/derm/ASAR/v3/spherical_paper/MC_trajectories/scene1_scan14.txt\"\n",
    "c2 = np.loadtxt(fn2)\n",
    "\n",
    "it = ICET(cloud1 = c1, cloud2 = c2, fid = 50, niter = 9, \n",
    "           draw = False, group = 2, RM = True, DNN_filter = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ff0c0",
   "metadata": {},
   "source": [
    "# get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cebb9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt2(rads, thresh = 0.5, mnp = 100):\n",
    "    \"\"\"testing new method of finding radial bins for spherical voxels\"\"\"\n",
    "    \n",
    "    before = time.time()\n",
    "\n",
    "    max_buffer = 0.2 \n",
    "\n",
    "    if len(tf.shape(rads)) < 2:\n",
    "        rads = rads[:,None]\n",
    "\n",
    "    OG_rads = rads #hold on to OG rads\n",
    "    #replace all zeros in rads (result of converting ragged -> standard tensor) with some arbitrarily large value\n",
    "    mask = tf.cast(tf.math.equal(rads, 0), tf.float32)*1000\n",
    "    rads = rads + mask\n",
    "    # print(rads)\n",
    "\n",
    "    #sort in ascending order for each column in tensor\n",
    "    top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "#     print(\"\\n top_k \\n\", top_k[1])\n",
    "    rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "    rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "    print(\"rads \\n\", rads)\n",
    "\n",
    "    # calculate the forward difference between neighboring points\n",
    "    z = tf.zeros([1, tf.shape(rads)[1].numpy()])\n",
    "    shifted = tf.concat((rads[1:], z), axis = 0)\n",
    "    diff = shifted - rads\n",
    "    # diff = tf.math.abs(rads - shifted) #debug 6/9/22\n",
    "#     print(\"\\n diff \\n\", diff)\n",
    "\n",
    "    # #find where difference jumps\n",
    "    jumps = tf.where(diff > thresh)\n",
    "#     print(\"\\n jumps \\n\", jumps) #[idx of jump, which spike is jumping]\n",
    "\n",
    "    #----------------------------------------------------------------------\n",
    "    #not sure if actually needed...\n",
    "    #get indexes of all used spikes\n",
    "    used = jumps[:,1][None,:]\n",
    "    # print(\"used\", used)\n",
    "    biggest = tf.math.reduce_max(used, axis = 1).numpy()[0]\n",
    "    # print(\"biggest\", biggest)\n",
    "    all_spikes = tf.cast(tf.linspace(0,biggest,biggest+1), tf.int64)[None,:] #list all spikes total\n",
    "    # print(\"all_spikes\", all_spikes)\n",
    "\n",
    "    #find differnce\n",
    "    missing = tf.sets.difference(all_spikes, used).values[None,:]\n",
    "    # print(\"\\n missing\", missing)\n",
    "    # z = tf.zeros(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # z = 51*tf.ones(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    #z should be this...\n",
    "    # print(\"\\n OG_rads\", OG_rads)\n",
    "    # ends = tf.math.argmax(OG_rads, axis = 0) #wrong -> not max arg, last nonzero argument!!\n",
    "    zero = tf.constant(0, dtype = tf.float32)\n",
    "    ends = tf.math.reduce_sum(tf.cast(tf.not_equal(OG_rads, zero), tf.int64), axis = 0) #correct\n",
    "    # print(\"\\n ends\", ends)\n",
    "\n",
    "    test = tf.gather(ends, missing[0])  #get index of last element of missing jump section\n",
    "    # print(\"\\n test\", test)\n",
    "    z = test[None,:]\n",
    "    z -= 2 #fixes indexing bug\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    missing = tf.transpose(tf.concat((z, missing), axis = 0))\n",
    "    # print(missing)\n",
    "\n",
    "    jumps = tf.concat((jumps, missing), axis = 0) #concat missing stuff back at the end of jumps\n",
    "#     print(\"\\n jumps after fix\", jumps)\n",
    "    #----------------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n jumps: \\n\", jumps.numpy())\n",
    "    \n",
    "    #find where the first large cluster occurs in each spike\n",
    "   \n",
    "\n",
    "    \n",
    "    bounds = None\n",
    "\n",
    "    return(bounds, jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f50c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " getting cluster took 0.626060962677002 seconds !!!\n",
      "\n",
      " took 0.626514196395874  s with old method \n",
      "\n",
      "\n",
      " bounds_old: \n",
      " tf.Tensor(\n",
      "[[ 6.24612904  8.17313671]\n",
      " [13.42310524 13.85848236]\n",
      " [17.12698936 19.22462273]\n",
      " [ 8.49700451  9.26582336]\n",
      " [ 4.87625551  6.12153435]\n",
      " [ 4.87632322  6.12142706]\n",
      " [19.32097054 22.42539024]\n",
      " [ 0.          0.        ]\n",
      " [ 6.24606848  8.17309666]\n",
      " [ 4.87628937  6.12145662]\n",
      " [ 6.24609518  8.17315769]\n",
      " [27.43743706 35.64250565]\n",
      " [ 8.80649471 12.60198975]\n",
      " [13.21931648 13.52005005]\n",
      " [15.29999828 17.19395065]\n",
      " [ 7.50367165  8.1603651 ]\n",
      " [ 8.41508961 12.00569153]\n",
      " [ 4.87628412  6.12150955]\n",
      " [ 4.87625456  6.12142181]\n",
      " [ 8.80651188 12.04703331]\n",
      " [ 0.          0.        ]\n",
      " [22.47119331 27.26955795]\n",
      " [ 6.24612474  8.17305088]\n",
      " [ 0.          0.        ]\n",
      " [15.3000164  16.33851814]\n",
      " [ 8.80652142 12.00578022]\n",
      " [ 6.24617672  8.55318737]\n",
      " [13.43597794 13.95995331]\n",
      " [14.59835339 15.70939255]\n",
      " [ 4.87631273  6.12150145]\n",
      " [ 4.87630606  6.1213932 ]\n",
      " [ 6.2460742   8.55319595]\n",
      " [ 8.4150753  12.00567532]\n",
      " [ 8.80648804 12.04695892]\n",
      " [ 8.41507149 12.00571632]\n",
      " [ 6.24611473  8.55319786]\n",
      " [ 8.4151516  12.00557232]\n",
      " [ 6.24610424  8.55323792]\n",
      " [ 8.41509914 12.00574398]\n",
      " [ 8.80646229 12.00575542]\n",
      " [ 4.87637234  6.12144852]\n",
      " [ 0.          0.        ]\n",
      " [ 6.24614906  8.55319786]\n",
      " [ 8.41504002 12.00571537]\n",
      " [ 8.80552864 12.04695606]\n",
      " [ 4.87633801  6.12144089]\n",
      " [ 6.24606466  8.55316925]\n",
      " [ 6.24609566  8.55326462]\n",
      " [16.61291122 17.33175659]\n",
      " [ 6.24616051  8.17310429]\n",
      " [ 6.24539709  8.55319881]\n",
      " [ 8.41509056 12.00575542]\n",
      " [ 8.80645847 12.04712009]\n",
      " [ 6.24608469  8.55323029]\n",
      " [ 8.41510201 12.0056572 ]\n",
      " [22.47117615 27.26982498]\n",
      " [ 6.24613523  8.55317783]\n",
      " [ 6.24611998  8.17310429]\n",
      " [ 4.87627506  6.12150431]\n",
      " [14.57697964 15.59994602]\n",
      " [ 4.87632084  6.12144947]\n",
      " [13.88248348 14.67231464]\n",
      " [ 4.87632895  6.1214447 ]\n",
      " [ 6.24615717  7.75403881]\n",
      " [ 0.          0.        ]\n",
      " [ 6.24615669  8.17314148]\n",
      " [ 6.2461257   8.55331898]\n",
      " [ 6.24606657  8.17311764]\n",
      " [13.88245869 14.67194748]\n",
      " [ 4.87627745  6.12136745]\n",
      " [ 4.87639856  6.12145758]\n",
      " [ 0.          0.        ]\n",
      " [ 8.50419426  9.37304974]\n",
      " [ 8.8065052  12.0469923 ]\n",
      " [ 8.41512394 12.00586987]\n",
      " [ 6.24613476  8.17307854]\n",
      " [ 8.80643368 12.04694176]\n",
      " [ 4.87585354  6.12148619]\n",
      " [16.01163101 20.54033852]\n",
      " [ 0.          0.        ]\n",
      " [ 4.8763113   6.1214757 ]\n",
      " [ 6.24607038  8.55327129]\n",
      " [ 8.80641747 12.04704571]\n",
      " [ 4.87630367  6.12150764]\n",
      " [ 4.87633419  6.12143135]\n",
      " [ 6.24608326  8.55317974]\n",
      " [ 4.87594271  6.12142324]\n",
      " [ 6.24608994  8.55323792]\n",
      " [ 7.57539511 12.00572681]\n",
      " [13.20963192 13.4220705 ]\n",
      " [ 8.41508389 12.00564861]\n",
      " [13.2194128  13.52027512]\n",
      " [ 6.24551821  8.55320358]\n",
      " [ 8.49189281  9.19564056]\n",
      " [35.95036316 44.81879425]\n",
      " [14.59829998 15.70910263]\n",
      " [13.42302895 13.85832596]\n",
      " [13.18812466 13.31557274]\n",
      " [ 4.87627697  6.12142086]\n",
      " [13.43126011 13.9517765 ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.2455163   8.55323887]\n",
      " [ 4.87631369  6.1215415 ]\n",
      " [ 8.41510487 12.00571442]\n",
      " [ 6.24604988  8.17310143]\n",
      " [ 0.          0.        ]\n",
      " [ 4.87633228  6.12143946]\n",
      " [ 8.41507626 12.00571537]\n",
      " [ 6.24611044  8.17300415]\n",
      " [ 8.41510677 12.00570774]\n",
      " [35.95040512 44.81897736]\n",
      " [26.02440453 26.72254372]\n",
      " [16.55619621 20.54035378]\n",
      " [ 6.24551296  8.55324268]\n",
      " [ 4.87635946  6.12141657]\n",
      " [16.55613708 20.5403595 ]\n",
      " [ 8.80649853 12.04698181]\n",
      " [ 4.87630272  6.12144232]\n",
      " [ 4.8763423   6.1214323 ]\n",
      " [ 6.24611807  8.55321789]\n",
      " [22.5256424  27.35632896]\n",
      " [13.2096777  13.42180061]\n",
      " [ 6.24612665  8.55318546]\n",
      " [ 6.24609756  8.17315006]\n",
      " [ 4.87633801  6.12144852]\n",
      " [ 8.41511726 12.00566196]\n",
      " [ 7.54060698  8.20464802]\n",
      " [ 6.24607992  8.55324459]\n",
      " [ 8.80651569 12.04708767]\n",
      " [ 8.80645084 12.04705906]\n",
      " [ 8.80648232 12.005723  ]\n",
      " [ 4.87632799  6.12142754]\n",
      " [ 6.24611807  8.55324268]\n",
      " [35.74513245 36.60674667]\n",
      " [ 4.87629271  6.12147617]\n",
      " [ 7.44073439  7.7139616 ]\n",
      " [ 0.          0.        ]\n",
      " [13.42767906 13.86618614]\n",
      " [ 6.24609661  8.55326462]\n",
      " [ 8.80577183 12.04696465]\n",
      " [ 6.24608994  8.17310524]\n",
      " [17.12689018 19.22472191]\n",
      " [13.87384987 14.57376862]\n",
      " [13.21784687 13.51579094]\n",
      " [ 4.87635279  6.12138462]\n",
      " [ 8.41511631 12.005723  ]\n",
      " [ 6.24613905  8.17312908]\n",
      " [ 0.          0.        ]\n",
      " [36.11047745 45.07469559]\n",
      " [ 6.24606991  8.17306232]\n",
      " [ 4.87632704  6.12141514]\n",
      " [14.58902264 15.61706257]\n",
      " [ 6.24612188  8.17315674]\n",
      " [ 0.          0.        ]\n",
      " [ 6.24561119  8.55321407]\n",
      " [ 8.8065033  12.04702854]\n",
      " [ 6.24603796  8.17308998]\n",
      " [19.32104874 22.42526054]\n",
      " [ 8.41506004 12.00564575]\n",
      " [ 8.41505814 12.00566578]\n",
      " [ 4.87635088  6.12158775]\n",
      " [ 4.8763051   6.12146139]\n",
      " [19.28495026 22.37155151]\n",
      " [15.30006313 16.33829689]\n",
      " [ 8.80648327 12.56381798]\n",
      " [ 6.24557829  8.55334949]\n",
      " [ 4.87637568  6.12161398]\n",
      " [ 8.41508579 12.0056839 ]\n",
      " [17.15180588 19.26037407]\n",
      " [13.18259048 13.21602631]\n",
      " [15.30001259 16.41005898]\n",
      " [16.01163673 20.5404129 ]\n",
      " [ 4.8763504   6.12143564]\n",
      " [ 4.87637234  6.12136412]\n",
      " [ 4.87635279  6.12147617]\n",
      " [ 8.80649376 12.60202312]\n",
      " [13.21776676 13.51587868]\n",
      " [13.18251419 13.21587276]\n",
      " [ 4.87632275  6.12141991]\n",
      " [ 8.41513252 12.00578594]\n",
      " [27.52526283 35.79968643]\n",
      " [13.8738203  14.57368279]\n",
      " [15.64258575 17.1122818 ]\n",
      " [ 7.53588247  8.14261341]\n",
      " [15.30002594 17.17512894]\n",
      " [13.43146706 13.95191383]\n",
      " [ 7.61245871 12.00563335]\n",
      " [ 8.80558586 12.04701424]\n",
      " [ 4.87589359  6.12151384]\n",
      " [13.87471104 14.65997887]\n",
      " [ 4.87634706  6.12144041]\n",
      " [ 4.87634659  6.12149668]\n",
      " [ 0.          0.        ]\n",
      " [ 8.41503906 12.00568867]\n",
      " [ 6.24612236  8.17307186]\n",
      " [ 0.          0.        ]\n",
      " [ 6.24610853  8.17306995]\n",
      " [ 4.87632084  6.12147665]\n",
      " [ 8.80649948 12.04699039]\n",
      " [14.58902264 15.6169672 ]\n",
      " [ 7.37594032  7.57120466]\n",
      " [ 6.24610519  8.1731081 ]\n",
      " [ 8.8065033  12.00575733]\n",
      " [13.18814659 13.31550789]\n",
      " [15.29996681 17.42061806]\n",
      " [ 8.8064642  12.04695129]\n",
      " [ 6.24612713  8.5531683 ]\n",
      " [15.62509632 17.08767891]\n",
      " [ 4.87624359  6.12142563]\n",
      " [ 4.87634802  6.12143517]\n",
      " [13.21111679 13.42659187]\n",
      " [ 4.87630606  6.12154865]\n",
      " [ 4.87631941  6.12145281]\n",
      " [24.92836952 26.73045921]\n",
      " [14.58624077 15.69184113]\n",
      " [ 0.          0.        ]\n",
      " [ 4.87628889  6.12151623]\n",
      " [ 4.87627554  6.12154198]\n",
      " [ 0.          0.        ]\n",
      " [ 8.80650806 12.56391716]\n",
      " [ 8.41513824 12.00568867]\n",
      " [ 4.87635374  6.12138748]\n",
      " [ 8.49870872  9.30191135]\n",
      " [ 6.24613667  8.55324268]\n",
      " [ 8.41507816 12.00580311]\n",
      " [ 6.24611521  8.55328846]\n",
      " [ 6.24609566  8.17310524]\n",
      " [ 8.41511726 12.00565529]\n",
      " [ 4.87585402  6.12147331]\n",
      " [ 6.24615955  8.55326748]\n",
      " [ 4.87639427  6.1215682 ]\n",
      " [13.86583328 14.56189346]\n",
      " [ 7.3728261   7.52015591]\n",
      " [19.28495789 22.37166405]\n",
      " [27.4374218  35.64260101]\n",
      " [13.43592167 13.96002579]\n",
      " [ 7.499084    8.09820938]\n",
      " [13.42744446 13.86605453]\n",
      " [ 8.8056488  12.0470047 ]\n",
      " [ 0.          0.        ]\n",
      " [22.52565193 27.35613823]\n",
      " [ 0.          0.        ]\n",
      " [13.21110153 13.42642307]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]], shape=(245, 2), dtype=float64)\n",
      "(245, 2)\n",
      "rads \n",
      " tf.Tensor(\n",
      "[[   6.246075   13.422641   17.126602 ...   13.210769   53.34173\n",
      "    53.34177 ]\n",
      " [   6.246129   13.423105   17.12699  ...   13.211102   53.343002\n",
      "    53.34266 ]\n",
      " [   6.246139   13.423246   17.127121 ...   13.211243   53.34325\n",
      "    53.343163]\n",
      " ...\n",
      " [1000.       1000.       1000.       ... 1000.       1000.\n",
      "  1000.      ]\n",
      " [1000.       1000.       1000.       ... 1000.       1000.\n",
      "  1000.      ]\n",
      " [1000.       1000.       1000.       ... 1000.       1000.\n",
      "  1000.      ]], shape=(540, 245), dtype=float32)\n",
      "\n",
      " jumps: \n",
      " [[  4 243]\n",
      " [  4 244]\n",
      " [  9 243]\n",
      " ...\n",
      " [538 203]\n",
      " [538 214]\n",
      " [538 235]]\n",
      " \n",
      " took 0.013584613800048828  s with new method\n"
     ]
    }
   ],
   "source": [
    "from utils import get_cluster\n",
    "# print(\"rads: \\n\", it.rads)\n",
    "\n",
    "s = time.time()\n",
    "bounds_old = get_cluster(it.rads, mnp = it.min_num_pts)\n",
    "print(\"\\n took\", time.time() - s, \" s with old method \\n\")\n",
    "print(\"\\n bounds_old: \\n\", bounds_old)\n",
    "print(np.shape(bounds_old))\n",
    "\n",
    "s = time.time()\n",
    "bounds_new, jumps = gt2(it.rads, mnp = it.min_num_pts)\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7756ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old slow soln shape: \n",
      " tf.Tensor([245   2], shape=(2,), dtype=int32)\n",
      "\n",
      " jumps_rag \n",
      " <tf.RaggedTensor [[0, 243, 244], [0, 243, 244], [0, 243, 244], [0, 133],\n",
      " [0, 7, 20, 23, 41, 64, 71, 79, 100, 105, 112, 115, 136, 147, 153, 192, 195,\n",
      "  213, 215, 218, 239, 241]                                                  ,\n",
      " [0, 7, 20, 23, 24, 41, 64, 71, 79, 100, 105, 136, 147, 153, 163, 170, 192,\n",
      "  195, 213, 215, 218, 239, 241]                                            ,\n",
      " [0, 7, 20, 23, 24, 41, 64, 71, 79, 100, 105, 136, 153, 163, 170, 195, 213,\n",
      "  218, 239, 241]                                                           ,\n",
      " [0, 183], [0, 94, 110, 148],\n",
      " [0, 7, 20, 23, 24, 41, 64, 71, 79, 94, 100, 105, 110, 136, 148, 153, 163,\n",
      "  170, 195, 213, 218, 239, 241]                                           ]>\n",
      "\n",
      " npts_between_jumps:\n",
      "  tf.Tensor(\n",
      "[[ 243    1 -244    0    0    0    0    0    0    0]\n",
      " [ 243    1 -244    0    0    0    0    0    0    0]\n",
      " [ 243    1 -244    0    0    0    0    0    0    0]\n",
      " [ 133 -133    0    0    0    0    0    0    0    0]\n",
      " [   7   13    3   18   23    7    8   21    5    7]\n",
      " [   7   13    3    1   17   23    7    8   21    5]\n",
      " [   7   13    3    1   17   23    7    8   21    5]\n",
      " [ 183 -183    0    0    0    0    0    0    0    0]\n",
      " [  94   16   38 -148    0    0    0    0    0    0]\n",
      " [   7   13    3    1   17   23    7    8   15    6]], shape=(10, 10), dtype=int64)\n",
      "\n",
      " biggest_jump \n",
      " tf.Tensor(\n",
      "[243 243 243 133  39  31  31 183  94  26  94 236  94  94  94 133  94  26\n",
      "  94  94  94  94  94  94  26 126 180 223 126  54  15 120 111  44 151 162\n",
      " 213  48  36 239 105 105 213 213 213  33 213 105 105 213  19 112  72 105\n",
      " 105  72  19  72  72 112 186  88 105 105  19 105 133 186   3 213 213  88\n",
      " 213 204 204 186 204  88   8 105 105 168 204  79  78 186  78  78  56  93\n",
      "  93  93  93  93  93  93  36], shape=(97,), dtype=int64)\n",
      "\n",
      " no_good_clusters \n",
      " tf.Tensor(\n",
      "[0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1], shape=(97,), dtype=int32)\n",
      "\n",
      " first_big_enough: \n",
      " tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(15,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#identifying location of jumps without looping\n",
    "print(\"old slow soln shape: \\n\", tf.shape(bounds_old)) #want to produce this same shape!!!\n",
    "# print(\"\\n bounds_old: \\n\", bounds_old[:10])\n",
    "\n",
    "#get all radial measurements\n",
    "#(temp-- already done inside function)-----------------------------\n",
    "mask = tf.cast(tf.math.equal(it.rads, 0), tf.float32)*1000\n",
    "rads = it.rads + mask\n",
    "#sort in ascending order for each column in tensor\n",
    "top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "# print(\"\\n rads: \\n\", rads[:10])\n",
    "# print(\"\\n it.rads \\n\", it.rads)\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# print(\"\\n jumps: \\n\", tf.shape(jumps))\n",
    "# print(\"\\n jumps: \\n\",jumps[:30])\n",
    "\n",
    "y, idx = tf.unique(jumps[:,0])\n",
    "# print(\"\\n y \\n\", y, \"\\n \\n idx\", idx)\n",
    "# print(\"\\n jumps \\n\", jumps)\n",
    "\n",
    "# get ragged tensor containing indices where jumps occur sin each wedge shaped voxel\n",
    "jumps_rag = tf.RaggedTensor.from_value_rowids(jumps[:,1], idx)\n",
    "# append 0 to beginning of each ragged elemet of jumps_rag\n",
    "zeros = tf.zeros(tf.shape(jumps_rag)[0])[:,None]\n",
    "zeros = tf.cast(tf.RaggedTensor.from_tensor(zeros), tf.int64)\n",
    "jumps_rag = tf.concat([zeros.with_row_splits_dtype(tf.int64), jumps_rag.with_row_splits_dtype(tf.int64)], axis = 1)\n",
    "print(\"\\n jumps_rag \\n\", jumps_rag[:10])\n",
    "# print(\"\\n jumps_rag \\n\", tf.shape(jumps_rag))\n",
    "\n",
    "#get num points between each jump \n",
    "npts_between_jumps = tf.experimental.numpy.diff(jumps_rag.to_tensor())\n",
    "print(\"\\n npts_between_jumps:\\n \",npts_between_jumps[:10,:10])\n",
    "# print(\"\\n npts_between_jumps:\\n \",npts_between_jumps)\n",
    "\n",
    "#flag spikes where all npts_between_jumps are less than mnp\n",
    "biggest_jump = tf.math.reduce_max(npts_between_jumps, axis = 1)\n",
    "print(\"\\n biggest_jump \\n\", biggest_jump)\n",
    "mnp = 50 #minumum number of points per cluster (defined in ICET class)\n",
    "no_good_clusters = tf.cast(tf.math.less(biggest_jump, mnp), tf.int32)\n",
    "print(\"\\n no_good_clusters \\n\", no_good_clusters)\n",
    "\n",
    "#get idx within jumps_rag corresponding to first sufficiently large jump\n",
    "big_enough = tf.cast(tf.math.greater(npts_between_jumps, 100), tf.int32)\n",
    "# print(big_enough[:10])\n",
    "first_big_enough = tf.math.argmax(big_enough, axis = 1)\n",
    "print(\"\\n first_big_enough: \\n\", first_big_enough[:15])\n",
    "# print(\"\\n first_big_enough: \\n\", first_big_enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92a61db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " inner: \n",
      " tf.Tensor([0 0 0 0 0 0 0 0 0 0], shape=(10,), dtype=int64)\n",
      "tf.Tensor(540, shape=(), dtype=int32)\n",
      "tf.Tensor([539], shape=(1,), dtype=int32)\n",
      "\n",
      " idx \n",
      " tf.Tensor(\n",
      "[[  0   0]\n",
      " [  1   0]\n",
      " [  2   0]\n",
      " ...\n",
      " [537   0]\n",
      " [538   0]\n",
      " [539   0]], shape=(540, 2), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 15:18:59.091895: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at gather_nd_op.cc:46 : INVALID_ARGUMENT: indices[539] = [0, 539] does not index into param shape [540,245], node name: GatherNd\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[539] = [0, 539] does not index into param shape [540,245], node name: GatherNd [Op:GatherNd]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# idx1 = tf.concat((inner[:,None], tf.cast(tf.range(len(inner))[:,None], tf.int64)), axis = 1) #test\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m idx \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, idx)\n\u001b[0;32m---> 22\u001b[0m inside_bound \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather_nd(rads, idx1)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m inside_bound \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, inside_bound[:\u001b[38;5;241m15\u001b[39m])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#repeat for outside bound\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[539] = [0, 539] does not index into param shape [540,245], node name: GatherNd [Op:GatherNd]"
     ]
    }
   ],
   "source": [
    "#(continuted)\n",
    "#------------------\n",
    "#get inner and outer (temp simple way-- just use radial measurements of inner and outermost points in cluster)\n",
    "inner = tf.gather(jumps_rag.to_tensor(), first_big_enough, batch_dims = 1)\n",
    "print(\"\\n inner: \\n\", inner[:10])\n",
    "# print(\"\\n inner: \\n\", inner)\n",
    "\n",
    "#infill zero elements throughout (use tf.ragged.from_value_rowids keyed by y)\n",
    "inner = tf.RaggedTensor.from_value_rowids(inner, y).to_tensor()[:,0]\n",
    "#add zeros to end of bounds to get to same number of total voxels as OG_rads \n",
    "print(tf.shape(rads)[0])\n",
    "print(tf.shape(inner))\n",
    "# inner = tf.pad(inner, [[0,tf.shape(rads)[1]-len(inner)]]) #old\n",
    "inner = tf.pad(inner, [[0,tf.shape(rads)[0]-len(inner)]]) #new\n",
    "# print(\"\\n inner \\n\", inner)\n",
    "# print(\"\\n inner \\n\", tf.shape(inner))\n",
    "\n",
    "#concat idx and y, use gather_nd instead of converting to ragged and back?? \n",
    "idx = tf.concat((tf.cast(tf.range(len(inner))[:,None], tf.int64), inner[:,None]), axis = 1) #wrong?\n",
    "# idx1 = tf.concat((inner[:,None], tf.cast(tf.range(len(inner))[:,None], tf.int64)), axis = 1) #test\n",
    "print(\"\\n idx \\n\", idx)\n",
    "inside_bound = tf.gather_nd(rads, idx1)\n",
    "print(\"\\n inside_bound \\n\", inside_bound[:15])\n",
    "\n",
    "#repeat for outside bound\n",
    "outer = tf.gather(jumps_rag.to_tensor(), first_big_enough +1, batch_dims = 1)\n",
    "outer = tf.RaggedTensor.from_value_rowids(outer, y).to_tensor()[:,0]\n",
    "outer = tf.pad(outer, [[0,tf.shape(rads)[1]-len(outer)]]) #DEBUG-- make sure I'm using correct dimension of tf.shape(rads)\n",
    "idx2 = tf.concat((outer[:,None], tf.cast(tf.range(len(outer))[:,None], tf.int64)), axis = 1) #test\n",
    "outside_bound = tf.gather_nd(rads, idx2)\n",
    "print(\"\\n outside_bound \\n\", outside_bound[:15])\n",
    "\n",
    "#------------------\n",
    "\n",
    "# #test-----------------\n",
    "# #infill zero elements throughout (use tf.ragged.from_value_rowids keyed by y)\n",
    "# first_big_enough = tf.RaggedTensor.from_value_rowids(first_big_enough, y).to_tensor()[:,0]\n",
    "# #add zeros to end of bounds to get to same number of total voxels as OG_rads \n",
    "# first_big_enough = tf.pad(first_big_enough, [[0,tf.shape(rads)[1]-len(first_big_enough)]])\n",
    "# print(\"\\n first_big_enough: \\n\", first_big_enough[:15])\n",
    "\n",
    "# # inner_idx = tf.gather(jumps_rag.to_tensor(), first_big_enough)\n",
    "# # idx = tf.concat((tf.cast(tf.range(len(inner))[:,None], tf.int64), inner[:,None]), axis = 1)\n",
    "# #--------------------\n",
    "\n",
    "#TODO add voxel length padding \n",
    "#  (max half distance betweeen last in cluster and first point outside cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec14bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#multi-dimensional indexing test\n",
    "# a = tf.random.uniform([3,3])\n",
    "# print(a)\n",
    "# idx = tf.constant([[1,1],[2,2]])\n",
    "# b = tf.gather_nd(a, idx)\n",
    "# print(b)\n",
    "\n",
    "#test adding zeros to start of each ragged tensor\n",
    "# print(tf.shape(jumps_rag))\n",
    "zeros = tf.zeros(tf.shape(jumps_rag)[0])[:,None]\n",
    "zeros = tf.cast(tf.RaggedTensor.from_tensor(zeros), tf.int64)\n",
    "# print(tf.shape(zeros))\n",
    "# print(tf.shape(jumps_rag))\n",
    "test = tf.concat([zeros.with_row_splits_dtype(tf.int64), jumps_rag.with_row_splits_dtype(tf.int64)], axis = 1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbe43f",
   "metadata": {},
   "source": [
    "# fit_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg2(cloud, rag, npts):\n",
    "    \"\"\"new method of fitting gaussian to better handle ragged input data\"\"\"\n",
    "    numSamples = 3\n",
    "    \n",
    "    coords = tf.gather(cloud, rag)\n",
    "    mu = tf.math.reduce_mean(coords, axis = 1)[:,None]\n",
    "#     mu = tf.math.reduce_mean(coords, axis = 1) #old\n",
    "#     print(mu)\n",
    "\n",
    "#   TODO: try randomly sampling 30 points from each ragged cell, use reduced num pts to calculate covariance\n",
    "#     subsampled = tf.map_fn(sample, it.inside2) #works but SLOW\n",
    "#     subsampled = tf.map_fn(sample, it.inside2, parallel_iterations=True)\n",
    "#     subsampled = tf.gather(rag,tf.range(tf.shape(rag)[0]))[:numSamples] #wrong\n",
    "#     print(subsampled)\n",
    "\n",
    "    xpos = tf.gather(cloud[:,0], rag)\n",
    "    ypos = tf.gather(cloud[:,1], rag)\n",
    "    zpos = tf.gather(cloud[:,2], rag)\n",
    "#     c = tfp.stats.covariance(xpos.to_tensor(), ypos.to_tensor())\n",
    "\n",
    "#     print(xpos)\n",
    "    idx = tf.range(30)\n",
    "    xpos = tf.gather(xpos, idx, axis = 1)\n",
    "    ypos = tf.gather(ypos, idx, axis = 1)\n",
    "    zpos = tf.gather(zpos, idx, axis = 1)\n",
    "    print(xpos)\n",
    "\n",
    "    xx = tf.math.reduce_sum(tf.math.square(xpos - mu[:,:,0] ), axis = 1)/npts\n",
    "    yy = tf.math.reduce_sum(tf.math.square(ypos - mu[:,:,1] ), axis = 1)/npts\n",
    "    zz = tf.math.reduce_sum(tf.math.square(zpos - mu[:,:,2] ), axis = 1)/npts\n",
    "    xy = tf.math.reduce_sum( (xpos - mu[:,:,0])*(ypos - mu[:,:,1]), axis = 1)/npts  #+\n",
    "    xz = tf.math.reduce_sum( (xpos - mu[:,:,0])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "    yz = tf.math.reduce_sum( (ypos - mu[:,:,1])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "\n",
    "    sigma = tf.Variable([xx, xy, xz,\n",
    "                        xy, yy, yz,\n",
    "                        xz, yz, zz]) \n",
    "    sigma = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "        \n",
    "#     mu = None\n",
    "    return(mu, sigma)\n",
    "\n",
    "@tf.function\n",
    "def sample(x, samples=3):\n",
    "  \"\"\"https://stackoverflow.com/questions/71073873/sample-from-ragged-tensor\"\"\"  \n",
    "  length = tf.shape(x)[0]\n",
    "#   was this\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.random.shuffle(tf.range(length))[:samples]))\n",
    " \n",
    "#   test\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.range(length))[:samples])\n",
    "  x = tf.gather(x,tf.range(length))[:samples]\n",
    "\n",
    "    \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "mu2, sigma2 = it.fit_gaussian(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\"\\n took\", time.time() - s, \" s with old method\")\n",
    "\n",
    "s = time.time()\n",
    "mu2, sigma2 = fg2(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")\n",
    "\n",
    "# print(it.npts2)\n",
    "# print(it.inside2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c39b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect <tf.RaggedTensor [[], [1, 2, 3, 4], [5, 4, 3, 2, 1], [6], [99], [7, 8, 9, 10, 11, 12, 13]]>\n",
      "\n",
      " idx tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "\n",
      " test tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 1  2  3]\n",
      " [ 5  4  3]\n",
      " [ 6 99  7]\n",
      " [99  7  8]\n",
      " [ 7  8  9]], shape=(6, 3), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: object of type 'RaggedTensor' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m test\u001b[39m\u001b[38;5;124m\"\u001b[39m, test) \u001b[38;5;66;03m#NOTE: indices with too few elements produce unexpected behavior\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                         \u001b[38;5;66;03m#that doesn't matter since they get suppressed anyways\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m vec2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'RaggedTensor' has no len()\n"
     ]
    }
   ],
   "source": [
    "# vect = it.inside2\n",
    "vect = tf.ragged.constant([[],[1,2,3,4],[5,4,3,2,1],[6],[99],[7,8,9,10,11,12,13]])\n",
    "# print(tf.shape(vect)[0])\n",
    "print(\"vect\", vect)\n",
    "c = tf.map_fn(sample, vect)\n",
    "# print(c)\n",
    "\n",
    "#wrong\n",
    "# test = tf.gather(vect,tf.range(tf.shape(vect)[0]))[:3]\n",
    "idx = tf.range(3)\n",
    "print(\"\\n idx\", idx)\n",
    "test = tf.gather(vect, idx , axis = 1)\n",
    "print(\"\\n test\", test) #NOTE: indices with too few elements produce unexpected behavior\n",
    "                        #that doesn't matter since they get suppressed anyways\n",
    "    \n",
    "vec2 = tf.random.categorical(vect, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608026c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
