{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df034054",
   "metadata": {},
   "source": [
    "# Notebook for identifying and removing bottlenecks from ICET implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc1c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:45:02.509489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 16:45:03.129978: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-27 16:45:04.120045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-27 16:45:04.120139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-27 16:45:04.120146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-27 16:45:05.466886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:05.578677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:05.578952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:45:05.878743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 16:45:05.880226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:05.880422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:05.880561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:06.803608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:06.803848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:06.804031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 16:45:06.804157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "# tf.config.set_visible_devices([], 'GPU') #run on CPU only -- seems to actually execute main parts of code faster here...\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "from ICET_spherical import ICET\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook\n",
    "\n",
    "# %%bash\n",
    "# # python -m cProfile scan_match.py\n",
    "# python scan_match.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e4c23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth poses are not avaialble for sequence 09.\n",
      "\n",
      " loading model took 4.76837158203125e-07 \n",
      " total:  5.0067901611328125e-06\n",
      "\n",
      " shuffling and converting to tensor took  0.012696027755737305 \n",
      " total:  0.012722015380859375\n",
      "\n",
      " converting to spherical took 0.1445903778076172 \n",
      " total:  0.15732693672180176\n",
      "\n",
      " getting cluster took 0.4924807548522949 seconds !!!\n",
      "\n",
      " fit_gaussian for scan 1 0.045018672943115234 \n",
      " total:  0.846733808517456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:45:10.450968: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-11-27 16:45:10.520179: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x84a4f60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05652356147766113 \n",
      " total:  2.3468685150146484 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.2882643   0.02340015  0.00240992 -0.00082739  0.00107237 -0.0050481 ], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.6005465984344482 \n",
      " total:  2.9474680423736572 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.04670572280883789 \n",
      " total:  2.9946579933166504 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 5.7045066e-01  1.6899558e-02  6.7746909e-03 -4.9210084e-04\n",
      "  1.4997894e-03 -2.4524932e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01548910140991211 \n",
      " total:  3.0101685523986816 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.041318416595458984 \n",
      " total:  3.051738739013672 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 7.54447639e-01  1.06849279e-02  1.01552475e-02 -5.68593270e-04\n",
      "  1.74943893e-03  1.21660996e-05], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.015802383422851562 \n",
      " total:  3.067560911178589 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.04346060752868652 \n",
      " total:  3.1112751960754395 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 8.5498261e-01  9.4913431e-03  1.1190054e-02 -3.8290620e-04\n",
      "  1.9344859e-03  1.3419795e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.015557050704956055 \n",
      " total:  3.1268510818481445 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.04314589500427246 \n",
      " total:  3.1702497005462646 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.0119147e-01  1.0699836e-02  1.2114017e-02 -3.6564076e-04\n",
      "  2.0296175e-03  2.1441644e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01680922508239746 \n",
      " total:  3.187105655670166 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.04457426071166992 \n",
      " total:  3.231961727142334 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.21601593e-01  1.12603838e-02  1.18092075e-02 -1.98800990e-04\n",
      "  2.07913946e-03  2.43837293e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01677417755126953 \n",
      " total:  3.2487595081329346 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05138516426086426 \n",
      " total:  3.300412893295288 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.2971718e-01  1.1615807e-02  1.1929913e-02 -1.9444249e-04\n",
      "  2.0848722e-03  2.5653541e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.02075791358947754 \n",
      " total:  3.3212060928344727 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.047452688217163086 \n",
      " total:  3.3689188957214355 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.017629384994506836 \n",
      " total:  3.386568546295166 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.2876995e-01  1.1718589e-02  1.1939676e-02 -1.9853140e-04\n",
      "  2.0918786e-03  2.6000005e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01682424545288086 \n",
      " total:  3.4034206867218018 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05337834358215332 \n",
      " total:  3.4572131633758545 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.011728048324584961 \n",
      " total:  3.4689626693725586 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.2848295e-01  1.1766404e-02  1.1925073e-02 -1.9916683e-04\n",
      "  2.0908755e-03  2.5983769e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016275882720947266 \n",
      " total:  3.4852511882781982 \n",
      " ~~~~~~~~~~~~~~\n",
      "pred_stds: \n",
      " tf.Tensor(\n",
      "[1.57394388e-03 5.28894656e-04 1.10012086e-04 2.74085414e-05\n",
      " 1.68870738e-05 1.19968987e-04], shape=(6,), dtype=float32)\n",
      " L2: \n",
      " tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "basepath = '/media/derm/06EF-127D1/KITTI'\n",
    "# sequence = '03' #forest\n",
    "sequence = '09' #trees and small town\n",
    "dataset = pykitti.odometry(basepath, sequence)\n",
    "velo1 = dataset.get_velo(400)\n",
    "c1 = velo1[:,:3]\n",
    "velo2 = dataset.get_velo(401)\n",
    "c2 = velo2[:,:3]\n",
    "\n",
    "# fn1 = \"/home/derm/ASAR/v3/spherical_paper/MC_trajectories/scene1_scan13.txt\"\n",
    "# c1 = np.loadtxt(fn1)\n",
    "# fn2 = \"/home/derm/ASAR/v3/spherical_paper/MC_trajectories/scene1_scan14.txt\"\n",
    "# c2 = np.loadtxt(fn2)\n",
    "\n",
    "it = ICET(cloud1 = c1, cloud2 = c2, fid = 50, niter = 9, \n",
    "           draw = False, group = 2, RM = True, DNN_filter = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ff0c0",
   "metadata": {},
   "source": [
    "# get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebb9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt2(rads, thresh = 0.5, mnp = 100):\n",
    "    \"\"\"testing new method of finding radial bins for spherical voxels\"\"\"\n",
    "    \n",
    "    before = time.time()\n",
    "\n",
    "    max_buffer = 0.2 \n",
    "\n",
    "    if len(tf.shape(rads)) < 2:\n",
    "        rads = rads[:,None]\n",
    "\n",
    "    OG_rads = rads #hold on to OG rads\n",
    "    #replace all zeros in rads (result of converting ragged -> standard tensor) with some arbitrarily large value\n",
    "    mask = tf.cast(tf.math.equal(rads, 0), tf.float32)*1000\n",
    "    rads = rads + mask\n",
    "    # print(rads)\n",
    "\n",
    "    #sort in ascending order for each column in tensor\n",
    "    top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "#     print(\"\\n top_k \\n\", top_k[1])\n",
    "    rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "    rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "#     print(\"rads \\n\", rads)\n",
    "\n",
    "    # calculate the forward difference between neighboring points\n",
    "    z = tf.zeros([1, tf.shape(rads)[1].numpy()])\n",
    "    shifted = tf.concat((rads[1:], z), axis = 0)\n",
    "    diff = shifted - rads\n",
    "\n",
    "    # #find where difference jumps\n",
    "    jumps = tf.where(diff > thresh)\n",
    "#     print(\"\\n jumps \\n\", jumps) #[idx of jump, which spike is jumping]\n",
    "\n",
    "    #----------------------------------------------------------------------\n",
    "    #not sure if actually needed...\n",
    "    #get indexes of all used spikes\n",
    "    used = jumps[:,1][None,:]\n",
    "    # print(\"used\", used)\n",
    "    biggest = tf.math.reduce_max(used, axis = 1).numpy()[0]\n",
    "    # print(\"biggest\", biggest)\n",
    "    all_spikes = tf.cast(tf.linspace(0,biggest,biggest+1), tf.int64)[None,:] #list all spikes total\n",
    "    # print(\"all_spikes\", all_spikes)\n",
    "\n",
    "    #find differnce\n",
    "    missing = tf.sets.difference(all_spikes, used).values[None,:]\n",
    "    # print(\"\\n missing\", missing)\n",
    "    # z = tf.zeros(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # z = 51*tf.ones(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    #z should be this...\n",
    "    # print(\"\\n OG_rads\", OG_rads)\n",
    "    # ends = tf.math.argmax(OG_rads, axis = 0) #wrong -> not max arg, last nonzero argument!!\n",
    "    zero = tf.constant(0, dtype = tf.float32)\n",
    "    ends = tf.math.reduce_sum(tf.cast(tf.not_equal(OG_rads, zero), tf.int64), axis = 0) #correct\n",
    "    # print(\"\\n ends\", ends)\n",
    "\n",
    "    test = tf.gather(ends, missing[0])  #get index of last element of missing jump section\n",
    "    # print(\"\\n test\", test)\n",
    "    z = test[None,:]\n",
    "    z -= 2 #fixes indexing bug\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    missing = tf.transpose(tf.concat((z, missing), axis = 0))\n",
    "    # print(missing)\n",
    "\n",
    "    jumps = tf.concat((jumps, missing), axis = 0) #concat missing stuff back at the end of jumps\n",
    "#     print(\"\\n jumps after fix\", jumps)\n",
    "    #----------------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n jumps: \\n\", jumps)\n",
    "    \n",
    "    #find where the first large cluster occurs in each spike\n",
    "   \n",
    "\n",
    "    \n",
    "    bounds = None\n",
    "\n",
    "    return(bounds, jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f50c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " getting cluster took 0.4227633476257324 seconds !!!\n",
      "\n",
      " took 0.42305421829223633  s with old method \n",
      "\n",
      "\n",
      " bounds_old: \n",
      " tf.Tensor(\n",
      "[[ 8.5336237  14.82997036]\n",
      " [ 6.87181711 11.42481709]\n",
      " [29.31493568 42.68794632]\n",
      " [ 9.48455429 15.15051174]\n",
      " [ 7.33260059 11.61510181]\n",
      " [ 3.22240448  3.43098164]\n",
      " [ 6.44483805  9.70490646]\n",
      " [ 4.55999422  5.19567156]\n",
      " [10.68612194 12.32955456]\n",
      " [ 8.53601074 10.99322033]], shape=(10, 2), dtype=float64)\n",
      "(247, 2)\n",
      "\n",
      " getting cluster took 0.019646406173706055 seconds !!!\n",
      "\n",
      " bounds_new: \n",
      " tf.Tensor(\n",
      "[[ 8.522524  14.541453 ]\n",
      " [ 6.7979364 11.412506 ]\n",
      " [27.810429  42.660294 ]\n",
      " [ 9.476366  14.949856 ]\n",
      " [ 7.323119  11.605854 ]\n",
      " [ 3.2152867  3.4199846]\n",
      " [ 6.439029   9.676741 ]\n",
      " [ 4.553308   5.183438 ]\n",
      " [10.583586  12.2757635]\n",
      " [ 8.534277  10.990534 ]], shape=(10, 2), dtype=float32)\n",
      " \n",
      " took 0.02012801170349121  s with new method\n"
     ]
    }
   ],
   "source": [
    "from utils import get_cluster, get_cluster_fast\n",
    "# print(\"rads: \\n\", it.rads)\n",
    "\n",
    "s = time.time()\n",
    "bounds_old = get_cluster(it.rads, mnp = it.min_num_pts)\n",
    "print(\"\\n took\", time.time() - s, \" s with old method \\n\")\n",
    "print(\"\\n bounds_old: \\n\", bounds_old[:10])\n",
    "print(np.shape(bounds_old))\n",
    "\n",
    "s = time.time()\n",
    "# bounds_new, jumps = gt2(it.rads, mnp = it.min_num_pts)\n",
    "bounds_new = get_cluster_fast(it.rads, mnp = it.min_num_pts)\n",
    "print(\"\\n bounds_new: \\n\", bounds_new[:10])\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7756ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old slow soln shape: \n",
      " tf.Tensor([247   2], shape=(2,), dtype=int32)\n",
      "\n",
      " y \n",
      " tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14], shape=(15,), dtype=int64) \n",
      " tf.Tensor([247], shape=(1,), dtype=int32) \n",
      " \n",
      " idx \n",
      " tf.Tensor([0 0 1 1 1 1 1 1 2 2 2 2 2 2 2], shape=(15,), dtype=int32) \n",
      " tf.Tensor([793], shape=(1,), dtype=int32)\n",
      "\n",
      " rads[0,_] \n",
      " tf.Tensor(\n",
      "[8.522524  8.533624  8.546218  8.55991   8.569108  8.572579  8.577195\n",
      " 8.584386  8.585438  8.611754  8.617272  8.625081  8.626165  8.634203\n",
      " 8.636234  8.636838  8.637456  8.651796  8.652797  8.655872  8.65624\n",
      " 8.663728  8.6686325 8.670218  8.671909  8.680213  8.680515  8.685126\n",
      " 8.693569  8.69501  ], shape=(30,), dtype=float32)\n",
      "\n",
      " jumps_rag \n",
      " <tf.RaggedTensor [[0, 602, 603], [0, 498, 718, 719, 725, 806, 812],\n",
      " [0, 43, 87, 131, 175, 220, 264, 308, 710, 712, 798, 813, 818, 819],\n",
      " [0, 586, 587, 588], [0, 476, 519], [0, 537, 582], [0, 502], [0, 213],\n",
      " [0, 101, 102, 105, 107, 490], [0, 322, 367, 457, 502, 547, 591, 636],\n",
      " [0, 744, 745, 746, 748], [0, 597, 598, 599, 600, 603], [0, 538], [0, 503],\n",
      " [0, 612, 622, 639]]>\n",
      "\n",
      " good_clusters (hold on to this for later) \n",
      " tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0], shape=(247,), dtype=int32)\n",
      "\n",
      " first_big_enough: \n",
      " tf.Tensor(\n",
      "[ 0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  6  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  1  1  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 16  0  0  0\n",
      "  0  1  0  0  0  0  0  1  0  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  1  1  0  0  0  0  1  0  2  0  1  3  0  0  0  7  0  0  0\n",
      "  0  0  1  0  0  0  0  0  4  0  0  0  2  0  1  0  1  5  2  0  0  0  0  0\n",
      "  0  0  0  1  0  0  0  0 15  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  2  0  0  0  0  0  2  0  0  0  1  0  1  0  0  0  1  0  0  0\n",
      "  0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0], shape=(247,), dtype=int64)\n",
      "\n",
      " everything looks good up to this point :)\n"
     ]
    }
   ],
   "source": [
    "#identifying location of jumps without looping\n",
    "print(\"old slow soln shape: \\n\", tf.shape(bounds_old)) #want to produce this same shape!!!\n",
    "# print(\"\\n bounds_old: \\n\", bounds_old[:10])\n",
    "\n",
    "#get all radial measurements\n",
    "#(temp-- already done inside function)-----------------------------\n",
    "mask = tf.cast(tf.math.equal(it.rads, 0), tf.float32)*1000\n",
    "rads = it.rads + mask\n",
    "#sort in ascending order for each column in tensor\n",
    "top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "# print(\"\\n rads: \\n\", rads[:10])\n",
    "# print(\"\\n rads: \\n\", np.shape(rads))\n",
    "# print(\"\\n it.rads \\n\", it.rads)\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# print(\"\\n jumps: \\n\", tf.shape(jumps))\n",
    "# print(\"\\n jumps: \\n\", jumps) #[idx of jump, which spike is jumping]\n",
    "\n",
    "# y, idx = tf.unique(jumps[:,0]) #was this\n",
    "jumps_temp = tf.gather(jumps, tf.argsort(jumps[:,1]), axis=0) #reorder based on index\n",
    "y, idx = tf.unique(jumps_temp[:,1]) #test\n",
    "print(\"\\n y \\n\", y[:15], \"\\n\", tf.shape(y), \"\\n \\n idx \\n\", idx[:15], \"\\n\", tf.shape(idx))\n",
    "# print(\"\\n jumps_temp \\n\", jumps_temp[:15])\n",
    "# print(\"\\n jumps[:,_]: \\n\", jumps[:,0])\n",
    "\n",
    "# get ragged tensor containing indices where jumps occur inside each wedge shaped voxel\n",
    "# jumps_rag = tf.RaggedTensor.from_value_rowids(jumps[:,1], idx) #WAS THIS --wrong!!\n",
    "\n",
    "jumps_rag = tf.RaggedTensor.from_value_rowids(jumps_temp[:,0], jumps_temp[:,1]) #TEST - should be this??\n",
    "# jumps_rag = tf.RaggedTensor.from_value_rowids(jumps[:,1], jumps[:,0]) #TEST\n",
    "# print(\"\\n jumps_rag \\n\", jumps_rag[:15])\n",
    "print(\"\\n rads[0,_] \\n\", rads[:30,0])\n",
    "\n",
    "\n",
    "# append 0 to beginning of each ragged elemet of jumps_rag\n",
    "zeros = tf.zeros(tf.shape(jumps_rag)[0])[:,None]\n",
    "zeros = tf.cast(tf.RaggedTensor.from_tensor(zeros), tf.int64)\n",
    "jumps_rag = tf.concat([zeros.with_row_splits_dtype(tf.int64), jumps_rag.with_row_splits_dtype(tf.int64)], axis = 1)\n",
    "print(\"\\n jumps_rag \\n\", jumps_rag[:15])\n",
    "# print(\"\\n jumps_rag \\n\", jumps_rag.to_tensor())\n",
    "\n",
    "#get num points between each jump \n",
    "npts_between_jumps = tf.experimental.numpy.diff(jumps_rag.to_tensor())\n",
    "# print(\"\\n npts_between_jumps:\\n \",npts_between_jumps[:10,:10])\n",
    "# print(\"\\n npts_between_jumps:\\n \",npts_between_jumps)\n",
    "\n",
    "#flag spikes where all npts_between_jumps are less than mnp\n",
    "biggest_jump = tf.math.reduce_max(npts_between_jumps, axis = 1)\n",
    "# print(\"\\n biggest_jump \\n\", biggest_jump)\n",
    "mnp = 100 #minumum number of points per cluster (defined in ICET class)\n",
    "good_clusters = tf.cast(tf.math.greater(biggest_jump, mnp), tf.int32)\n",
    "# good_clusters = tf.RaggedTensor.from_value_rowids(good_clusters, y).to_tensor()[:,0]  #fill in skipped indices\n",
    "print(\"\\n good_clusters (hold on to this for later) \\n\", good_clusters)\n",
    "\n",
    "#get idx within jumps_rag corresponding to first sufficiently large jump\n",
    "big_enough = tf.cast(tf.math.greater(npts_between_jumps, 100), tf.int32)\n",
    "# print(big_enough[:10])\n",
    "first_big_enough = tf.math.argmax(big_enough, axis = 1)\n",
    "print(\"\\n first_big_enough: \\n\", first_big_enough)\n",
    "# print(\"\\n first_big_enough: \\n\", first_big_enough)\n",
    "\n",
    "print(\"\\n everything looks good up to this point :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e5266f74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.522524  14.541453 ]\n",
      " [ 6.7979364 11.412506 ]\n",
      " [27.810429  42.660294 ]\n",
      " [ 9.476366  14.949856 ]\n",
      " [ 7.323119  11.605854 ]\n",
      " [ 3.2152867  3.4199846]\n",
      " [ 6.439029   9.676741 ]\n",
      " [ 4.553308   5.183438 ]\n",
      " [10.583586  12.2757635]\n",
      " [ 8.534277  10.990534 ]\n",
      " [ 7.3641324  9.163473 ]\n",
      " [ 9.827092  13.412587 ]\n",
      " [ 4.4736133  6.4647164]\n",
      " [ 5.4322524  8.0986805]\n",
      " [ 7.2821875  9.111587 ]\n",
      " [ 6.429257   8.14609  ]\n",
      " [ 5.6875544  8.22032  ]\n",
      " [ 7.3912487 11.784734 ]\n",
      " [ 3.184801   3.3724418]\n",
      " [20.301628  26.280018 ]\n",
      " [ 6.316912   7.9331627]\n",
      " [12.843592  13.716571 ]\n",
      " [ 4.45389    5.0881677]\n",
      " [ 4.2877073  4.974927 ]\n",
      " [ 8.358009  15.102823 ]\n",
      " [ 7.557136  13.214449 ]\n",
      " [ 6.534025   8.523699 ]\n",
      " [26.140818  31.868149 ]\n",
      " [ 3.570882   4.049336 ]\n",
      " [ 3.3989444  4.90052  ]\n",
      " [ 6.9524817 13.892774 ]\n",
      " [16.547949  31.744976 ]\n",
      " [ 6.164683   7.63967  ]\n",
      " [ 5.5995975  7.8524923]\n",
      " [12.339181  13.730462 ]\n",
      " [ 4.3467436  5.264814 ]\n",
      " [ 4.879744   6.309086 ]\n",
      " [ 5.2533135  7.2804375]\n",
      " [ 4.4016423  5.292855 ]\n",
      " [ 6.5445576 10.054061 ]\n",
      " [11.01975   16.61229  ]\n",
      " [ 2.2459195  5.913182 ]\n",
      " [10.550849  11.847686 ]\n",
      " [ 4.9212623  6.5439095]\n",
      " [ 3.2599356  5.347102 ]\n",
      " [17.550495  23.402489 ]\n",
      " [ 5.743952   6.46776  ]\n",
      " [ 7.504178  13.623266 ]\n",
      " [ 4.284515   5.0440245]\n",
      " [ 4.884039  14.787328 ]\n",
      " [ 4.628094   5.519573 ]\n",
      " [12.155548  15.764299 ]\n",
      " [ 4.503432   5.148718 ]\n",
      " [ 4.1782327  4.80688  ]\n",
      " [ 5.216215   7.4705358]\n",
      " [13.013313  17.384672 ]\n",
      " [ 7.0360975 11.522577 ]\n",
      " [ 5.6261888  8.308146 ]\n",
      " [ 4.9783382  6.6429453]\n",
      " [ 6.6289253  8.774899 ]\n",
      " [ 4.231694   4.902011 ]\n",
      " [ 5.7478237  7.9226046]\n",
      " [ 5.3732824  6.727049 ]\n",
      " [ 6.482811   9.842282 ]\n",
      " [15.20188   29.642231 ]\n",
      " [ 7.2456045 12.155133 ]\n",
      " [ 4.3378496  5.2959614]\n",
      " [ 7.548961  13.185008 ]\n",
      " [11.996191  18.773    ]\n",
      " [ 5.1146927  7.033653 ]\n",
      " [ 6.87527   11.05158  ]\n",
      " [ 3.2677007  4.420605 ]\n",
      " [ 4.2958655  5.4939666]\n",
      " [21.371506  29.292927 ]\n",
      " [ 6.6965523  8.583441 ]\n",
      " [ 5.117547   7.2043586]\n",
      " [ 5.0169764  7.4203935]\n",
      " [ 6.499327   8.735938 ]\n",
      " [20.579397  32.340473 ]\n",
      " [ 5.002077   6.344604 ]\n",
      " [ 8.489985  10.972036 ]\n",
      " [ 7.82664    9.91175  ]\n",
      " [15.710832  16.214926 ]\n",
      " [ 4.2394485  4.9639125]\n",
      " [ 3.358301   4.1191483]\n",
      " [ 8.259904  13.342706 ]\n",
      " [ 4.4587502  4.9608264]\n",
      " [ 6.361728   8.244221 ]\n",
      " [ 4.8807373  6.4417505]\n",
      " [ 5.586936   7.821101 ]\n",
      " [ 5.2992773  9.43529  ]\n",
      " [ 7.473721  12.021357 ]\n",
      " [60.136898  69.312965 ]\n",
      " [ 4.831764   5.5822115]\n",
      " [ 8.396652  14.152786 ]\n",
      " [ 9.951272  18.300163 ]\n",
      " [10.393739  17.480406 ]\n",
      " [ 2.303664   5.228184 ]\n",
      " [ 3.5135264  4.0310807]\n",
      " [ 4.333486   5.5490484]\n",
      " [ 3.9977384  4.739354 ]\n",
      " [ 5.0117736  5.6051536]\n",
      " [ 6.416884   9.583557 ]\n",
      " [ 5.104098   9.320953 ]\n",
      " [ 6.742506  10.631742 ]\n",
      " [ 3.2788403  5.424754 ]\n",
      " [17.02124   23.33477  ]\n",
      " [ 6.2365794  7.720794 ]\n",
      " [12.709918  22.43401  ]\n",
      " [ 5.1072054  7.028887 ]\n",
      " [ 4.379091   5.8660865]\n",
      " [ 8.726687  10.803078 ]\n",
      " [10.767283  12.274259 ]\n",
      " [ 5.0453024  6.8228745]\n",
      " [ 3.38219    5.571987 ]\n",
      " [ 4.675681   5.8556833]\n",
      " [ 9.878347  20.8165   ]\n",
      " [ 7.261455  11.477992 ]\n",
      " [11.511446  13.624962 ]\n",
      " [ 5.6240473  7.9491897]\n",
      " [ 3.7639115  4.3554544]\n",
      " [ 8.465306  10.199658 ]\n",
      " [ 3.3376372  4.2934012]\n",
      " [ 8.089634  13.212239 ]\n",
      " [10.684753  16.302372 ]\n",
      " [14.129338  27.202927 ]\n",
      " [ 3.397109   5.5845494]\n",
      " [ 6.320382   8.999492 ]\n",
      " [ 3.4037063  5.231035 ]\n",
      " [ 4.267149   4.9648576]\n",
      " [ 4.6846614  6.650497 ]\n",
      " [ 2.7668858  7.2629976]\n",
      " [ 8.449831  14.983509 ]\n",
      " [63.507427  74.27592  ]\n",
      " [11.108151  12.032744 ]\n",
      " [ 3.289943   5.411745 ]\n",
      " [17.026665  20.985788 ]\n",
      " [ 3.2556338  3.4962258]\n",
      " [ 6.46418    8.293905 ]\n",
      " [ 4.377577   4.8397493]\n",
      " [37.442036  41.958076 ]\n",
      " [15.302305  18.341564 ]\n",
      " [ 3.367468   3.852553 ]\n",
      " [ 7.158551  13.275279 ]\n",
      " [ 4.201394   4.878622 ]\n",
      " [ 4.8558855  6.3405857]\n",
      " [ 4.3481245 12.88197  ]\n",
      " [ 5.206258   7.4399867]\n",
      " [ 8.004379  14.375328 ]\n",
      " [ 6.1646256  7.9569798]\n",
      " [ 6.733628   8.3074465]\n",
      " [ 4.969198   6.472672 ]\n",
      " [42.277348  48.35745  ]\n",
      " [ 6.297245   9.4646845]\n",
      " [10.15557   18.771479 ]\n",
      " [ 6.141406   9.197318 ]\n",
      " [15.774376  23.513298 ]\n",
      " [ 4.3961535  4.995075 ]\n",
      " [ 2.6998036  5.0681086]\n",
      " [ 5.637609   6.9525514]\n",
      " [17.49643   29.545176 ]\n",
      " [18.534792  22.619606 ]\n",
      " [ 9.925438  13.341051 ]\n",
      " [ 8.495631  17.321146 ]\n",
      " [ 4.3438234  5.1004944]\n",
      " [ 5.140816   7.062725 ]\n",
      " [ 5.7411575  6.3519726]\n",
      " [ 5.245723   7.068107 ]\n",
      " [14.09732   14.788738 ]\n",
      " [ 3.4877949  5.229812 ]\n",
      " [ 7.9343243 15.986709 ]\n",
      " [12.424781  23.408134 ]\n",
      " [ 5.1803565  7.7195287]\n",
      " [ 3.2694721  3.5403802]\n",
      " [10.760703  15.601354 ]\n",
      " [ 4.835713   6.320031 ]\n",
      " [56.36145   60.571903 ]\n",
      " [ 2.9856813  4.9600706]\n",
      " [ 6.0732565  7.4648046]\n",
      " [ 8.267883  12.863779 ]\n",
      " [ 3.5606604  3.754878 ]\n",
      " [ 3.2749722  4.3630967]\n",
      " [ 4.284246   5.0312457]\n",
      " [ 4.8939624  5.475046 ]\n",
      " [11.986931  13.440241 ]\n",
      " [ 8.47364    9.587919 ]\n",
      " [26.488834  28.211353 ]\n",
      " [ 3.4676542  4.0882998]\n",
      " [ 8.345512  12.519516 ]\n",
      " [ 3.185937   3.4318168]\n",
      " [ 5.1672177  7.1217785]\n",
      " [ 4.368697   5.2740173]\n",
      " [13.247302  16.260298 ]\n",
      " [ 3.3853722  4.1338058]\n",
      " [20.250042  23.367964 ]\n",
      " [ 8.443696  10.805728 ]\n",
      " [14.041873  20.38938  ]\n",
      " [ 8.725428  13.702904 ]\n",
      " [ 4.8157897  6.155527 ]\n",
      " [ 6.6266284 10.322149 ]\n",
      " [ 4.4605026  5.1399555]\n",
      " [ 4.8873806  5.540472 ]\n",
      " [12.819023  18.57038  ]\n",
      " [ 4.350948   4.7926526]\n",
      " [ 3.8532877  4.441451 ]\n",
      " [ 4.847113   6.37426  ]\n",
      " [ 3.4207807  5.7034326]\n",
      " [ 5.655535   8.011262 ]\n",
      " [ 3.645092   5.144943 ]\n",
      " [ 3.932908   4.7696724]\n",
      " [ 4.936266   5.094731 ]\n",
      " [ 5.1645584  7.3518977]\n",
      " [10.058903  12.192071 ]\n",
      " [ 8.642368  10.761019 ]\n",
      " [ 5.4365563  7.9310794]\n",
      " [ 4.6436687  5.708494 ]\n",
      " [11.625726  13.208314 ]\n",
      " [ 4.185963   4.822247 ]\n",
      " [32.65981   47.99317  ]\n",
      " [12.569258  18.780977 ]\n",
      " [ 3.2981603  4.108026 ]\n",
      " [ 7.9248843 10.122801 ]\n",
      " [ 3.5639498  3.7447624]\n",
      " [25.4291    31.4496   ]\n",
      " [ 4.198239   4.849397 ]\n",
      " [ 4.3300953  5.6022153]\n",
      " [ 8.368917  14.352038 ]\n",
      " [ 3.4909122  4.4261403]\n",
      " [ 6.3962345  7.8497133]\n",
      " [ 3.5875049  3.930584 ]\n",
      " [ 4.1791053  4.790954 ]\n",
      " [ 4.52738    5.1892343]\n",
      " [ 4.245995   4.7089844]\n",
      " [ 3.730365   4.1848526]\n",
      " [ 5.576806   8.096378 ]\n",
      " [ 3.4089413  5.0286546]\n",
      " [ 5.3897405  8.148342 ]\n",
      " [ 3.3871553  3.852978 ]\n",
      " [ 3.2385838  3.5904548]\n",
      " [43.938576  44.583683 ]\n",
      " [ 4.287508   5.0436554]\n",
      " [ 4.8200293  5.050805 ]\n",
      " [ 4.426933   4.7317104]\n",
      " [ 4.680234   4.971085 ]\n",
      " [ 4.9532394  5.1329327]\n",
      " [ 3.5214775  3.9785638]\n",
      " [ 5.6153393  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "#get inner and outer (temp simple way-- just use radial measurements of inner and outermost points in cluster)\n",
    "# print(\"jumps_rag.to_tensor(): \\n\", jumps_rag.to_tensor(), \"\\n\")\n",
    "\n",
    "#get index of radial measurements that defines inner bounds of voxel \n",
    "inner_idx = tf.gather(jumps_rag.to_tensor(), first_big_enough, batch_dims=1)\n",
    "# print(\"\\n inner_idx: \\n\", inner_idx, \"\\n\")\n",
    "inner  = tf.gather(tf.transpose(rads), inner_idx, batch_dims=1)\n",
    "# print(\"\\n inner: \\n\", inner)\n",
    "\n",
    "outer_idx = tf.gather(jumps_rag.to_tensor(), first_big_enough + 1, batch_dims=1) - 1 #DEBUG: figure out if I need -1\n",
    "# print(\"\\n outer_idx: \\n\", outer_idx, \"\\n\")\n",
    "outer  = tf.gather(tf.transpose(rads), outer_idx, batch_dims=1)\n",
    "# print(\"\\n outer: \\n\", outer)\n",
    "\n",
    "bounds = np.array([inner, outer]).T\n",
    "print(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92a61db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(871, shape=(), dtype=int32)\n",
      "tf.Tensor([247], shape=(1,), dtype=int32)\n",
      "\n",
      " idx \n",
      " tf.Tensor(\n",
      "[[  0   0]\n",
      " [  1   0]\n",
      " [  2 308]\n",
      " [  3   0]\n",
      " [  4   0]\n",
      " [  5   0]\n",
      " [  6   0]], shape=(7, 2), dtype=int64)\n",
      "\n",
      " inside_bound \n",
      " tf.Tensor(\n",
      "[8.522524 8.533624 0.       8.55991  8.569108 8.572579 8.577195 8.584386\n",
      " 8.585438 8.611754 8.617272 8.625081 8.626165 8.634203 8.636234], shape=(15,), dtype=float32)\n",
      "\n",
      " outside_bound \n",
      " tf.Tensor(\n",
      "[14.82997   11.424817  42.687946  15.150512  11.615102   3.4309816\n",
      "  9.704906   5.1956716 12.329555  10.99322    9.232235  13.532985\n",
      "  6.536972   8.101664   9.171636 ], shape=(15,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#infill zero elements throughout (use tf.ragged.from_value_rowids keyed by y)\n",
    "inner = tf.RaggedTensor.from_value_rowids(inner, y).to_tensor()[:,0]\n",
    "#add zeros to end of bounds to get to same number of total voxels as OG_rads \n",
    "print(tf.shape(rads)[0])\n",
    "print(tf.shape(inner))\n",
    "# inner = tf.pad(inner, [[0,tf.shape(rads)[1]-len(inner)]]) #old\n",
    "inner = tf.pad(inner, [[0,tf.shape(rads)[0]-len(inner)-1]]) #new\n",
    "# print(\"\\n inner \\n\", inner)\n",
    "# print(\"\\n inner \\n\", tf.shape(inner))\n",
    "\n",
    "#concat idx and y, use gather_nd instead of converting to ragged and back?? \n",
    "idx1 = tf.concat((tf.cast(tf.range(len(inner))[:,None], tf.int64), inner[:,None]), axis = 1) #wrong?\n",
    "# idx1 = tf.concat((inner[:,None], tf.cast(tf.range(len(inner))[:,None], tf.int64)), axis = 1) #test\n",
    "print(\"\\n idx \\n\", idx1[:7])\n",
    "inside_bound = tf.gather_nd(rads, idx1)\n",
    "print(\"\\n inside_bound \\n\", inside_bound[:15])\n",
    "\n",
    "#repeat for outside bound\n",
    "outer = tf.gather(jumps_rag.to_tensor(), first_big_enough +1, batch_dims = 1)\n",
    "outer = tf.RaggedTensor.from_value_rowids(outer, y).to_tensor()[:,0]\n",
    "outer = tf.pad(outer, [[0,tf.shape(rads)[0]-len(outer)-1]])\n",
    "idx2 = tf.concat((outer[:,None], tf.cast(tf.range(len(outer))[:,None], tf.int64)), axis = 1) #test\n",
    "outside_bound = tf.gather_nd(rads, idx2)\n",
    "print(\"\\n outside_bound \\n\", outside_bound[:15])\n",
    "\n",
    "\n",
    "#TODO add voxel length padding \n",
    "#  (max half distance betweeen last in cluster and first point outside cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "557cd8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1], shape=(1,), dtype=int32)\n",
      "tf.Tensor([[  0 602 603]], shape=(1, 3), dtype=int64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1104, in __len__\n    raise TypeError(\"Scalar tensor has no `len()`\")\n\nTypeError: Scalar tensor has no `len()`\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m start_pt_idx  \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(jumps_rag, tf\u001b[38;5;241m.\u001b[39mgather(first_big_enough, spike_id))\u001b[38;5;241m.\u001b[39mto_tensor()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_pt_idx)\n\u001b[0;32m---> 13\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mspike_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pt_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m test \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather_nd(rads, idx)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(test)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1104, in __len__\n    raise TypeError(\"Scalar tensor has no `len()`\")\n\nTypeError: Scalar tensor has no `len()`\n\n"
     ]
    }
   ],
   "source": [
    "#debug\n",
    "\n",
    "#init output vector\n",
    "# bounds = np.zeros([tf.shape(first_big_enough)[0], 2]) #DEBUG: why is first_big_enough longer than total cells?\n",
    "bounds = np.zeros([tf.shape(rads)[1].numpy(), 2]) #what I should have\n",
    "\n",
    "spike_id = tf.constant([1])\n",
    "print(spike_id)\n",
    "\n",
    "start_pt_idx  = tf.gather(jumps_rag, tf.gather(first_big_enough, spike_id)).to_tensor()\n",
    "print(start_pt_idx)\n",
    "\n",
    "idx = tf.constant([spike_id, start_pt_idx])\n",
    "test = tf.gather_nd(rads, idx)\n",
    "print(test)\n",
    "\n",
    "# for i in range(tf.shape(first_big_enough)[0]):\n",
    "\n",
    "#     inner = tf.gather(rads, )\n",
    "    \n",
    "#     bounds[i, 0] = inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ec14bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.10179257 0.6037365  0.48156595]\n",
      " [0.53692627 0.8813385  0.3952589 ]\n",
      " [0.6917515  0.13837957 0.05244076]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor([0.8813385  0.05244076], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#multi-dimensional indexing test\n",
    "a = tf.random.uniform([3,3])\n",
    "print(a)\n",
    "idx = tf.constant([[1,1],[2,2]])\n",
    "b = tf.gather_nd(a, idx)\n",
    "print(b)\n",
    "\n",
    "#test adding zeros to start of each ragged tensor\n",
    "# # print(tf.shape(jumps_rag))\n",
    "# zeros = tf.zeros(tf.shape(jumps_rag)[0])[:,None]\n",
    "# zeros = tf.cast(tf.RaggedTensor.from_tensor(zeros), tf.int64)\n",
    "# # print(tf.shape(zeros))\n",
    "# # print(tf.shape(jumps_rag))\n",
    "# test = tf.concat([zeros.with_row_splits_dtype(tf.int64), jumps_rag.with_row_splits_dtype(tf.int64)], axis = 1)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbe43f",
   "metadata": {},
   "source": [
    "# fit_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg2(cloud, rag, npts):\n",
    "    \"\"\"new method of fitting gaussian to better handle ragged input data\"\"\"\n",
    "    numSamples = 3\n",
    "    \n",
    "    coords = tf.gather(cloud, rag)\n",
    "    mu = tf.math.reduce_mean(coords, axis = 1)[:,None]\n",
    "#     mu = tf.math.reduce_mean(coords, axis = 1) #old\n",
    "#     print(mu)\n",
    "\n",
    "#   TODO: try randomly sampling 30 points from each ragged cell, use reduced num pts to calculate covariance\n",
    "#     subsampled = tf.map_fn(sample, it.inside2) #works but SLOW\n",
    "#     subsampled = tf.map_fn(sample, it.inside2, parallel_iterations=True)\n",
    "#     subsampled = tf.gather(rag,tf.range(tf.shape(rag)[0]))[:numSamples] #wrong\n",
    "#     print(subsampled)\n",
    "\n",
    "    xpos = tf.gather(cloud[:,0], rag)\n",
    "    ypos = tf.gather(cloud[:,1], rag)\n",
    "    zpos = tf.gather(cloud[:,2], rag)\n",
    "#     c = tfp.stats.covariance(xpos.to_tensor(), ypos.to_tensor())\n",
    "\n",
    "#     print(xpos)\n",
    "    idx = tf.range(30)\n",
    "    xpos = tf.gather(xpos, idx, axis = 1)\n",
    "    ypos = tf.gather(ypos, idx, axis = 1)\n",
    "    zpos = tf.gather(zpos, idx, axis = 1)\n",
    "    print(xpos)\n",
    "\n",
    "    xx = tf.math.reduce_sum(tf.math.square(xpos - mu[:,:,0] ), axis = 1)/npts\n",
    "    yy = tf.math.reduce_sum(tf.math.square(ypos - mu[:,:,1] ), axis = 1)/npts\n",
    "    zz = tf.math.reduce_sum(tf.math.square(zpos - mu[:,:,2] ), axis = 1)/npts\n",
    "    xy = tf.math.reduce_sum( (xpos - mu[:,:,0])*(ypos - mu[:,:,1]), axis = 1)/npts  #+\n",
    "    xz = tf.math.reduce_sum( (xpos - mu[:,:,0])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "    yz = tf.math.reduce_sum( (ypos - mu[:,:,1])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "\n",
    "    sigma = tf.Variable([xx, xy, xz,\n",
    "                        xy, yy, yz,\n",
    "                        xz, yz, zz]) \n",
    "    sigma = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "        \n",
    "#     mu = None\n",
    "    return(mu, sigma)\n",
    "\n",
    "@tf.function\n",
    "def sample(x, samples=3):\n",
    "  \"\"\"https://stackoverflow.com/questions/71073873/sample-from-ragged-tensor\"\"\"  \n",
    "  length = tf.shape(x)[0]\n",
    "#   was this\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.random.shuffle(tf.range(length))[:samples]))\n",
    " \n",
    "#   test\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.range(length))[:samples])\n",
    "  x = tf.gather(x,tf.range(length))[:samples]\n",
    "\n",
    "    \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "mu2, sigma2 = it.fit_gaussian(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\"\\n took\", time.time() - s, \" s with old method\")\n",
    "\n",
    "s = time.time()\n",
    "mu2, sigma2 = fg2(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")\n",
    "\n",
    "# print(it.npts2)\n",
    "# print(it.inside2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c39b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vect = it.inside2\n",
    "vect = tf.ragged.constant([[],[1,2,3,4],[5,4,3,2,1],[6],[99],[7,8,9,10,11,12,13]])\n",
    "# print(tf.shape(vect)[0])\n",
    "print(\"vect\", vect)\n",
    "c = tf.map_fn(sample, vect)\n",
    "# print(c)\n",
    "\n",
    "#wrong\n",
    "# test = tf.gather(vect,tf.range(tf.shape(vect)[0]))[:3]\n",
    "idx = tf.range(3)\n",
    "print(\"\\n idx\", idx)\n",
    "test = tf.gather(vect, idx , axis = 1)\n",
    "print(\"\\n test\", test) #NOTE: indices with too few elements produce unexpected behavior\n",
    "                        #that doesn't matter since they get suppressed anyways\n",
    "    \n",
    "vec2 = tf.random.categorical(vect, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608026c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
