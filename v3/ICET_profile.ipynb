{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df034054",
   "metadata": {},
   "source": [
    "# Notebook for identifying and removing bottlenecks from ICET implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc1c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 14:36:08.471606: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 14:36:09.087791: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-20 14:36:10.084863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-20 14:36:10.084926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-11-20 14:36:10.084930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-20 14:36:11.457206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:11.567653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:11.567966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 14:36:11.870839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 14:36:11.872523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:11.872804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:11.873008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:12.796972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:12.797212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:12.797395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 14:36:12.797518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "# tf.config.set_visible_devices([], 'GPU') #run on CPU only -- seems to actually execute main parts of code faster here...\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "from ICET_spherical import ICET\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook\n",
    "\n",
    "# %%bash\n",
    "# # python -m cProfile scan_match.py\n",
    "# python scan_match.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e4c23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth poses are not avaialble for sequence 09.\n",
      "\n",
      " loading model took 4.76837158203125e-07 \n",
      " total:  5.0067901611328125e-06\n",
      "\n",
      " shuffling and converting to tensor took  0.006960153579711914 \n",
      " total:  0.006984710693359375\n",
      "\n",
      " converting to spherical took 0.016175270080566406 \n",
      " total:  0.023174524307250977\n",
      "\n",
      " getting cluster took 1.4108836650848389 seconds !!!\n",
      "\n",
      " fit_gaussian for scan 1 0.01434469223022461 \n",
      " total:  1.5166802406311035\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.06150174140930176 \n",
      " total:  1.6386260986328125 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.30780596  0.01272369  0.00220542 -0.00058785  0.0013874  -0.00494641], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016361474990844727 \n",
      " total:  1.655013084411621 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05533647537231445 \n",
      " total:  1.7106268405914307 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 6.6496092e-01  8.5625611e-04  8.4208352e-03 -5.2704889e-04\n",
      "  1.6456378e-03  2.3170570e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016980409622192383 \n",
      " total:  1.7276616096496582 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05356740951538086 \n",
      " total:  1.7814998626708984 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 8.5250759e-01  8.0876341e-03  1.1381898e-02 -2.5937642e-04\n",
      "  1.9679905e-03  3.1701033e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016651391983032227 \n",
      " total:  1.7981736660003662 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05035209655761719 \n",
      " total:  1.848818063735962 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.2882746e-01  1.1814938e-02  1.2264088e-02 -1.5480773e-04\n",
      "  2.1038877e-03  3.1589910e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016408920288085938 \n",
      " total:  1.8652455806732178 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.06293153762817383 \n",
      " total:  1.9284470081329346 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.4632494e-01  1.3968879e-02  1.2635446e-02 -1.7832813e-04\n",
      "  2.0971075e-03  3.1888711e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.020333528518676758 \n",
      " total:  1.9488372802734375 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05550384521484375 \n",
      " total:  2.004610061645508 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.49940801e-01  1.46531127e-02  1.26227895e-02 -2.11399281e-04\n",
      "  2.06797780e-03  3.10263108e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016224145889282227 \n",
      " total:  2.0208516120910645 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05292868614196777 \n",
      " total:  2.0740482807159424 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.5062900e-01  1.4656672e-02  1.2564672e-02 -2.3340771e-04\n",
      "  2.0373184e-03  3.0300040e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016283512115478516 \n",
      " total:  2.0903480052948 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.05021238327026367 \n",
      " total:  2.140831708908081 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.014286041259765625 \n",
      " total:  2.1551544666290283 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.5056748e-01  1.4556045e-02  1.2592514e-02 -2.3337132e-04\n",
      "  2.0381508e-03  3.0117312e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.016800880432128906 \n",
      " total:  2.171969175338745 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " fit_gaussian for scan 2 0.056238651275634766 \n",
      " total:  2.2284960746765137 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " ---checking for moving objects---\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " removed moving 0.01194000244140625 \n",
      " total:  2.240452289581299 \n",
      " ~~~~~~~~~~~~~~\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor(\n",
      "[ 9.5053536e-01  1.4538124e-02  1.2593805e-02 -2.3391946e-04\n",
      "  2.0379745e-03  3.0081559e-03], shape=(6,), dtype=float32)\n",
      "\n",
      " ~~~~~~~~~~~~~~ \n",
      " correcting solution estimate 0.01665043830871582 \n",
      " total:  2.2571163177490234 \n",
      " ~~~~~~~~~~~~~~\n",
      "pred_stds: \n",
      " tf.Tensor(\n",
      "[1.1801335e-03 5.1536522e-04 1.0416927e-04 2.2147322e-05 1.6642454e-05\n",
      " 1.0180958e-04], shape=(6,), dtype=float32)\n",
      " L2: \n",
      " tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "basepath = '/media/derm/06EF-127D1/KITTI'\n",
    "# sequence = '03' #forest\n",
    "sequence = '09' #trees and small town\n",
    "dataset = pykitti.odometry(basepath, sequence)\n",
    "velo1 = dataset.get_velo(400)\n",
    "c1 = velo1[:,:3]\n",
    "velo2 = dataset.get_velo(401)\n",
    "c2 = velo2[:,:3]\n",
    "\n",
    "it = ICET(cloud1 = c1, cloud2 = c2, fid = 70, niter = 9, \n",
    "           draw = False, group = 2, RM = True, DNN_filter = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ff0c0",
   "metadata": {},
   "source": [
    "# get_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cebb9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt2(rads, thresh = 0.5, mnp = 100):\n",
    "    \"\"\"testing new method of finding radial bins for spherical voxels\"\"\"\n",
    "    \n",
    "    before = time.time()\n",
    "\n",
    "    max_buffer = 0.2 \n",
    "\n",
    "    if len(tf.shape(rads)) < 2:\n",
    "        rads = rads[:,None]\n",
    "\n",
    "    OG_rads = rads #hold on to OG rads\n",
    "    #replace all zeros in rads (result of converting ragged -> standard tensor) with some arbitrarily large value\n",
    "    mask = tf.cast(tf.math.equal(rads, 0), tf.float32)*1000\n",
    "    rads = rads + mask\n",
    "    # print(rads)\n",
    "\n",
    "    #sort in ascending order for each column in tensor\n",
    "    top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "#     print(\"\\n top_k \\n\", top_k[1])\n",
    "    rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "    rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "    print(\"rads \\n\", rads)\n",
    "\n",
    "    # calculate the forward difference between neighboring points\n",
    "    z = tf.zeros([1, tf.shape(rads)[1].numpy()])\n",
    "    shifted = tf.concat((rads[1:], z), axis = 0)\n",
    "    diff = shifted - rads\n",
    "    # diff = tf.math.abs(rads - shifted) #debug 6/9/22\n",
    "#     print(\"\\n diff \\n\", diff)\n",
    "\n",
    "    # #find where difference jumps\n",
    "    jumps = tf.where(diff > thresh)\n",
    "#     print(\"\\n jumps \\n\", jumps) #[idx of jump, which spike is jumping]\n",
    "\n",
    "    #----------------------------------------------------------------------\n",
    "    #not sure if actually needed...\n",
    "    #get indexes of all used spikes\n",
    "    used = jumps[:,1][None,:]\n",
    "    # print(\"used\", used)\n",
    "    biggest = tf.math.reduce_max(used, axis = 1).numpy()[0]\n",
    "    # print(\"biggest\", biggest)\n",
    "    all_spikes = tf.cast(tf.linspace(0,biggest,biggest+1), tf.int64)[None,:] #list all spikes total\n",
    "    # print(\"all_spikes\", all_spikes)\n",
    "\n",
    "    #find differnce\n",
    "    missing = tf.sets.difference(all_spikes, used).values[None,:]\n",
    "    # print(\"\\n missing\", missing)\n",
    "    # z = tf.zeros(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # z = 51*tf.ones(tf.shape(missing), dtype = tf.int64) #wrong...\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    #z should be this...\n",
    "    # print(\"\\n OG_rads\", OG_rads)\n",
    "    # ends = tf.math.argmax(OG_rads, axis = 0) #wrong -> not max arg, last nonzero argument!!\n",
    "    zero = tf.constant(0, dtype = tf.float32)\n",
    "    ends = tf.math.reduce_sum(tf.cast(tf.not_equal(OG_rads, zero), tf.int64), axis = 0) #correct\n",
    "    # print(\"\\n ends\", ends)\n",
    "\n",
    "    test = tf.gather(ends, missing[0])  #get index of last element of missing jump section\n",
    "    # print(\"\\n test\", test)\n",
    "    z = test[None,:]\n",
    "    z -= 2 #fixes indexing bug\n",
    "    # print(\"z\", z)\n",
    "\n",
    "    missing = tf.transpose(tf.concat((z, missing), axis = 0))\n",
    "    # print(missing)\n",
    "\n",
    "    jumps = tf.concat((jumps, missing), axis = 0) #concat missing stuff back at the end of jumps\n",
    "#     print(\"\\n jumps after fix\", jumps)\n",
    "    #----------------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n jumps: \\n\", jumps.numpy())\n",
    "    \n",
    "    #find where the first large cluster occurs in each spike\n",
    "   \n",
    "\n",
    "    \n",
    "    bounds = None\n",
    "\n",
    "    return(bounds, jumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0f50c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " took 1.4740512371063232  s with old method \n",
      "\n",
      "rads \n",
      " tf.Tensor(\n",
      "[[   6.308901     4.503432     3.6884313 ...    4.6837316    5.6261888\n",
      "    54.913895 ]\n",
      " [   6.4553094    4.5076594    9.501441  ...    4.6909585 1000.\n",
      "  1000.       ]\n",
      " [   6.456663     4.5077553    9.515896  ... 1000.        1000.\n",
      "  1000.       ]\n",
      " ...\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]], shape=(506, 536), dtype=float32)\n",
      "\n",
      " jumps: \n",
      " [[  0   2]\n",
      " [  0 163]\n",
      " [  0 283]\n",
      " ...\n",
      " [501 118]\n",
      " [502 162]\n",
      " [504 162]]\n",
      " \n",
      " took 0.006463766098022461  s with new method\n"
     ]
    }
   ],
   "source": [
    "from utils import get_cluster\n",
    "# print(\"rads: \\n\", it.rads)\n",
    "\n",
    "s = time.time()\n",
    "bounds_old = get_cluster(it.rads, mnp = it.min_num_pts)\n",
    "print(\"\\n took\", time.time() - s, \" s with old method \\n\")\n",
    "\n",
    "s = time.time()\n",
    "bounds_new, jumps = gt2(it.rads, mnp = it.min_num_pts)\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b7756ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " jumps: \n",
      " tf.Tensor([1404    2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([536   2], shape=(2,), dtype=int32)\n",
      "\n",
      " jumps_rag \n",
      " <tf.RaggedTensor [[2, 163, 283, 392, 409, 486, 492, 501, 511, 520, 524, 534, 535],\n",
      " [164, 249, 354, 485, 492, 506, 532, 533], [116, 140, 334, 450, 502],\n",
      " [93, 281, 283, 450, 523, 526], [121, 283, 374, 528],\n",
      " [31, 70, 141, 520, 523], [167, 283, 527, 529], [132, 528], [20, 273, 486],\n",
      " [283, 478, 497, 502, 518, 519, 531]]>\n",
      "\n",
      " npts_between_jumps:\n",
      "  tf.Tensor(\n",
      "[[ 161  120  109   17   77    6    9   10    9    4   10    1]\n",
      " [  85  105  131    7   14   26    1 -533    0    0    0    0]\n",
      " [  24  194  116   52 -502    0    0    0    0    0    0    0]\n",
      " [ 188    2  167   73    3 -526    0    0    0    0    0    0]\n",
      " [ 162   91  154 -528    0    0    0    0    0    0    0    0]\n",
      " [  39   71  379    3 -523    0    0    0    0    0    0    0]\n",
      " [ 116  244    2 -529    0    0    0    0    0    0    0    0]\n",
      " [ 396 -528    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 253  213 -486    0    0    0    0    0    0    0    0    0]\n",
      " [ 195   19    5   16    1   12 -531    0    0    0    0    0]], shape=(10, 12), dtype=int64)\n",
      "\n",
      " first_big_enough: \n",
      " tf.Tensor([0 1 1 0 0 2 0 0 0 0], shape=(10,), dtype=int64)\n",
      "\n",
      " rads: \n",
      " tf.Tensor(\n",
      "[[   6.308901     4.503432     3.6884313 ...    4.6837316    5.6261888\n",
      "    54.913895 ]\n",
      " [   6.4553094    4.5076594    9.501441  ...    4.6909585 1000.\n",
      "  1000.       ]\n",
      " [   6.456663     4.5077553    9.515896  ... 1000.        1000.\n",
      "  1000.       ]\n",
      " ...\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]\n",
      " [1000.        1000.        1000.        ... 1000.        1000.\n",
      "  1000.       ]], shape=(506, 536), dtype=float32)\n",
      "\n",
      " inner: \n",
      " tf.Tensor([  2 249 140  93 121 141 167 132  20 283], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#identifying location of jumps without looping\n",
    "print(\"\\n jumps: \\n\", tf.shape(jumps))\n",
    "# print(\"\\n jumps: \\n\",jumps[:30])\n",
    "print(tf.shape(bounds_old))\n",
    "\n",
    "y, idx = tf.unique(jumps[:,0])\n",
    "# print(\"\\n y \\n\", y, \"\\n \\n idx\", idx)\n",
    "\n",
    "#get ragged tensor containing indices where jumps occur in each wedge shaped voxel\n",
    "jumps_rag = tf.RaggedTensor.from_value_rowids(jumps[:,1], idx)\n",
    "print(\"\\n jumps_rag \\n\", jumps_rag[:10])\n",
    "# print(\"\\n jumps_rag \\n\", tf.shape(jumps_rag))\n",
    "\n",
    "#get num points between each jump \n",
    "npts_between_jumps = tf.experimental.numpy.diff(jumps_rag.to_tensor())\n",
    "print(\"\\n npts_between_jumps:\\n \",npts_between_jumps[:10])\n",
    "\n",
    "#get idx within jumps_rag corresponding to first sufficiently large jump\n",
    "big_enough = tf.cast(tf.math.greater(npts_between_jumps, 100), tf.int32)\n",
    "# print(big_enough[:10])\n",
    "first_big_enough = tf.math.argmax(test, axis = 1)\n",
    "print(\"\\n first_big_enough: \\n\", first_big_enough[:10])\n",
    "\n",
    "#get all radial measurements\n",
    "#(temp-- already done inside function)-----------------------------\n",
    "mask = tf.cast(tf.math.equal(it.rads, 0), tf.float32)*1000\n",
    "rads = it.rads + mask\n",
    "#sort in ascending order for each column in tensor\n",
    "top_k = tf.math.top_k(tf.transpose(rads), k = tf.shape(rads)[0])\n",
    "rads = tf.transpose(tf.gather(tf.transpose(rads), top_k[1], batch_dims = 1))\n",
    "rads = tf.reverse(rads, axis = tf.constant([0]))\n",
    "print(\"\\n rads: \\n\", rads)\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "#get inner and outer (temp simple way-- just use radial measurements of inner and outermost points in cluster)\n",
    "inner = tf.gather(jumps_rag.to_tensor(), first_big_enough, batch_dims = 1)\n",
    "print(\"\\n inner: \\n\", inner[:10])\n",
    "# inner_rads = tf.gather(rads, inner, batch_dims = 0) #wrong\n",
    "# print(\"\\n inner rads: \\n\", inner_rads)\n",
    "\n",
    "# outer = tf.gather(jumps_rag.to_tensor(), first_big_enough+1, batch_dims = 1)\n",
    "# print(\"\\n outer: \\n\", outer)\n",
    "\n",
    "#TODO add padding \n",
    "#  (max half distance betweeen last in cluster and first point outside cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbe43f",
   "metadata": {},
   "source": [
    "# fit_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg2(cloud, rag, npts):\n",
    "    \"\"\"new method of fitting gaussian to better handle ragged input data\"\"\"\n",
    "    numSamples = 3\n",
    "    \n",
    "    coords = tf.gather(cloud, rag)\n",
    "    mu = tf.math.reduce_mean(coords, axis = 1)[:,None]\n",
    "#     mu = tf.math.reduce_mean(coords, axis = 1) #old\n",
    "#     print(mu)\n",
    "\n",
    "#   TODO: try randomly sampling 30 points from each ragged cell, use reduced num pts to calculate covariance\n",
    "#     subsampled = tf.map_fn(sample, it.inside2) #works but SLOW\n",
    "#     subsampled = tf.map_fn(sample, it.inside2, parallel_iterations=True)\n",
    "#     subsampled = tf.gather(rag,tf.range(tf.shape(rag)[0]))[:numSamples] #wrong\n",
    "#     print(subsampled)\n",
    "\n",
    "    xpos = tf.gather(cloud[:,0], rag)\n",
    "    ypos = tf.gather(cloud[:,1], rag)\n",
    "    zpos = tf.gather(cloud[:,2], rag)\n",
    "#     c = tfp.stats.covariance(xpos.to_tensor(), ypos.to_tensor())\n",
    "\n",
    "#     print(xpos)\n",
    "    idx = tf.range(30)\n",
    "    xpos = tf.gather(xpos, idx, axis = 1)\n",
    "    ypos = tf.gather(ypos, idx, axis = 1)\n",
    "    zpos = tf.gather(zpos, idx, axis = 1)\n",
    "    print(xpos)\n",
    "\n",
    "    xx = tf.math.reduce_sum(tf.math.square(xpos - mu[:,:,0] ), axis = 1)/npts\n",
    "    yy = tf.math.reduce_sum(tf.math.square(ypos - mu[:,:,1] ), axis = 1)/npts\n",
    "    zz = tf.math.reduce_sum(tf.math.square(zpos - mu[:,:,2] ), axis = 1)/npts\n",
    "    xy = tf.math.reduce_sum( (xpos - mu[:,:,0])*(ypos - mu[:,:,1]), axis = 1)/npts  #+\n",
    "    xz = tf.math.reduce_sum( (xpos - mu[:,:,0])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "    yz = tf.math.reduce_sum( (ypos - mu[:,:,1])*(zpos - mu[:,:,2]), axis = 1)/npts #-\n",
    "\n",
    "    sigma = tf.Variable([xx, xy, xz,\n",
    "                        xy, yy, yz,\n",
    "                        xz, yz, zz]) \n",
    "    sigma = tf.reshape(tf.transpose(sigma), (tf.shape(sigma)[1] ,3,3))\n",
    "        \n",
    "#     mu = None\n",
    "    return(mu, sigma)\n",
    "\n",
    "@tf.function\n",
    "def sample(x, samples=3):\n",
    "  \"\"\"https://stackoverflow.com/questions/71073873/sample-from-ragged-tensor\"\"\"  \n",
    "  length = tf.shape(x)[0]\n",
    "#   was this\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.random.shuffle(tf.range(length))[:samples]))\n",
    " \n",
    "#   test\n",
    "#   x = tf.cond(tf.less_equal(length, samples), lambda: x, lambda: tf.gather(x, tf.range(length))[:samples])\n",
    "  x = tf.gather(x,tf.range(length))[:samples]\n",
    "\n",
    "    \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "mu2, sigma2 = it.fit_gaussian(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\"\\n took\", time.time() - s, \" s with old method\")\n",
    "\n",
    "s = time.time()\n",
    "mu2, sigma2 = fg2(it.cloud2_tensor, it.inside2, tf.cast(it.npts2, tf.float32))\n",
    "print(\" \\n took\", time.time() - s, \" s with new method\")\n",
    "\n",
    "# print(it.npts2)\n",
    "# print(it.inside2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c39b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect <tf.RaggedTensor [[], [1, 2, 3, 4], [5, 4, 3, 2, 1], [6], [99], [7, 8, 9, 10, 11, 12, 13]]>\n",
      "\n",
      " idx tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "\n",
      " test tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 1  2  3]\n",
      " [ 5  4  3]\n",
      " [ 6 99  7]\n",
      " [99  7  8]\n",
      " [ 7  8  9]], shape=(6, 3), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: object of type 'RaggedTensor' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m test\u001b[39m\u001b[38;5;124m\"\u001b[39m, test) \u001b[38;5;66;03m#NOTE: indices with too few elements produce unexpected behavior\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                         \u001b[38;5;66;03m#that doesn't matter since they get suppressed anyways\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m vec2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'RaggedTensor' has no len()\n"
     ]
    }
   ],
   "source": [
    "# vect = it.inside2\n",
    "vect = tf.ragged.constant([[],[1,2,3,4],[5,4,3,2,1],[6],[99],[7,8,9,10,11,12,13]])\n",
    "# print(tf.shape(vect)[0])\n",
    "print(\"vect\", vect)\n",
    "c = tf.map_fn(sample, vect)\n",
    "# print(c)\n",
    "\n",
    "#wrong\n",
    "# test = tf.gather(vect,tf.range(tf.shape(vect)[0]))[:3]\n",
    "idx = tf.range(3)\n",
    "print(\"\\n idx\", idx)\n",
    "test = tf.gather(vect, idx , axis = 1)\n",
    "print(\"\\n test\", test) #NOTE: indices with too few elements produce unexpected behavior\n",
    "                        #that doesn't matter since they get suppressed anyways\n",
    "    \n",
    "vec2 = tf.random.categorical(vect, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608026c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
