{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.31410828 -0.00153609  0.09991124 -0.00620458  0.00421205  0.01244162], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.33431602  0.00695762  0.05746645 -0.00567841  0.00349628  0.0138566 ], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34085846 -0.0063442   0.02839667 -0.00417265  0.0029643   0.01407214], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34080637 -0.0074435   0.00955635 -0.00288681  0.00245076  0.01413573], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3411951  -0.00805545  0.00306188 -0.00260942  0.0022355   0.01418984], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3427948  -0.0112745   0.00202577 -0.00269312  0.00242362  0.01419091], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3434888  -0.01408371 -0.00178519 -0.00258752  0.00253043  0.01416827], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34443748 -0.01737556 -0.00741063 -0.00240817  0.00275299  0.01412222], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3443934  -0.01725774 -0.01102356 -0.00249238  0.00346886  0.01409075], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34454763 -0.01723238 -0.01242729 -0.00250928  0.00391234  0.01406707], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34471405 -0.01745864 -0.0128724  -0.00251829  0.00404155  0.01406602], shape=(6,), dtype=float32)\n",
      "\n",
      " ---identified moving objects---\n",
      "pred_stds: \n",
      " tf.Tensor([0.00165539 0.00200249 0.00698845 0.00086046 0.00049221 0.00012146], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from ICET_spherical import ICET\n",
    "\n",
    "# init KITTI dataset -----------------------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "idx = 0\n",
    "# drive = '0093'\n",
    "# idx = 220\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(idx) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "c1 = velo1[:,:3]\n",
    "c1 = c1[c1[:,2] > -1.5] #ignore ground plane\n",
    "velo2 = dataset.get_velo(idx+1) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "c2 = velo2[:,:3]\n",
    "c2 = c2[c2[:,2] > -1.5] #ignore ground plane\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# ## load custom point cloud geneated in matlab------------------------------------------\n",
    "# c1 = np.loadtxt(\"scene1_scan1.txt\", dtype = float)\n",
    "# # c2 = c1 + np.array([2.0, 0.2, 0])\n",
    "# c2 = c1 + np.array([0.1, 0., 0.])\n",
    "\n",
    "# # c1 = c1[c1[:,2] > -1.5] #ignore ground plane\n",
    "# # c2 = c2[c2[:,2] > -1.5] #ignore ground plane\n",
    "# ## ------------------------------------------------------------------------------------\n",
    "\n",
    "# #single distinct cluster---------------------------------------------------------------\n",
    "# c1 = np.random.randn(3000,3)*tf.constant([0.04,0.3,0.3]) + tf.constant([6.,0.,0.])\n",
    "# c2 = np.random.randn(3000,3)*tf.constant([0.04,0.3,0.3]) + tf.constant([6.,0.,0.]) - np.array([0., 0.25, 0.0])\n",
    "# # # c2 = c1 - np.array([0.1, 0.3, 0.0])\n",
    "# # -------------------------------------------------------------------------------------\n",
    "\n",
    "# D = True\n",
    "D = False\n",
    "X = tf.constant([0., 0., 0., 0., 0., 0.])\n",
    "it1 = ICET(cloud1 = c1, cloud2 = c2,  fid = 50, draw = False, x0 = X, niter = 12, group= 2, RM = True)\n",
    "# it2 = ICET(cloud1 = it1.cloud1_static, cloud2 = c2, fid = 50, niter = 20, draw = True, group = 2, RM = False)\n",
    "\n",
    "if D:\n",
    "    ViewInteractiveWidget(it2.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015AA5A2FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015AA5A2FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([-0.02386692  0.00629028 -0.00421011], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process points from ICET to feed to DNN\n",
    "\n",
    "#Get ragged tensor containing all points from each scan inside each sufficient voxel\n",
    "in1 = it1.inside1\n",
    "npts1 = it1.npts1\n",
    "in2 = it1.inside2\n",
    "npts2 = it1.npts2\n",
    "corr = it1.corr #indices of bins that have enough points from scan1 and scan2\n",
    "\n",
    "# print(tf.shape(in2.to_tensor()))\n",
    "\n",
    "#get indices of rag with >= 25 elements\n",
    "ncells = tf.shape(corr)[0].numpy() #num of voxels with sufficent number of points\n",
    "# print(tf.gather(npts2, corr))\n",
    "enough1 = tf.gather(in1, corr)\n",
    "enough2 = tf.gather(in2, corr)\n",
    "print(tf.shape(enough2.to_tensor())[0].numpy())\n",
    "# print(npts2)\n",
    "# print(corr)\n",
    "\n",
    "#init array to store indices\n",
    "idx1 = np.zeros([ncells ,25])\n",
    "idx2 = np.zeros([ncells ,25])\n",
    "\n",
    "#loop through each element of ragged tensor\n",
    "for i in range(ncells):\n",
    "    idx1[i,:] = tf.random.shuffle(enough1[i])[:25].numpy() #shuffle order and take first 25 elements\n",
    "    idx2[i,:] = tf.random.shuffle(enough2[i])[:25].numpy() #shuffle order and take first 25 elements\n",
    "\n",
    "idx1 = tf.cast(tf.convert_to_tensor(idx1), tf.int32)\n",
    "idx2 = tf.cast(tf.convert_to_tensor(idx2), tf.int32)\n",
    "\n",
    "# print(it1.cloud1_tensor)\n",
    "from1 = tf.gather(it1.cloud1_tensor, idx1)\n",
    "# from2 = tf.gather(it1.cloud2_tensor_OG, idx2)\n",
    "from2 = tf.gather(it1.cloud2_tensor, idx2)\n",
    "# print(from1)\n",
    "\n",
    "x_test = tf.concat((from1, from2), axis = 1)\n",
    "# np.savetxt('perspective_shift/ICET_KITTI_frame0.txt', tf.reshape(from1, [-1, 3]).numpy())\n",
    "# np.savetxt('perspective_shift/ICET_KITTI_frame1.txt', tf.reshape(from2, [-1, 3]).numpy())\n",
    "\n",
    "model = tf.keras.models.load_model(\"perspective_shift/KITTInet.kmod\")\n",
    "from_DNN = model.predict(x_test)\n",
    "# print(from_DNN)\n",
    "# print(np.shape(from_DNN))\n",
    "print(tf.math.reduce_mean(from_DNN, axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify compact directions where ICET and DNN disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.37983456e-01  6.91502541e-02  3.23325284e-02]\n",
      " [ 4.89876680e-02  1.31267563e-01  5.36474586e-03]\n",
      " [ 8.64065140e-02  9.51721668e-02  4.77753580e-02]\n",
      " [ 5.87065630e-02  5.37295528e-02  6.19594008e-04]\n",
      " [ 4.20989431e-02  1.27513669e-02  9.79841128e-03]\n",
      " [-3.71711031e-02 -5.18291816e-02  2.85657421e-02]\n",
      " [-3.72207630e-03  9.15056989e-02 -1.65947005e-02]\n",
      " [ 3.78499813e-02  8.08158144e-02 -2.31608283e-03]\n",
      " [-1.02414221e-01 -5.16712487e-01  1.16202282e-02]\n",
      " [-1.67563483e-02 -2.03320738e-02  2.64154701e-03]\n",
      " [-6.05618581e-02  3.39975655e-02  3.69084626e-03]\n",
      " [-1.46405986e-02  6.09222567e-04 -1.69675082e-01]\n",
      " [ 8.51367787e-02  5.01784161e-02 -1.36203421e-02]\n",
      " [-7.09618330e-02  1.17868349e-01 -2.31520385e-02]\n",
      " [-3.85052413e-02  7.32377172e-02 -7.72441924e-02]\n",
      " [-6.31802380e-02  7.72530958e-03 -6.24094829e-02]\n",
      " [-2.09369510e-02  9.00394097e-03 -6.50332421e-02]\n",
      " [-1.20060638e-01  8.04620460e-02  2.77101547e-02]\n",
      " [-5.66690490e-02  3.18022460e-01 -1.25443980e-01]\n",
      " [ 6.16331771e-02  3.33237648e-03  7.51928985e-03]\n",
      " [-3.56167316e-01  1.97660476e-01 -2.22103298e-02]\n",
      " [-8.42971355e-02  1.92783047e-02 -9.31892917e-02]\n",
      " [ 2.22254395e-02 -5.42966872e-02  3.13393548e-02]\n",
      " [ 5.23389876e-03  2.10789237e-02  3.12412158e-02]\n",
      " [-2.05946341e-02  1.74759887e-03 -2.85673328e-03]\n",
      " [ 3.28490511e-02 -3.76037769e-02 -1.48040708e-02]\n",
      " [-1.46724880e-01  8.89471099e-02 -2.57022623e-02]\n",
      " [-7.76917785e-02 -2.69862376e-02 -8.95581767e-03]\n",
      " [-2.34133720e-01  6.46176636e-02  3.03854197e-02]\n",
      " [ 1.20108947e-02 -3.10541689e-02  8.07866901e-02]\n",
      " [ 2.67869234e-01  1.24761634e-01 -2.86874235e-01]\n",
      " [ 3.42457741e-02  8.83664861e-02  7.88328648e-02]\n",
      " [ 1.25882268e-01 -1.54982135e-02  5.64169958e-02]\n",
      " [-1.26205146e-01 -1.54305063e-02  1.42662093e-01]\n",
      " [-3.66775125e-01 -8.57023299e-02  1.44702867e-01]\n",
      " [-4.22905147e-01  7.18023419e-01 -6.90400451e-02]\n",
      " [ 5.97442687e-02 -9.09410119e-02  1.85697511e-01]\n",
      " [-4.72190753e-02  2.62914281e-02 -2.39832662e-02]\n",
      " [-1.18995190e-01 -4.17711735e-02  9.38133523e-03]\n",
      " [ 7.16664456e-03  1.35029539e-01 -1.61855482e-03]\n",
      " [ 1.15184918e-01  9.93189737e-02 -1.76614933e-02]\n",
      " [ 1.67213798e-01 -1.06748477e-01  3.67520824e-02]\n",
      " [-7.70573020e-02 -2.41495818e-01 -9.95662734e-02]\n",
      " [-4.67342809e-02  1.55974641e-01 -1.35950092e-02]\n",
      " [-1.19686529e-01 -1.98392242e-01 -2.70607024e-02]\n",
      " [ 3.35030705e-01 -8.41616988e-02  1.13853877e-02]\n",
      " [-8.26906562e-02 -1.89607125e-02 -6.03151806e-02]\n",
      " [ 1.52632624e-01  1.20780990e-02 -8.30211490e-03]\n",
      " [-1.24491632e-01  1.12110645e-01  1.53084397e-02]\n",
      " [-5.89040518e-01 -1.67984277e-01 -3.85941006e-03]\n",
      " [-3.11652929e-01  2.15015680e-01 -7.85893574e-02]\n",
      " [-9.15188342e-02  1.06161043e-01  3.74366343e-02]\n",
      " [-1.81122720e-02  4.94651720e-02 -2.67759375e-02]\n",
      " [-1.53352410e-01  4.33736779e-02 -7.55614489e-02]\n",
      " [-5.85416496e-01  3.61640602e-02  1.79177653e-02]\n",
      " [-3.38611156e-02  2.10595243e-02  5.13101742e-03]\n",
      " [-1.84641004e-01  7.77546018e-02 -3.55178863e-03]\n",
      " [-5.95370770e-01 -5.69640756e-01  2.44708806e-02]\n",
      " [-6.01299033e-02 -3.57222557e-02 -1.71946868e-01]\n",
      " [ 2.78560698e-01  1.28894776e-01  6.83737025e-02]\n",
      " [ 9.33425277e-02  1.05134092e-01  1.09552868e-01]\n",
      " [-3.33511770e-01 -1.07398331e-02 -7.30326325e-02]\n",
      " [ 1.31364763e-02  3.84427002e-03 -2.33218819e-03]\n",
      " [ 2.16425397e-02 -5.94280474e-02  8.19616839e-02]\n",
      " [-5.94889164e-01 -5.97016960e-02  7.55902827e-02]\n",
      " [-5.59200644e-02  2.42123008e-02  5.03553264e-02]\n",
      " [-1.37568787e-02  4.22216766e-03  6.41701147e-02]\n",
      " [-1.34317838e-02  1.67930573e-01  6.29363954e-02]\n",
      " [-1.96055043e-02  3.10284168e-01 -3.34431231e-02]\n",
      " [ 1.85739389e-03  1.28064454e-01  1.59231536e-02]\n",
      " [ 6.64939657e-02 -1.57426409e-02  9.50550102e-03]\n",
      " [-1.93489902e-02 -1.33131221e-02  5.87571561e-02]\n",
      " [-8.77416059e-02  2.18579173e-02 -1.02055185e-01]\n",
      " [ 3.55132252e-01  1.81246921e-03  4.61439677e-02]\n",
      " [-8.01133066e-02 -2.36628130e-02 -8.96250010e-02]\n",
      " [ 4.78505373e-01  1.70124948e-01 -8.44422430e-02]\n",
      " [-4.43284929e-01  4.11032327e-02 -1.02449628e-02]\n",
      " [-4.17218894e-01 -2.75057852e-02  5.05848154e-02]\n",
      " [-3.18706870e-01  1.81610808e-02  1.46254659e-01]\n",
      " [-8.53378028e-02  5.27842417e-02  2.59008929e-02]\n",
      " [-3.62068787e-02  4.60017473e-03  2.46975385e-02]\n",
      " [-6.19983766e-03  1.40701625e-02 -2.23559048e-02]\n",
      " [ 6.41299263e-02  1.99964102e-02  3.09929084e-02]\n",
      " [-5.81042133e-02 -7.85693824e-02 -3.12424805e-02]\n",
      " [-6.81455294e-03 -8.68922658e-03 -2.54400615e-02]\n",
      " [-1.24786329e-03 -4.54599457e-03 -3.77360322e-02]\n",
      " [-1.16918571e-02  6.03697896e-02 -3.21813561e-02]\n",
      " [ 1.05087515e-02  1.17288269e-02  2.69227587e-02]\n",
      " [ 2.76435077e-01 -1.47819472e-02  1.14791142e-02]\n",
      " [ 3.77834976e-01 -9.28185731e-02 -1.35128116e-02]\n",
      " [ 7.68532883e-03 -2.21556053e-03 -1.13551635e-02]\n",
      " [ 2.11466663e-02 -1.12146325e-02  5.99682610e-03]\n",
      " [-1.85892023e-02 -2.88443137e-02  1.49556445e-02]\n",
      " [-6.66058739e-04  2.93802805e-02 -2.34764069e-02]\n",
      " [ 2.04373915e-02 -8.90742242e-03  1.69359837e-02]\n",
      " [ 2.49180980e-02  2.98068160e-03 -1.46683566e-02]\n",
      " [ 1.24521777e-02 -6.57137111e-02  9.67818871e-03]], shape=(97, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#compare per cell translation estimates between ICET and DNN on converged results\n",
    "dnnsoln = tf.convert_to_tensor(from_DNN)\n",
    "# n = 0 #cell idx\n",
    "# print(dnnsoln[n])\n",
    "# print(it1.residuals[n])\n",
    "print(dnnsoln - icetsoln)\n",
    "# print(tf.math.reduce_mean(it1.residuals, axis = 0))\n",
    "# print(tf.math.reduce_mean(dnnsoln, axis = 0))\n",
    "\n",
    "#align differences between solutions with the principal axis of ICET scan1\n",
    "\n",
    "\n",
    "#remove extended axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify outlier cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "nbins = 25\n",
    "nstd = 2\n",
    "\n",
    "# print(it.dx_i[:,0])\n",
    "# print(tf.math.reduce_sum(it.dx_i, axis = 0))\n",
    "# print(it.W)\n",
    "# print(it.H)\n",
    "# print(it.residuals[:,0])\n",
    "\n",
    "component = it1.residuals_full[:,1]\n",
    "print(tf.shape(component))\n",
    "# print(component)\n",
    "\n",
    "print(\"\\n before:\")\n",
    "mu = tf.math.reduce_mean(component)\n",
    "print(\"mean\", mu)\n",
    "sigma = tf.math.reduce_std(component)\n",
    "print(\"standard deviation\", sigma)\n",
    "bad_idx = tf.where( tf.math.abs(component) > mu + nstd*sigma )\n",
    "# print(\"bad idx\", bad_idx)\n",
    "good_idx = tf.where( tf.math.abs(component) < mu + nstd*sigma )\n",
    "# print(tf.gather(component, bad_idx))\n",
    "# ax.hist(it.dx_i[:,0], nbins);\n",
    "ax[0].hist(component, nbins);\n",
    "ax[0].set_xlabel(\"y_i - y0_i (forward translation error)\")\n",
    "ax[0].set_ylabel(\"frequency\")\n",
    "ax[0].set_title(\"All Distributions\")\n",
    "\n",
    "#test to make sure outliers are being removed correctly\n",
    "component = it1.residuals[:,1]\n",
    "print(tf.shape(component))\n",
    "# print(component)\n",
    "\n",
    "print(\"\\n after:\")\n",
    "mu = tf.math.reduce_mean(component)\n",
    "print(\"mean\", mu)\n",
    "sigma = tf.math.reduce_std(component)\n",
    "print(\"standard deviation\", sigma)\n",
    "\n",
    "ax[1].hist(component, nbins);\n",
    "ax[1].set_xlabel(\"y_i - y0_i (forward translation error)\")\n",
    "ax[1].set_ylabel(\"frequency\")\n",
    "ax[1].set_title(\"Best Fitting Distributions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "# print(it.residuals_full[:,0])\n",
    "edges = tf.linspace(-1.,1.,30)\n",
    "# print(edges)\n",
    "print(edges)\n",
    "\n",
    "bins_soln = tfp.stats.find_bins(it.residuals_full[:,0], edges)\n",
    "# print(bins_soln)\n",
    "\n",
    "good_idx = tf.where(bins_soln == 14)\n",
    "bad_idx = tf.where(bins_soln == 14)\n",
    "# print(bad_idx)\n",
    "# print(good_idx)\n",
    "# print(tf.gather(it.residuals_full[:,0], good_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[5, 6, 7, 8]])\n",
    "b = tf.constant([[8, 7, 10]])\n",
    "print(tf.sets.difference(a,b).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Useful Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import get_cluster\n",
    "\n",
    "#index of spike that each of the points from cloud 1 is occupying\n",
    "print(it.bins_spike)\n",
    "\n",
    "occupied_spikes, idxs = tf.unique(it.bins_spike)\n",
    "print(\"\\n occupied_spikes \\n\", occupied_spikes)\n",
    "temp =  tf.where(it.bins_spike == occupied_spikes[:,None])\n",
    "rag = tf.RaggedTensor.from_value_rowids(temp[:,1], temp[:,0])\n",
    "idx_by_rag = tf.gather(it.cloud1_tensor_spherical[:,0], rag)\n",
    "\n",
    "# rads = idx_by_rag[50,:] #single element from ragged tensor\n",
    "rads = tf.transpose(idx_by_rag.to_tensor()[:3,:])\n",
    "# rads = tf.transpose(idx_by_rag.to_tensor())\n",
    "# print(rads) #starts out unordered\n",
    "\n",
    "# #_________________________________________________________________\n",
    "fig, ax = plt.subplots(2,1)\n",
    "nbins = 25\n",
    "ax[0].hist(rads.numpy(), nbins, histtype = 'step');\n",
    "yax = tf.ones(tf.shape(rads), tf.float32) #plots everything on top of eachother\n",
    "yax = yax * tf.cast(tf.linspace(1, 0, tf.shape(rads)[1]), tf.float32)\n",
    "# print(tf.linspace(0, 1, tf.shape(rads)[1])[:,None] )\n",
    "ax[1].plot(rads,yax, 'b.', markersize = 3)\n",
    "# #_________________________________________________________________\n",
    "\"\"\n",
    "bounds = get_cluster(rads)\n",
    "print(\"\\n Bounds \\n\", bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([1,2])\n",
    "b = np.ones([3,2])\n",
    "print(np.append(b, a, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_r = bounds[6,:]\n",
    "print(edges_r)\n",
    "pts = tf.cast(tf.convert_to_tensor(c1[:,1]), tf.float64)\n",
    "print(pts)\n",
    "\n",
    "bins_r = tfp.stats.find_bins(pts, edges_r)\n",
    "print(bins_r)\n",
    "#get rid of NaNs\n",
    "nonnan = 1 - tf.cast(tf.math.is_nan(bins_r), tf.float32)\n",
    "idxnonan = tf.where(nonnan == 1)\n",
    "print(tf.gather(bins_r, idxnonan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33398169 -0.00806366 -0.01034651]]\n",
      "[[ 0.36177183  0.0056728   0.00114252  0.000432   -0.00459209 -0.01451318]]\n",
      "0.110133\n"
     ]
    }
   ],
   "source": [
    "#get true transformation between frames\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "idx = 0\n",
    "poses0 = dataset.oxts[idx] #<- ID of 1st scan\n",
    "poses1 = dataset.oxts[idx+1] #<- ID of 2nd scan\n",
    "lat0 = poses0.packet.lat\n",
    "lon0 = poses0.packet.lon\n",
    "alt0 = poses0.packet.alt\n",
    "lat1 = poses1.packet.lat\n",
    "lon1 = poses1.packet.lon\n",
    "alt1 = poses1.packet.alt\n",
    "\n",
    "# print(lat0)\n",
    "# print(lon0)\n",
    "\n",
    "dx_oxts, dy_oxts = lat_lon_grid_deltas(np.array([lon0,lon1]), np.array([lat0, lat1]))\n",
    "# print(dx_oxts, dy_oxts) \n",
    "dx_oxts = dx_oxts[0,0].magnitude\n",
    "dy_oxts = dy_oxts[0,0].magnitude\n",
    "dz_oxts = (alt0-alt1)\n",
    "droll_oxts = (poses0.packet.roll - poses1.packet.roll)\n",
    "dpitch_oxts = (poses0.packet.pitch - poses1.packet.pitch)\n",
    "dyaw_oxts = (poses0.packet.yaw - poses1.packet.yaw)\n",
    "\n",
    "rot = poses1.T_w_imu[:3,:3] #trying this\n",
    "\n",
    "dxyz_oxts = np.array([[dx_oxts, dy_oxts, dz_oxts]])\n",
    "dxyz_lidar = dxyz_oxts.dot(rot)\n",
    "print(dxyz_lidar)\n",
    "\n",
    "# dt = 0.10\n",
    "dt = 0.1037 #mean time between lidar samples\n",
    "from_vel = np.array([[poses1.packet.vf*dt, poses1.packet.vl*dt, poses1.packet.vu*dt, -poses1.packet.wf*dt, -poses1.packet.wl*dt, -poses1.packet.wu*dt]])\n",
    "print(from_vel)\n",
    "\n",
    "# print(poses1.packet.vel_accuracy)\n",
    "print((dataset.timestamps[idx+1] - dataset.timestamps[idx]).microseconds/(10e5))\n",
    "\n",
    "# # print(np.shape(dataset.timestamps)[0])\n",
    "# # tvec = np.zeros(np.shape(dataset.timestamps)[0])\n",
    "# tvec = np.zeros(149)\n",
    "# # for i in range(np.shape(dataset.timestamps)[0] - 1):\n",
    "# for i in range(149):\n",
    "# #     print((dataset.timestamps[i+1] - dataset.timestamps[i]).microseconds/(10e5))\n",
    "#     tvec[i] = (dataset.timestamps[i+1] - dataset.timestamps[i]).microseconds/(10e5)\n",
    "# print(tvec)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1,2,3,4]])\n",
    "test = np.append(test,np.array([[0,2,3,4]]),axis = 0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test batch rotation matrix conversions\n",
    "from utils import R_tf\n",
    "\n",
    "print(R_tf(tf.Variable([[0., 0., 1.]])), \"\\n\")\n",
    "\n",
    "angs = tf.Variable([[0., 0., 1.], [0., 0., 1.]])\n",
    "# angs = tf.Variable([[0., 0., 1.]])\n",
    "print(angs)\n",
    "\n",
    "rots = R_tf(angs) \n",
    "print(rots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad tensors to get them to the same length\n",
    "#to fix bug in get_U_and_L()\n",
    "\n",
    "t1 = tf.ones([8,3], tf.int32)\n",
    "print(t1)\n",
    "t2 = tf.ones([7,3], tf.int32)\n",
    "print(t2)\n",
    "\n",
    "bofa = tf.sets.intersection(t1, t2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test- workaround for in place tensor operations\n",
    "indices = tf.cast(tf.constant([1, 2, 3, 5]), tf.int32)[:,None]\n",
    "print(\"indices\", indices)\n",
    "updates = tf.ones(tf.shape(indices))\n",
    "print(\"updates\", updates)\n",
    "shape = tf.constant([7, 1])\n",
    "print(\"shape\", shape)\n",
    "\n",
    "b = tf.scatter_nd(indices, updates, shape)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results of ICET estimates on KITTI lidar point clouds vs GPS/INS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "font = {'fontname':'Times New Roman'}\n",
    "\n",
    "#v8 is the best so far...\n",
    "ICET_estimates = np.loadtxt(\"ICET_estimates_v8.txt\")\n",
    "OXTS_baseline = np.loadtxt(\"OXTS_baseline_v8.txt\")\n",
    "# ICET_estimates = np.loadtxt(\"ICET_estimates_v10.txt\")\n",
    "# OXTS_baseline = np.loadtxt(\"OXTS_baseline_v10.txt\")\n",
    "\n",
    "\n",
    "# vf_from_matlab = np.loadtxt(\"vf.txt\")\n",
    "# vf_from_matlab = np.append(vf_from_matlab, 0)\n",
    "# # print(vf_from_matlab)\n",
    "# OXTS_baseline[:,0] = vf_from_matlab\n",
    "\n",
    "# OXTS_baseline = np.loadtxt(\"OXTS_baseline_gps.txt\")\n",
    "\n",
    "# OXTS_baseline[:,3:] = OXTS_baseline[:,3:]/0.1*0.1037\n",
    "OXTS_baseline = OXTS_baseline/0.1*0.1037\n",
    "\n",
    "# ICET_estimates[:,0] = ICET_estimates[:,0]/tvec*0.1\n",
    "\n",
    "#fix sign errors\n",
    "ICET_estimates[:,1] = -ICET_estimates[:,1]\n",
    "ICET_estimates[:,3:] = -ICET_estimates[:,3:]\n",
    "style1 = 'b-'\n",
    "style2 = 'r-'\n",
    "\n",
    "fig, ax = plt.subplots(3,2, constrained_layout = True)\n",
    "ax[0,0].plot(ICET_estimates[:,0], style1, label = 'ICET')\n",
    "# ax[0,0].plot(OXTS_baseline[:,0], style2, label = 'GPS/INS Baseline')\n",
    "ax[0,0].plot(np.sqrt(OXTS_baseline[:,0]**2 + OXTS_baseline[:,1]**2), style2, label = 'GPS/INS Baseline')\n",
    "ax[0,0].set_title(\"change in x per frame\", **font)\n",
    "ax[0,0].set_ylabel(\"dx (m)\", **font)\n",
    "ax[0,0].legend(loc = 'upper left')\n",
    "ax[0,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "ax[1,0].plot(ICET_estimates[:,1], style1, lw = 1)\n",
    "ax[1,0].plot(-OXTS_baseline[:,1], style2, lw = 1)\n",
    "# ax[1,0].plot(np.arange(n//2, np.shape(ICET_estimates)[0] - n//2 ), moving_avg(OXTS_baseline[:,1], n),  style2, lw = 1)\n",
    "ax[1,0].set_title(\"change in y per frame\", **font)\n",
    "ax[1,0].set_ylabel(\"dy (m)\", **font)\n",
    "ax[1,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[2,0].plot(ICET_estimates[:,2], style1, lw = 1)\n",
    "ax[2,0].plot(OXTS_baseline[:,2], style2, lw = 1)\n",
    "# ax[2,0].plot(np.arange(n//2, np.shape(ICET_estimates)[0] - n//2 ), moving_avg(OXTS_baseline[:,2], n),  style2, lw = 1)\n",
    "ax[2,0].set_title(\"change in z per frame\", **font)\n",
    "ax[2,0].set_ylabel(\"dz (m)\", **font)\n",
    "ax[2,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "ax[0,1].plot(ICET_estimates[:,3], style1, lw = 1)\n",
    "ax[0,1].plot(OXTS_baseline[:,3], style2, lw = 1)\n",
    "ax[0,1].set_title(\"change in roll per frame\", **font)\n",
    "ax[0,1].set_ylabel(\"droll (rad)\", **font)\n",
    "ax[0,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[1,1].plot(ICET_estimates[:,4], style1, lw = 1)\n",
    "ax[1,1].plot(OXTS_baseline[:,4], style2, lw = 1)\n",
    "ax[1,1].set_title(\"change in pitch per frame\", **font)\n",
    "ax[1,1].set_ylabel(\"dpitch (rad)\", **font)\n",
    "ax[1,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[2,1].plot(ICET_estimates[:,5], style1, lw = 1)\n",
    "ax[2,1].plot(OXTS_baseline[:,5], style2, lw = 1)\n",
    "ax[2,1].set_title(\"change in yaw per frame\", **font)\n",
    "ax[2,1].set_ylabel(\"dyaw (rad)\", **font)\n",
    "ax[2,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "# fig.tight_layout(h_pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error between ICET and absolute position\n",
    "plt.rc('font',family='Times New Roman')\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "\n",
    "ICET_pred_stds = np.loadtxt(\"ICET_pred_stds_v8.txt\")\n",
    "# ICET_pred_stds = (2*np.sqrt(ICET_pred_stds))**2\n",
    "# ICET_pred_stds = np.sqrt(2*(ICET_pred_stds**2))\n",
    "\n",
    "\n",
    "#which component to look at\n",
    "# c = 5 #yaw\n",
    "c = 0 # x (forward movement)\n",
    "\n",
    "diffx = OXTS_baseline[:,c] - ICET_estimates[:,c]\n",
    "\n",
    "print(abs(diffx))\n",
    "print(\"correlation coefficient \\n\", np.corrcoef(abs(diffx), ICET_pred_stds[:,0]))\n",
    "\n",
    "#flip sign when looking at yaw\n",
    "if c ==5:\n",
    "    diffx = -diffx \n",
    "    \n",
    "cum_err = np.zeros(np.shape(ICET_pred_stds))\n",
    "cum_diffx = np.zeros(np.shape(diffx))\n",
    "\n",
    "for i in range(np.shape(ICET_pred_stds)[0]):\n",
    "    cum_err[i,:] = np.sum(ICET_pred_stds[:i,:]**2, axis = 0)\n",
    "    #add in baseline OXTS 1-sigma errors\n",
    "#     cum_err[i,:] += np.sqrt(2)*np.array([0.05,0.05,0.1,0.0005,0.0005,0.001])**2\n",
    "    cum_err[i,:] += np.sqrt(2)*np.array([0.08,0.08,0.1,0.0005,0.0005,0.001745])**2\n",
    "    cum_err[i,:] = np.sqrt(cum_err[i,:]) \n",
    "    \n",
    "for j in range(np.shape(diffx)[0]):\n",
    "    cum_diffx[j] = np.sum(diffx[:j]) \n",
    "\n",
    "# # #old (error for each individual timestep)------------------------\n",
    "ax3.plot(diffx, label = 'GPS/INS - ICET')\n",
    "ax3.fill_between(np.linspace(0,150,np.shape(ICET_pred_stds)[0]), -2*ICET_pred_stds[:,c], 2*ICET_pred_stds[:,c], \n",
    "                 color = (0,0,1,0.2), label = 'ICET Predicted 2σ Error Bounds')\n",
    "# # #-------------------------------------------------------------------\n",
    "\n",
    "# #new (accumulated differences in error)--------------------------\n",
    "# # ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx_with_ground, label = 'GPS/INS - ICET')\n",
    "# ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx, label = 'GPS/INS - ICET')\n",
    "# ax3.fill_between(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), -2*cum_err[:,c], 2*cum_err[:,c], \n",
    "#                  color = (0,0,1,0.2), label = 'Predicted 2σ Error Bounds')\n",
    "# # --------------------------------------------------------------------\n",
    "\n",
    "ax3.legend(loc = 'lower left')\n",
    "ax3.set_title(\"Predicted vs Actual Error in x\")\n",
    "ax3.set_xlabel(\"time (s)\", **font)\n",
    "ax3.set_ylabel(\"GPS/INS Baseline x - Odometry Estimate x (m)\", **font)\n",
    "# ax3.set_ylim([-0.07,0.07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test where points are inside spherical cell...\n",
    "# print(it.cloud1_tensor_spherical)\n",
    "maxtheta = tf.constant([[0.2],[0.7]])\n",
    "maxr = tf.constant([[0.5],[2.]])\n",
    "\n",
    "ans1 = tf.greater(it.cloud1_tensor_spherical[:,1], maxtheta)\n",
    "# print(ans1)\n",
    "ans2 = tf.less(it.cloud1_tensor_spherical[:,0], maxr)\n",
    "# print(ans2)\n",
    "combined = tf.Variable([ans1, ans2])\n",
    "# print(combined)\n",
    "ans3 = tf.math.reduce_all(combined, axis = 1)\n",
    "\n",
    "print(ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate each element of an n*1 vector 3 times\n",
    "t = tf.linspace(0,5,6)[:,None]\n",
    "print(t)\n",
    "\n",
    "test  = tf.tile(t, [3,1])\n",
    "# print(test)\n",
    "test2 = tf.reshape(tf.transpose(tf.reshape(test, [3,-1])), [-1,1])\n",
    "print(test2)\n",
    "test3 = tf.reshape(tf.transpose(tf.reshape(test, [3,-1])), [-1,3])\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate each element of an n*3 vector 3 times\n",
    "t = tf.linspace(1,5,5)\n",
    "t = tf.transpose(tf.Variable([t, 2*t, 3*t]))\n",
    "print(t)\n",
    "\n",
    "test  = tf.tile(t, [4,1])\n",
    "# print(test)\n",
    "\n",
    "test = tf.reshape(tf.transpose(test), [3, 4, -1])\n",
    "# print(test)\n",
    "\n",
    "test = tf.transpose(test, [2,1,0])\n",
    "# print(test)\n",
    "\n",
    "test = tf.reshape(test, [-1,3])\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MC sim to compare performance estimation in \"realistic\" scenes with flat vs curved surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "c1_OG = np.loadtxt(\"scene2_scan1.txt\", dtype = float) #thin cylinders\n",
    "c2_OG = np.loadtxt(\"scene2_scan2.txt\", dtype = float)\n",
    "# c1_OG = np.loadtxt(\"scene3_scan1.txt\", dtype = float) #rectangles\n",
    "# c2_OG = np.loadtxt(\"scene3_scan2.txt\", dtype = float)\n",
    "# c1 = np.loadtxt(\"scene4_scan1.txt\", dtype = float) #cylinders\n",
    "# c2 = np.loadtxt(\"scene4_scan2.txt\", dtype = float)\n",
    "\n",
    "xvec = np.zeros([epochs, 6])\n",
    "pred_stds = np.zeros([epochs, 6])\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"\\n -------------- Epoch\", i, \"--------------------\")\n",
    "    #add noise (if not generated when point clouds were created)\n",
    "    c1 = c1_OG + 0.02*np.random.randn(np.shape(c1_OG)[0], 3)\n",
    "    c2 = c2_OG + 0.02*np.random.randn(np.shape(c2_OG)[0], 3)  \n",
    "\n",
    "    it = ICET(cloud1 = c1, cloud2 = c2, fid = 70, niter = 20, draw = False, group = 2, RM = True)\n",
    "    xvec[i] = it.X\n",
    "    pred_stds[i] = it.pred_stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_soln_err = np.array([-0.5, 0, 0, 0, 0, 0,]) - np.mean(xvec, axis = 0)\n",
    "\n",
    "print(\"Smaller Clylindrical features, no occlusion, no outlier rejection, n=10:\\n\")\n",
    "# print(\"Rectangular features, no occlusion, no outlier rejection, n=50:\\n\")\n",
    "\n",
    "print(\"mean solution error: \\n\", mean_soln_err)\n",
    "soln_std = np.std(xvec, axis = 0)\n",
    "print(\"\\n experimentally determined std: \\n\", soln_std)\n",
    "mean_pred_std = np.mean(pred_stds, axis = 0)\n",
    "print(\"\\n predicted std: \\n\", mean_pred_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "nbins = 10\n",
    "ax.hist(xvec[:,0], nbins)\n",
    "# ax.set_title(\"Clylindrical features, no occlusion, no outlier rejection, n=50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
