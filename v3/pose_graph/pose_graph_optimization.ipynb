{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db869367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "np.set_printoptions(precision=8, linewidth = 75)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ece94a",
   "metadata": {},
   "source": [
    "# Pose Graph Optimization\n",
    "\n",
    "### GOAL: Adjust configuration of absolute poses (nodes) to minimize squared error intorduced by constraints (edges)\n",
    "\n",
    "\n",
    "Node: [x, y, z, r, p, y]\n",
    "\n",
    "Edge: Odometry Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714bdd0",
   "metadata": {},
   "source": [
    "# State vector $x$\n",
    "\n",
    "absolute position and orientation of vehicle at each timestep\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{x} = \n",
    "\\begin{bmatrix}\n",
    "\\textbf{x}_1\\\\\n",
    "\\textbf{x}_2\\\\\n",
    "\\textbf{x}_3 \\\\\n",
    "\\vdots\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "x_1 & y_1 & z_1 & r_1 & p_1 & y_1 \\\\\n",
    "x_2 & y_2 & z_2 & r_2 & p_2 & y_2 \\\\\n",
    "x_3 & y_3 & z_3 & r_3 & p_3 & y_3 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45989fb",
   "metadata": {},
   "source": [
    "# Transformations $\\mathbf{X}$  \n",
    "Represeneted in Homogenous Coordinates. This is an overparameterization (similar to using quaternions) which helps avoid singularities when calculating the error function to adjust each Gauss-Newton iteration, however, the additional degrees of freedom need to be removed before forming our state vector\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X_i} = \n",
    "\\begin{bmatrix}\n",
    "R_{11} & R_{12} & R_{13} & dx\\\\\n",
    "R_{21} & R_{22} & R_{23} & dy \\\\\n",
    "R_{31} & R_{32} & R_{33} & dz \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$\\big(\\mathbf{X}_i^{-1} \\mathbf{X}_{i+1} \\big)$  describes how node $i$ sees node $(i+1)$ (ex: odometry)\n",
    "\n",
    "$\\big(\\mathbf{X}_i^{-1} \\mathbf{X}_{j} \\big)$  describes how node $i$ sees node $j$ (ex: loop closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbae8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2t(vector):\n",
    "    \"\"\"converts a transformation vector to homogenous coordinate system\"\"\"\n",
    "    if len(tf.shape(vector)) == 1: #allow for 1-D or N-D input\n",
    "        vector = vector[None,:]\n",
    "    angs = vector[:,3:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    rot = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]])\n",
    "    rot = tf.transpose(rot, [2, 0, 1])\n",
    "    trans = vector[:,:3]\n",
    "    trans = np.reshape(trans, (np.shape(rot)[0], 3, 1))\n",
    "    transform = tf.concat((rot, trans), axis = -1)\n",
    "    extra = tf.tile(tf.constant([[[0., 0., 0., 1.]]], dtype = tf.double), (np.shape(rot)[0],1,1))\n",
    "    transform = tf.concat((transform, extra), axis = -2)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e25b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2v(mat):\n",
    "    \"\"\"converts transformation matrix to state vector\"\"\"\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    vector = tf.concat((mat[:,:3,-1], angs.T), axis =1)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c66d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: v2t() -> t2v() is returning to the same value only if I take inverse (for rotation) \n",
    "#                     and without inverse only (for translation). [T]^-1 @ [T] = I still\n",
    "#Question: is this normal?  \n",
    "\n",
    "# # test = np.array([1., 2., 3., 0.05, 0.00, -0.14])\n",
    "# test = np.ones([2,6])\n",
    "# test[1,:] = np.array([1., 2., 3., 0.003, 0.001, 0.3])\n",
    "# T = v2t(test)\n",
    "# # print(\"T: \\n\",T)\n",
    "# vect_trans = t2v(T).numpy()[:,:3]\n",
    "# vect_rot = t2v(tf.linalg.inv(T)).numpy()[:,3:]\n",
    "# print(np.append(vect_trans, vect_rot, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d90777",
   "metadata": {},
   "source": [
    "# Least Squares Error Function\n",
    "\n",
    "\n",
    "The optimial state vector, $x^*$, occurs where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x^* = \\arg\\min_x \\sum_{ij}^{} e^T_{ij}(x_i,x_j)\\Omega_{ij}e_{ij}(x_i,x_j)\n",
    "\\end{equation}\n",
    "\n",
    "$\\Omega_{ij}$ is the information matrix associated with the odometry estimate that relates $i$ and $j$. $\\Omega_{ij}$ is the inverse of the covariance matrix $\\sigma_{ij}$\n",
    "\n",
    "the error funcion for each connected node $i,j$ as a function of the state vector $x$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "e_{ij}(x) = \\text{t2v}(Z_{ij}^{-1} (X_j^{-1}X_i))\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Z_{ij}^{-1} = \\text{constraint (from measurement)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "(X_j^{-1}X_i) = x_i \\text{ relative to }x_j \\text{ given the current model of system} \n",
    "\\end{equation}\n",
    "\n",
    "$ \\text{Stachniss and Grisetti use} \\boxplus \\text{to repersent the mapping of euclidian space } v \\text{ to a homogenous coordinate frame } t$\n",
    "\n",
    "\n",
    "Important Note: $e_{ij}(x)$ only depends on $x_i$ and $x_j$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "78eb22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_e(Zij, Xij):\n",
    "    \"\"\"calculates error function w.r.t. nodes i and j\n",
    "    Zij == pose j relative to i according to nodes (rotation matrix)\n",
    "    Xij == pose j relative to i according to constraints (rotation matrix)\n",
    "    \"\"\"        \n",
    "    e = t2v(tf.linalg.pinv(Zij) @ Xij)\n",
    "\n",
    "    return(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f0c970bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zij = v2t(np.array([1.,  1.9, 0., 0.0003, 0.0005, 0.01 ])) # get from graph \n",
    "# # Xij = v2t(np.array([1.1, 2.0, 0., 0.,     0.0,    0.008])) # get from odometry message\n",
    "# Zij =  v2t(np.zeros([2,6]))\n",
    "# Xij =  v2t(np.random.randn(2,6))\n",
    "\n",
    "# e = get_e(Zij, Xij)\n",
    "# print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8eae54",
   "metadata": {},
   "source": [
    "# Linearizing the System\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "e_{ij}(x + \\Delta x) \\approx e_{ij}(x) + J_{ij} \\Delta x\n",
    "\\end{equation}\n",
    "\n",
    "Here, $J_{ij}$ is the the jacobian of $e_{ij}$ with respect to x\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "J_{ij} = \\frac{\\delta e_{ij}(x)}{\\delta x} = \\bigg{(} 0 \\dots \\frac{\\delta e_{ij}(x_i)}{\\delta x_i}\n",
    "\\dots \\frac{\\delta e_{ij}(x_j)}{\\delta x_j} \\dots 0 \\bigg{)} = \\bigg{(} 0 \\dots A_{ij} \\dots B_{ij} \\dots 0 \\bigg{)} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "A_{ij}, B_{ij} \\in \\mathbb{R}^{6 \\times 6}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eaec61",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J_{ij}(x) \\in \\mathbb{R}^{6 \\times 6N}\n",
    "\\end{equation}\n",
    "where $N$ is the total number of poses being solved for (nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ce6d7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_ij_B_ij(e_ij):\n",
    "    \"\"\"calculates nonzero terms from the Jacobian of error function w.r.t. nodes i and j using TensorFlow\n",
    "        e_ij == error function [x, y, z, phi, theta, psi]\n",
    "        \n",
    "        NOTE: this works with batch operations: error vectors passed in as tensor will result in\n",
    "                corresponding output in the same order \n",
    "    \"\"\"\n",
    "    e_ij = tf.cast(e_ij, tf.float32)\n",
    "    \n",
    "    p_point = e_ij[:,:3]\n",
    "    phi = e_ij[:,3][:,None]\n",
    "    theta = e_ij[:,4][:,None]\n",
    "    psi = e_ij[:,5][:,None]\n",
    "    \n",
    "    eyes = tf.tile(-tf.eye(3)[None,:,:], [tf.shape(p_point)[0] , 1, 1])\n",
    "    \n",
    "#     deriv of R() wrt phi\n",
    "    dRdPhi = tf.Variable([[tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-sin(psi)*sin(phi) + cos(phi)*sin(theta)*cos(psi)), (cos(phi)*sin(psi) + sin(theta)*sin(phi)*cos(psi))],\n",
    "                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-sin(phi)*cos(psi) - cos(phi)*sin(theta)*sin(psi)), (cos(phi)*cos(psi) - sin(theta)*sin(psi)*sin(phi))], \n",
    "                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-cos(phi)*cos(theta)), (-sin(phi)*cos(theta))] ])[:,:,:,0]\n",
    "    dRdPhi = tf.transpose(dRdPhi, (2,0,1))\n",
    "    Jx = dRdPhi @ p_point[:,:,None]\n",
    "    \n",
    "    # (deriv of R() wrt theta).dot(p_point)\n",
    "    dRdTheta = tf.Variable([[(-sin(theta)*cos(psi)), (cos(theta)*sin(phi)*cos(psi)), (-cos(theta)*cos(phi)*cos(psi))],\n",
    "                               [(sin(psi)*sin(theta)), (-cos(theta)*sin(phi)*sin(psi)), (cos(theta)*sin(psi)*cos(phi))],\n",
    "                               [(cos(theta)), (sin(phi)*sin(theta)), (-sin(theta)*cos(phi))] ])[:,:,:,0]\n",
    "    dRdTheta = tf.transpose(dRdTheta, (2,0,1))\n",
    "    Jy = dRdTheta @ p_point[:,:,None]\n",
    "\n",
    "    # deriv of R() wrt psi\n",
    "    dRdPsi = tf.Variable([[(-cos(theta)*sin(psi)), (cos(psi)*cos(phi) - sin(phi)*sin(theta)*sin(psi)), (cos(psi)*sin(phi) + sin(theta)*cos(phi)*sin(psi)) ],\n",
    "                                       [(-cos(psi)*cos(theta)), (-sin(psi)*cos(phi) - sin(phi)*sin(theta)*cos(psi)), (-sin(phi)*sin(psi) + sin(theta)*cos(psi)*cos(phi))],\n",
    "                                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None],tf.zeros(len(phi), dtype = phi.dtype)[:,None],tf.zeros(len(phi), dtype = phi.dtype)[:,None]]])[:,:,:,0]\n",
    "    dRdPsi = tf.transpose(dRdPsi, (2,0,1))\n",
    "    Jz = dRdPsi @ p_point[:,:,None]\n",
    "    \n",
    "    top = tf.concat([eyes, Jx, Jy, Jz], axis = 2)\n",
    "    flipped = tf.concat([tf.transpose(Jx, (0,2,1)), \n",
    "                         tf.transpose(Jy, (0,2,1)), \n",
    "                         tf.transpose(Jz, (0,2,1))], axis = 1)\n",
    "    bottom = tf.concat([flipped, eyes], axis = 2)\n",
    "    A_ij = tf.concat([top, bottom], axis = 1)\n",
    "    B_ij = -A_ij\n",
    "    \n",
    "    return A_ij, B_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3cea8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_J(e, ij):\n",
    "    \"\"\"Forms sparse jacobian J, with entries A and B at indices i and j \n",
    "    J == [N, 6, 6*N], N = number of nodes\n",
    "    e == [N, 6] error vectors\n",
    "    ij == [N, 2] contains scan indices of each node ex: [scan2, scan5]\n",
    "    \"\"\"\n",
    "    total_num_of_nodes = np.max(ij) + 1 #TODO: is this too big??\n",
    "    if len(tf.shape(ij))< 2: #expand dimensions if only single pair passed in\n",
    "        ij = ij[None,:]\n",
    "    A_ij, B_ij = get_A_ij_B_ij(e)\n",
    "    \n",
    "    # Need to tile DIFFERENT AMOUNT depending on the index \n",
    "    #    TODO: move to batch operation?\n",
    "    J = tf.zeros([0,6,total_num_of_nodes*6])\n",
    "    for k in range(len(ij)):\n",
    "        #TODO: add logic for when i and j are same value, when j = i + 1 ...\n",
    "        leading = tf.tile(tf.zeros([6,6]), [1, ij[k,0] ]) #leading zeros before i\n",
    "#         print(\"\\n leading \\n\", leading)\n",
    "        between = tf.tile(tf.zeros([6,6]), [1, ij[k,1] - ij[k,0] - 1 ]) #zeros between i and j\n",
    "#         print(\"\\n between: \\n\", between)\n",
    "        ending  = tf.tile(tf.zeros([6,6]), [1, total_num_of_nodes - ij[k,1] - 1 ])\n",
    "        J_ij = tf.concat([leading, A_ij[k], between, B_ij[k], ending], axis = 1)\n",
    "        J = tf.concat((J, J_ij[None,:,:]), axis = 0)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "eee31e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ij = tf.constant(odometry_history[1:3,6:].astype(int))\n",
    "# ij = np.array([[1,3],\n",
    "#                [0,2]])\n",
    "# # print(ij)\n",
    "# # print(np.max(ij))\n",
    "# # print(\"e: \\n\", e)\n",
    "\n",
    "# J = get_J(e, ij)  \n",
    "# # print(\"\\n J \\n\",J[0])\n",
    "# # print(\"\\n J \\n\",tf.shape(J),  \"\\n\", np.around(J.numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf95ce",
   "metadata": {},
   "source": [
    "# Accumumlate Sparse Tensors\n",
    "\n",
    "calculate jacobians in batch operation first, then bring to sparse tensor for matmul??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166659e",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Large\n",
    "b^T = \\sum_{ij}^{}b_{ij} = \\sum_{ij}^{}e_{ij}^T \\Omega_{ij} J_{ij}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c29ab330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_matrix(pred_stds):\n",
    "    \"\"\"returns information matrix sigma from ICET cov_estimates\"\"\"\n",
    "    pred_stds = tf.convert_to_tensor(pred_stds)[:,:,None] #convert to TF Tensor\n",
    "    cov = pred_stds @ tf.transpose(pred_stds, (0,2,1))    #convert predicted stds -> covariance matrix\n",
    "    info = tf.linalg.pinv(cov) #invert\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6c6f5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b(e, omega, J):\n",
    "    \"\"\"gets b matrix, using batched operations \"\"\"\n",
    "    b_T = tf.math.reduce_sum(tf.transpose(e, (0,2,1)) @ omega @ tf.cast(J, tf.double), axis = 0)\n",
    "#     print(\"\\n b_T: \\n\", tf.shape(b_T))\n",
    "    b = tf.transpose(b_T)\n",
    "#     print(\"e: \\n\", tf.shape(e))\n",
    "#     print(\"J: \\n\", tf.shape(J))\n",
    "#     print(\"omega: \\n\", tf.shape(omega))\n",
    "#     print(\"b: \\n\", tf.shape(b))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "74ba0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ij(ij_raw):\n",
    "    \"\"\"generates ij matrix, which describes which nodes are connected to \n",
    "       each other through odometry constraints. \n",
    "       Removes skipped indices and shifts everything to start at 0\"\"\"\n",
    "\n",
    "#     print(\"ij_raw: \\n\", ij_raw)    \n",
    "    y, idx = tf.unique(tf.reshape(ij_raw, [-1]))\n",
    "#     print(\"\\n y: \\n\", y, \"\\n idx: \\n\", idx)    \n",
    "    ij = tf.reshape(idx, [-1,2])\n",
    "#     print(\"ij: \\n\", ij)\n",
    "    return ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abe80a",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Large\n",
    "H = \\sum_{ij}^{}H_{ij} = \\sum_{ij}^{}J_{ij}^T \\Omega J_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "Init Hessian once at start of simulation, update in place as new linearizations are added(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "06ed5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H(J, omega):\n",
    "    \"\"\"returns hessian H\"\"\"\n",
    "    H_ij = tf.transpose(J, (0,2,1)) @ tf.cast(omega, tf.float32) @ J\n",
    "    H = tf.math.reduce_sum(H_ij, axis = 0)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "de8e65ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([42  1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([42 42], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "odometry_history = np.load(\"test_data/leddartech_pixset/T_vec_history.npy\")[:10,:] #Load test data\n",
    "pred_stds_history = np.load(\"test_data/leddartech_pixset/cov_vec_history.npy\")[:10,:]\n",
    "ij = get_ij(odometry_history[:,6:].astype(np.int32))\n",
    "\n",
    "# constraints (from odometry measurements)\n",
    "Z =  v2t(odometry_history[:,:6])      \n",
    "# relative pose estimates (from initial configuration of graph)\n",
    "X =  v2t(odometry_history[:,:6] + 0.01*np.ones(np.shape(odometry_history[:,:6])))\n",
    "\n",
    "#TODO: make function to get X given x\n",
    "\n",
    "e = get_e(Z, X)\n",
    "omega = get_information_matrix(pred_stds_history[:,:6])\n",
    "J = get_J(e, ij)\n",
    "\n",
    "b = get_b(e[:,:,None], omega, J)\n",
    "print(tf.shape(b))\n",
    "\n",
    "H = get_H(J, omega)\n",
    "print(tf.shape(H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f8510",
   "metadata": {},
   "source": [
    "Similar to ICET, we can use Newton-Raphson to iteratively solve for small perterbations to the state vector $x$ that bring us towards a better solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "H \\Delta x = -b\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x \\rightarrow x + \\Delta x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a1f2c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    1.5   0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.5   0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.55]], shape=(6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "indices = tf.constant([[1,3], [3,1], [5,5]], dtype = tf.int64) #[N, ndims]\n",
    "values = tf.constant([1.5, 1.5, -0.55])\n",
    "dense_shape = tf.constant([6, 6], dtype = tf.int64)\n",
    "sparse_J =  tf.sparse.SparseTensor(indices, values, dense_shape)\n",
    "# print(sparse_J)\n",
    "print(tf.sparse.to_dense(sparse_J))\n",
    "# print(tf.linalg.det(tf.sparse.to_dense(sparse_J)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d6d19fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[10.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.   10.    0.    1.5   0.    0.  ]\n",
      "  [ 0.    0.   10.    0.    0.    0.  ]\n",
      "  [ 0.    1.5   0.   10.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.   10.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    9.45]]], shape=(1, 6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[3.1622777  0.         0.         0.         0.         0.        ]\n",
      "  [0.         3.1622777  0.         0.         0.         0.        ]\n",
      "  [0.         0.         3.1622777  0.         0.         0.        ]\n",
      "  [0.         0.47434163 0.         3.1264994  0.         0.        ]\n",
      "  [0.         0.         0.         0.         3.1622777  0.        ]\n",
      "  [0.         0.         0.         0.         0.         3.0740852 ]]], shape=(1, 6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.05622515  0.06674117  0.00209131 -0.00835607 -0.02905761\n",
      "   -0.12618788]\n",
      "  [ 0.068854    0.07326397  0.03567062  0.06599127  0.01796907\n",
      "    0.07600282]\n",
      "  [ 0.04940329  0.20818421 -0.12486959 -0.06554834 -0.05827968\n",
      "   -0.06529091]\n",
      "  [-0.06887669 -0.13288568  0.04117076 -0.12038639 -0.04279433\n",
      "   -0.09988555]\n",
      "  [-0.02092358 -0.03086608  0.17814255 -0.01639498  0.00815606\n",
      "   -0.10422896]\n",
      "  [-0.00689026 -0.10140619 -0.0629163   0.00720818  0.18635397\n",
      "    0.09260269]]], shape=(1, 6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test = tf.sparse.to_dense(sparse_J)[None,:,:] + 10*tf.eye(6)[None,:,:]\n",
    "print(test)\n",
    "\n",
    "chol = tf.linalg.cholesky(test) #needs to be symmetric and positive definite\n",
    "print(chol)\n",
    "\n",
    "rhs = tf.random.normal([1,6,6])\n",
    "ans =  tf.linalg.cholesky_solve(chol, rhs)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f69499",
   "metadata": {},
   "source": [
    "# Apply Constraint to First Node in Kinematic Chain\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "H_{11} \\rightarrow H_{11} + I\n",
    "\\end{equation}\n",
    "\n",
    "Optimization routine can't make sense of only relative measurements. We need to specify the first pose as the origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0517636",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Figure out references in Jupyter Notebook\n",
    "\n",
    "\n",
    "# Questions\n",
    "\n",
    "Should $A_{ij} = -B_{ij}$?\n",
    "\n",
    "Are there advantages to reporting state vector in unit quaternions? Besides being less intuitive to work with I've read they can also introduce problems in optimization routine since they add an additional degree of freedom. Every guide I've seen so far uses homogenous coordinate representation for the transformation matrices when computing the loss function, since they can be applied neatly in series. So rotation matrices do not produce singularities?\n",
    "\n",
    "Is what we did in ICET to handle sparsity (i.e. accumulating contributions for corresponding elements rather than performing full matrix inversion) similar to a Choelesky Decomposition?\n",
    "\n",
    "<span style=\"color:red\"> What is going on with the numerics in get_e_ij()? Why is it not just t2v(Zij) - t2v(Zij)?? </span>\n",
    "\n",
    "\n",
    "\n",
    "# Potential Contributions\n",
    "\n",
    "Use ICET error covaraince estimation to demonstrate improvement in accuracy for Volpe Dataset\n",
    "\n",
    "Use ICET output to inform $\\Omega$ as a spatially dependant weighting field rather than simply indexing each unique point. Explore Gaussian Process Regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a759f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.random.normal([600,600])\n",
    "# print(tf.linalg.pinv(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645def28",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.inv.html#scipy.sparse.linalg.inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_a = tf.sparse.SparseTensor(indices=[[0, 2], [3, 4]],\n",
    "                       values=[31.0, 2.0], \n",
    "                       dense_shape=[4, 6])\n",
    "st_b = tf.sparse.SparseTensor(indices=[[0, 2], [3, 0]],\n",
    "                       values=[56.0, 38.0],\n",
    "                       dense_shape=[4, 6])\n",
    "st_sum = tf.sparse.add(st_a, st_b)\n",
    "# print(st_sum)\n",
    "print(tf.linalg.pinv(tf.sparse.to_dense(st_sum)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0c566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4748134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
