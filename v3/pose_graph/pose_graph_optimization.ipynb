{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db869367",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "from utils import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "np.set_printoptions(precision=8, linewidth = 75)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ece94a",
   "metadata": {},
   "source": [
    "# Pose Graph Optimization\n",
    "\n",
    "### GOAL: Adjust configuration of absolute poses (nodes) to minimize squared error intorduced by constraints (edges)\n",
    "\n",
    "\n",
    "Node: [x, y, z, r, p, y]\n",
    "\n",
    "Edge: Odometry Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714bdd0",
   "metadata": {},
   "source": [
    "# State vector $x$\n",
    "\n",
    "absolute position and orientation of vehicle at each timestep\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{x} = \n",
    "\\begin{bmatrix}\n",
    "\\textbf{x}_1\\\\\n",
    "\\textbf{x}_2\\\\\n",
    "\\textbf{x}_3 \\\\\n",
    "\\vdots\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "x_1 & y_1 & z_1 & r_1 & p_1 & y_1 \\\\\n",
    "x_2 & y_2 & z_2 & r_2 & p_2 & y_2 \\\\\n",
    "x_3 & y_3 & z_3 & r_3 & p_3 & y_3 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45989fb",
   "metadata": {},
   "source": [
    "# Transformations $\\mathbf{X}$  \n",
    "Represeneted in Homogenous Coordinates. This is an overparameterization (similar to using quaternions) which helps avoid singularities when calculating the error function to adjust each Gauss-Newton iteration, however, the additional degrees of freedom need to be removed before forming our state vector\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X_i} = \n",
    "\\begin{bmatrix}\n",
    "R_{11} & R_{12} & R_{13} & dx\\\\\n",
    "R_{21} & R_{22} & R_{23} & dy \\\\\n",
    "R_{31} & R_{32} & R_{33} & dz \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$\\big(\\mathbf{X}_i^{-1} \\mathbf{X}_{i+1} \\big)$  describes how node $i$ sees node $(i+1)$ (ex: odometry)\n",
    "\n",
    "$\\big(\\mathbf{X}_i^{-1} \\mathbf{X}_{j} \\big)$  describes how node $i$ sees node $j$ (ex: loop closure)\n",
    "\n",
    "\n",
    "<span style=\"color:red\"> Important note: $X$ will need to contain more elements than $x$, since $X$ must represent all state pairs observed in constraints $Z$, while $x$ only needs a single element to represent the absolute pose of each state </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2t(vector):\n",
    "    \"\"\"converts a transformation vector to homogenous coordinate system\"\"\"\n",
    "    if len(tf.shape(vector)) == 1: #allow for 1-D or N-D input\n",
    "        vector = vector[None,:]\n",
    "    angs = vector[:,3:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    rot = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]])\n",
    "    rot = tf.transpose(rot, [2, 0, 1])\n",
    "    trans = vector[:,:3]\n",
    "    trans = np.reshape(trans, (np.shape(rot)[0], 3, 1))\n",
    "    transform = tf.concat((rot, trans), axis = -1)\n",
    "    extra = tf.tile(tf.constant([[[0., 0., 0., 1.]]], dtype = tf.double), (np.shape(rot)[0],1,1))\n",
    "    transform = tf.concat((transform, extra), axis = -2)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e25b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2v(mat):\n",
    "    \"\"\"converts transformation matrix to state vector\"\"\"\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    vector = tf.concat((mat[:,:3,-1], angs.T), axis =1)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c66d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: v2t() -> t2v() is returning to the same value only if I take inverse (for rotation) \n",
    "#                     and without inverse only (for translation). [T]^-1 @ [T] = I still\n",
    "#Question: is this normal?  \n",
    "\n",
    "# # test = np.array([1., 2., 3., 0.05, 0.00, -0.14])\n",
    "# test = np.ones([2,6])\n",
    "# test[1,:] = np.array([1., 2., 3., -0.003, 0.001, -0.3])\n",
    "# T = v2t(test)\n",
    "# # print(\"T: \\n\",T)\n",
    "# vect_trans = t2v(T).numpy()[:,:3]\n",
    "# vect_rot = t2v(tf.linalg.inv(T)).numpy()[:,3:]\n",
    "# print(np.append(vect_trans, vect_rot, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d90777",
   "metadata": {},
   "source": [
    "# Least Squares Error Function\n",
    "\n",
    "\n",
    "The optimial state vector, $x^*$, occurs where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x^* = \\arg\\min_x \\sum_{ij}^{} e^T_{ij}(x_i,x_j)\\Omega_{ij}e_{ij}(x_i,x_j)\n",
    "\\end{equation}\n",
    "\n",
    "$\\Omega_{ij}$ is the information matrix associated with the odometry estimate that relates $i$ and $j$. $\\Omega_{ij}$ is the inverse of the covariance matrix $\\sigma_{ij}$\n",
    "\n",
    "the error funcion for each connected node $i,j$ as a function of the state vector $x$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "e_{ij}(x) = \\text{t2v}(Z_{ij}^{-1} (X_j^{-1}X_i))\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Z_{ij}^{-1} = \\text{constraint (from measurement)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "(X_j^{-1}X_i) = x_i \\text{ relative to }x_j \\text{ given the current model of system} \n",
    "\\end{equation}\n",
    "\n",
    "$ \\text{Stachniss and Grisetti use} \\boxplus \\text{to repersent the mapping of euclidian space } v \\text{ to a homogenous coordinate frame } t$\n",
    "\n",
    "\n",
    "Important Note: $e_{ij}(x)$ only depends on $x_i$ and $x_j$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c970bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zij = v2t(np.array([[1.,  1.9, 0., 0.000, 0.000, 0.00 ]])) # get from graph \n",
    "Xij = v2t(np.array([[1.1, 2.0, 0., 0.,     0.0,    0.00]])) # get from odometry message\n",
    "# Zij =  v2t(np.zeros([2,6]))\n",
    "# Xij =  v2t(np.random.randn(2,6))\n",
    "ij = np.array([[0,1],[1,2]])\n",
    "\n",
    "e = get_e(Zij, Xij)\n",
    "print(e)\n",
    "\n",
    "# a, b = get_A_ij_B_ij(e)\n",
    "# # print(a)\n",
    "\n",
    "# J = get_J(e, ij)\n",
    "# # print(J[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8eae54",
   "metadata": {},
   "source": [
    "# Linearizing the System\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "e_{ij}(x + \\Delta x) \\approx e_{ij}(x) + J_{ij} \\Delta x\n",
    "\\end{equation}\n",
    "\n",
    "Here, $J_{ij}$ is the the jacobian of $e_{ij}$ with respect to x\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "J_{ij} = \\frac{\\delta e_{ij}(x)}{\\delta x} = \\bigg{(} 0 \\dots \\frac{\\delta e_{ij}(x_i)}{\\delta x_i}\n",
    "\\dots \\frac{\\delta e_{ij}(x_j)}{\\delta x_j} \\dots 0 \\bigg{)} = \\bigg{(} 0 \\dots A_{ij} \\dots B_{ij} \\dots 0 \\bigg{)} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "A_{ij}, B_{ij} \\in \\mathbb{R}^{6 \\times 6}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eaec61",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J_{ij}(x) \\in \\mathbb{R}^{6 \\times 6N}\n",
    "\\end{equation}\n",
    "where $N$ is the total number of poses being solved for (nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_J(e, ij):\n",
    "    \"\"\"Forms sparse jacobian J, with entries A and B at indices i and j \n",
    "    J == [N, 6, 6*N], N = number of nodes\n",
    "    e == [N, 6] error vectors\n",
    "    ij == [N, 2] contains scan indices of each node ex: [scan2, scan5]\n",
    "    \"\"\"\n",
    "    total_num_of_nodes = np.max(ij) + 1 #TODO: is this too big??\n",
    "    if len(tf.shape(ij))< 2: #expand dimensions if only single pair passed in\n",
    "        ij = ij[None,:]\n",
    "    A_ij, B_ij = get_A_ij_B_ij(e)\n",
    "    \n",
    "    # Need to tile DIFFERENT AMOUNT depending on the index \n",
    "    #    TODO: move to batch operation?\n",
    "    J = tf.zeros([0,6,total_num_of_nodes*6])\n",
    "    for k in range(len(ij)):\n",
    "        #TODO: add logic for when i and j are same value, when j = i + 1 ...\n",
    "        leading = tf.tile(tf.zeros([6,6]), [1, ij[k,0] ]) #leading zeros before i\n",
    "#         print(\"\\n leading \\n\", leading)\n",
    "        between = tf.tile(tf.zeros([6,6]), [1, ij[k,1] - ij[k,0] - 1 ]) #zeros between i and j\n",
    "#         print(\"\\n between: \\n\", between)\n",
    "        ending  = tf.tile(tf.zeros([6,6]), [1, total_num_of_nodes - ij[k,1] - 1 ])\n",
    "        J_ij = tf.concat([leading, A_ij[k], between, B_ij[k], ending], axis = 1)\n",
    "        J = tf.concat((J, J_ij[None,:,:]), axis = 0)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee31e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ij = tf.constant(odometry_history[1:3,6:].astype(int))\n",
    "# ij = np.array([[1,3],\n",
    "#                [0,2]])\n",
    "# print(ij)\n",
    "# # print(np.max(ij))\n",
    "# # print(\"e: \\n\", e)\n",
    "\n",
    "# J = get_J(e, ij)  \n",
    "# print(\"\\n J \\n\",J[-1])\n",
    "# print(\"\\n J \\n\",tf.shape(J))  \n",
    "# # print(\"\\n\", np.around(J.numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf95ce",
   "metadata": {},
   "source": [
    "# Accumumlate Sparse Tensors\n",
    "\n",
    "calculate jacobians in batch operation first, then bring to sparse tensor for matmul??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166659e",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Large\n",
    "b^T = \\sum_{ij}^{}b_{ij} = \\sum_{ij}^{}e_{ij}^T \\Omega_{ij} J_{ij}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ab330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_matrix(pred_stds):\n",
    "    \"\"\"returns information matrix (omega) from ICET cov_estimates\"\"\"\n",
    "#     #I think this is wrong ... \n",
    "#     pred_stds = tf.convert_to_tensor(pred_stds)[:,:,None] #convert to TF Tensor\n",
    "#     cov = pred_stds @ tf.transpose(pred_stds, (0,2,1))    #convert predicted stds -> covariance matrix\n",
    "#     info = tf.linalg.pinv(cov) #invert\n",
    "    \n",
    "    #debug - set to identity\n",
    "    info = tf.tile(tf.eye(6)[None,:,:], [tf.shape(pred_stds)[0] , 1, 1])\n",
    "    info = tf.cast(info, tf.double)\n",
    "\n",
    "#     #debug - weigh rotations more heavily than translations\n",
    "# #     m = tf.linalg.diag(tf.constant([1., 1., 1., 10., 10., 10.]))\n",
    "# #     m = tf.linalg.diag(tf.constant([10., 10., 10., 1., 1., 1.])) #vice-versa\n",
    "#     m = tf.linalg.diag(tf.constant([100., 100., 100., 100., 100., 100.])) #huge values\n",
    "#     info = tf.tile(m[None,:,:], [tf.shape(pred_stds)[0] , 1, 1])\n",
    "#     info = tf.cast(info, tf.double)\n",
    "\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_information_matrix(pred_stds_history)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60686e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b(e, omega, J):\n",
    "    \"\"\"gets b matrix, using batched operations \"\"\"\n",
    "    b_T = tf.math.reduce_sum(tf.transpose(e, (0,2,1)) @ omega @ tf.cast(J, tf.double), axis = 0)\n",
    "#     print(\"\\n b_T: \\n\", tf.shape(b_T))\n",
    "    b = tf.transpose(b_T)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ij(ij_raw):\n",
    "    \"\"\"generates ij matrix, which describes which nodes are connected to \n",
    "       each other through odometry constraints. \n",
    "       Removes skipped indices and shifts everything to start at 0\"\"\"\n",
    "#     print(\"ij_raw: \\n\", ij_raw)    \n",
    "    y, idx = tf.unique(tf.reshape(ij_raw, [-1]))\n",
    "#     print(\"\\n y: \\n\", y, \"\\n idx: \\n\", idx)    \n",
    "    ij = tf.reshape(idx, [-1,2])\n",
    "    return ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abe80a",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Large\n",
    "H = \\sum_{ij}^{}H_{ij} = \\sum_{ij}^{}J_{ij}^T \\Omega J_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "Init Hessian once at start of simulation, update in place as new linearizations are added(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f69499",
   "metadata": {},
   "source": [
    "### Need to apply constraint to first node in kinematic chain\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "H_{11} \\rightarrow H_{11} + I\n",
    "\\end{equation}\n",
    "\n",
    "Optimization routine can't make sense of only relative measurements. We need to specify the first pose as the origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H(J, omega):\n",
    "    \"\"\"returns hessian H\"\"\"\n",
    "    H_ij = tf.transpose(J, (0,2,1)) @ tf.cast(omega, tf.float32) @ J\n",
    "    H = tf.math.reduce_sum(H_ij, axis = 0)\n",
    "    #produces negative eigenvals if we don't fix first point in chain\n",
    "#     print(\"\\n eigval H before constraint:\\n\", tf.linalg.eigvals(H))\n",
    "    constrain_11 = tf.pad(tf.eye(6), [[0,len(H)-6],[0,len(H)-6]]) #was this\n",
    "#     constrain_11 = tf.pad(tf.ones([6,6]), [[0,len(H)-6],[0,len(H)-6]]) #test - nope\n",
    "#     constrain_11 = tf.pad(tf.linalg.diag(tf.constant([1., 0, 0, 0, 0, 0])), [[0,len(H)-6],[0,len(H)-6]]) #test - nope\n",
    "    H = H + constrain_11\n",
    "#     print(\"\\n eigval H after constraint:\\n\", tf.linalg.eigvals(H))\n",
    "#     H = tf.convert_to_tensor(np.tril(H.numpy()).T + np.tril(H.numpy(),-1)) #force H to be symmetric\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfaf81f",
   "metadata": {},
   "source": [
    "# Convert between $X$ and $x$\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "X \\in \\mathbb{R}^{M \\times 4 \\times 4}\n",
    "\\end{equation}\n",
    "\n",
    "Where $M$ is the total number of constraints\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x \\in \\mathbb{R}^{N \\times 6}\n",
    "\\end{equation}\n",
    "\n",
    "$N$ is the total number of nodes being optimized for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb310be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(x, ij):\n",
    "    \"\"\"given x, a list of global poses, this function returns \n",
    "       the relative transformations X, that describe the same relationships described by the constraints z\n",
    "       x  -> global poses of each transform\n",
    "       ij -> indices of first and second element of x being considered\n",
    "       \"\"\"\n",
    "    #get transform of fist elements in each pair, ordered by how they appear in ij\n",
    "    first_vec = tf.gather(x, ij[:,0])\n",
    "    second_vec = tf.gather(x, ij[:,1])\n",
    "\n",
    "    first_tensor = v2t(tf.cast(first_vec, tf.double))\n",
    "    second_tensor = v2t(tf.cast(second_vec, tf.double))\n",
    "    #represents pose of x in 2nd node relative to pose in 1st\n",
    "    X = tf.linalg.pinv(first_tensor) @ second_tensor #was this\n",
    "#     X = second_tensor @ tf.linalg.pinv(first_tensor) #works better(?)\n",
    "\n",
    "    return X\n",
    "\n",
    "# X_test = get_X(x, ij)\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f133b0",
   "metadata": {},
   "source": [
    "# Solve the Linear System \n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "H \\Delta x = -b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_ij_B_ij(e_ij):\n",
    "    \"\"\"calculates nonzero terms from the Jacobian of error function w.r.t. nodes i and j using TensorFlow\n",
    "        e_ij == error function [x, y, z, phi, theta, psi]\n",
    "        \n",
    "        NOTE: this works with batch operations: error vectors passed in as tensor will result in\n",
    "                corresponding output in the same order \n",
    "    \"\"\"\n",
    "    e_ij = tf.cast(e_ij, tf.float32)\n",
    "    p_point = e_ij[:,:3]\n",
    "    phi = e_ij[:,3][:,None]\n",
    "    theta = e_ij[:,4][:,None]\n",
    "    psi = e_ij[:,5][:,None]\n",
    "    \n",
    "    eyes = tf.tile(-tf.eye(3)[None,:,:], [tf.shape(p_point)[0] , 1, 1]) #was this\n",
    "#     eyes = tf.tile(tf.eye(3)[None,:,:], [tf.shape(p_point)[0] , 1, 1]) #test\n",
    "    \n",
    "#     deriv of R() wrt phi\n",
    "    dRdPhi = tf.Variable([[tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-sin(psi)*sin(phi) + cos(phi)*sin(theta)*cos(psi)), (cos(phi)*sin(psi) + sin(theta)*sin(phi)*cos(psi))],\n",
    "                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-sin(phi)*cos(psi) - cos(phi)*sin(theta)*sin(psi)), (cos(phi)*cos(psi) - sin(theta)*sin(psi)*sin(phi))], \n",
    "                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-cos(phi)*cos(theta)), (-sin(phi)*cos(theta))] ])[:,:,:,0]\n",
    "    dRdPhi = tf.transpose(dRdPhi, (2,0,1))\n",
    "    Jx = dRdPhi @ p_point[:,:,None]\n",
    "    \n",
    "    # (deriv of R() wrt theta).dot(p_point)\n",
    "    dRdTheta = tf.Variable([[(-sin(theta)*cos(psi)), (cos(theta)*sin(phi)*cos(psi)), (-cos(theta)*cos(phi)*cos(psi))],\n",
    "                               [(sin(psi)*sin(theta)), (-cos(theta)*sin(phi)*sin(psi)), (cos(theta)*sin(psi)*cos(phi))],\n",
    "                               [(cos(theta)), (sin(phi)*sin(theta)), (-sin(theta)*cos(phi))] ])[:,:,:,0]\n",
    "    dRdTheta = tf.transpose(dRdTheta, (2,0,1))\n",
    "    Jy = dRdTheta @ p_point[:,:,None]\n",
    "\n",
    "    # deriv of R() wrt psi\n",
    "    dRdPsi = tf.Variable([[(-cos(theta)*sin(psi)), (cos(psi)*cos(phi) - sin(phi)*sin(theta)*sin(psi)), (cos(psi)*sin(phi) + sin(theta)*cos(phi)*sin(psi)) ],\n",
    "                                       [(-cos(psi)*cos(theta)), (-sin(psi)*cos(phi) - sin(phi)*sin(theta)*cos(psi)), (-sin(phi)*sin(psi) + sin(theta)*cos(psi)*cos(phi))],\n",
    "                                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None],tf.zeros(len(phi), dtype = phi.dtype)[:,None],tf.zeros(len(phi), dtype = phi.dtype)[:,None]]])[:,:,:,0]\n",
    "    dRdPsi = tf.transpose(dRdPsi, (2,0,1))\n",
    "    Jz = dRdPsi @ p_point[:,:,None]\n",
    "    \n",
    "    top = tf.concat([eyes, Jx, Jy, Jz], axis = 2) #was this\n",
    "    flipped = tf.transpose(tf.concat([Jx, Jy, Jz], axis = 2), (0,2,1))     #was this\n",
    "    \n",
    "    bottom = tf.concat([-flipped, -eyes], axis = 2) #works???\n",
    "#     bottom = tf.concat([flipped, -eyes], axis = 2) #test\n",
    "\n",
    "#     top = tf.concat([eyes, tf.zeros(tf.shape(flipped))], axis = 2) #test\n",
    "#     bottom = tf.concat([tf.zeros(tf.shape(flipped)), -eyes], axis = 2) #test\n",
    "    \n",
    "    A_ij = tf.concat([top, bottom], axis = 1) #was this\n",
    "    B_ij = -A_ij #was this\n",
    "#     print(\"\\n A_ij: \\n\", A_ij[0])\n",
    "    return A_ij, B_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "def get_e(Zij, Xij):\n",
    "    \"\"\"calculates error function w.r.t. nodes i and j\n",
    "    Zij == pose j relative to i according to nodes (rotation matrix)\n",
    "    Xij == pose j relative to i according to constraints (rotation matrix)\n",
    "    \"\"\"        \n",
    "    e = t2v(tf.linalg.pinv(Zij) @ Xij) # was this\n",
    "#     e = t2v(tf.linalg.pinv(tf.linalg.pinv(Zij) @ Xij)) #nope\n",
    "#     e = t2v(tf.linalg.pinv(Xij) @ tf.linalg.pinv(Zij) @ Xij) # test - not quite but I think I'm on to something\n",
    "    \n",
    "    #get error  in frame of Xij(?)\n",
    "#     error = tf.linalg.pinv(Zij) @ Xij\n",
    "#     print(\"\\n error \\n\", error)\n",
    "    \n",
    "    #rotate to align with world frame axis? - no\n",
    "    \n",
    "    #rotae to align with frame of Xi\n",
    "    \n",
    "#     e = t2v(error)\n",
    "\n",
    "    return(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NEW\n",
    "# def get_e(Zij, x, ij):\n",
    "#     \"\"\"calculates error function w.r.t. nodes i and j\n",
    "#     Zij == pose j relative to i according to nodes (rotation matrix)\n",
    "#     x   == global poses x (vector)\n",
    "#     ij  == indices of constraints \n",
    "#     \"\"\"        \n",
    "#     #TODO: return error w.r.t. Xi (rather than wrt global pose)\n",
    "\n",
    "#     xi = tf.gather(x, ij[:,0])\n",
    "#     Xi = v2t(tf.cast(xi, tf.double))\n",
    "    \n",
    "#     Xij = get_X(x, ij)\n",
    "    \n",
    "#     #wrong\n",
    "#     e = t2v(Xi @ tf.linalg.pinv(Zij) @ Xij)\n",
    "\n",
    "#     return(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "de8e65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ij: \n",
      " [[0 1 2]\n",
      " [1 2 3]]\n",
      "e: \n",
      " tf.Tensor([3 6], shape=(2,), dtype=int32)\n",
      "J: \n",
      " tf.Tensor([ 3  6 24], shape=(3,), dtype=int32)\n",
      "omega: \n",
      " tf.Tensor([3 6 6], shape=(3,), dtype=int32)\n",
      "b: \n",
      " tf.Tensor([24  1], shape=(2,), dtype=int32)\n",
      "H: \n",
      " tf.Tensor([24 24], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# # test data generated from LeddarTech PixSet trajectory-----------------------------------\n",
    "# odometry_history = np.load(\"test_data/leddartech_pixset/T_vec_history.npy\")[:15,:]\n",
    "# pred_stds_history = np.load(\"test_data/leddartech_pixset/cov_vec_history.npy\")[:15,:]\n",
    "# ij = get_ij(odometry_history[:,6:].astype(np.int32))\n",
    "# #-----------------------------------------------------------------------------------------\n",
    "\n",
    "# simplified test data--------------------------------------------------------------------\n",
    "npts = 3\n",
    "# odometry_history = np.tile(np.array([0.05, 0.0, 0.02, 0.0, 0.0, 0.15]), (npts,1))\n",
    "odometry_history = np.tile(np.array([0.2, .10, 0.0, 0.0, 0.0, 0.0]), (npts,1)) #no rotation (for debug)\n",
    "pred_stds_history = np.tile(np.array([[0.01, 0.01, 0.01, 1e-4, 1e-4, 1e-4]]), (len(odometry_history),1))\n",
    "ij = np.array([[0,1]])\n",
    "for i in range(1,len(odometry_history)):\n",
    "    ij = np.append(ij, np.array([[i, i+1]]), axis = 0)\n",
    "# ij = np.array([[0,1], [1,2], [2,3], [3,4], [4,5], [5,6], [6,7], [0,7]]) #mess with last constraint\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "# # random trajectory data------------------------------------------------------------------\n",
    "# npts = 15\n",
    "# odometry_history = np.tile(np.array([0.05, 0.0, 0.01, 0.0, 0.0, 0.15]), (npts,1))\n",
    "# odometry_history += np.array([0.1, 0.1, 0.1, 0.0001, 0.0001, 0.01]) * \\\n",
    "#                     np.random.randn(np.shape(odometry_history)[0], np.shape(odometry_history)[1])\n",
    "# pred_stds_history = np.tile(np.array([[0.01, 0.01, 0.01, 1e-4, 1e-4, 1e-4]]), (len(odometry_history),1))\n",
    "# ij = np.array([[0,1]])\n",
    "# for i in range(1,len(odometry_history)):\n",
    "#     ij = np.append(ij, np.array([[i, i+1]]), axis = 0)\n",
    "# # ij = np.array([[0,1], [1,2], [2,3], [3,4], [4,5], [5,6], [6,7], [0,7]]) #mess with last constraint\n",
    "# #-----------------------------------------------------------------------------------------\n",
    "\n",
    "# print(\"odometry history: \\n\", odometry_history)\n",
    "# print(pred_stds_history)\n",
    "# print(\"\\n ij raw: \\n\", odometry_history[:,-2:])\n",
    "\n",
    "Z =  v2t(odometry_history[:,:6]) # constraints (from odometry measurements)\n",
    "X = get_X(x, ij) # relative pose estimates (from initial configuration of graph)\n",
    "e = get_e(Z, X) #old get_e()\n",
    "# e = get_e(Z, x, ij) #new get_e()\n",
    "omega = get_information_matrix(pred_stds_history[:,:6])\n",
    "# print(\"\\n omega:\\n\", omega[0])\n",
    "J = get_J(e, ij)\n",
    "b = get_b(e[:,:,None], omega, J)\n",
    "H = get_H(J, omega)\n",
    "print(\"ij: \\n\", ij.T)\n",
    "# print(\"e: \\n\", tf.shape(e))\n",
    "print(\"e: \\n\", tf.shape(e))\n",
    "print(\"J: \\n\", tf.shape(J))\n",
    "print(\"omega: \\n\", tf.shape(omega))\n",
    "print(\"b: \\n\", tf.shape(b))\n",
    "print(\"H: \\n\", tf.shape(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b00aca9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #close estimate for initial conditions \n",
    "# x = np.zeros([tf.math.reduce_max(ij)+1,6])\n",
    "# print(np.shape(x))\n",
    "# for i in range(1, len(x)):\n",
    "#     x[i] = x[i-1] + np.array([0.05, 0.0, 0.01, 0., 0., 0.15]) #explodes\n",
    "# #     x[i] = x[i-1] + np.array([0.05, 0.0, 0.01, 0., 0., 0.0]) #converges to incorrect solution\n",
    "#     rot = v2t(np.array([0.05, 0.0, 0.01, 0.0, 0.0, 0.15]))[0,:3,:3]\n",
    "#     x[:,:3] = x[:,:3].dot(rot)\n",
    "# x = tf.cast(tf.convert_to_tensor(x), tf.float32)\n",
    "    \n",
    "# #zero initial conditions\n",
    "x_init = tf.zeros([tf.math.reduce_max(ij)+1,6])\n",
    "# print(x)\n",
    "\n",
    "# #cheat with correct solution\n",
    "# x_init = tf.convert_to_tensor(x_ground_truth, tf.float32)\n",
    "# # print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "00b04b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " initial global state estimates: \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " Z: \n",
      " [[ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]]\n",
      "\n",
      " X: \n",
      " [[ 0.  0.  0. -0.  0. -0.]\n",
      " [ 0.  0.  0. -0.  0. -0.]\n",
      " [ 0.  0.  0. -0.  0. -0.]]\n",
      "\n",
      " e: \n",
      " [[-0.2 -0.1  0.  -0.   0.   0. ]\n",
      " [-0.2 -0.1  0.  -0.   0.   0. ]\n",
      " [-0.2 -0.1  0.  -0.   0.   0. ]]\n",
      "\n",
      " Z: \n",
      " [[ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]]\n",
      "\n",
      " X: \n",
      " [[ 0.2  0.1 -0.   0.  -0.   0. ]\n",
      " [ 0.2  0.1 -0.   0.  -0.   0. ]\n",
      " [ 0.2  0.1 -0.   0.  -0.   0. ]]\n",
      "\n",
      " e: \n",
      " [[ 0. -0. -0.  0. -0.  0.]\n",
      " [ 0. -0. -0.  0. -0.  0.]\n",
      " [ 0. -0. -0.  0. -0.  0.]]\n",
      "\n",
      " Z: \n",
      " [[ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]]\n",
      "\n",
      " X: \n",
      " [[ 0.2  0.1 -0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.   0.   0.  -0. ]]\n",
      "\n",
      " e: \n",
      " [[ 0.  0. -0. -0.  0. -0.]\n",
      " [-0.  0.  0. -0.  0. -0.]\n",
      " [-0.  0.  0.  0.  0. -0.]]\n",
      "\n",
      " Z: \n",
      " [[ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]]\n",
      "\n",
      " X: \n",
      " [[ 0.2  0.1  0.  -0.  -0.   0. ]\n",
      " [ 0.2  0.1 -0.  -0.  -0.   0. ]\n",
      " [ 0.2  0.1 -0.  -0.   0.   0. ]]\n",
      "\n",
      " e: \n",
      " [[ 0.  0.  0. -0. -0.  0.]\n",
      " [ 0. -0. -0. -0. -0.  0.]\n",
      " [ 0.  0. -0. -0.  0.  0.]]\n",
      "\n",
      " Z: \n",
      " [[ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]]\n",
      "\n",
      " X: \n",
      " [[ 0.2  0.1 -0.   0.  -0.  -0. ]\n",
      " [ 0.2  0.1 -0.   0.  -0.  -0. ]\n",
      " [ 0.2  0.1 -0.  -0.   0.  -0. ]]\n",
      "\n",
      " e: \n",
      " [[ 0.  0. -0.  0. -0. -0.]\n",
      " [ 0. -0. -0.  0. -0.  0.]\n",
      " [ 0.  0. -0. -0.  0. -0.]]\n",
      "\n",
      " Z: \n",
      " [[ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.  -0. ]]\n",
      "\n",
      " X: \n",
      " [[ 0.2  0.1  0.  -0.   0.   0. ]\n",
      " [ 0.2  0.1  0.  -0.   0.   0. ]\n",
      " [ 0.2  0.1  0.   0.   0.   0. ]]\n",
      "\n",
      " e: \n",
      " [[ 0.  0.  0. -0.  0.  0.]\n",
      " [ 0. -0.  0. -0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      " final global state estimates: \n",
      " [[-0.2 -0.  -0.  -0.  -0.  -0. ]\n",
      " [ 0.   0.1 -0.  -0.  -0.  -0. ]\n",
      " [ 0.2  0.2 -0.  -0.  -0.  -0. ]\n",
      " [ 0.4  0.3 -0.  -0.  -0.  -0. ]]\n",
      "\n",
      " x_ground_truth: \n",
      " [[ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.2         0.1         0.         -0.          0.         -0.2       ]\n",
      " [ 0.41588025  0.15827279  0.         -0.          0.         -0.4       ]\n",
      " [ 0.63903428  0.17249522  0.         -0.          0.         -0.6       ]\n",
      " [ 0.86056565  0.14210029  0.         -0.          0.         -0.8       ]\n",
      " [ 1.0716426   0.06829974  0.         -0.          0.         -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#solve the naive way\n",
    "np.random.seed(7220)\n",
    "#get constraints\n",
    "Z =  v2t(odometry_history[:,:6])   # [N, 6] -> [N, 4, 4]   \n",
    "x = x_init\n",
    "print(\"\\n initial global state estimates: \\n\", np.around(x, 4))    \n",
    "\n",
    "runlen = 6\n",
    "\n",
    "for count in range(runlen):\n",
    "    #create linear system----------------------------\n",
    "    #update transformation matrix using ground new ground truth solution vector\n",
    "    X = get_X(x, ij)\n",
    "    e = get_e(Z, X) #old get_e()\n",
    "#     e = get_e(Z, x, ij) #new get_e()\n",
    "    print(\"\\n Z: \\n\", np.around(t2v(Z), 6))\n",
    "    print(\"\\n X: \\n\", np.around(t2v(X), 4))\n",
    "    print(\"\\n e: \\n\", np.around(e, 4))\n",
    "    omega = get_information_matrix(pred_stds_history[:,:6])\n",
    "    J = get_J(e, ij)\n",
    "    b = get_b(e[:,:,None], omega, J)\n",
    "    H = get_H(J, omega)\n",
    "#     print(\"\\n J[0]: \\n\", J[0])\n",
    "    \n",
    "    #solve linear system-----------------------------\n",
    "    # H * delta_x = b\n",
    "    # H^T * H * delta_x = H^T * b\n",
    "    # delta_x = (H^T * H)^-1 * H^T * b\n",
    "    delta_x = tf.linalg.pinv(tf.transpose(H) @ H) @ tf.transpose(H) @ tf.cast(-b, tf.float32)\n",
    "    delta_x = tf.reshape(delta_x, (-1, 6))\n",
    "#     print(\"\\n delta_x \\n\", np.around(delta_x, 4))\n",
    "    \n",
    "    #update solution vector--------------------------\n",
    "    x = x + delta_x #was this\n",
    "    #------------------------------------------------\n",
    "    \n",
    "# #debug - force x[0] to zeros\n",
    "# x = x.numpy()\n",
    "# x[:,:] -= x[0,:]\n",
    "# # x[:,:3] -= x[0,:3]\n",
    "# x = tf.convert_to_tensor(x)\n",
    "# print(x)\n",
    "    \n",
    "print(\"\\n final global state estimates: \\n\", np.around(x.numpy(), 4))\n",
    "print(\"\\n x_ground_truth: \\n\", x_ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e96a0",
   "metadata": {},
   "source": [
    "# Plot Optimized Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a18d3769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac80c68cd9b48bcb92b5776f94c5f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt1 = Plotter(N = 1, axes = 1, bg =(1, 1, 1), interactive = True) #ax=7 gives rulers\n",
    "disp = []\n",
    "\n",
    "#plot estimated solution\n",
    "c = np.linspace(0.1,1.00, len(x))[:,None]\n",
    "cname = np.append(-c, c, axis = 1)\n",
    "cname = np.append(cname, c, axis = 1).tolist()\n",
    "p = Points(x.numpy()[:,:3], c=cname, r = 10)\n",
    "disp.append(p)\n",
    "L = Line(p0=x.numpy()[:,:3], p1=x.numpy()[:,:3], c = 'k', lw = 3).legend(\"LS Solution\") #plot line of estimated trajectory from pose graph\n",
    "disp.append(L)\n",
    "disp.append(Line(p0 = x.numpy()[0,:3], p1 = np.array([0,0,0]), lw = 3))#add line between first point in x and origin (to show bug)\n",
    "o = Points([[0.,0.,0.]], c ='g', r = 15).legend('start position') #plot origin\n",
    "disp.append(o)\n",
    "#add in body frame axis for each pose in x\n",
    "disp = draw_body_frame_axis(x, disp)\n",
    "\n",
    "#draw ground truth (for debug)\n",
    "ground_truth_line, x_ground_truth = get_ground_truth(Z, disp)\n",
    "disp.append(ground_truth_line)\n",
    "# print(\"x_estimated: \\n\", np.around(x.numpy(),4))\n",
    "# print(\"\\n x_ground_truth: \\n\", x_ground_truth)\n",
    "\n",
    "lb = LegendBox([ground_truth_line, L, o], width = 0.25, height = 0.25, markers=[\"--\", '-', '.']).font(\"Kanopus\")\n",
    "plt1.show(disp, lb, \"Graph Slam Test\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d12bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(Z, disp =[]):\n",
    "    \"\"\"loops through odometry measurements in Zij and plots absolute poses of each\n",
    "        FOR DEBUG ONLY- ONLY WORKS WITH LINEAR ODOMETRY HISTORY\n",
    "    \"\"\"\n",
    "    x = np.zeros([len(Z)+1,6])\n",
    "    Zcum = Z[0]\n",
    "    for i in range(1, len(Z)+1):\n",
    "        euls = t2v(Zcum) #convert to euler angles\n",
    "        x[i] = euls\n",
    "        testp = Points([[Zcum[0,3], Zcum[1,3], Zcum[2,3]]], r = 7)\n",
    "        disp.append(testp)\n",
    "        Zcum = Z[i-1] @ Zcum\n",
    "#     print(\"\\n x \\n\", x)\n",
    "    \n",
    "    draw_body_frame_axis(tf.convert_to_tensor(x), disp)  \n",
    "    ground_truth_line = Line(p0=x[:,:3], p1=x[:,:3], lw = 3).pattern('- -', repeats=10).legend(\"ground truth\")\n",
    "#     disp.append(ground_truth_line)\n",
    "    return(ground_truth_line, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9c3e574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_body_frame_axis(x, disp = []):\n",
    "    \"\"\"draws local xyz axis arrows on each pose in x \"\"\"\n",
    "    scale = 0.025 #axis length\n",
    "    for i in range(len(x)):\n",
    "        rot = R_tf(x[i,3:])\n",
    "        A = rot @ np.eye(3) * scale\n",
    "        xvec = Arrow(x.numpy()[i,:3], x.numpy()[i,:3] + A[:,0], c = 'red') \n",
    "        yvec = Arrow(x.numpy()[i,:3], x.numpy()[i,:3] + A[:,1], c = 'green') \n",
    "        zvec = Arrow(x.numpy()[i,:3], x.numpy()[i,:3] + A[:,2], c = 'blue') \n",
    "        disp.append(xvec)\n",
    "        disp.append(yvec)\n",
    "        disp.append(zvec)\n",
    "    return(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87129d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_tf(angs):\n",
    "    \"\"\"generates rotation matrix using euler angles\n",
    "    angs = tf.constant(phi, theta, psi) (aka rot about (x,y,z))\n",
    "            can be single set of angles or batch for multiple cells\n",
    "    \"\"\"\n",
    "\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "#     #old (wrong??)\n",
    "#     phi = angs[:,0]\n",
    "#     theta = angs[:,1]\n",
    "#     psi = angs[:,2]\n",
    "    #new\n",
    "    phi = -angs[:,0]\n",
    "    theta = -angs[:,1]\n",
    "    psi = -angs[:,2]\n",
    "\n",
    "\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c1ac1",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Takes ~100 iterations to converge for 10 samples\n",
    "\n",
    "zero initial conditions works better than trying to estimate using data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5ab8f",
   "metadata": {},
   "source": [
    "# Try using Cholesky Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.linalg.det(H))\n",
    "# H_sparse = tf.sparse.from_dense(H)\n",
    "H_chol = tf.linalg.cholesky(H)\n",
    "# print(H_chol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weird numerical errors here making H very slightly non-symmetric\n",
    "#  preventing me from using cholesky decomp.\n",
    "H_ij = J[0].numpy().T @ tf.cast(omega[0], tf.float32) @ J[0]\n",
    "# print(H_ij)\n",
    "test = H_ij.numpy() - H_ij.numpy().T\n",
    "# print(test)\n",
    "\n",
    "print(H, \"\\n\")\n",
    "# test = np.tril(H.numpy())\n",
    "test = np.tril(H.numpy(), -1)\n",
    "# print(test)\n",
    "print(np.tril(H.numpy()).T + np.tril(H.numpy(),-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8bf196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = H.numpy() - H.numpy().T\n",
    "h = np.random.randn(3,5)\n",
    "ohm = np.eye(3)\n",
    "test = h.T @ ohm @ h\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "indices = tf.constant([[1,3], [3,1], [5,5]], dtype = tf.int64) #[N, ndims]\n",
    "values = tf.constant([1.5, 1.5, -0.55])\n",
    "dense_shape = tf.constant([6, 6], dtype = tf.int64)\n",
    "sparse_J =  tf.sparse.SparseTensor(indices, values, dense_shape)\n",
    "# print(sparse_J)\n",
    "print(tf.sparse.to_dense(sparse_J))\n",
    "# print(tf.linalg.det(tf.sparse.to_dense(sparse_J)))\n",
    "\n",
    "test = tf.sparse.to_dense(sparse_J)[None,:,:] + 10*tf.eye(6)[None,:,:]\n",
    "print(test)\n",
    "\n",
    "chol = tf.linalg.cholesky(test) #needs to be symmetric and positive definite\n",
    "print(chol)\n",
    "\n",
    "rhs = tf.random.normal([1,6,6])\n",
    "ans =  tf.linalg.cholesky_solve(chol, rhs)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f8510",
   "metadata": {},
   "source": [
    "Similar to ICET, we can use Newton-Raphson to iteratively solve for small perterbations to the state vector $x$ that bring us towards a better solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x \\rightarrow x + \\Delta x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0517636",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Figure out references in Jupyter Notebook\n",
    "\n",
    "\n",
    "# Questions\n",
    "\n",
    "Should $A_{ij} = -B_{ij}$?\n",
    "\n",
    "Are there advantages to reporting state vector in unit quaternions? Besides being less intuitive to work with I've read they can also introduce problems in optimization routine since they add an additional degree of freedom. Every guide I've seen so far uses homogenous coordinate representation for the transformation matrices when computing the loss function, since they can be applied neatly in series. So rotation matrices do not produce singularities?\n",
    "\n",
    "Is what we did in ICET to handle sparsity (i.e. accumulating contributions for corresponding elements rather than performing full matrix inversion) similar to a Choelesky Decomposition?\n",
    "\n",
    "<span style=\"color:red\"> What is going on with the numerics in get_e_ij()? Why is it not just t2v(Zij) - t2v(Zij)?? </span>\n",
    "\n",
    "\n",
    "\n",
    "# Potential Contributions\n",
    "\n",
    "Use ICET error covaraince estimation to demonstrate improvement in accuracy for Volpe Dataset\n",
    "\n",
    "Use ICET output to inform $\\Omega$ as a spatially dependant weighting field rather than simply indexing each unique point. Explore Gaussian Process Regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a759f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.random.normal([600,600])\n",
    "# print(tf.linalg.pinv(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645def28",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.inv.html#scipy.sparse.linalg.inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_a = tf.sparse.SparseTensor(indices=[[0, 2], [3, 4]],\n",
    "                       values=[31.0, 2.0], \n",
    "                       dense_shape=[4, 6])\n",
    "st_b = tf.sparse.SparseTensor(indices=[[0, 2], [3, 0]],\n",
    "                       values=[56.0, 38.0],\n",
    "                       dense_shape=[4, 6])\n",
    "st_sum = tf.sparse.add(st_a, st_b)\n",
    "# print(st_sum)\n",
    "print(tf.linalg.pinv(tf.sparse.to_dense(st_sum)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f2c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0c566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4748134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
