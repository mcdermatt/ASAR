{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db869367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "np.set_printoptions(precision=8, linewidth = 75)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ece94a",
   "metadata": {},
   "source": [
    "# Pose Graph Optimization\n",
    "\n",
    "### GOAL: Adjust configuration of absolute poses (nodes) to minimize squared error intorduced by constraints (edges)\n",
    "\n",
    "\n",
    "Node: [x, y, z, r, p, y]\n",
    "\n",
    "Edge: Odometry Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714bdd0",
   "metadata": {},
   "source": [
    "# State vector $x$\n",
    "\n",
    "absolute position and orientation of vehicle at each timestep\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{x} = \n",
    "\\begin{bmatrix}\n",
    "\\textbf{x}_1\\\\\n",
    "\\textbf{x}_2\\\\\n",
    "\\textbf{x}_3 \\\\\n",
    "\\vdots\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "x_1 & y_1 & z_1 & r_1 & p_1 & y_1 \\\\\n",
    "x_2 & y_2 & z_2 & r_2 & p_2 & y_2 \\\\\n",
    "x_3 & y_3 & z_3 & r_3 & p_3 & y_3 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45989fb",
   "metadata": {},
   "source": [
    "# Transformations $\\mathbf{X}$  \n",
    "Represeneted in Homogenous Coordinates. This is an overparameterization (similar to using quaternions) which helps avoid singularities when calculating the error function to adjust each Gauss-Newton iteration, however, the additional degrees of freedom need to be removed before forming our state vector\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X_i} = \n",
    "\\begin{bmatrix}\n",
    "R_{11} & R_{12} & R_{13} & dx\\\\\n",
    "R_{21} & R_{22} & R_{23} & dy \\\\\n",
    "R_{31} & R_{32} & R_{33} & dz \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$\\big(\\mathbf{X}_i^{-1} \\mathbf{X}_{i+1} \\big)$  describes how node $i$ sees node $(i+1)$ (ex: odometry)\n",
    "\n",
    "$\\big(\\mathbf{X}_i^{-1} \\mathbf{X}_{j} \\big)$  describes how node $i$ sees node $j$ (ex: loop closure)\n",
    "\n",
    "\n",
    "<span style=\"color:red\"> Important note: $X$ will need to contain more elements than $x$, since $X$ must represent all state pairs observed in constraints $Z$, while $x$ only needs a single element to represent the absolute pose of each state </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbae8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2t(vector):\n",
    "    \"\"\"converts a transformation vector to homogenous coordinate system\"\"\"\n",
    "    if len(tf.shape(vector)) == 1: #allow for 1-D or N-D input\n",
    "        vector = vector[None,:]\n",
    "    angs = vector[:,3:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    rot = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]])\n",
    "    rot = tf.transpose(rot, [2, 0, 1])\n",
    "    trans = vector[:,:3]\n",
    "    trans = np.reshape(trans, (np.shape(rot)[0], 3, 1))\n",
    "    transform = tf.concat((rot, trans), axis = -1)\n",
    "    extra = tf.tile(tf.constant([[[0., 0., 0., 1.]]], dtype = tf.double), (np.shape(rot)[0],1,1))\n",
    "    transform = tf.concat((transform, extra), axis = -2)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e25b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2v(mat):\n",
    "    \"\"\"converts transformation matrix to state vector\"\"\"\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    vector = tf.concat((mat[:,:3,-1], angs.T), axis =1)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c66d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: v2t() -> t2v() is returning to the same value only if I take inverse (for rotation) \n",
    "#                     and without inverse only (for translation). [T]^-1 @ [T] = I still\n",
    "#Question: is this normal?  \n",
    "\n",
    "# # test = np.array([1., 2., 3., 0.05, 0.00, -0.14])\n",
    "# test = np.ones([2,6])\n",
    "# test[1,:] = np.array([1., 2., 3., 0.003, 0.001, 0.3])\n",
    "# T = v2t(test)\n",
    "# # print(\"T: \\n\",T)\n",
    "# vect_trans = t2v(T).numpy()[:,:3]\n",
    "# vect_rot = t2v(tf.linalg.inv(T)).numpy()[:,3:]\n",
    "# print(np.append(vect_trans, vect_rot, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d90777",
   "metadata": {},
   "source": [
    "# Least Squares Error Function\n",
    "\n",
    "\n",
    "The optimial state vector, $x^*$, occurs where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x^* = \\arg\\min_x \\sum_{ij}^{} e^T_{ij}(x_i,x_j)\\Omega_{ij}e_{ij}(x_i,x_j)\n",
    "\\end{equation}\n",
    "\n",
    "$\\Omega_{ij}$ is the information matrix associated with the odometry estimate that relates $i$ and $j$. $\\Omega_{ij}$ is the inverse of the covariance matrix $\\sigma_{ij}$\n",
    "\n",
    "the error funcion for each connected node $i,j$ as a function of the state vector $x$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "e_{ij}(x) = \\text{t2v}(Z_{ij}^{-1} (X_j^{-1}X_i))\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Z_{ij}^{-1} = \\text{constraint (from measurement)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "(X_j^{-1}X_i) = x_i \\text{ relative to }x_j \\text{ given the current model of system} \n",
    "\\end{equation}\n",
    "\n",
    "$ \\text{Stachniss and Grisetti use} \\boxplus \\text{to repersent the mapping of euclidian space } v \\text{ to a homogenous coordinate frame } t$\n",
    "\n",
    "\n",
    "Important Note: $e_{ij}(x)$ only depends on $x_i$ and $x_j$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "78eb22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_e(Zij, Xij):\n",
    "    \"\"\"calculates error function w.r.t. nodes i and j\n",
    "    Zij == pose j relative to i according to nodes (rotation matrix)\n",
    "    Xij == pose j relative to i according to constraints (rotation matrix)\n",
    "    \"\"\"        \n",
    "    e = t2v(tf.linalg.pinv(Zij) @ Xij)\n",
    "\n",
    "    return(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "f0c970bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 9.89950043e-02  1.00994994e-01 -1.91990095e-05  3.00000000e-04\n",
      "   5.00000000e-04  2.00000000e-03]], shape=(1, 6), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "Zij = v2t(np.array([[1.,  1.9, 0., 0.0003, 0.0005, 0.01 ]])) # get from graph \n",
    "Xij = v2t(np.array([[1.1, 2.0, 0., 0.,     0.0,    0.008]])) # get from odometry message\n",
    "# Zij =  v2t(np.zeros([2,6]))\n",
    "# Xij =  v2t(np.random.randn(2,6))\n",
    "ij = np.array([[0,1],[1,2]])\n",
    "\n",
    "e = get_e(Zij, Xij)\n",
    "print(e)\n",
    "\n",
    "# a, b = get_A_ij_B_ij(e)\n",
    "# # print(a)\n",
    "\n",
    "# J = get_J(e, ij)\n",
    "# # print(J[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8eae54",
   "metadata": {},
   "source": [
    "# Linearizing the System\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "e_{ij}(x + \\Delta x) \\approx e_{ij}(x) + J_{ij} \\Delta x\n",
    "\\end{equation}\n",
    "\n",
    "Here, $J_{ij}$ is the the jacobian of $e_{ij}$ with respect to x\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "J_{ij} = \\frac{\\delta e_{ij}(x)}{\\delta x} = \\bigg{(} 0 \\dots \\frac{\\delta e_{ij}(x_i)}{\\delta x_i}\n",
    "\\dots \\frac{\\delta e_{ij}(x_j)}{\\delta x_j} \\dots 0 \\bigg{)} = \\bigg{(} 0 \\dots A_{ij} \\dots B_{ij} \\dots 0 \\bigg{)} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "A_{ij}, B_{ij} \\in \\mathbb{R}^{6 \\times 6}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eaec61",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J_{ij}(x) \\in \\mathbb{R}^{6 \\times 6N}\n",
    "\\end{equation}\n",
    "where $N$ is the total number of poses being solved for (nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "ce6d7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_ij_B_ij(e_ij):\n",
    "    \"\"\"calculates nonzero terms from the Jacobian of error function w.r.t. nodes i and j using TensorFlow\n",
    "        e_ij == error function [x, y, z, phi, theta, psi]\n",
    "        \n",
    "        NOTE: this works with batch operations: error vectors passed in as tensor will result in\n",
    "                corresponding output in the same order \n",
    "    \"\"\"\n",
    "    e_ij = tf.cast(e_ij, tf.float32)\n",
    "    \n",
    "    p_point = e_ij[:,:3]\n",
    "    phi = e_ij[:,3][:,None]\n",
    "    theta = e_ij[:,4][:,None]\n",
    "    psi = e_ij[:,5][:,None]\n",
    "    \n",
    "#     eyes = tf.tile(-tf.eye(3)[None,:,:], [tf.shape(p_point)[0] , 1, 1]) #was this\n",
    "    eyes = tf.tile(tf.eye(3)[None,:,:], [tf.shape(p_point)[0] , 1, 1]) #test\n",
    "\n",
    "    \n",
    "#     deriv of R() wrt phi\n",
    "    dRdPhi = tf.Variable([[tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-sin(psi)*sin(phi) + cos(phi)*sin(theta)*cos(psi)), (cos(phi)*sin(psi) + sin(theta)*sin(phi)*cos(psi))],\n",
    "                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-sin(phi)*cos(psi) - cos(phi)*sin(theta)*sin(psi)), (cos(phi)*cos(psi) - sin(theta)*sin(psi)*sin(phi))], \n",
    "                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None], (-cos(phi)*cos(theta)), (-sin(phi)*cos(theta))] ])[:,:,:,0]\n",
    "    dRdPhi = tf.transpose(dRdPhi, (2,0,1))\n",
    "    Jx = dRdPhi @ p_point[:,:,None]\n",
    "    \n",
    "    # (deriv of R() wrt theta).dot(p_point)\n",
    "    dRdTheta = tf.Variable([[(-sin(theta)*cos(psi)), (cos(theta)*sin(phi)*cos(psi)), (-cos(theta)*cos(phi)*cos(psi))],\n",
    "                               [(sin(psi)*sin(theta)), (-cos(theta)*sin(phi)*sin(psi)), (cos(theta)*sin(psi)*cos(phi))],\n",
    "                               [(cos(theta)), (sin(phi)*sin(theta)), (-sin(theta)*cos(phi))] ])[:,:,:,0]\n",
    "    dRdTheta = tf.transpose(dRdTheta, (2,0,1))\n",
    "    Jy = dRdTheta @ p_point[:,:,None]\n",
    "\n",
    "    # deriv of R() wrt psi\n",
    "    dRdPsi = tf.Variable([[(-cos(theta)*sin(psi)), (cos(psi)*cos(phi) - sin(phi)*sin(theta)*sin(psi)), (cos(psi)*sin(phi) + sin(theta)*cos(phi)*sin(psi)) ],\n",
    "                                       [(-cos(psi)*cos(theta)), (-sin(psi)*cos(phi) - sin(phi)*sin(theta)*cos(psi)), (-sin(phi)*sin(psi) + sin(theta)*cos(psi)*cos(phi))],\n",
    "                                       [tf.zeros(len(phi), dtype = phi.dtype)[:,None],tf.zeros(len(phi), dtype = phi.dtype)[:,None],tf.zeros(len(phi), dtype = phi.dtype)[:,None]]])[:,:,:,0]\n",
    "    dRdPsi = tf.transpose(dRdPsi, (2,0,1))\n",
    "    Jz = dRdPsi @ p_point[:,:,None]\n",
    "    \n",
    "    top = tf.concat([eyes, Jx, Jy, Jz], axis = 2)\n",
    "    flipped = tf.concat([tf.transpose(Jx, (0,2,1)), \n",
    "                         tf.transpose(Jy, (0,2,1)), \n",
    "                         tf.transpose(Jz, (0,2,1))], axis = 1)\n",
    "    bottom = tf.concat([flipped, eyes], axis = 2) #was this\n",
    "#     bottom = tf.concat([-flipped, -eyes], axis = 2) #test\n",
    "    A_ij = tf.concat([top, bottom], axis = 1) #was this\n",
    "#     A_ij = -tf.concat([top, bottom], axis = 1) #test\n",
    "    B_ij = -A_ij #was this\n",
    "#     B_ij = A_ij #test\n",
    "\n",
    "\n",
    "    return A_ij, B_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "3cea8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_J(e, ij):\n",
    "    \"\"\"Forms sparse jacobian J, with entries A and B at indices i and j \n",
    "    J == [N, 6, 6*N], N = number of nodes\n",
    "    e == [N, 6] error vectors\n",
    "    ij == [N, 2] contains scan indices of each node ex: [scan2, scan5]\n",
    "    \"\"\"\n",
    "    total_num_of_nodes = np.max(ij) + 1 #TODO: is this too big??\n",
    "    if len(tf.shape(ij))< 2: #expand dimensions if only single pair passed in\n",
    "        ij = ij[None,:]\n",
    "    A_ij, B_ij = get_A_ij_B_ij(e)\n",
    "    \n",
    "    # Need to tile DIFFERENT AMOUNT depending on the index \n",
    "    #    TODO: move to batch operation?\n",
    "    J = tf.zeros([0,6,total_num_of_nodes*6])\n",
    "    for k in range(len(ij)):\n",
    "        #TODO: add logic for when i and j are same value, when j = i + 1 ...\n",
    "        leading = tf.tile(tf.zeros([6,6]), [1, ij[k,0] ]) #leading zeros before i\n",
    "#         print(\"\\n leading \\n\", leading)\n",
    "        between = tf.tile(tf.zeros([6,6]), [1, ij[k,1] - ij[k,0] - 1 ]) #zeros between i and j\n",
    "#         print(\"\\n between: \\n\", between)\n",
    "        ending  = tf.tile(tf.zeros([6,6]), [1, total_num_of_nodes - ij[k,1] - 1 ])\n",
    "        J_ij = tf.concat([leading, A_ij[k], between, B_ij[k], ending], axis = 1)\n",
    "        J = tf.concat((J, J_ij[None,:,:]), axis = 0)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "eee31e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ij = tf.constant(odometry_history[1:3,6:].astype(int))\n",
    "# ij = np.array([[1,3],\n",
    "#                [0,2]])\n",
    "# print(ij)\n",
    "# # print(np.max(ij))\n",
    "# # print(\"e: \\n\", e)\n",
    "\n",
    "# J = get_J(e, ij)  \n",
    "# print(\"\\n J \\n\",J[-1])\n",
    "# print(\"\\n J \\n\",tf.shape(J))  \n",
    "# # print(\"\\n\", np.around(J.numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf95ce",
   "metadata": {},
   "source": [
    "# Accumumlate Sparse Tensors\n",
    "\n",
    "calculate jacobians in batch operation first, then bring to sparse tensor for matmul??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166659e",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Large\n",
    "b^T = \\sum_{ij}^{}b_{ij} = \\sum_{ij}^{}e_{ij}^T \\Omega_{ij} J_{ij}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "c29ab330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_matrix(pred_stds):\n",
    "    \"\"\"returns information matrix (omega) from ICET cov_estimates\"\"\"\n",
    "    pred_stds = tf.convert_to_tensor(pred_stds)[:,:,None] #convert to TF Tensor\n",
    "    cov = pred_stds @ tf.transpose(pred_stds, (0,2,1))    #convert predicted stds -> covariance matrix\n",
    "    info = tf.linalg.pinv(cov) #invert\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "08600211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b(e, omega, J):\n",
    "    \"\"\"gets b matrix, using batched operations \"\"\"\n",
    "    b_T = tf.math.reduce_sum(tf.transpose(e, (0,2,1)) @ omega @ tf.cast(J, tf.double), axis = 0)\n",
    "#     print(\"\\n b_T: \\n\", tf.shape(b_T))\n",
    "    b = tf.transpose(b_T)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "id": "75f3ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ij(ij_raw):\n",
    "    \"\"\"generates ij matrix, which describes which nodes are connected to \n",
    "       each other through odometry constraints. \n",
    "       Removes skipped indices and shifts everything to start at 0\"\"\"\n",
    "#     print(\"ij_raw: \\n\", ij_raw)    \n",
    "    y, idx = tf.unique(tf.reshape(ij_raw, [-1]))\n",
    "#     print(\"\\n y: \\n\", y, \"\\n idx: \\n\", idx)    \n",
    "    ij = tf.reshape(idx, [-1,2])\n",
    "    return ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abe80a",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\Large\n",
    "H = \\sum_{ij}^{}H_{ij} = \\sum_{ij}^{}J_{ij}^T \\Omega J_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "Init Hessian once at start of simulation, update in place as new linearizations are added(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f69499",
   "metadata": {},
   "source": [
    "### Need to apply constraint to first node in kinematic chain\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "H_{11} \\rightarrow H_{11} + I\n",
    "\\end{equation}\n",
    "\n",
    "Optimization routine can't make sense of only relative measurements. We need to specify the first pose as the origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "019abecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H(J, omega):\n",
    "    \"\"\"returns hessian H\"\"\"\n",
    "    H_ij = tf.transpose(J, (0,2,1)) @ tf.cast(omega, tf.float32) @ J\n",
    "    H = tf.math.reduce_sum(H_ij, axis = 0)\n",
    "    constrain_11 = tf.pad(tf.eye(6), [[0,len(H)-6],[0,len(H)-6]])\n",
    "    H = H + constrain_11    \n",
    "#     H = tf.convert_to_tensor(np.tril(H.numpy()).T + np.tril(H.numpy(),-1)) #forces H to be symmetric\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f92084",
   "metadata": {},
   "source": [
    "# Convert between $X$ and $x$\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "X \\in \\mathbb{R}^{M \\times 4 \\times 4}\n",
    "\\end{equation}\n",
    "\n",
    "Where $M$ is the total number of constraints\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x \\in \\mathbb{R}^{N \\times 6}\n",
    "\\end{equation}\n",
    "\n",
    "$N$ is the total number of nodes being optimized for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "c0d1ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.14030524  0.97476326 -0.17364051  1.6117208 ]\n",
      "  [-0.95504208  0.17949874  0.23595513  4.98359632]\n",
      "  [ 0.26116864  0.13272825  0.95612455  3.13402367]\n",
      "  [ 0.          0.          0.          1.        ]]\n",
      "\n",
      " [[ 0.23098854  0.08706167 -0.96905343  2.30986285]\n",
      "  [-0.96909372  0.10924953 -0.22118295  2.15832639]\n",
      "  [ 0.08661208  0.99019433  0.10960631  1.86193109]\n",
      "  [ 0.          0.          0.          1.        ]]\n",
      "\n",
      " [[ 0.41967611  0.80778805 -0.41394496 -7.27337503]\n",
      "  [-0.38445967 -0.25492151 -0.88724618 -7.56842709]\n",
      "  [-0.82223034  0.53150117  0.20357746 -7.84195375]\n",
      "  [ 0.          0.          0.          1.        ]]\n",
      "\n",
      " [[ 0.28718498  0.2044747  -0.93579639 -0.74682963]\n",
      "  [ 0.8676423   0.35841184  0.3445835  -1.29654193]\n",
      "  [ 0.40585912 -0.91089574 -0.0744804  -1.26139498]\n",
      "  [ 0.          0.          0.          1.        ]]], shape=(4, 4, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def get_X(x, ij):\n",
    "    \"\"\"given x, a list of global poses, this function returns \n",
    "       the relative transformations X, that describe the same relationships described by the constraints z\n",
    "       x  -> global poses of each transpose\n",
    "       ij -> indices of first and second element of x being considered\n",
    "       \"\"\"\n",
    "    #get transform of fist elements in each pair, ordered by how they appear in ij\n",
    "    first_vec = tf.gather(x, ij[:,0])\n",
    "    second_vec = tf.gather(x, ij[:,1])\n",
    "#     difference = first_vec - second_vec #was this (wrong?)\n",
    "    difference = second_vec - first_vec\n",
    "    #linearize differnce using euler angles\n",
    "    X = v2t(tf.cast(difference, tf.double))    \n",
    "    return X\n",
    "\n",
    "X_test = get_X(x, ij)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f6ce8",
   "metadata": {},
   "source": [
    "# Solve the Linear System \n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "H \\Delta x = -b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "de8e65ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odometry history: \n",
      " [[0.5  0.25 0.05 0.   0.   0.  ]\n",
      " [0.5  0.25 0.05 0.   0.   0.  ]\n",
      " [0.5  0.25 0.05 0.   0.   0.  ]\n",
      " [0.5  0.25 0.05 0.   0.   0.  ]]\n",
      "ij: \n",
      " [[0 1]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [3 4]]\n",
      "e: \n",
      " tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "J: \n",
      " tf.Tensor([ 4  6 30], shape=(3,), dtype=int32)\n",
      "omega: \n",
      " tf.Tensor([4 6 6], shape=(3,), dtype=int32)\n",
      "b: \n",
      " tf.Tensor([30  1], shape=(2,), dtype=int32)\n",
      "H: \n",
      " tf.Tensor([30 30], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# # test data generated from LeddarTech PixSet trajectory-----------------------------------\n",
    "# odometry_history = np.load(\"test_data/leddartech_pixset/T_vec_history.npy\")[5:15,:]\n",
    "# pred_stds_history = np.load(\"test_data/leddartech_pixset/cov_vec_history.npy\")[5:15,:]\n",
    "# ij = get_ij(odometry_history[:,6:].astype(np.int32))\n",
    "# #-----------------------------------------------------------------------------------------\n",
    "\n",
    "# simplified test data--------------------------------------------------------------------\n",
    "# odometry_history = np.tile(np.array([0.5, 0.25, 0.05, 0.0001, 0.0002, 0.0003]), (4,1))\n",
    "odometry_history = np.tile(np.array([0.5, 0.25, 0.05, 0.0, 0.0, 0.0]), (4,1))\n",
    "pred_stds_history = np.tile(np.array([[0.01, 0.01, 0.01, 1e-4, 1e-4, 1e-4]]), (len(odometry_history),1))\n",
    "ij = np.array([[0,1], [1,2], [2,3], [3,4]])\n",
    "#-----------------------------------------------------------------------------------------\n",
    "print(\"odometry history: \\n\", odometry_history)\n",
    "# print(pred_stds_history)\n",
    "# print(ij)\n",
    "\n",
    "# constraints (from odometry measurements)\n",
    "Z =  v2t(odometry_history[:,:6])      \n",
    "# relative pose estimates (from initial configuration of graph)\n",
    "# X =  v2t(odometry_history[:,:6] + 0.01*np.ones(np.shape(odometry_history[:,:6])))\n",
    "X = get_X(x, ij)\n",
    "# X =  v2t(odometry_history[:,:6]*0)\n",
    "\n",
    "e = get_e(Z, X)\n",
    "omega = get_information_matrix(pred_stds_history[:,:6])\n",
    "# print(omega[0])\n",
    "J = get_J(e, ij)\n",
    "b = get_b(e[:,:,None], omega, J)\n",
    "H = get_H(J, omega)\n",
    "print(\"ij: \\n\", ij)\n",
    "# print(\"e: \\n\", tf.shape(e))\n",
    "print(\"e: \\n\", tf.shape(e))\n",
    "print(\"J: \\n\", tf.shape(J))\n",
    "print(\"omega: \\n\", tf.shape(omega))\n",
    "print(\"b: \\n\", tf.shape(b))\n",
    "print(\"H: \\n\", tf.shape(H))\n",
    "# print(tf.linalg.eigvals(H)) # negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "a99057b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " initial global state estimates: \n",
      " [[-0.0551  0.0553 -0.0681  0.      0.      0.    ]\n",
      " [ 0.4885  0.2412 -0.0395  0.      0.      0.    ]\n",
      " [ 0.8933  0.5369  0.1969  0.      0.      0.    ]\n",
      " [ 1.4909  0.8131  0.227   0.      0.      0.    ]\n",
      " [ 1.9652  0.9322  0.2222  0.      0.      0.    ]]\n",
      "\n",
      " Z: \n",
      " [[ 0.5   0.25  0.05 -0.    0.   -0.  ]]\n",
      "\n",
      " X: \n",
      " [[ 0.5436  0.1859  0.0286 -0.      0.     -0.    ]]\n",
      "\n",
      " e: \n",
      " [ 0.0436 -0.0641 -0.0214 -0.      0.     -0.    ]\n",
      "\n",
      " delta_x: \n",
      ": [-7.0483610e-03  2.4569895e-02  2.1038413e-02 -5.6385994e-05\n",
      " -2.8642416e-03  2.4873018e-03]\n",
      "\n",
      " Z: \n",
      " [[ 0.5   0.25  0.05 -0.    0.   -0.  ]]\n",
      "\n",
      " X: \n",
      " [[ 0.5781  0.1886  0.035   0.0057 -0.0145  0.0101]]\n",
      "\n",
      " e: \n",
      " [ 0.0781 -0.0614 -0.015   0.0057 -0.0145  0.0101]\n",
      "\n",
      " delta_x: \n",
      ": [ 0.00179516  0.00271673  0.00347867 -0.00019391 -0.00028041  0.0003458 ]\n",
      "\n",
      " Z: \n",
      " [[ 0.5   0.25  0.05 -0.    0.   -0.  ]]\n",
      "\n",
      " X: \n",
      " [[ 0.5785  0.1881  0.0337  0.0061 -0.0164  0.0116]]\n",
      "\n",
      " e: \n",
      " [ 0.0785 -0.0619 -0.0163  0.0061 -0.0164  0.0116]\n",
      "\n",
      " delta_x: \n",
      ": [ 4.4356199e-04  2.7967614e-04  4.2183770e-04 -1.7920858e-05\n",
      " -3.9620558e-05  4.4093584e-05]\n",
      "\n",
      " Z: \n",
      " [[ 0.5   0.25  0.05 -0.    0.   -0.  ]]\n",
      "\n",
      " X: \n",
      " [[ 0.5784  0.1881  0.0336  0.0062 -0.0166  0.0118]]\n",
      "\n",
      " e: \n",
      " [ 0.0784 -0.0619 -0.0164  0.0062 -0.0166  0.0118]\n",
      "\n",
      " delta_x: \n",
      ": [ 6.0988496e-05  3.8421658e-05  5.8200570e-05 -1.9466243e-06\n",
      " -4.2443717e-06  3.1755335e-06]\n",
      "\n",
      " Z: \n",
      " [[ 0.5   0.25  0.05 -0.    0.   -0.  ]]\n",
      "\n",
      " X: \n",
      " [[ 0.5783  0.1881  0.0336  0.0062 -0.0167  0.0118]]\n",
      "\n",
      " e: \n",
      " [ 0.0783 -0.0619 -0.0164  0.0062 -0.0167  0.0118]\n",
      "\n",
      " delta_x: \n",
      ": [ 8.1284716e-06  5.2941909e-06  7.7860059e-06 -3.5346784e-07\n",
      " -5.7129182e-07  3.0240335e-07]\n",
      "\n",
      " final global state estimates: \n",
      " [[-5.98832630e-02  8.29400793e-02 -4.31133881e-02 -2.70519493e-04\n",
      "  -3.18908785e-03  2.88067712e-03]\n",
      " [ 5.18446088e-01  2.71029621e-01 -9.54478700e-03 -6.28265180e-03\n",
      "   1.35639515e-02 -8.82331189e-03]\n",
      " [ 8.77460659e-01  5.21393716e-01  1.81088373e-01  8.00650567e-03\n",
      "  -1.63491629e-02  8.79990589e-03]\n",
      " [ 1.44058025e+00  7.62660384e-01  1.76708430e-01  6.45316672e-04\n",
      "   4.64210846e-03 -3.77739803e-03]\n",
      " [ 1.98532653e+00  9.52310443e-01  2.42290974e-01 -1.73244241e-03\n",
      "  -7.87369616e-04  1.91431027e-03]]\n"
     ]
    }
   ],
   "source": [
    "#solve the naive way\n",
    "#get constraints\n",
    "Z =  v2t(odometry_history[:,:6])   # [N, 6] -> [N, 4, 4]   \n",
    "# x = tf.zeros([tf.math.reduce_max(ij)+1,6]) #zero initial conditions\n",
    "# nonzero initial conditions\n",
    "x = np.zeros([5,6])\n",
    "for i in range(len(odometry_history)+1):\n",
    "    x[i] = np.sum(odometry_history[:i], axis = 0) + np.array([0.05,0.05,0.05,0.,0.,0.])*np.random.randn(1,6)\n",
    "print(\"\\n initial global state estimates: \\n\", np.around(x, 4))    \n",
    "\n",
    "for count in range(5):\n",
    "    #create linear system----------------------------\n",
    "    #update transformation matrix using ground new ground truth solution vector\n",
    "    X = get_X(x, ij)\n",
    "    e = get_e(Z, X) #was this\n",
    "#     e = -get_e(Z, X) #test\n",
    "    print(\"\\n Z: \\n\", np.around(t2v(Z[0]), 6))\n",
    "    print(\"\\n X: \\n\", np.around(t2v(X[0]), 4))\n",
    "    print(\"\\n e: \\n\", np.around(e[0], 4))\n",
    "\n",
    "    #TODO DEBUG: I think bug is a signage issue with my error function(?)\n",
    "    \n",
    "    omega = get_information_matrix(pred_stds_history[:,:6])\n",
    "    J = get_J(e, ij)\n",
    "    b = get_b(e[:,:,None], omega, J)\n",
    "    H = get_H(J, omega)\n",
    "#     print(\"\\n J[0]: \\n\", J[0])\n",
    "    #------------------------------------------------\n",
    "    \n",
    "    #solve linear system-----------------------------\n",
    "    delta_x = -tf.linalg.pinv(H) @ tf.cast(b, tf.float32)\n",
    "    #delta_x is a [N*6, 1] vector, need to reshape to same dimensions as x\n",
    "    delta_x = tf.reshape(delta_x, (-1, 6))\n",
    "    print(\"\\n delta_x: \\n:\",delta_x.numpy()[0])\n",
    "    #------------------------------------------------\n",
    "    \n",
    "    #update solution vector--------------------------\n",
    "    x = x + delta_x\n",
    "    #------------------------------------------------\n",
    "    \n",
    "print(\"\\n final global state estimates: \\n\", x.numpy())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5094b3",
   "metadata": {},
   "source": [
    "# Try using Cholesky Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "6c0f1468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[nan  0.  0. ...  0.  0.  0.]\n",
      " [nan nan  0. ...  0.  0.  0.]\n",
      " [nan nan nan ...  0.  0.  0.]\n",
      " ...\n",
      " [nan nan nan ... nan  0.  0.]\n",
      " [nan nan nan ... nan nan  0.]\n",
      " [nan nan nan ... nan nan nan]], shape=(42, 42), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 15:36:21.314356: W tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc:211] Cholesky decomposition was not successful for batch 0. The input might not be valid. Filling lower-triangular output with NaNs.\n"
     ]
    }
   ],
   "source": [
    "# print(tf.linalg.det(H))\n",
    "# H_sparse = tf.sparse.from_dense(H)\n",
    "H_chol = tf.linalg.cholesky(H)\n",
    "# print(H_chol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "f272735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.1119098e+05 1.1033832e+05 2.0050373e+04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.1033832e+05 9.8016703e+04 1.1668230e+04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [2.0050375e+04 1.1668232e+04 1.9388010e+03 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.8292395e+01\n",
      "  2.8159603e+01 7.5015114e+01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.8161198e+01\n",
      "  4.3370384e+01 1.1544238e+02]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 7.5017174e+01\n",
      "  1.1543901e+02 3.0748639e+02]], shape=(42, 42), dtype=float32) \n",
      "\n",
      "[[2.1119098e+05 1.1033832e+05 2.0050375e+04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.1033832e+05 9.8016703e+04 1.1668232e+04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [2.0050375e+04 1.1668232e+04 1.9388010e+03 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.8292395e+01\n",
      "  2.8161198e+01 7.5017174e+01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.8161198e+01\n",
      "  4.3370384e+01 1.1543901e+02]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 7.5017174e+01\n",
      "  1.1543901e+02 3.0748639e+02]]\n"
     ]
    }
   ],
   "source": [
    "#getting weird numerical errors here making H very slightly non-symmetric\n",
    "#  preventing me from using cholesky decomp.\n",
    "H_ij = J[0].numpy().T @ tf.cast(omega[0], tf.float32) @ J[0]\n",
    "# print(H_ij)\n",
    "test = H_ij.numpy() - H_ij.numpy().T\n",
    "# print(test)\n",
    "\n",
    "print(H, \"\\n\")\n",
    "# test = np.tril(H.numpy())\n",
    "test = np.tril(H.numpy(), -1)\n",
    "# print(test)\n",
    "print(np.tril(H.numpy()).T + np.tril(H.numpy(),-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "cac0a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.75665171  0.78445855  0.47290638  0.84413965 -1.1716865 ]\n",
      " [ 0.78445855  1.04991795 -0.04214071  0.94974895 -0.55332488]\n",
      " [ 0.47290638 -0.04214071  0.09245641 -0.14894456 -0.07675058]\n",
      " [ 0.84413965  0.94974895 -0.14894456  2.52638372 -0.80502034]\n",
      " [-1.1716865  -0.55332488 -0.07675058 -0.80502034  0.51758776]]\n"
     ]
    }
   ],
   "source": [
    "# test = H.numpy() - H.numpy().T\n",
    "h = np.random.randn(3,5)\n",
    "ohm = np.eye(3)\n",
    "test = h.T @ ohm @ h\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "3d6d19fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    1.5   0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.5   0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.55]], shape=(6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[10.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.   10.    0.    1.5   0.    0.  ]\n",
      "  [ 0.    0.   10.    0.    0.    0.  ]\n",
      "  [ 0.    1.5   0.   10.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.   10.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    9.45]]], shape=(1, 6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[3.1622777  0.         0.         0.         0.         0.        ]\n",
      "  [0.         3.1622777  0.         0.         0.         0.        ]\n",
      "  [0.         0.         3.1622777  0.         0.         0.        ]\n",
      "  [0.         0.47434163 0.         3.1264994  0.         0.        ]\n",
      "  [0.         0.         0.         0.         3.1622777  0.        ]\n",
      "  [0.         0.         0.         0.         0.         3.0740852 ]]], shape=(1, 6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.13469943 -0.00427978 -0.07603329  0.05682243  0.05796693\n",
      "    0.1555664 ]\n",
      "  [-0.0805357  -0.05683429 -0.08281001  0.19694486  0.04078411\n",
      "   -0.01289242]\n",
      "  [-0.14628741 -0.15485843  0.05571511 -0.11697913 -0.02863031\n",
      "    0.01270711]\n",
      "  [ 0.08867881  0.04332542  0.07729524 -0.05765633 -0.03614028\n",
      "   -0.03970031]\n",
      "  [-0.02227064 -0.13593459  0.23252906 -0.0345275   0.04747796\n",
      "    0.10992254]\n",
      "  [-0.08774079  0.02315751  0.16853628  0.03066783  0.21642584\n",
      "    0.02054984]]], shape=(1, 6, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "indices = tf.constant([[1,3], [3,1], [5,5]], dtype = tf.int64) #[N, ndims]\n",
    "values = tf.constant([1.5, 1.5, -0.55])\n",
    "dense_shape = tf.constant([6, 6], dtype = tf.int64)\n",
    "sparse_J =  tf.sparse.SparseTensor(indices, values, dense_shape)\n",
    "# print(sparse_J)\n",
    "print(tf.sparse.to_dense(sparse_J))\n",
    "# print(tf.linalg.det(tf.sparse.to_dense(sparse_J)))\n",
    "\n",
    "test = tf.sparse.to_dense(sparse_J)[None,:,:] + 10*tf.eye(6)[None,:,:]\n",
    "print(test)\n",
    "\n",
    "chol = tf.linalg.cholesky(test) #needs to be symmetric and positive definite\n",
    "print(chol)\n",
    "\n",
    "rhs = tf.random.normal([1,6,6])\n",
    "ans =  tf.linalg.cholesky_solve(chol, rhs)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f8510",
   "metadata": {},
   "source": [
    "Similar to ICET, we can use Newton-Raphson to iteratively solve for small perterbations to the state vector $x$ that bring us towards a better solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\n",
    "x \\rightarrow x + \\Delta x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0517636",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Figure out references in Jupyter Notebook\n",
    "\n",
    "\n",
    "# Questions\n",
    "\n",
    "Should $A_{ij} = -B_{ij}$?\n",
    "\n",
    "Are there advantages to reporting state vector in unit quaternions? Besides being less intuitive to work with I've read they can also introduce problems in optimization routine since they add an additional degree of freedom. Every guide I've seen so far uses homogenous coordinate representation for the transformation matrices when computing the loss function, since they can be applied neatly in series. So rotation matrices do not produce singularities?\n",
    "\n",
    "Is what we did in ICET to handle sparsity (i.e. accumulating contributions for corresponding elements rather than performing full matrix inversion) similar to a Choelesky Decomposition?\n",
    "\n",
    "<span style=\"color:red\"> What is going on with the numerics in get_e_ij()? Why is it not just t2v(Zij) - t2v(Zij)?? </span>\n",
    "\n",
    "\n",
    "\n",
    "# Potential Contributions\n",
    "\n",
    "Use ICET error covaraince estimation to demonstrate improvement in accuracy for Volpe Dataset\n",
    "\n",
    "Use ICET output to inform $\\Omega$ as a spatially dependant weighting field rather than simply indexing each unique point. Explore Gaussian Process Regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a759f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.random.normal([600,600])\n",
    "# print(tf.linalg.pinv(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645def28",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.inv.html#scipy.sparse.linalg.inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_a = tf.sparse.SparseTensor(indices=[[0, 2], [3, 4]],\n",
    "                       values=[31.0, 2.0], \n",
    "                       dense_shape=[4, 6])\n",
    "st_b = tf.sparse.SparseTensor(indices=[[0, 2], [3, 0]],\n",
    "                       values=[56.0, 38.0],\n",
    "                       dense_shape=[4, 6])\n",
    "st_sum = tf.sparse.add(st_a, st_b)\n",
    "# print(st_sum)\n",
    "print(tf.linalg.pinv(tf.sparse.to_dense(st_sum)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f2c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0c566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4748134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
