{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661ffbc6",
   "metadata": {},
   "source": [
    "# Exploring GTSAM  Package for Pose Optimization with Factor Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook\n",
    "\n",
    "# import gtsampy as gtsam\n",
    "import gtsam\n",
    "import gtsam.utils.plot as gtsam_plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "from vedo import  *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1451e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import  sin, cos, tan\n",
    "\n",
    "def R_tf(angs):\n",
    "    \"\"\"generates rotation matrix using euler angles\n",
    "    angs = tf.constant(phi, theta, psi) (aka rot about (x,y,z))\n",
    "            can be single set of angles or batch for multiple cells\n",
    "    \"\"\"\n",
    "\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80502e7",
   "metadata": {},
   "source": [
    "# Establish Origin \n",
    "\n",
    "$ [x, y, z, \\phi, \\theta, \\psi ] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86795090",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([0,0,0,0,0,0], dtype = np.float64)\n",
    "start = gtsam.Pose3(p)\n",
    "print(start)\n",
    "\n",
    "# newpt = gtsam.Pose3(np.array([1,1,1,0,0,0], dtype = np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12ffd1",
   "metadata": {},
   "source": [
    "#  Debug Skip 1,3,5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0f6ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt, ax = plt.subplots(2,1)\n",
    "\n",
    "startidx = 20\n",
    "nframes = 1000\n",
    "# odometry_history = np.load(\"test_data/leddartech_pixset/T_vec_history_1and3and5.npy\")[:nframes,:6]\n",
    "# ij = np.load(\"test_data/leddartech_pixset/T_vec_history_1and3and5.npy\")[:nframes,6:]\n",
    "# odometry_history = np.load(\"test_data/Ford_Campus_Dataset/T_vec_history_1and3and5.npy\")[:nframes,:6]\n",
    "# ij = np.load(\"test_data/Ford_Campus_Dataset/T_vec_history_1and3and5.npy\")[:nframes,6:]\n",
    "odometry_history = np.load(\"test_data/KITTI/117/T_vec_history_3and4and5.npy\")[startidx:startidx+nframes,:6]\n",
    "ij = np.load(\"test_data/KITTI/117/T_vec_history_3and4and5.npy\")[startidx:startidx+nframes,6:]\n",
    "\n",
    "# print(odometry_history)\n",
    "# print(ij)\n",
    "# ij = get_ij(tf.convert_to_tensor(ij))\n",
    "# print(ij)\n",
    "\n",
    "skips = ij[:,1] - ij[:,0]\n",
    "# ones = np.where(skips == 1)\n",
    "threes = np.where(skips == 3)\n",
    "fours = np.where(skips == 4)\n",
    "fives = np.where(skips == 5)\n",
    "\n",
    "vf = odometry_history[:,0]/skips #forward velocity, normalized by num frames elapsed\n",
    "# vf = odometry_history[:,-1]/skips #rotation, normalized by num frames elapsed\n",
    "# vf[threes] = vf[threes]\n",
    "# vf[fives] = vf[fives]*4/5\n",
    "# ax[1].plot(ones[0], vf[ones])  #ones are the problem!!!??!!\n",
    "ax[0].set_title(\"Forward Translation Estimate Per Thread\")\n",
    "ax[0].plot(fours[0], vf[fours], label = \"every 4th frame\")\n",
    "ax[0].plot(fives[0], vf[fives], label = 'every 5th frame')\n",
    "ax[0].plot(threes[0], vf[threes], label = 'every 3rd frame')\n",
    "ax[0].legend(loc = 'best')\n",
    "\n",
    "yaw = odometry_history[:,-1]/skips #rotation, normalized by num frames elapsed\n",
    "ax[1].set_title(\"Yaw Estimate Per Thread\")\n",
    "ax[1].plot(fours[0], yaw[fours], label = \"every 4th frame\")\n",
    "ax[1].plot(fives[0], yaw[fives], label = 'every 5th frame')\n",
    "ax[1].plot(threes[0], yaw[threes], label = 'every 3rd frame')\n",
    "ax[1].legend(loc = 'best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b853cd",
   "metadata": {},
   "source": [
    "# 3D Braided Odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7844240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# real braided odometry via ICET ROS pkg ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "startidx = 20\n",
    "nframes = 100\n",
    "# odometry_history = np.load(\"test_data/leddartech_pixset/T_vec_history_1and3and5.npy\")[:nframes,:]\n",
    "# pred_stds_history = np.load(\"test_data/leddartech_pixset/cov_vec_history_1and3and5.npy\")[:nframes,:]\n",
    "# # odometry_history = np.load(\"test_data/Ford_Campus_Dataset/T_vec_history_1and3and5.npy\")[startidx:nframes+startidx,:]\n",
    "# # pred_stds_history = np.load(\"test_data/Ford_Campus_Dataset/cov_vec_history_1and3and5.npy\")[startidx:nframes+startidx,:]\n",
    "odometry_history = np.load(\"test_data/KITTI/117/T_vec_history_3and4and5.npy\")[startidx:startidx+nframes]\n",
    "#actual ICET covariance estimate\n",
    "pred_stds_history =  np.load(\"test_data/KITTI/117/cov_vec_history_3and4and5.npy\")[startidx:startidx+nframes]\n",
    "#keep static\n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "ij = np.load(\"test_data/KITTI/117/T_vec_history_3and4and5.npy\")[startidx:startidx+nframes,6:]\n",
    "# print(\"ij before: \\n\", ij[:10])\n",
    "\n",
    "#debug: only keep threes -------------------------\n",
    "skips = ij[:,1] - ij[:,0]\n",
    "threes = np.where(skips == 3)\n",
    "# print(threes)\n",
    "ij = ij[threes]\n",
    "odometry_history = odometry_history[threes]\n",
    "pred_stds_history = pred_stds_history[threes]\n",
    "# ------------------------------------------------\n",
    "\n",
    "ij = get_ij(ij.astype(np.int32)).numpy()\n",
    "# print(\"ij after: \\n\", ij)\n",
    "\n",
    "#raw Ford dataset ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# startidx = 800\n",
    "# nframes = 500\n",
    "# odometry_history = np.loadtxt(\"/home/derm/ASAR/v3/spherical_paper/FORD_results/ICET_estimates_ford.txt\")[startidx:nframes+startidx,:]\n",
    "# ij = np.append(np.arange(len(odometry_history))[:,None], np.arange(len(odometry_history))[:,None] + 1, axis = 1)\n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "# odometry_history = np.append(odometry_history, ij, axis= 1)   #match format output by ROS package\n",
    "\n",
    "#simplified data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# odometry_history = np.array([[1., 1, 0, 0, 0, 0., 0, 1],\n",
    "#                              [1., 1, 0, 0, 0, 0., 1, 2],\n",
    "#                              [1., 1, 0, 0, 0, 0., 2, 3], \n",
    "#                              [0., 1, 0, 0, 0, 0.0, 1, 4], #add conflicting measurement\n",
    "#                              [1., 1, 0, 0, 0, 0., 3, 4] ]) \n",
    "# ij = odometry_history[:,-2:].astype(int)\n",
    "# print(ij)\n",
    "\n",
    "# npts = 200\n",
    "# odometry_history = np.tile(np.array([0.0, 0.05, 0.002, 0.0, 0.0, 0.1]), (npts,1))\n",
    "# #add process noise\n",
    "# # odometry_history += np.random.randn(np.shape(odometry_history)[0], \n",
    "# #                                     np.shape(odometry_history)[1])*np.array([0,0,0, 0.0,0.1,0.])  \n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.005, 0.001, 1e-6, 1e-6, 1e-5]]), (len(odometry_history),1))\n",
    "# # pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# ij = np.array([[0,1]])\n",
    "# for i in range(1,len(odometry_history)):\n",
    "#     ij = np.append(ij, np.array([[i, i+1]]), axis = 0)\n",
    "# #mess with last constraint (add loop closure)\n",
    "# # ij[-1,1] = 50\n",
    "# # ij = np.append(np.array([[0,15]]), ij[:-1], axis = 0)\n",
    "# odometry_history = np.append(odometry_history, ij, axis= 1)   #match format output by ROS package\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "\n",
    "# braided corkscrew ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# num_nodes = 50 #total number of poses in graph\n",
    "# skips = 5 #number of frames to skip for low frequency registration\n",
    "# odometry_history = np.tile(np.array([0.0, 0.05, 0.002, 0.0, 0.0, 0.1]), (num_nodes,1))\n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# ij = np.array([[0,1]])\n",
    "# #get first constraints\n",
    "# for i in range(1,len(odometry_history)):\n",
    "#     ij = np.append(ij, np.array([[i, i+1]]), axis = 0)\n",
    "# for j in np.arange(1,len(odometry_history) - skips, skips):\n",
    "#     ij = np.append(ij, np.array([[j, j+skips]]), axis = 0)\n",
    "#     skip_odom =  skips*np.array([[0.0, 0.05, 0.002, 0.0, 0.0, 0.1]]) #simple linearization\n",
    "# #     skip_odom =  np.array([[0.1, 0.24, 0.006, 0.0, 0.0, 0.6]]) \n",
    "#     odometry_history = np.append(odometry_history, skip_odom, axis = 0)\n",
    "#     skip_pred_stds = np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]])\n",
    "#     pred_stds_history = np.append(pred_stds_history, skip_pred_stds, axis = 0)   \n",
    "# odometry_history = np.append(odometry_history, ij, axis= 1)   #match format output by ROS package\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# print(ij)\n",
    "# print(odometry_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0edb1",
   "metadata": {},
   "source": [
    "# Single Batch Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee77d0b",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "Falls apart with > 50 frames at near-zero initial conditions\n",
    "\n",
    "\"Indeterminate system\" error if > 200 frames, even from a single thread \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41041561",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import get_ij\n",
    "\n",
    "# Create an empty nonlinear factor graph\n",
    "graph = gtsam.NonlinearFactorGraph() \n",
    "\n",
    "# Add a prior on the first pose, setting it to the origin\n",
    "# A prior factor consists of a mean and a noise model (covariance matrix)\n",
    "# priorMean = gtsam.Pose3(np.zeros([6,1], dtype = np.float64))  # prior at origin\n",
    "priorRot = gtsam.Rot3(R_tf(np.array([0., 0., 0.8])))\n",
    "priorMean = gtsam.Pose3(priorRot, np.array([0., 0., .0])) #prior at nonzero pose\n",
    "PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(\n",
    "    np.array([0.003, 0.003, 0.003, 1e-5, 1e-5, 1e-5], dtype = np.float64))\n",
    "# firstKey = initial.keys()[0] #TODO: what does this do???\n",
    "graph.add(gtsam.PriorFactorPose3(0, priorMean, PRIOR_NOISE)) #constrain first point at priorMean\n",
    "\n",
    "#loop through all constraints \n",
    "for i in range(len(ij)):\n",
    "# for i in range(int(np.max(ij))):\n",
    "# for i in range(1,int(np.max(ij)) + 1): #test\n",
    "    #get constraint \n",
    "    raw_odom = odometry_history[i,:-2] #omit scan indices stored at end of line\n",
    "    #convert to Point3 strucutre\n",
    "    point = raw_odom[:3] \n",
    "    rot = gtsam.Rot3(R_tf(raw_odom[3:]))\n",
    "    odometry_estimate = gtsam.Pose3(rot, point)\n",
    "#     print(\"\\n odometry estimate:\\n\", odometry_estimate)\n",
    "    cov_estimate = gtsam.noiseModel.Diagonal.Sigmas(pred_stds_history[i,:-2])\n",
    "#     cov_estimate = gtsam.noiseModel.Diagonal.Sigmas(pred_stds_history[i,:]) #dont need to omit scan indices for fake data\n",
    "    first_idx = ij[i,0]\n",
    "    second_idx = ij[i,1] \n",
    "#     print(first_idx, second_idx) #misses last element in ij!!!\n",
    "    graph.add(gtsam.BetweenFactorPose3(first_idx, second_idx, odometry_estimate, cov_estimate))\n",
    "\n",
    "# print(graph.size())\n",
    "#set to zero initial conditions\n",
    "initial = gtsam.Values()\n",
    "# print(initial.keys())\n",
    "# print(\"\\n graph size:\", graph.size())\n",
    "# print(int(np.max(ij)))\n",
    "# for j in range(graph.size()):\n",
    "for j in range(int(np.max(ij))+1):\n",
    "#     zero_rot = gtsam.Rot3(R_tf(np.array([0., 0., 0.])))\n",
    "#     zero_pose3 = gtsam.Pose3(zero_rot, np.array([0., 0., 0.])) #does not work with zero initial conds??\n",
    "#     initial.insert(j, zero_pose3)\n",
    "    init_rot = gtsam.Rot3(R_tf(0.01*np.random.randn(3)))\n",
    "    init_pose = gtsam.Pose3(init_rot, np.random.randn(3))\n",
    "    initial.insert(j, init_pose)\n",
    "    \n",
    "# # optimize using Levenberg-Marquardt optimization\n",
    "# # damped optimizer - seems to work much better here\n",
    "# params = gtsam.LevenbergMarquardtParams()\n",
    "# optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial, params)\n",
    "\n",
    "# # simple gauss newton - kinda unreliable for high DOF problems (especially with zero initial conditions)\n",
    "# params = gtsam.GaussNewtonParams()\n",
    "# params.setVerbosity(\"Termination\")  # this will show info about stopping conds\n",
    "# optimizer = gtsam.GaussNewtonOptimizer(graph, initial, params)\n",
    "\n",
    "# dogleg\n",
    "params = gtsam.DoglegParams()\n",
    "params.setVerbosity(\"Termination\")\n",
    "params.setMaxIterations(100)\n",
    "optimizer = gtsam.DoglegOptimizer(graph, initial, params)\n",
    "\n",
    "result = optimizer.optimize()\n",
    "marginals = gtsam.Marginals(graph, result) #calculate covariance estimates for each pose\n",
    "\n",
    "print(\"initial error = \", graph.error(initial))\n",
    "print(\"final error = \", graph.error(result))\n",
    "# print(initial.keys())\n",
    "# print(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8beae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot results\n",
    "plt1 = Plotter(N = 1, axes = 1, bg =(1, 1, 1), interactive = True) #ax=7 gives rulers\n",
    "disp = []\n",
    "# disp = plot_results(disp, result, ij, draw_axis=True)\n",
    "disp = plot_results(disp, result, ij, marginals, draw_axis = True) #draws covarince ellipsoids\n",
    "plt1.show(disp, \"Factor Graph Test\")\n",
    "ViewInteractiveWidget(plt1.window) #need to comment out when working on laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ell(disp, frame, sigma, pc = 1, alpha = 0.5):\n",
    "    \"\"\"draw distribution ellipses given mu and sigma tensors\"\"\"\n",
    "    color = [0.3, 0.3, 0.8]\n",
    "\n",
    "    mu = frame[:3,-1]\n",
    "    eig = np.linalg.eig(sigma[:,:].numpy())\n",
    "    eigenval = eig[0] #correspond to lengths of axis\n",
    "    eigenvec = eig[1]\n",
    "\n",
    "    #eigenvals not ordered in decreasing size when scale large enough\n",
    "    a1 = tf.sort(eigenval).numpy()[-1]\n",
    "    a2 = tf.sort(eigenval).numpy()[-2]\n",
    "    a3 = tf.sort(eigenval).numpy()[-3]\n",
    "#     a1 = eigenval[0]\n",
    "#     a2 = eigenval[1]\n",
    "#     a3 = eigenval[2]\n",
    "    \n",
    "    #only need 3x3 of eigenvector to describe rotation of covariance ellipse\n",
    "    eigenvec = tf.gather(eigenvec, tf.argsort(eigenval, direction='DESCENDING'), axis = 1)\n",
    "#     eigenvec = tf.gather(eigenvec, tf.argsort(eigenval, direction='DESCENDING'), axis = 0)\n",
    "\n",
    "    #rotate into frame of previous odometry estimate (instead of world xyz frame)     \n",
    "#         eigenvec = eigenvec @ frame[0,:3,:3]  #frame has axis switched up in some frames\n",
    "#         eigenvec = eigenvec @ tf.gather(frame[0,:3,:3], tf.argsort(eigenval, direction='DESCENDING'), axis = 1)      \n",
    "    #DEBUG- issues because each frame is not centered w.r.t origin??\n",
    "    rot = frame[:3,:3]\n",
    "#         rot = -tf.linalg.pinv(frame[:3,:3])\n",
    "#     print(\"\\n rot \\n:\",  rot)\n",
    "#     print(\"\\n eigenvec before: \\n\", eigenvec)\n",
    "    eigenvec = eigenvec @ rot #works(ish) if I comment this out ...\n",
    "#         print(\"\\n eigenvec after: \\n\", eigenvec)\n",
    "\n",
    "#     #DEBUG--------------------------\n",
    "#     scale = 2\n",
    "#     rot = frame[:3,:3]\n",
    "# #         E = np.eye(3) #TODO: need to switch order of rows with a1,a2,a3\n",
    "#     correct_order = tf.argsort(np.linalg.eig(sigma[:,:].numpy())[0], direction = \"DESCENDING\").numpy()\n",
    "# #         correct_order = tf.argsort(np.linalg.eig(sigma[:,:].numpy())[0]).numpy()\n",
    "# #     E = np.eye(3)[correct_order]\n",
    "#     E = np.eye(3)\n",
    "#     A = rot @ E * scale * np.sqrt(np.array([a1, a2, a3]))\n",
    "#     xvec = Arrow(frame[:3,-1], frame[:3,-1] + A[:,0], c = 'red', alpha = alpha) \n",
    "#     yvec = Arrow(frame[:3,-1], frame[:3,-1] + A[:,1], c = 'green', alpha = alpha) \n",
    "#     zvec = Arrow(frame[:3,-1], frame[:3,-1] + A[:,2], c = 'blue', alpha = alpha) \n",
    "#     disp.append(xvec)\n",
    "#     disp.append(yvec)\n",
    "#     disp.append(zvec)\n",
    "#     # -------------------------------\n",
    "\n",
    "    if mu[0] != 0 and mu[1] != 0:\n",
    "        ell = Ell(pos=(mu[0], mu[1], mu[2]), axis1 = 4*np.sqrt(abs(a1)), \n",
    "        axis2 = 4*np.sqrt(abs(a2)), axis3 = 4*np.sqrt(abs(a3)), \n",
    "#         angs = (np.array([R2Euler(rot)[0], R2Euler(rot)[1], R2Euler(rot)[2] ])), c=color, alpha=alpha, res=12)\n",
    "        angs = (np.array([R2Euler(eigenvec)[0], R2Euler(eigenvec)[1], R2Euler(eigenvec)[2] ])), c=color, alpha=alpha, res=12)\n",
    "        disp.append(ell)\n",
    "\n",
    "    return(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(disp, results, ij, marginals = None, draw_axis = False):\n",
    "    \n",
    "    #plot coordinates of point centers\n",
    "    for i in range(result.size()): #loop through all elements in results\n",
    "        p = result.atPose3(i).matrix()\n",
    "        p_center = Points([[p[0,-1], p[1,-1],  p[2,-1]]], r = 5)\n",
    "        disp.append(p_center)\n",
    "        #add text labels\n",
    "        t = Text3D(i, p[:3,-1], s = 0.01, alpha = 0.3).followCamera() #need for deskop\n",
    "#         t = Text3D(i, p[:3,-1], s = 0.01, alpha = 0.3).follow_camera() #newer Vedo on Laptop?\n",
    "        disp.append(t)\n",
    "        if draw_axis is True:\n",
    "            disp = draw_body_frame_axis(p, disp) #draw coordinate frames\n",
    "        if marginals and i < len(ij): #num marginals in a chain = length of chain -1\n",
    "            frame = result.atPose3(ij[i,0]).matrix()#[None,:]\n",
    "            sigma = marginals.marginalCovariance(i)[:3,:3] #[None,:3,:3] #just ignore parts of sigma related to rotations\n",
    "            sigma = tf.convert_to_tensor(sigma)\n",
    "            disp = draw_ell(disp, frame, sigma)\n",
    "            #TODO: plot last ellispe\n",
    "            \n",
    "    #draw constraints using ij\n",
    "    for c in range(len(ij)):\n",
    "        pt1 = results.atPose3(ij[c,0]).translation()   #get coords of results i and j \n",
    "        pt2 = results.atPose3(ij[c,1]).translation()\n",
    "        L = Line(p0 = pt1, p1 = pt2, lw = 1)\n",
    "        disp.append(L)\n",
    "        \n",
    "    #draw covarince ellipsoids for each pose\n",
    "    #TODO: transform to respective frame (CURRENTLY PLOTTING IN GLOBAL XYZ!!!)\n",
    "#     if marginals:\n",
    "#         for k in range(0, int(np.max(ij))):\n",
    "#             frame = result.atPose3(ij[k,0]).matrix()[None,:] #coordinate frame of pose i\n",
    "# #             frame = result.atPose3(ij[k,1]).matrix()[None,:] #draw ellispse at subsequent point j\n",
    "# #             sigma = marginals.marginalCovariance(k)[None,:,:] #was this\n",
    "#             sigma = marginals.marginalCovariance(k)[None,:3,:3] #just ignore parts of sigma related to rotations\n",
    "#             sigma = tf.convert_to_tensor(sigma)\n",
    "#             disp = draw_ell(disp, frame, sigma)\n",
    "#             print(\"--------- frame \", k, \"---------------\")\n",
    "#             print(frame)\n",
    "#             print(\"\\n sigma: \\n\", np.sqrt(np.diag(marginals.marginalCovariance(k))))\n",
    "                                                 \n",
    "    return(disp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_body_frame_axis(x, disp = []):\n",
    "    \"\"\"draws local xyz axis arrows on each pose in x \"\"\"\n",
    "    scale = 0.25 #axis length\n",
    "    alpha = 1\n",
    "#     print(x)\n",
    "    rot = x[:3,:3]\n",
    "    A = rot @ np.eye(3) * scale\n",
    "    xvec = Arrow(x[:3,-1], x[:3,-1] + A[:,0], c = 'red', alpha = alpha) \n",
    "    yvec = Arrow(x[:3,-1], x[:3,-1] + A[:,1], c = 'green', alpha = alpha) \n",
    "    zvec = Arrow(x[:3,-1], x[:3,-1] + A[:,2], c = 'blue', alpha = alpha) \n",
    "    disp.append(xvec)\n",
    "    disp.append(yvec)\n",
    "    disp.append(zvec)\n",
    "    return(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc28339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ell(Mesh):\n",
    "    \"\"\"\n",
    "    Build a 3D ellipsoid centered at position `pos`.\n",
    "\n",
    "    |projectsphere|\n",
    "\n",
    "    |pca| |pca.py|_\n",
    "    \"\"\"\n",
    "    def __init__(self, pos=(0, 0, 0), axis1= 1, axis2 = 2, axis3 = 3, angs = np.array([0,0,0]),\n",
    "                 c=\"cyan4\", alpha=1, res=24):\n",
    "\n",
    "        self.center = pos\n",
    "        self.va_error = 0\n",
    "        self.vb_error = 0\n",
    "        self.vc_error = 0\n",
    "        self.axis1 = axis1\n",
    "        self.axis2 = axis2\n",
    "        self.axis3 = axis3\n",
    "        self.nr_of_points = 1 # used by pcaEllipsoid\n",
    "\n",
    "        if utils.isSequence(res): #new Vedo\n",
    "#         if utils.is_sequence(res): #old Vedo\n",
    "            res_t, res_phi = res\n",
    "        else:\n",
    "            res_t, res_phi = 2*res, res\n",
    "\n",
    "        elliSource = vtk.vtkSphereSource()\n",
    "        elliSource.SetThetaResolution(res_t)\n",
    "        elliSource.SetPhiResolution(res_phi)\n",
    "        elliSource.Update()\n",
    "        l1 = axis1\n",
    "        l2 = axis2\n",
    "        l3 = axis3\n",
    "        self.va = l1\n",
    "        self.vb = l2\n",
    "        self.vc = l3\n",
    "        axis1 = 1\n",
    "        axis2 = 1\n",
    "        axis3 = 1\n",
    "        angle = angs[0] #np.arcsin(np.dot(axis1, axis2))\n",
    "        theta = angs[1] #np.arccos(axis3[2])\n",
    "        phi =  angs[2] #np.arctan2(axis3[1], axis3[0])\n",
    "\n",
    "        t = vtk.vtkTransform()\n",
    "        t.PostMultiply()\n",
    "        t.Scale(l1, l2, l3)\n",
    "\n",
    "        #needed theta and angle to be negative before messing with E_xz, E_yz...\n",
    "        t.RotateZ(np.rad2deg(phi))\n",
    "        t.RotateY(-np.rad2deg(theta)) #flipped sign here 5/19\n",
    "        t.RotateX(-np.rad2deg(angle)) #flipped sign here 5/19\n",
    "        \n",
    "        tf = vtk.vtkTransformPolyDataFilter()\n",
    "        tf.SetInputData(elliSource.GetOutput())\n",
    "        tf.SetTransform(t)\n",
    "        tf.Update()\n",
    "        pd = tf.GetOutput()\n",
    "        self.transformation = t\n",
    "\n",
    "        Mesh.__init__(self, pd, c, alpha)\n",
    "        self.phong()\n",
    "        self.GetProperty().BackfaceCullingOn()\n",
    "        self.SetPosition(pos)\n",
    "        self.Length = -np.array(axis1) / 2 + pos\n",
    "        self.top = np.array(axis1) / 2 + pos\n",
    "        self.name = \"Ell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faffa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2Euler(mat):\n",
    "    \"\"\"determines euler angles from euler rotation matrix\"\"\"\n",
    "\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60dd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG - [x, y, z, phi, theta, psi] -> Pose3\n",
    "# t = np.array([1, 2, 3, 0.0 ,0.0 ,0.1])\n",
    "# point = t[:3] \n",
    "# rot = gtsam.Rot3(R_tf(t[3:]))\n",
    "# Pose = gtsam.Pose3(rot, point)\n",
    "# print(Pose)\n",
    "\n",
    "print(marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175908e1",
   "metadata": {},
   "source": [
    "# 2D Odometry Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab23d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noise models\n",
    "ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.2, 0.2, 0.1]))\n",
    "ODOMETRY_NOISE2 = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.2, 0.2, 0.5])) #test\n",
    "# PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3, 0.3, 0.1]))\n",
    "PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.05, 0.05, 0.05])) #test\n",
    "\n",
    "\n",
    "# Create an empty nonlinear factor graph\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "\n",
    "# Add a prior on the first pose, setting it to the origin\n",
    "# A prior factor consists of a mean and a noise model (covariance matrix)\n",
    "priorMean = gtsam.Pose2(0.0, 0.0, 0.0)  # prior at origin\n",
    "graph.add(gtsam.PriorFactorPose2(1, priorMean, PRIOR_NOISE))\n",
    "\n",
    "# Add odometry factors\n",
    "odometry = gtsam.Pose2(2.0, 0.0, 0.2)\n",
    "# For simplicity, we will use the same noise model for each odometry factor\n",
    "# Create odometry (Between) factors between consecutive poses\n",
    "graph.add(gtsam.BetweenFactorPose2(1, 2, odometry, ODOMETRY_NOISE))\n",
    "graph.add(gtsam.BetweenFactorPose2(2, 3, odometry, ODOMETRY_NOISE2))\n",
    "graph.add(gtsam.BetweenFactorPose2(3, 4, odometry, ODOMETRY_NOISE2)) #test\n",
    "# print(\"\\nFactor Graph:\\n{}\".format(graph))\n",
    "\n",
    "# Create the data structure to hold the initialEstimate estimate to the solution\n",
    "# For illustrative purposes, these have been deliberately set to incorrect values\n",
    "initial = gtsam.Values()\n",
    "initial.insert(1, gtsam.Pose2(0.5, 0.0, 0.2))\n",
    "initial.insert(2, gtsam.Pose2(2.3, 0.1, -0.2))\n",
    "initial.insert(3, gtsam.Pose2(4.1, 0.1, 0.1))\n",
    "initial.insert(4, gtsam.Pose2(4.1, 0.1, 0.1))#test\n",
    "# print(\"\\nInitial Estimate:\\n{}\".format(initial))\n",
    "\n",
    "#used for 2D\n",
    "# optimize using Levenberg-Marquardt optimization\n",
    "params = gtsam.LevenbergMarquardtParams() \n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial, params)\n",
    "\n",
    "result = optimizer.optimize()\n",
    "# print(\"\\nFinal Result:\\n{}\".format(result))\n",
    "\n",
    "# 5. Calculate and print marginal covariances for all variables\n",
    "marginals = gtsam.Marginals(graph, result)\n",
    "# for i in range(1, 4):\n",
    "#     print(\"X{} covariance:\\n{}\\n\".format(i,\n",
    "#                                          marginals.marginalCovariance(i)))\n",
    "\n",
    "for i in range(1, 5):\n",
    "    gtsam_plot.plot_pose2(0, result.atPose2(i), 0.5,\n",
    "                          marginals.marginalCovariance(i))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test plotting 2D odometry estimates\n",
    "# a = gtsam.Pose2(0.5, 0.0, 0.2)\n",
    "\n",
    "print(result.atPose2(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd77a17",
   "metadata": {},
   "source": [
    "# Pose3 SLAM Example\n",
    "\n",
    "g2o is a file format for representing human-readable graphs for optimization problems\n",
    "https://github.com/uoip/g2opy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2oFile = \"gtsampy/Data/pose3example.txt\"\n",
    "# g2oFile = gtsam.findExampleDataFile(\"pose3example.txt\")\n",
    "is3D = True\n",
    "graph, initial  = gtsam.readG2o(g2oFile, is3D)\n",
    "# print(initial)\n",
    "\n",
    "priorModel = gtsam.noiseModel.Diagonal.Variances(\n",
    "        np.array([1e-6, 1e-6, 1e-6, 1e-4, 1e-4, 1e-4]))\n",
    "\n",
    "firstKey = initial.keys()[0]\n",
    "graph.add(gtsam.PriorFactorPose3(0, gtsam.Pose3(), priorModel))\n",
    "\n",
    "initialization = gtsam.InitializePose3.initialize(graph)\n",
    "# print(initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66574005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f4022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
