{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661ffbc6",
   "metadata": {},
   "source": [
    "# Exploring GTSAM  Package for Pose Optimization with Factor Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f6786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook\n",
    "\n",
    "# import gtsampy as gtsam\n",
    "import gtsam\n",
    "import gtsam.utils.plot as gtsam_plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "from vedo import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1451e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ecd05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 00:47:13.905987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 00:47:14.046562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-07 00:47:14.046580: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-07 00:47:14.804223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-07 00:47:14.804356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-07 00:47:14.804365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import  sin, cos, tan\n",
    "\n",
    "def R_tf(angs):\n",
    "    \"\"\"generates rotation matrix using euler angles\n",
    "    angs = tf.constant(phi, theta, psi) (aka rot about (x,y,z))\n",
    "            can be single set of angles or batch for multiple cells\n",
    "    \"\"\"\n",
    "\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80502e7",
   "metadata": {},
   "source": [
    "# Establish Origin \n",
    "\n",
    "$ [x, y, z, \\phi, \\theta, \\psi ] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86795090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: [\n",
      "\t0, 2.7346e+161, 5.60796e-316;\n",
      "\t0, 1.63042e-322, 5.89425e-316;\n",
      "\t0, 0, 6.92534e-310\n",
      "]\n",
      "t: 9.43466e-309 4.00193e-322 5.65565e-316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = np.array([0,0,0,0,0,0], dtype = np.float64)\n",
    "start = gtsam.Pose3(p)\n",
    "print(start)\n",
    "\n",
    "# newpt = gtsam.Pose3(np.array([1,1,1,0,0,0], dtype = np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b853cd",
   "metadata": {},
   "source": [
    "# 3D Odometry with PixSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f7844240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#leddartech braided odometry via ICET ROS pkg ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# startidx = 800\n",
    "# nframes = 300\n",
    "# odometry_history = np.load(\"test_data/leddartech_pixset/T_vec_history_1and3and5.npy\")[:nframes,:]\n",
    "# pred_stds_history = np.load(\"test_data/leddartech_pixset/cov_vec_history_1and3and5.npy\")[:nframes,:]\n",
    "# # odometry_history = np.load(\"test_data/Ford_Campus_Dataset/T_vec_history_1and3and5.npy\")[startidx:nframes+startidx,:]\n",
    "# # pred_stds_history = np.load(\"test_data/Ford_Campus_Dataset/cov_vec_history_1and3and5.npy\")[startidx:nframes+startidx,:]\n",
    "\n",
    "# #debug- only use non-releated indices\n",
    "# # good_idx = np.array([0,1,3]) #,5,7])\n",
    "# # odometry_history = odometry_history[good_idx]\n",
    "# # print(odometry_history.dtype)\n",
    "# ij = get_ij(odometry_history[:,6:].astype(np.int32)).numpy() #indices of each\n",
    "# #debug: \n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "\n",
    "#raw Ford dataset ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# startidx = 800\n",
    "# nframes = 500\n",
    "# odometry_history = np.loadtxt(\"/home/derm/ASAR/v3/spherical_paper/FORD_results/ICET_estimates_ford.txt\")[startidx:nframes+startidx,:]\n",
    "# ij = np.append(np.arange(len(odometry_history))[:,None], np.arange(len(odometry_history))[:,None] + 1, axis = 1)\n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "# odometry_history = np.append(odometry_history, ij, axis= 1)   #match format output by ROS package\n",
    "\n",
    "#simplified data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# odometry_history = np.array([[1., 1, 0, 0, 0, 0., 0, 1],\n",
    "#                              [1., 1, 0, 0, 0, 0., 1, 2],\n",
    "#                              [1., 1, 0, 0, 0, 0., 2, 3], \n",
    "#                              [0., 1, 0, 0, 0, 0.0, 1, 4], #add conflicting measurement\n",
    "#                              [1., 1, 0, 0, 0, 0., 3, 4] ]) \n",
    "# ij = odometry_history[:,-2:].astype(int)\n",
    "# print(ij)\n",
    "\n",
    "# npts = 200\n",
    "# odometry_history = np.tile(np.array([0.0, 0.05, 0.002, 0.0, 0.0, 0.1]), (npts,1))\n",
    "# #add process noise\n",
    "# # odometry_history += np.random.randn(np.shape(odometry_history)[0], \n",
    "# #                                     np.shape(odometry_history)[1])*np.array([0,0,0, 0.0,0.1,0.])  \n",
    "# pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "# ij = np.array([[0,1]])\n",
    "# for i in range(1,len(odometry_history)):\n",
    "#     ij = np.append(ij, np.array([[i, i+1]]), axis = 0)\n",
    "# #mess with last constraint (add loop closure)\n",
    "# ij[-1,1] = 150\n",
    "# # ij = np.append(np.array([[0,15]]), ij[:-1], axis = 0)\n",
    "# odometry_history = np.append(odometry_history, ij, axis= 1)   #match format output by ROS package\n",
    "# pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "\n",
    "# braided corkscrew ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "num_nodes = 50 #total number of poses in graph\n",
    "skips = 3 #number of frames to skip for low frequency registration\n",
    "odometry_history = np.tile(np.array([0.0, 0.05, 0.002, 0.0, 0.0, 0.1]), (num_nodes,1))\n",
    "pred_stds_history = np.tile(np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]]), (len(odometry_history),1))\n",
    "ij = np.array([[0,1]])\n",
    "#get first constraints\n",
    "for i in range(1,len(odometry_history)):\n",
    "    ij = np.append(ij, np.array([[i, i+1]]), axis = 0)\n",
    "\n",
    "for j in np.arange(1,len(odometry_history) - skips, skips):\n",
    "    \n",
    "    ij = np.append(ij, np.array([[j, j+skips]]), axis = 0)\n",
    "    skip_odom =  skips*np.array([[0.0, 0.05, 0.002, 0.0, 0.0, 0.1]]) #simple linearization\n",
    "    odometry_history = np.append(odometry_history, skip_odom, axis = 0)\n",
    "    skip_pred_stds = np.array([[0.001, 0.001, 0.001, 1e-6, 1e-6, 1e-6]])\n",
    "    pred_stds_history = np.append(pred_stds_history, skip_pred_stds, axis = 0)\n",
    "\n",
    "    \n",
    "odometry_history = np.append(odometry_history, ij, axis= 1)   #match format output by ROS package\n",
    "pred_stds_history = np.append(pred_stds_history, ij, axis= 1) #match format output by ROS package\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# print(ij)\n",
    "# print(odometry_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "efe5127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #debug: only consider n-skips constraints\n",
    "# skips = 5\n",
    "# good_idx = np.where(ij[:,1] - ij[:,0] == skips)\n",
    "# # print(good_idx)\n",
    "# # print(ij[good_idx])\n",
    "# ij = ij[good_idx]\n",
    "# odometry_history = odometry_history[good_idx]\n",
    "# pred_stds_history = pred_stds_history[good_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "41041561",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error = converged\n",
      "errorThreshold: 267083.253538 <? 0\n",
      "absoluteDecrease: 2.49324205553 <? 1e-05\n",
      "relativeDecrease: 9.33498730494e-06 <? 1e-05\n",
      "iterations: 16 >? 200\n",
      " 143933310390505.38\n",
      "final error =  267083.2535384974\n"
     ]
    }
   ],
   "source": [
    "from utils import get_ij\n",
    "\n",
    "# Create an empty nonlinear factor graph\n",
    "graph = gtsam.NonlinearFactorGraph() \n",
    "\n",
    "# Add a prior on the first pose, setting it to the origin\n",
    "# A prior factor consists of a mean and a noise model (covariance matrix)\n",
    "# priorMean = gtsam.Pose3(np.zeros([6,1], dtype = np.float64))  # prior at origin\n",
    "priorRot = gtsam.Rot3(R_tf(np.array([0., 0., 0.8])))\n",
    "priorMean = gtsam.Pose3(priorRot, np.array([0., 0., 1.0])) #prior at nonzero pose\n",
    "PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(\n",
    "    np.array([0.001, 0.001, 0.001, 1e-5, 1e-5, 1e-5], dtype = np.float64))\n",
    "# firstKey = initial.keys()[0] #TODO: what does this do???\n",
    "graph.add(gtsam.PriorFactorPose3(0, priorMean, PRIOR_NOISE)) #constrain first point at priorMean\n",
    "\n",
    "#loop through all constraints \n",
    "for i in range(len(ij)):\n",
    "# for i in range(int(np.max(ij))):\n",
    "# for i in range(1,int(np.max(ij)) + 1): #test\n",
    "    #get constraint \n",
    "    raw_odom = odometry_history[i,:-2] #omit scan indices stored at end of line\n",
    "    #convert to Point3 strucutre\n",
    "    point = raw_odom[:3] \n",
    "    rot = gtsam.Rot3(R_tf(raw_odom[3:]))\n",
    "    odometry_estimate = gtsam.Pose3(rot, point)\n",
    "#     print(\"\\n odometry estimate:\\n\", odometry_estimate)\n",
    "    cov_estimate = gtsam.noiseModel.Diagonal.Sigmas(pred_stds_history[i,:-2])\n",
    "#     cov_estimate = gtsam.noiseModel.Diagonal.Sigmas(pred_stds_history[i,:]) #dont need to omit scan indices for fake data\n",
    "    first_idx = ij[i,0]\n",
    "    second_idx = ij[i,1] \n",
    "#     print(first_idx, second_idx) #misses last element in ij!!!\n",
    "    graph.add(gtsam.BetweenFactorPose3(first_idx, second_idx, odometry_estimate, cov_estimate))\n",
    "\n",
    "# print(graph.size())\n",
    "#set to zero initial conditions\n",
    "initial = gtsam.Values()\n",
    "# print(initial.keys())\n",
    "# print(\"\\n graph size:\", graph.size())\n",
    "# print(int(np.max(ij)))\n",
    "# for j in range(graph.size()):\n",
    "for j in range(int(np.max(ij))+1):\n",
    "#     zero_rot = gtsam.Rot3(R_tf(np.array([0., 0., 0.])))\n",
    "#     zero_pose3 = gtsam.Pose3(zero_rot, np.array([0., 0., 0.])) #does not work with zero initial conds??\n",
    "#     initial.insert(j, zero_pose3)\n",
    "    init_rot = gtsam.Rot3(R_tf(0.01*np.random.randn(3)))\n",
    "    init_pose = gtsam.Pose3(init_rot, np.random.randn(3))\n",
    "    initial.insert(j, init_pose)\n",
    "    \n",
    "# # optimize using Levenberg-Marquardt optimization\n",
    "# # damped optimizer - seems to work much better here\n",
    "# params = gtsam.LevenbergMarquardtParams()\n",
    "# optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial, params)\n",
    "\n",
    "# # simple gauss newton - kinda unreliable for high DOF problems (especially with zero initial conditions)\n",
    "# params = gtsam.GaussNewtonParams()\n",
    "# params.setVerbosity(\"Termination\")  # this will show info about stopping conds\n",
    "# optimizer = gtsam.GaussNewtonOptimizer(graph, initial, params)\n",
    "\n",
    "# dogleg\n",
    "params = gtsam.DoglegParams()\n",
    "params.setVerbosity(\"Termination\")\n",
    "params.setMaxIterations(200)\n",
    "optimizer = gtsam.DoglegOptimizer(graph, initial, params)\n",
    "\n",
    "result = optimizer.optimize()\n",
    "marginals = gtsam.Marginals(graph, result) #calculate covariance estimates for each pose\n",
    "\n",
    "print(\"initial error = \", graph.error(initial))\n",
    "print(\"final error = \", graph.error(result))\n",
    "# print(initial.keys())\n",
    "# print(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "55d8beae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vedo.plotter.Plotter at 0x7f7ba9c3db50>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot results\n",
    "plt1 = Plotter(N = 1, axes = 1, bg =(1, 1, 1), interactive = True) #ax=7 gives rulers\n",
    "disp = []\n",
    "disp = plot_results(disp, result, ij, draw_axis=True)\n",
    "# disp = plot_results(disp, result, ij, marginals, draw_axis = True) #draws covarince ellipsoids\n",
    "plt1.show(disp, \"Factor Graph Test\")\n",
    "# ViewInteractiveWidget(plt1.window) #need to comment out when working on laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71b4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ell(disp, frame, sigma, pc = 1, alpha = 0.5):\n",
    "    \"\"\"draw distribution ellipses given mu and sigma tensors\"\"\"\n",
    "    color = [0.3, 0.3, 0.8]\n",
    "\n",
    "    for i in range(tf.shape(sigma)[0]):\n",
    "\n",
    "        mu = frame[:,:3,-1]\n",
    "        \n",
    "        eig = np.linalg.eig(sigma[i,:,:].numpy())\n",
    "                \n",
    "        eigenval = eig[0] #correspond to lengths of axis\n",
    "        eigenvec = eig[1]\n",
    "        \n",
    "        #TODO:transform eigenvect to represent angles in frame of last odometry estimate\n",
    "        print(\"\\n sigma: \\n\", sigma)\n",
    "        print(\"\\n eigenval: \\n\", eigenval)\n",
    "#         print(\"\\n eigenvec: \\n\", eigenvec)\n",
    "#         print(\"\\n frame[:,:3,:3] \\n\", frame[:,:3,:3])\n",
    "        print(\"\\n sorted eigenvals: \\n\", tf.sort(eigenval).numpy(), tf.argsort(eigenval))\n",
    "\n",
    "        #eigenvals not ordered in decreasing size when scale large enough\n",
    "        a1 = tf.sort(eigenval).numpy()[-1]\n",
    "        a2 = tf.sort(eigenval).numpy()[-2]\n",
    "        a3 = tf.sort(eigenval).numpy()[-3]\n",
    "        \n",
    "        #only need 3x3 of eigenvector to describe rotation of covariance ellipse\n",
    "        eigenvec = tf.gather(eigenvec, tf.argsort(eigenval, direction='DESCENDING'), axis = 1)\n",
    "\n",
    "        #rotate into frame of previous odometry estimate (instead of world xyz frame)     \n",
    "#         eigenvec = eigenvec @ frame[0,:3,:3]  #frame has axis switched up in some frames\n",
    "        eigenvec = eigenvec @ tf.gather(frame[0,:3,:3], tf.argsort(eigenval, direction='DESCENDING'), axis = 1)      \n",
    "        print(\"\\n eigenvec after: \\n\", eigenvec)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         test = np.array([-R2Euler(eigenvec)[0], -R2Euler(eigenvec)[1], -R2Euler(eigenvec)[2] ])\n",
    "#         test = R2Euler(eigenvec)\n",
    "#         print(\"test: \\n\", test)\n",
    "\n",
    "        if mu[i,0] != 0 and mu[i,1] != 0:\n",
    "            ell = Ell(pos=(mu[i,0], mu[i,1], mu[i,2]), axis1 = 4*np.sqrt(abs(a1)), \n",
    "                axis2 = 4*np.sqrt(abs(a2)), axis3 = 4*np.sqrt(abs(a3)), \n",
    "#                 angs = (np.array([-R2Euler(eigenvec)[0], -R2Euler(eigenvec)[1], -R2Euler(eigenvec)[2] ])), c=color, alpha=alpha, res=12)\n",
    "                angs = (np.array([R2Euler(eigenvec)[0], R2Euler(eigenvec)[1], R2Euler(eigenvec)[2] ])), c=color, alpha=alpha, res=12)\n",
    "            \n",
    "            disp.append(ell)\n",
    "            \n",
    "    return(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fb3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(disp, results, ij, marginals = None, draw_axis = False):\n",
    "    \n",
    "    #plot coordinates of point centers\n",
    "    for i in range(result.size()): #loop through all elements in results\n",
    "        p = result.atPose3(i).matrix()\n",
    "        p_center = Points([[p[0,-1], p[1,-1],  p[2,-1]]], r = 5)\n",
    "        disp.append(p_center)\n",
    "        #add text labels\n",
    "#         t = Text3D(i, p[:3,-1], s = 0.01, alpha = 0.3).followCamera() #need for deskop\n",
    "        t = Text3D(i, p[:3,-1], s = 0.01, alpha = 0.3).follow_camera() #newer Vedo on Laptop?\n",
    "        disp.append(t)\n",
    "        if draw_axis is True:\n",
    "            disp = draw_body_frame_axis(p, disp) #draw coordinate frames\n",
    "\n",
    "    #draw constraints using ij\n",
    "    for c in range(len(ij)):\n",
    "        #get coords of results i and j \n",
    "        pt1 = results.atPose3(ij[c,0]).translation()\n",
    "        pt2 = results.atPose3(ij[c,1]).translation()\n",
    "        L = Line(p0 = pt1, p1 = pt2, lw = 1)\n",
    "        disp.append(L)\n",
    "#         print(\"\\n\",ij[c])\n",
    "#         print(\"pt1, pt2: \\n\", pt1, pt2)\n",
    "    #TODO: color constraints by which ICET thread they came from (i.e. skip1, skip3, skip5, etc.)\n",
    "\n",
    "    #draw covarince ellipsoids for each pose\n",
    "    #TODO: transform to respective frame (CURRENTLY PLOTTING IN GLOBAL XYZ!!!)\n",
    "    if marginals:\n",
    "        for k in range(0, int(np.max(ij))):\n",
    "            frame = result.atPose3(ij[k,0]).matrix()[None,:] #coordinate frame of pose i\n",
    "#             frame = result.atPose3(ij[k,1]).matrix()[None,:] #draw ellispse at subsequent point j\n",
    "#             sigma = marginals.marginalCovariance(k)[None,:,:] #was this\n",
    "            sigma = marginals.marginalCovariance(k)[None,:3,:3] #just ignore parts of sigma related to rotations\n",
    "            sigma = tf.convert_to_tensor(sigma)\n",
    "            disp = draw_ell(disp, frame, sigma)\n",
    "            print(\"--------- frame \", k, \"---------------\")\n",
    "#             print(frame)\n",
    "#             print(\"\\n sigma: \\n\", np.sqrt(np.diag(marginals.marginalCovariance(k))))\n",
    "                                                 \n",
    "    return(disp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c6e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_body_frame_axis(x, disp = []):\n",
    "    \"\"\"draws local xyz axis arrows on each pose in x \"\"\"\n",
    "    scale = 0.025 #axis length\n",
    "    alpha = 1\n",
    "    rot = x[:3,:3]\n",
    "    A = rot @ np.eye(3) * scale\n",
    "    xvec = Arrow(x[:3,-1], x[:3,-1] + A[:,0], c = 'red', alpha = alpha) \n",
    "    yvec = Arrow(x[:3,-1], x[:3,-1] + A[:,1], c = 'green', alpha = alpha) \n",
    "    zvec = Arrow(x[:3,-1], x[:3,-1] + A[:,2], c = 'blue', alpha = alpha) \n",
    "    disp.append(xvec)\n",
    "    disp.append(yvec)\n",
    "    disp.append(zvec)\n",
    "    return(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc28339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ell(Mesh):\n",
    "    \"\"\"\n",
    "    Build a 3D ellipsoid centered at position `pos`.\n",
    "\n",
    "    |projectsphere|\n",
    "\n",
    "    |pca| |pca.py|_\n",
    "    \"\"\"\n",
    "    def __init__(self, pos=(0, 0, 0), axis1= 1, axis2 = 2, axis3 = 3, angs = np.array([0,0,0]),\n",
    "                 c=\"cyan4\", alpha=1, res=24):\n",
    "\n",
    "        self.center = pos\n",
    "        self.va_error = 0\n",
    "        self.vb_error = 0\n",
    "        self.vc_error = 0\n",
    "        self.axis1 = axis1\n",
    "        self.axis2 = axis2\n",
    "        self.axis3 = axis3\n",
    "        self.nr_of_points = 1 # used by pcaEllipsoid\n",
    "\n",
    "#         if utils.isSequence(res): #desktop\n",
    "        if utils.is_sequence(res): #laptop\n",
    "            res_t, res_phi = res\n",
    "        else:\n",
    "            res_t, res_phi = 2*res, res\n",
    "\n",
    "        elliSource = vtk.vtkSphereSource()\n",
    "        elliSource.SetThetaResolution(res_t)\n",
    "        elliSource.SetPhiResolution(res_phi)\n",
    "        elliSource.Update()\n",
    "        l1 = axis1\n",
    "        l2 = axis2\n",
    "        l3 = axis3\n",
    "        self.va = l1\n",
    "        self.vb = l2\n",
    "        self.vc = l3\n",
    "        axis1 = 1\n",
    "        axis2 = 1\n",
    "        axis3 = 1\n",
    "        angle = angs[0] #np.arcsin(np.dot(axis1, axis2))\n",
    "        theta = angs[1] #np.arccos(axis3[2])\n",
    "        phi =  angs[2] #np.arctan2(axis3[1], axis3[0])\n",
    "\n",
    "        t = vtk.vtkTransform()\n",
    "        t.PostMultiply()\n",
    "        t.Scale(l1, l2, l3)\n",
    "\n",
    "        #needed theta and angle to be negative before messing with E_xz, E_yz...\n",
    "        t.RotateZ(np.rad2deg(phi))\n",
    "        t.RotateY(-np.rad2deg(theta)) #flipped sign here 5/19\n",
    "        t.RotateX(-np.rad2deg(angle)) #flipped sign here 5/19\n",
    "        \n",
    "        tf = vtk.vtkTransformPolyDataFilter()\n",
    "        tf.SetInputData(elliSource.GetOutput())\n",
    "        tf.SetTransform(t)\n",
    "        tf.Update()\n",
    "        pd = tf.GetOutput()\n",
    "        self.transformation = t\n",
    "\n",
    "        Mesh.__init__(self, pd, c, alpha)\n",
    "        self.phong()\n",
    "        self.GetProperty().BackfaceCullingOn()\n",
    "        self.SetPosition(pos)\n",
    "        self.Length = -np.array(axis1) / 2 + pos\n",
    "        self.top = np.array(axis1) / 2 + pos\n",
    "        self.name = \"Ell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7faffa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2Euler(mat):\n",
    "    \"\"\"determines euler angles from euler rotation matrix\"\"\"\n",
    "\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60dd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG - [x, y, z, phi, theta, psi] -> Pose3\n",
    "# t = np.array([1, 2, 3, 0.0 ,0.0 ,0.1])\n",
    "# point = t[:3] \n",
    "# rot = gtsam.Rot3(R_tf(t[3:]))\n",
    "# Pose = gtsam.Pose3(rot, point)\n",
    "# print(Pose)\n",
    "\n",
    "print(marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175908e1",
   "metadata": {},
   "source": [
    "# 2D Odometry Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab23d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noise models\n",
    "ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.2, 0.2, 0.1]))\n",
    "ODOMETRY_NOISE2 = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.2, 0.2, 0.5])) #test\n",
    "# PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3, 0.3, 0.1]))\n",
    "PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.05, 0.05, 0.05])) #test\n",
    "\n",
    "\n",
    "# Create an empty nonlinear factor graph\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "\n",
    "# Add a prior on the first pose, setting it to the origin\n",
    "# A prior factor consists of a mean and a noise model (covariance matrix)\n",
    "priorMean = gtsam.Pose2(0.0, 0.0, 0.0)  # prior at origin\n",
    "graph.add(gtsam.PriorFactorPose2(1, priorMean, PRIOR_NOISE))\n",
    "\n",
    "# Add odometry factors\n",
    "odometry = gtsam.Pose2(2.0, 0.0, 0.2)\n",
    "# For simplicity, we will use the same noise model for each odometry factor\n",
    "# Create odometry (Between) factors between consecutive poses\n",
    "graph.add(gtsam.BetweenFactorPose2(1, 2, odometry, ODOMETRY_NOISE))\n",
    "graph.add(gtsam.BetweenFactorPose2(2, 3, odometry, ODOMETRY_NOISE2))\n",
    "graph.add(gtsam.BetweenFactorPose2(3, 4, odometry, ODOMETRY_NOISE2)) #test\n",
    "# print(\"\\nFactor Graph:\\n{}\".format(graph))\n",
    "\n",
    "# Create the data structure to hold the initialEstimate estimate to the solution\n",
    "# For illustrative purposes, these have been deliberately set to incorrect values\n",
    "initial = gtsam.Values()\n",
    "initial.insert(1, gtsam.Pose2(0.5, 0.0, 0.2))\n",
    "initial.insert(2, gtsam.Pose2(2.3, 0.1, -0.2))\n",
    "initial.insert(3, gtsam.Pose2(4.1, 0.1, 0.1))\n",
    "initial.insert(4, gtsam.Pose2(4.1, 0.1, 0.1))#test\n",
    "# print(\"\\nInitial Estimate:\\n{}\".format(initial))\n",
    "\n",
    "#used for 2D\n",
    "# optimize using Levenberg-Marquardt optimization\n",
    "params = gtsam.LevenbergMarquardtParams() \n",
    "optimizer = gtsam.LevenbergMarquardtOptimizer(graph, initial, params)\n",
    "\n",
    "result = optimizer.optimize()\n",
    "# print(\"\\nFinal Result:\\n{}\".format(result))\n",
    "\n",
    "# 5. Calculate and print marginal covariances for all variables\n",
    "marginals = gtsam.Marginals(graph, result)\n",
    "# for i in range(1, 4):\n",
    "#     print(\"X{} covariance:\\n{}\\n\".format(i,\n",
    "#                                          marginals.marginalCovariance(i)))\n",
    "\n",
    "for i in range(1, 5):\n",
    "    gtsam_plot.plot_pose2(0, result.atPose2(i), 0.5,\n",
    "                          marginals.marginalCovariance(i))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test plotting 2D odometry estimates\n",
    "# a = gtsam.Pose2(0.5, 0.0, 0.2)\n",
    "\n",
    "print(result.atPose2(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd77a17",
   "metadata": {},
   "source": [
    "# Pose3 SLAM Example\n",
    "\n",
    "g2o is a file format for representing human-readable graphs for optimization problems\n",
    "https://github.com/uoip/g2opy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2oFile = \"gtsampy/Data/pose3example.txt\"\n",
    "# g2oFile = gtsam.findExampleDataFile(\"pose3example.txt\")\n",
    "is3D = True\n",
    "graph, initial  = gtsam.readG2o(g2oFile, is3D)\n",
    "# print(initial)\n",
    "\n",
    "priorModel = gtsam.noiseModel.Diagonal.Variances(\n",
    "        np.array([1e-6, 1e-6, 1e-6, 1e-4, 1e-4, 1e-4]))\n",
    "\n",
    "firstKey = initial.keys()[0]\n",
    "graph.add(gtsam.PriorFactorPose3(0, gtsam.Pose3(), priorModel))\n",
    "\n",
    "initialization = gtsam.InitializePose3.initialize(graph)\n",
    "# print(initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66574005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f4022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
