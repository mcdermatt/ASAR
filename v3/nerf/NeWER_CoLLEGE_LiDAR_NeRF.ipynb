{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2e24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load requirements for working with PCs\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 16*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "import sys\n",
    "import os\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "sys.path.append(parent_directory+\"/point_cloud_rectification\")\n",
    "from ICET_spherical import ICET\n",
    "from linear_corrector import LC\n",
    "\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import trimesh\n",
    "\n",
    "from pillow_heif import register_heif_opener\n",
    "from matplotlib import pyplot as p\n",
    "from colmapParsingUtils import *\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cv2\n",
    "from lidar_nerf_utils import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load raw point cloud data from Newer College Dataset\n",
    "\n",
    "#NEWER COLLEGE\n",
    "idx = 500 #7800 #1500 \n",
    "fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "pc1 = np.load(fn1)\n",
    "pc1 = np.flip(pc1, axis = 0)#flip to maintain CCW convention used in VICET\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "## purple -> green\n",
    "color = 255*np.linspace(0,1,len(pc1)) \n",
    "cname = np.array([255-color, color, 255-color]).T.tolist()\n",
    "# disp.append(Points(pc1, c=cname,  r = 3.5, alpha =0.5))\n",
    "# print(len(pc1) / 128)\n",
    "disp.append(Points(pc1, c='red',  r = 3.5, alpha =0.5))\n",
    "\n",
    "#remove NaNs\n",
    "# pc1[pc1[:,0]>64] = 100\n",
    "# pc1[pc1[:,0]<-64] = 100\n",
    "# pc1 = np.nan_to_num(pc1, nan=0.0)\n",
    "\n",
    "plt.show(disp, \"Raw Point Cloud\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78b9ed",
   "metadata": {},
   "source": [
    "# Convert Point Cloud to Depth Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c57e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "pc1_spherical = LC.c2s(LC,pc1).numpy() #[r, theta, phi]\n",
    "pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "pcs = np.flip(pcs, axis = 1)\n",
    "raw_data = pcs[:,:,0].T\n",
    "\n",
    "# print(np.shape(data))\n",
    "\n",
    "data = np.zeros([64, 1024])\n",
    "for i in range(np.shape(data)[0]//4):\n",
    "    #shift left\n",
    "#     data[4*i,:-18] = raw_data[4*i,18:]\n",
    "#     data[4*i+1,:-12] = raw_data[4*i+1,12:]\n",
    "#     data[4*i+2,:-6] = raw_data[4*i+2,6:]\n",
    "#     data[4*i+3,:] = raw_data[4*i+3,:]\n",
    "    #shift right\n",
    "    data[4*i,:] = raw_data[4*i,:]\n",
    "    data[4*i+1,6:] = raw_data[4*i+1,:-6]\n",
    "    data[4*i+2,12:] = raw_data[4*i+2,:-12]\n",
    "    data[4*i+3,18:] = raw_data[4*i+3,:-18]\n",
    "#     #keep centered-- avoids needing to fill in gaps\n",
    "#     data[4*i,1:-8] = raw_data[4*i,9:]\n",
    "#     data[4*i+1,1:-2] = raw_data[4*i+1,3:]\n",
    "#     data[4*i+2,4:] = raw_data[4*i+2,:-4]\n",
    "#     data[4*i+3,10:] = raw_data[4*i+3,:-10]\n",
    "    \n",
    "# # data = np.flip(data, axis =1)\n",
    "# #try shifting horizontally\n",
    "# n = 16\n",
    "# data = np.hstack((data[:, n:], data[:, :n]))\n",
    "\n",
    "fig, ax = p.subplots(2,1)\n",
    "ax[0].set_title(\"Raw Depth Image\")\n",
    "ax[0].imshow(raw_data, cmap = \"YlGnBu\", norm='log')\n",
    "ax[0].set_aspect(5)\n",
    "ax[1].set_title(\"Destaggered Depth Image\")\n",
    "ax[1].imshow(data, cmap = \"YlGnBu\", norm='log')\n",
    "ax[1].set_aspect(5)\n",
    "print(np.shape(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacaf774",
   "metadata": {},
   "source": [
    "# Reproject 2D Depth image back to 3D point cloud\n",
    "\n",
    "#### IMPORTANT: look into pixel_shift_by_row parameter from OUSTER\n",
    "https://ouster.com/insights/blog/firmware-2-4-industry-standard-protocols-and-improved-alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max and min phi values of sensor by looking at actual point xyz data\n",
    "pc1_spherical = pc1_spherical[~np.isnan(pc1_spherical).any(axis=1)]\n",
    "print(np.shape(pc1_spherical))\n",
    "print(90-np.rad2deg(np.max(pc1_spherical[:,2]))) #-15.59\n",
    "print(90-np.rad2deg(np.min(pc1_spherical[:,2]))) #17.74\n",
    "\n",
    "#look at point elevations\n",
    "fig, ax = p.subplots();\n",
    "print(np.shape(90-np.rad2deg((pc1_spherical[1024:1092,2]))))\n",
    "ax.scatter(np.linspace(0,63,64), 90-np.rad2deg((pc1_spherical[4096:4160,2])))\n",
    "ax.set_xlabel(\"range sensor idx\")\n",
    "ax.set_ylabel(\"elevation angle\")\n",
    "test = np.diff(90-np.rad2deg((pc1_spherical[:64,2])))\n",
    "print(test[0], \"deg between vertical samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OS1 LiDAR Intrinsics\n",
    "#as specified in datasheet\n",
    "# phimin = np.deg2rad(-16.6) #supposed to be this\n",
    "# phimax = np.deg2rad(16.6)\n",
    "#angles required to reproduce observed point clouds\n",
    "# phimin = np.deg2rad(-16) \n",
    "# phimax = np.deg2rad(17.75)\n",
    "#test\n",
    "phimax = np.deg2rad(17.74)\n",
    "phimin = np.deg2rad(-15.59)\n",
    "depth_img  = data.T\n",
    "\n",
    "new_point_cloud_spherical = np.zeros([np.shape(pcs)[0]*np.shape(pcs)[1],3])\n",
    "pc1_spherical = new_point_cloud_spherical\n",
    "\n",
    "count = 0\n",
    "for w in range(np.shape(depth_img)[0]):\n",
    "    for h in range(np.shape(depth_img)[1]):\n",
    "        new_point_cloud_spherical[count,0] = depth_img[w,h] #radius\n",
    "        new_point_cloud_spherical[count,1] = 2*np.pi*(w/np.shape(depth_img)[0]) #theta\n",
    "#         new_point_cloud_spherical[count,1] = (1023/1024) * 2*np.pi*(w/np.shape(depth_img)[0]) #test\n",
    "#         new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/np.shape(depth_img)[1]) #phi\n",
    "        new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/(np.shape(depth_img)[1] - 1)) #BETTER\n",
    "        count+= 1\n",
    "\n",
    "new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy()\n",
    "new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z \n",
    "\n",
    "#shape image to have same angular field of view in width and height\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "# print(vert_fov)\n",
    "# vert_fov/360\n",
    "# print((vert_fov/360)*np.shape(pcs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c617d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "color = 255*np.linspace(0,1,len(new_point_cloud_cart)) \n",
    "cname = np.array([255-color, color, 255-color]).T.tolist()\n",
    "disp.append(Points(new_point_cloud_cart, c=cname,  r = 3.5, alpha =0.5))\n",
    "# disp.append(Points(new_point_cloud_cart[::32], c='red',  r = 3.5, alpha =0.8))\n",
    "# disp.append(Points(new_point_cloud_cart[::4], c='blue',  r = 5., alpha =0.125))\n",
    "\n",
    "disp.append(Points(pc1, c = 'blue', r = 3.5, alpha = 0.5))\n",
    "\n",
    "plt.show(disp, \"Raw Point Cloud\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d93ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST depth-rendering\n",
    "z = np.linspace(0,10)\n",
    "print(z)\n",
    "alpha = 1. - tf.exp(-z)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# print(plt.get_backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11a1ec7",
   "metadata": {},
   "source": [
    "## Load ground truth poses (map frame) and convert to NeRF LH Coordinate System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c793893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "dir_name = \"/media/derm/06EF-127D4/Newer College Dataset/\"\n",
    "experiment_name = \"01_short_experiment-20230331T172433Z-009/01_short_experiment/\"\n",
    "fn_gt = dir_name + experiment_name + \"ground_truth/registered_poses.csv\"\n",
    "# print(fn_gt)\n",
    "\n",
    "#sec,nsec,x,y,z,qx,qy,qz,qw\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "# print(np.shape(gt))\n",
    "# print(gt[20,:])\n",
    "\n",
    "scan_dir = dir_name + experiment_name + \"raw_format/ouster_zip_files/ouster_scan-007/ouster_scan/\"\n",
    "list_of_all_scans = sorted(listdir(scan_dir))\n",
    "\n",
    "#plot ground truth trajectory\n",
    "fig, ax = p.subplots()\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")\n",
    "ax.plot(gt[:,2], gt[:,3], label = \"ground truth\")\n",
    "\n",
    "#superimpose trajectory from <short_experiment_01>\n",
    "# first_timestamp = int(list_of_all_scans[0][6:16])\n",
    "# last_timestamp = int(list_of_all_scans[-1][6:16]) #scrape timestamp from name of velodyne .pcl file\n",
    "# first_idx = np.argwhere(gt[:,0] == first_timestamp)[0][0]\n",
    "# last_idx = np.argwhere(gt[:,0] == last_timestamp)[0][0]\n",
    "first_idx = 7650#7700 #1500 #1450 #700\n",
    "last_idx = 8700 #2100 #1950 #1000\n",
    "\n",
    "ax.plot(gt[first_idx:last_idx,2], gt[first_idx:last_idx,3], 'r', lw = 10, alpha = 0.3, label = 'training region')\n",
    "ax.legend(loc = 'best')\n",
    "ax.set_ylim([-150,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ece5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "#convert gt from xyzquat to homogenous rotation matrix\n",
    "n_images = 50 #20 \n",
    "n_rots = 8 #8 \n",
    "#Ouster OS1-64\n",
    "phimin = np.deg2rad(-16) \n",
    "phimax = np.deg2rad(17.75)\n",
    "#just for debug\n",
    "# phimin = np.deg2rad(-6) \n",
    "# phimax = np.deg2rad(27.75)\n",
    "# phimin = -0.53529248 #rad\n",
    "# phimax = 0.18622663 #rad\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "\n",
    "poses = np.zeros([n_images*n_rots,4,4])\n",
    "images = np.ones([n_images*n_rots, 64, 64, 2]) #depth image and raydrop\n",
    "\n",
    "#focal length (in pixels) = Image Size / (2 tan(FOV/2)) #needs to be array!\n",
    "# focal = np.array(np.shape(images)[1]/(2*np.tan((phimax-phimin)/2))) #not used here\n",
    "H, W = images.shape[1:3]\n",
    "print(H, W)\n",
    "\n",
    "for i in range(n_images):\n",
    "    #load point cloud\n",
    "    idx = i*10 + 600 #1450 #700    \n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "    pc1 = np.flip(pc1, axis = 0)# uncomment to flip and maintain CCW convention used in VICET\n",
    "\n",
    "    #convert to depth image\n",
    "    pc1_spherical = LC.c2s(LC,pc1).numpy() #[r, theta, phi]\n",
    "    pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "    pcs = np.flip(pcs, axis = 1)\n",
    "    raw_data = pcs[:,:,:]\n",
    "    raw_data = np.transpose(pcs, [1,0,2])\n",
    "\n",
    "    #destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "    data = np.zeros([64, 1024])\n",
    "    for k in range(np.shape(data)[0]//4):\n",
    "        data[4*k,1:-8] = raw_data[4*k,9:,0]\n",
    "        data[4*k+1,1:-2] = raw_data[4*k+1,3:,0]\n",
    "        data[4*k+2,4:] = raw_data[4*k+2,:-4,0]\n",
    "        data[4*k+3,10:] = raw_data[4*k+3,:-10,0]\n",
    "    data = np.flip(data, axis =1)\n",
    "\n",
    "#     print(np.shape(data))\n",
    "#     print(np.shape(pc1_spherical))\n",
    "\n",
    "    for j in range(n_rots):\n",
    "        \n",
    "        #get cropped depth image ~~~~~~~~~~~~~~~~~~~~\n",
    "#         pcs = np.flip(data, axis = 1) #flip vertical\n",
    "#         pcs = np.flip(pcs, axis = 0) #flip horizontal to look at first clockwise patch of scan sweep \n",
    "#         pcs = pcs.T\n",
    "        pcs = data.T\n",
    "        \n",
    "        #resize image to 64x64\n",
    "        image_width = int((vert_fov/360)*np.shape(pcs)[0])        \n",
    "#         pcs = pcs[j*image_width:(j+1)*image_width,:].T #SQUARE\n",
    "        pcs = pcs[(j+1)*image_width:(j+2)*image_width,:].T #SQUARE-- skip beginning of frame (blocked by human)\n",
    "#         pcs = pcs[(j*image_width//32):((j+1)*image_width//32),:,0].T #32nds\n",
    "        pcs = cv2.resize(pcs, (64, 64), cv2.INTER_NEAREST) #keep square\n",
    "        #TEST\n",
    "#         pcs = np.flip(pcs, axis =1)\n",
    "    \n",
    "        #preserve aspect ratio and focal length but just take middle\n",
    "#         pcs = pcs[:,31:33] #uncomment for 32nds\n",
    "        images[j+(i*n_rots),:,:,0] = pcs #save depth information to first channel\n",
    "        a = np.argwhere(pcs == 0)\n",
    "        #TODO: why do some distant windows register as being close (but not non-returns)??\n",
    "        images[j+(i*n_rots),a[:,0],a[:,1],1] = 0 #save raydrop mask to 2nd channel\n",
    "        \n",
    "        #get transformation matrix ~~~~~~~~~~~~~~~~~~\n",
    "        rotm = np.eye(4)\n",
    "        rotm[1,3] = -gt[idx,2] #x\n",
    "        rotm[2,3] = gt[idx,3] #y\n",
    "        rotm[0,3] = -gt[idx,4] #z\n",
    "        rotm[:3,:3] = R.from_quat(gt[idx,5:]).as_matrix() \n",
    "\n",
    "# #         #orient yellow (-z) pointing forward\n",
    "        fix1 = R.from_euler('xyz', [0,-np.pi/2,0]).as_matrix()\n",
    "        fix2 = R.from_euler('xyz', [np.pi/2,0,0]).as_matrix()\n",
    "        rotm[:3,:3] = rotm[:3,:3] @ fix1 @ fix2\n",
    "\n",
    "        #unreliable?\n",
    "        temp = R.from_matrix(rotm[:3,:3]).as_euler('zxy')\n",
    "        rotm[:3,:3] = R.from_euler('xyz', [temp[0], temp[1], -temp[2]]).as_matrix()\n",
    "                \n",
    "        #account for image crop in rotation\n",
    "        #swapping sign convention from what was used in synthetic data(?) ...+j*(phimax-phimin)\n",
    "#         crop_angle = 0 #DEBUG ONLY\n",
    "#         crop_angle = -(phimax-phimin)/2 + j*(phimax-phimin) #square\n",
    "        crop_angle = -(phimax-phimin)/2 + (j+1)*(phimax-phimin) #square-- but skip beginning of frame\n",
    "        #         crop_angle = -(phimax-phimin)/64 - j*(phimax-phimin)/32 #2-pixels wide\n",
    "        \n",
    "        #account for the fact that sensor points back and to the left\n",
    "        crop_angle -= np.pi/4 \n",
    "        rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix() #looks better\n",
    "        rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "        #also need to account for the fact that the LIDAR beam isn't actually centered at horizon\n",
    "        sensor_elevation_zero_rotm = R.from_euler('xyz', [(phimin+phimax)/2,0,0]).as_matrix() #was this\n",
    "#         sensor_elevation_zero_rotm = R.from_euler('xyz', [0,(phimin+phimax)/2,0]).as_matrix() #TODO: not sure if rot about y or z\n",
    "        rotm[:3,:3] = rotm[:3,:3] @ sensor_elevation_zero_rotm\n",
    "\n",
    "        #flip x and z axis\n",
    "#         rotm[0,-1], rotm[2,-1] = rotm[2,-1], rotm[0,-1] \n",
    "#         rotm[0,-1], rotm[1,-1] = rotm[1,-1], rotm[0,-1]  #test\n",
    "\n",
    "# #         # flip sign of axis\n",
    "#         rotm[0:3,2] *= -1 #was this\n",
    "#         rotm[0:3,1] *= -1 #was this\n",
    "#         rotm[0:3,0] *= -1 #test\n",
    "#         rotm = rotm[[1,0,2,3],:] #was this\n",
    "#         rotm = rotm[[2,0,1,3],:]\n",
    "#         rotm[2,:] *= -1 # flip whole world upside down\n",
    "#         #translate all frames above xy plane\n",
    "        rotm[2,-1] += 45 \n",
    "        \n",
    "        #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "        rotm[:3,-1] *= 0.05\n",
    "        images[j+(i*n_rots),:,:,0] *= 0.05\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        poses[j+(i*n_rots)] = rotm\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "        \n",
    "# test on one only\n",
    "testimg, testpose = images[(n_images*n_rots)-1], poses[(n_images*n_rots)-1]\n",
    "images = images[:((n_images*n_rots)-1),...,:3]\n",
    "poses = poses[:((n_images*n_rots)-1)]\n",
    "\n",
    "# #90/10 split\n",
    "# cutoff = (n_images*9)//10\n",
    "# print(cutoff)\n",
    "# testimg, testpose = images[cutoff:], poses[cutoff:]\n",
    "# images = images[:cutoff,...,:3]\n",
    "# poses = poses[:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab518d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "fig, ax = p.subplots(2,5)\n",
    "ax[0,0].set_title(\"depth image patches for training\")\n",
    "\n",
    "# ax[0,0].imshow(images[0,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,1].imshow(images[1,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,2].imshow(images[2,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,3].imshow(images[3,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,4].imshow(images[4,:,:,0])#, vmin=0, vmax=64)\n",
    "\n",
    "ax[0,0].imshow(images[-4,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,1].imshow(images[-3,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,2].imshow(images[-2,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,3].imshow(images[-1,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,4].imshow(testimg[:,:,0])#, vmin=0, vmax=64)\n",
    "\n",
    "ax[1,0].set_title(\"ray drop masks\")\n",
    "ax[1,0].imshow(images[-4,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,1].imshow(images[-3,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,2].imshow(images[-2,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,3].imshow(images[-1,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,4].imshow(testimg[:,:,1],cmap=\"gray\", vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06102dc2",
   "metadata": {},
   "source": [
    "# Debug: draw frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615ecc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Raw frames, in Newer College RHCS convention\n",
    "phimin = np.deg2rad(-16) \n",
    "phimax = np.deg2rad(17.75)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "# new_point_cloud_spherical = np.zeros([np.shape(images)[1]*np.shape(images)[2],3])\n",
    "\n",
    "for i in range(30):\n",
    "    idx = i*20 + 600    \n",
    "    \n",
    "    rotm = np.eye(4)\n",
    "    rotm[0,3] = gt[idx,2] #x\n",
    "    rotm[1,3] = gt[idx,3] #y\n",
    "    rotm[2,3] = gt[idx,4] #z\n",
    "    rotm[:3,:3] = R.from_quat(gt[idx,5:]).as_matrix() \n",
    "    \n",
    "    #draw frames for each sub-scan \n",
    "    alph = 1-(i/30)\n",
    "    #forward view direction (-z in NeRF c2w convention)\n",
    "    headings = rotm[:3,:3] @ np.array([0,0,-1])\n",
    "    disp.append(Arrows(rotm[:3,-1][None,:], (rotm[:3,-1] + headings)[None,:], c = \"yellow\", alpha = alph))\n",
    "    # x\n",
    "    headings = rotm[:3,:3] @ np.array([1,0,0])\n",
    "    disp.append(Arrows(rotm[:3,-1][None,:], (rotm[:3,-1] + headings)[None,:], c = \"red\", alpha = alph))\n",
    "    #y\n",
    "    headings = rotm[:3,:3] @ np.array([0,1,0])\n",
    "    disp.append(Arrows(rotm[:3,-1][None,:], (rotm[:3,-1] + headings)[None,:], c = \"green\", alpha = alph))\n",
    "    #z\n",
    "    headings = rotm[:3,:3] @ np.array([0,0,1])\n",
    "    disp.append(Arrows(rotm[:3,-1][None,:], (rotm[:3,-1] + headings)[None,:], c = \"blue\", alpha = alph))\n",
    "\n",
    "disp.append(Points(np.array([[0,0,0]]), r = 10, c = 'black'))\n",
    "plt.show(disp, \"Actual Ground Truth Path (Newer College Frame)\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG-- find appropriate cutoff threshold for structural regularization loss\n",
    "thresh_horiz = 0.025\n",
    "thresh_vert = 0.025\n",
    "# thresh_horiz = 0.001\n",
    "# thresh_vert = 0.01\n",
    "aspect = 1\n",
    "idx = 112\n",
    "\n",
    "\n",
    "testy = images[idx,:,:]\n",
    "for i in range(6):\n",
    "    testy = np.append(testy, images[idx + i,:,:], axis = 1)\n",
    "\n",
    "print(np.shape(testy))\n",
    "\n",
    "fig, ax = p.subplots(3)\n",
    "# ax[0].imshow(data, aspect = 5)\n",
    "ax[0].imshow(testy[:,:,0], aspect = aspect)\n",
    "\n",
    "mask = np.ones(np.shape(testy))\n",
    "vertical_grad_target = np.gradient(testy)[0][:,:,0]\n",
    "# vertical_grad_target = np.gradient(vertical_grad_target)[0] #test for double gradient \n",
    "vertical_past_thresh = np.argwhere(tf.abs(vertical_grad_target) > thresh_vert)\n",
    "mask[vertical_past_thresh[:,0], vertical_past_thresh[:,1]] = 0\n",
    "\n",
    "horizontal_grad_target = np.gradient(testy)[1][:,:,0]\n",
    "# horizontal_grad_target = np.gradient(horizontal_grad_target)[1] #test for double gradient \n",
    "horizontal_past_thresh = np.argwhere(tf.abs(horizontal_grad_target) > thresh_horiz)\n",
    "mask[horizontal_past_thresh[:,0], horizontal_past_thresh[:,1]] = 0\n",
    "\n",
    "\n",
    "\n",
    "# print(np.shape(vertical_grad_target))\n",
    "# print(np.shape(mask))\n",
    "print(np.shape(np.gradient(images[idx,:,:])))\n",
    "print(np.shape(images[idx,:,:]))\n",
    "print(np.shape(depth))\n",
    "\n",
    "ax[1].imshow(mask[:,:,0], aspect=aspect)\n",
    "ax[2].imshow(testy[:,:,1], aspect = aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae56148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##DEBUG get_rays()\n",
    "# H = 64 \n",
    "# W = 1024\n",
    "H = 8 \n",
    "W = 8\n",
    "\n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 8 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "print(\"vertical bins\", np.rad2deg(vertical_bins), \"\\n\")\n",
    "\n",
    "i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "# print(i)\n",
    "# print(j)\n",
    "phimin = np.deg2rad(-15.593)\n",
    "phimax = np.deg2rad(17.743)\n",
    "print(\"phimin\", np.rad2deg(phimin))\n",
    "print(\"phimax\", np.rad2deg(phimax))\n",
    "\n",
    "# test = (phimax + phimin)/2 + ((-j+((H-1)/2))/(H-1))*(phimax-phimin) -np.pi/2\n",
    "\n",
    "for img_i in range(9):\n",
    "    #old-- was using for spherical projection(?)\n",
    "    phimin_patch = vertical_bins[img_i%n_vert_patches] \n",
    "    phimax_patch = vertical_bins[img_i%n_vert_patches + 1]\n",
    "#     phimin_patch = vertical_bins[img_i%(n_vert_patches-1)] \n",
    "#     phimax_patch = vertical_bins[img_i%(n_vert_patches-1) + 1]\n",
    "#     # send bins from top to bottom --- using for cylindrical projections\n",
    "#     phimin_patch = vertical_bins[len(vertical_bins) -1 - (img_i%n_vert_patches+1)] \n",
    "#     phimax_patch = vertical_bins[len(vertical_bins) -1 - (img_i%n_vert_patches)]\n",
    "\n",
    "    print(\"\\n phimin_patch\", np.rad2deg(phimin_patch), \" phimax_patch\", np.rad2deg(phimax_patch))\n",
    "    \n",
    "    #thought this was better yesterday, looks like I was still be double counting at borders though\n",
    "#     test = (phimax_patch + phimin_patch)/2 + ((-j+((H-1)/2))/(H-1))*(phimax_patch-phimin_patch) -np.pi/2 \n",
    "    \n",
    "#     test = (phimax_patch + phimin_patch)/2 + ((-j+((H)/2))/(H))*(phimax_patch-phimin_patch) -np.pi/2\n",
    "    test = (phimax_patch + phimin_patch)/2 - ((-j+((H)/2))/(H))*(phimax_patch-phimin_patch) -np.pi/2\n",
    "\n",
    "    print(np.rad2deg(test[:,0]) + 90)\n",
    "#     print(np.rad2deg(test) + 90)\n",
    "\n",
    "# print(90+np.rad2deg(test[:,0]))\n",
    "\n",
    "# print(np.rad2deg(phimax_patch), np.rad2deg(phimin_patch))\n",
    "\n",
    "# print((17.75 + 15.47)/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1320b6-5f38-4c6c-b39c-0d2f419214bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "\n",
    "phivals = np.linspace(phimin, phimax, 64)\n",
    "# print(\"all phivals: \", np.rad2deg(phivals), \"\\n\")\n",
    "\n",
    "for img_i in range(9):\n",
    "    print(img_i)\n",
    "#     print(\"old\", (img_i%(n_vert_patches))*(64//n_vert_patches), ((img_i+1)%(n_vert_patches))*(64//n_vert_patches)-1)    \n",
    "\n",
    "#     print(\"idx test first\", 64-(img_i%(n_vert_patches))*(64//n_vert_patches))\n",
    "#     print(\"idx test second\", 64-((img_i+1)%(n_vert_patches))*(64//n_vert_patches)-1)    \n",
    "    \n",
    "    #does correct thing but patches are flipped during training(?)\n",
    "    phimin_patch = phivals[(img_i%(n_vert_patches))*(64//n_vert_patches)]\n",
    "    phimax_patch = phivals[((img_i+1)%(n_vert_patches))*(64//n_vert_patches)-1]\n",
    "\n",
    "#     #send patches top->bottom\n",
    "#     idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "#     idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "# #     print(\"test \", idx_first, idx_second)\n",
    "#     phimin_patch = phivals[idx_first]\n",
    "#     phimax_patch = phivals[idx_second]    \n",
    "    \n",
    "    print(\" phimin_patch \", np.rad2deg(phimin_patch), \"phimax_patch \", np.rad2deg(phimax_patch))\n",
    "    \n",
    "    test = (phimax_patch + phimin_patch)/2 - ((-j+((H-1)/2))/(H-1))*(phimax_patch-phimin_patch) -np.pi/2 #correct\n",
    "#     test = (phimax_patch + phimin_patch)/2 + ((-j+((H-1)/2))/(H-1))*(phimax_patch-phimin_patch) -np.pi/2 #flips order\n",
    "    print(np.rad2deg(test[:,0]) + 90, \"\\n\")\n",
    "    \n",
    "    #brokent up by channel\n",
    "#     print(np.rad2deg(phivals[int(img_i*(64//n_vert_patches)):int((img_i+1)*(64//n_vert_patches))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c1d41-77fd-4f16-a1af-8f54c246a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "W = 8\n",
    "\n",
    "print(i[0])\n",
    "\n",
    "old = (i - (W//2))  /(W) * (2*np.pi/(1024//W))\n",
    "print(old[0])\n",
    "print((old[0,0] - old[0,-1]).numpy())\n",
    "\n",
    "# new = (i - ((W-1)/2))  /(W-1) * (2*np.pi/(1024//(W-1)))\n",
    "new = (i - ((W-1)/2))  /(W) * (2*np.pi/(1024//(W)))\n",
    "print(\"\\n\", new[0])\n",
    "print((new[0,0] - new[0,-1]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf605ec",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9dd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lidar_nerf_utils import *\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# model = init_model()\n",
    "# optimizer = tf.keras.optimizers.Adam(5e-4) #default tiny-NeRF\n",
    "# optimizer = tf.keras.optimizers.Adam(5e-5) #anneal to this (LiDAR NeRF)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "# optimizer = tf.keras.optimizers.Adam(5e-6) #anneal to this (Mip-NeRF)\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-6) #TEST\n",
    "\n",
    "N_samples = 128 #128\n",
    "near=0.\n",
    "far=1.\n",
    "N_iters = 5_000_000\n",
    "psnrs = []\n",
    "iternums = []\n",
    "i_plot = 64\n",
    "accumulate_gradients_steps = 4 #32\n",
    "runfine = True\n",
    "# runfine = False\n",
    "\n",
    "#IMPORTANT-- this needs to match values used when setting up training data \n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "\n",
    "phimin = np.deg2rad(-15.594) #observed in raw data \n",
    "phimax = np.deg2rad(17.743) #observed in raw data\n",
    "# phimin = np.deg2rad(-17.743) #flipped-- used for best synthetic-- WAS using this for best real data\n",
    "# phimax = np.deg2rad(15.594) #flipped\n",
    "#need to do this when actual data was [-25,5] according to print(90-np.rad2deg(np.max(pc1_spherical[:,2])))\n",
    "# phimin = np.deg2rad(-5) \n",
    "# phimax = np.deg2rad(25) \n",
    "\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)  \n",
    "phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "\n",
    "gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
    "accumulated_loss = 0.0\n",
    "\n",
    "for i in range(N_iters+1):\n",
    "#     print(i)\n",
    "    img_i = np.random.randint(images.shape[0])\n",
    "    target = images[img_i,:,:,:1]\n",
    "    target_drop_mask = images[img_i,:,:,1:]\n",
    "    pose = poses[img_i]\n",
    "\n",
    "#     #bottom to top\n",
    "#     phimin_patch = phivals[(img_i%(n_vert_patches))*(64//n_vert_patches)]\n",
    "#     phimax_patch = phivals[((img_i+1)%(n_vert_patches))*(64//n_vert_patches)-1]\n",
    "    #top to bottom -- used this to make v10 (best so far)\n",
    "    idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "    idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "#     phimin_patch = phivals[idx_first]     #was this (wrong??)\n",
    "#     phimax_patch = phivals[idx_second]    #was this (wrong??)\n",
    "    phimin_patch = phivals[idx_second]     #test\n",
    "    phimax_patch = phivals[idx_first]    #test\n",
    "\n",
    "    #get ray origins and ray directions\n",
    "    rays_o, rays_d = get_rays(H, W, pose, phimin_patch, phimax_patch)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # run coarse network~~~~~~~~~~~~~~~~~\n",
    "        z_vals = tf.linspace(near, far, N_samples)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "        z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "        z_vals = z_vals[:,:,:,None]#manually expand dimensions before passing in to coarse network (all pixels will share the same z_vals)\n",
    "#         depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "#         depth, acc, ray_drop, weights, d1, d2 = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        # depth, ray_drop, CDF = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "#         print(\"\\n depth:\", np.shape(depth))\n",
    "#         print(\"acc:\", np.shape(acc))\n",
    "#         print(\"ray_drop:\", np.shape(ray_drop))\n",
    "#         print(\"weights:\", np.shape(weights))\n",
    "\n",
    "        depth = depth[:,:,None]\n",
    "#         print(\"old\", np.shape(depth))\n",
    "        ray_drop = ray_drop[:,:,None]\n",
    "        # loss_coarse = calculate_loss(depth, ray_drop, target, target_drop_mask) #ignore similarity of d1&d2 and CDF\n",
    "        # print(np.shape(z_vals[...,:]), np.shape(target))\n",
    "        gtCDF = z_vals[:,:,:,0] > target[:,:,:]\n",
    "        gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "        loss_coarse = calculate_loss(depth, ray_drop, target, target_drop_mask, CDF = CDF, gtCDF = gtCDF) #punish similar depth returns\n",
    "        loss = loss_coarse\n",
    "\n",
    "        # #DEBUG---- calculate loss directly from CDF ~~~~~~~~\n",
    "        # gtCDF = z_vals[:,:,:,0] > target[:,:,:]\n",
    "        # gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "        # # print(\"\\n CDF: \", np.shape(CDF))\n",
    "        # # print(\"gtCDF: \", np.shape(gtCDF))\n",
    "        # # print(\"z_vals[:,:,:,0]\", np.shape(z_vals[:,:,:,0]))\n",
    "        # # print(\"target\", np.shape(target))\n",
    "        # loss = tf.abs(CDF - gtCDF)\n",
    "        # loss_coarse = tf.reduce_sum(loss)\n",
    "        # loss = loss_coarse\n",
    "        # # loss = loss*0.001\n",
    "        # # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        if runfine:\n",
    "            # run fine network ~~~~~~~~~~~~~~~~~~\n",
    "            #pad weights with zeros\n",
    "#             fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), weights, axis = -1)\n",
    "#             rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), axis = -1)\n",
    "#             #use additional axis to calculate all at once\n",
    "#             fwd_test = np.max(sliding_window_view(fwd, window_shape = 2, axis = 2), axis = -1)\n",
    "#             rev_test = np.max(sliding_window_view(rev, window_shape = 2, axis = 2), axis = -1)\n",
    "            #TEST-- slightly wider blur-pool\n",
    "            fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), weights, axis = -1)\n",
    "            rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), axis = -1)\n",
    "            fwd_test = np.max(sliding_window_view(fwd, window_shape = 4, axis = 2), axis = -1)\n",
    "            rev_test = np.max(sliding_window_view(rev, window_shape = 4, axis = 2), axis = -1)\n",
    "\n",
    "    \n",
    "            #blur-pool as vectorized operation\n",
    "            test2 = (fwd_test + rev_test) /2 #blur\n",
    "    #         test2 += 1/N_samples #shift up slightly\n",
    "            test2 += 1/(3*N_samples) #shift up slightly\n",
    "            test2 = test2 / np.sum(test2, axis = -1)[:,:,None] #renormalize\n",
    "            \n",
    "            cum_hist_vals = np.cumsum(test2, axis = -1)\n",
    "            randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "            cum_hist_vals_flat = cum_hist_vals.flatten()\n",
    "    \n",
    "            #modify cum_hist_vals so it is monotonically increasing (needed for interp func to work)\n",
    "            step_corr = np.linspace(0,W*H-1,W*H)\n",
    "            step_corr = np.tile(step_corr,(N_samples,1)).T\n",
    "            step_corr = np.reshape(step_corr, [1,-1])[0,:]\n",
    "            cum_hist_vals_flat+= step_corr\n",
    "    \n",
    "            linear_spaced = np.linspace(near, H*W, N_samples*H*W)\n",
    "            ans = np.interp(x=linear_spaced, xp=cum_hist_vals_flat, fp=linear_spaced)\n",
    "            ans -= step_corr\n",
    "            ans *= far #scale back to max value\n",
    "            ans = np.abs(ans)\n",
    "            z_vals = np.reshape(ans, [H,W,N_samples,1])\n",
    "            \n",
    "            gtCDF = z_vals[:,:,:,0] > target[:,:,:]\n",
    "            gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "            \n",
    "            #run actual 2nd pass through same network\n",
    "#             depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "#             depth, acc, ray_drop, weights, d1, d2 = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "            # depth, ray_drop = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "            depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "            depth = depth[:,:,None]\n",
    "            depth = tf.cast(depth, tf.float32) #why do I have to cast this here???\n",
    "            ray_drop = ray_drop[:,:,None]\n",
    "            \n",
    "            # loss_fine = calculate_loss(depth, ray_drop, target, target_drop_mask)\n",
    "            loss_fine = calculate_loss(depth, ray_drop, target, target_drop_mask, CDF = CDF, gtCDF = gtCDF)\n",
    "            loss = 0.1*loss_coarse + 0.9*loss_fine \n",
    "#             loss = loss_fine #test\n",
    "            # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        \n",
    "        #NEW--prevent NaN gradients from crashing training routine(?) -- needed for monotonically increasing outputs?\n",
    "        current_gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        current_gradients = [grad if grad is not None else tf.zeros_like(var) for grad, var in zip(current_gradients, model.trainable_variables)]\n",
    "        gradients = [grad_accum + current_grad for grad_accum, current_grad in zip(gradients, current_gradients)]        \n",
    "\n",
    "        # #OLD-- not working with CDF stuff\n",
    "        # current_gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        # gradients = [grad_accum + current_grad for grad_accum, current_grad in zip(gradients, current_gradients)]    \n",
    "        \n",
    "        accumulated_loss += loss\n",
    "    \n",
    "    if i%accumulate_gradients_steps==0:    \n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        accumulated_loss = 0.0\n",
    "        gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
    "        accumulated_loss = 0\n",
    "    \n",
    "    if i%i_plot==0:\n",
    "        # Render the holdout view for logging\n",
    "        rays_o, rays_d = get_rays(H, W, testpose, vertical_bins[-2], vertical_bins[-1]) #constant validation image\n",
    "        z_vals = tf.linspace(near, far, N_samples) \n",
    "        z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "        z_vals = z_vals[:,:,:,None]\n",
    "#         depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "#         depth, acc, ray_drop, weights, d1, d2 = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        # depth, ray_drop, CDF = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        depth = depth[:,:,None]\n",
    "        ray_drop = ray_drop[:,:,None]\n",
    "        target = testimg[:,:,:1]\n",
    "        target_drop_mask = testimg[:,:,1:]\n",
    "        # loss = calculate_loss(depth, ray_drop, target, target_drop_mask)\n",
    "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "        psnrs.append(psnr.numpy())\n",
    "        iternums.append(i)\n",
    "        p.figure(figsize=(10,4))\n",
    "        p.subplot(131)\n",
    "        p.imshow(depth,cmap = \"gray\")#, norm='log')\n",
    "        p.title(f'Estimated Depth at Iteration: {i}')\n",
    "#         p.imshow(testimg[:,:,1],cmap = \"gray\") #, norm='log')\n",
    "#         p.title(f'Actual Mask at Iteration: {i}')\n",
    "        p.subplot(133)\n",
    "        p.plot(iternums, psnrs)\n",
    "        p.title('PSNR')\n",
    "        #look at depth map\n",
    "        p.subplot(132)\n",
    "        p.imshow(ray_drop, cmap=\"gray\")#, norm = 'log')\n",
    "        p.title(\"estimated ray drop mask\")\n",
    "        p.show()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8450d9c-4dca-4c12-a415-b06c311fe1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.shape(z_vals))\n",
    "\n",
    "# #BUG IS HERE!!!\n",
    "# dists = tf.concat([z_vals[..., 1:] - z_vals[..., :-1], tf.broadcast_to([100.], z_vals[..., :1].shape)], axis=-1)\n",
    "# dists = dists[..., 0]\n",
    "# print(\"dists (old): \", np.shape(dists))\n",
    "\n",
    "# #FIXED BELOW\n",
    "# temp = z_vals[:,:,1:,0] - z_vals[:,:,:-1,0]\n",
    "# print(\"temp:\", np.shape(temp))\n",
    "# padding = tf.broadcast_to([100.], temp[:,:,0].shape)[:,:,None]\n",
    "# print(\"padding:\", np.shape(padding))\n",
    "# dists = tf.concat([temp, padding], axis=-1)\n",
    "# # dists = dists[..., None]\n",
    "\n",
    "# print(\"dists: (new)\", np.shape(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944cef3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40a038-2fb1-46cd-a0b4-f740a63ea3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros([np.shape(images)[1],0])\n",
    "print(np.shape(temp))\n",
    "for img_i in range(40,50):\n",
    "#     print(img_i)\n",
    "    # fig, ax = p.subplots()\n",
    "    # ax.imshow(images[img_i,:,:,0])\n",
    "    temp = np.append(temp,images[img_i,:,:,0], axis = 1)\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "ax.imshow(temp)\n",
    "\n",
    "# # # #get some window in our test\n",
    "testimg = images[4]\n",
    "testpose = poses[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493f2bd-d5e6-435b-a112-c0c4d2f4e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.summary())\n",
    "# print(CDF[0,0,:20])\n",
    "# loss = tf.abs(CDF - gtCDF)\n",
    "# print(loss)\n",
    "# loss = tf.reduce_sum(loss)\n",
    "# print(loss)\n",
    "# testpose = poses[499]\n",
    "%matplotlib inline\n",
    "\n",
    "rays_o, rays_d = get_rays(H, W, testpose, vertical_bins[-2], vertical_bins[-1]) #constant validation image\n",
    "z_vals = tf.linspace(near, far, N_samples) \n",
    "z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals = z_vals[:,:,:,None]\n",
    "depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "\n",
    "#~~~~~~~~~~~\n",
    "#run fine pass through network\n",
    "#     fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), weights, axis = -1)\n",
    "#     rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), axis = -1)\n",
    "#     fwd_test = np.max(sliding_window_view(fwd, window_shape = 2, axis = 2), axis = -1)\n",
    "#     rev_test = np.max(sliding_window_view(rev, window_shape = 2, axis = 2), axis = -1)\n",
    "fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), weights, axis = -1)\n",
    "rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), axis = -1)\n",
    "fwd_test = np.max(sliding_window_view(fwd, window_shape = 4, axis = 2), axis = -1)\n",
    "rev_test = np.max(sliding_window_view(rev, window_shape = 4, axis = 2), axis = -1)\n",
    "test2 = (fwd_test + rev_test) /2 #blur\n",
    "test2 += 1/(3*N_samples) #shift up slightly\n",
    "test2 = test2 / np.sum(test2, axis = -1)[:,:,None] #renormalize\n",
    "cum_hist_vals = np.cumsum(test2, axis = -1)\n",
    "randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "cum_hist_vals_flat = cum_hist_vals.flatten()\n",
    "step_corr = np.linspace(0,W*H-1,W*H)\n",
    "step_corr = np.tile(step_corr,(N_samples,1)).T\n",
    "step_corr = np.reshape(step_corr, [1,-1])[0,:]\n",
    "cum_hist_vals_flat+= step_corr\n",
    "linear_spaced = np.linspace(near, H*W, N_samples*H*W)\n",
    "ans = np.interp(x=linear_spaced, xp=cum_hist_vals_flat, fp=linear_spaced)\n",
    "ans -= step_corr\n",
    "ans *= far\n",
    "ans = np.abs(ans)\n",
    "z_vals = np.reshape(ans, [H,W,N_samples,1])\n",
    "# depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "#~~~~~~~~~~~\n",
    "\n",
    "fig, ax = p.subplots(1,2)\n",
    "output = np.flip(depth, axis = 0)\n",
    "output = output * np.round(np.flip(ray_drop, axis = 0))\n",
    "ax[0].imshow(output)\n",
    "ax[1].imshow(testimg[:,:,0])\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "for i in range(np.shape(CDF)[0]):\n",
    "    for j in range(np.shape(CDF)[1]//8):\n",
    "#         ax.plot(z_vals[i,j,:-1,0]*50,np.diff(CDF[i,j,:]), alpha = 0.8)\n",
    "#         ax.plot(z_vals[i,j,:63,0]*50,np.diff(CDF[i,j,:64]), alpha = 0.8)\n",
    "#         ax.plot(z_vals[i,j,:30,0]*50,CDF[i,j,:30], alpha = 0.8)\n",
    "        ax.plot(z_vals[i,j,:,0]*50,CDF[i,j,:], alpha = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e129f5b-afcb-492d-ac82-44400760258e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compare CDF output by network to CDF of target depth image\n",
    "fig, ax = p.subplots()\n",
    "\n",
    "#Convert depth output of target image (single value) to CDF\n",
    "# according to z_vals used in training\n",
    "print(np.shape(target), target[0,0,:])\n",
    "print(np.shape(z_vals)) #, z_vals[0,0,:,0])\n",
    "# print(gtCDF)\n",
    "\n",
    "#single\n",
    "gtCDF = z_vals[0,0,:,0] > target[0,0,:]\n",
    "gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "ax.plot(z_vals[0,0,:,0], gtCDF, color = 'red', label = \"ground truth\")\n",
    "ax.plot(z_vals[0,0,:,0], CDF[0,0,:], color = 'blue', label = \"network output\")\n",
    "# #all\n",
    "# test = z_vals[:,:,:,0] > target[:,:,:]\n",
    "# test = tf.cast(test, tf.float32)\n",
    "# for i in range(np.shape(test)[0]):\n",
    "#     for j in range(np.shape(test)[1]):\n",
    "#         ax.plot(z_vals[i,j,:,0],test[i,j,:], color = 'red', alpha = 0.1)\n",
    "#         ax.plot(z_vals[i,j,:,0],CDF[i,j,:], color = 'blue' , alpha = 0.1) \n",
    "\n",
    "ax.set_xlabel(\"distance along ray\")\n",
    "ax.set_ylabel(\"CDF\")\n",
    "ax.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547fed6b",
   "metadata": {},
   "source": [
    "# Infer point cloud at novel frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ef118",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_view = 128 #128 #number of (rotational?) patches to draw\n",
    "N_samples = 128 #128 #2048 #does not have to match what was used in training\n",
    "near=0.\n",
    "far=1 #2.\n",
    "n_rots = 128 #128 #number |of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #number of vertical patches between phimin and phimax\n",
    "\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "# phimin = np.deg2rad(-15.593) #observed in raw data\n",
    "# phimax = np.deg2rad(17.743)\n",
    "phimin = np.deg2rad(-17.743) #TEST\n",
    "phimax = np.deg2rad(15.593) #TEST\n",
    "# phimin = np.deg2rad(-16) #TEST\n",
    "# phimax = np.deg2rad(16) #TEST\n",
    "# phimin = np.deg2rad(-5) #test -- trying flipped sign first\n",
    "# phimax = np.deg2rad(25)  #test\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "savepc = np.zeros([0,3]) #to save poitn cloud to external file\n",
    "\n",
    "for j in range(num_view):\n",
    "# for j in np.linspace(0,7,15):\n",
    "    #get sensor transformation matrix\n",
    "    rotm = np.eye(4)\n",
    "\n",
    "    # account for image crop in rotation -------------------\n",
    "    crop_angle =  -(np.pi/n_rots) + j*(2*np.pi/n_rots) #test\n",
    "    rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix()\n",
    "    rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "#     #need to account for the fact that the LIDAR beam isn't actually centered at horizon\n",
    "#     sensor_elevation_zero_rotm = R.from_euler('xyz', [(phimin+phimax)/2,0,0]).as_matrix()\n",
    "#     rotm[:3,:3] = rotm[:3,:3] @ sensor_elevation_zero_rotm\n",
    "    # ------------------------------------------------------\n",
    "\n",
    "    # flip x and z axis\n",
    "    rotm[0,-1], rotm[2,-1] = rotm[2,-1], rotm[0,-1] \n",
    "\n",
    "    rotm[0:3,2] *= -1 # flip sign of y and z axis\n",
    "    rotm[0:3,1] *= -1\n",
    "    rotm = rotm[[1,0,2,3],:]\n",
    "    rotm[2,:] *= -1 # flip whole world upside down\n",
    "     #courtyard 2\n",
    "#     rotm[2,-1] = 0.25 #0.25 #x in world frame output\n",
    "#     rotm[0,-1] = -0.01 #- (i/3) #z in world frame output\n",
    "#     rotm[1,-1] = -.125 #+ (i/6) #y in world frame\n",
    "#     # #alt courtyard 1\n",
    "    rotm[2,-1] = 0.325  #x in world frame output\n",
    "    rotm[0,-1] = 0.005 #z in world frame output\n",
    "    rotm[1,-1] = 0.325  #y in world frame\n",
    "#     rotm[2,-1] = 0.45  #x in world frame output\n",
    "#     rotm[0,-1] = 0.01 #z in world frame output\n",
    "#     rotm[1,-1] = 0.40  #y in world frame\n",
    "\n",
    "    rotm = rotm.astype(np.float32)\n",
    "    \n",
    "    vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "    phimin_patch = vertical_bins[img_i%n_vert_patches] \n",
    "    phimax_patch = vertical_bins[img_i%n_vert_patches + 1]\n",
    "#     print(phimin_patch, phimax_patch)\n",
    "    \n",
    "    #call NeRF using specified novel rotm\n",
    "    rays_o, rays_d = get_rays(H, W, rotm, phimin_patch, phimax_patch)\n",
    "#     depth, acc, ray_drop = render_rays(model, rays_o, rays_d, near=0., far=2., N_samples=N_samples)\n",
    "    z_vals = tf.linspace(near, far, N_samples) \n",
    "    z_vals += 0.001*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    z_vals = z_vals[:,:,:,None]\n",
    "#     depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "#     depth, acc, ray_drop, weights, d1, d2 = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "    depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "\n",
    "    #~~~~~~~~~~~\n",
    "    #run fine pass through network\n",
    "#     fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), weights, axis = -1)\n",
    "#     rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), axis = -1)\n",
    "#     fwd_test = np.max(sliding_window_view(fwd, window_shape = 2, axis = 2), axis = -1)\n",
    "#     rev_test = np.max(sliding_window_view(rev, window_shape = 2, axis = 2), axis = -1)\n",
    "    fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), weights, axis = -1)\n",
    "    rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), axis = -1)\n",
    "    fwd_test = np.max(sliding_window_view(fwd, window_shape = 4, axis = 2), axis = -1)\n",
    "    rev_test = np.max(sliding_window_view(rev, window_shape = 4, axis = 2), axis = -1)\n",
    "    test2 = (fwd_test + rev_test) /2 #blur\n",
    "    test2 += 1/(3*N_samples) #shift up slightly\n",
    "    test2 = test2 / np.sum(test2, axis = -1)[:,:,None] #renormalize\n",
    "    cum_hist_vals = np.cumsum(test2, axis = -1)\n",
    "    randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "    cum_hist_vals_flat = cum_hist_vals.flatten()\n",
    "    step_corr = np.linspace(0,W*H-1,W*H)\n",
    "    step_corr = np.tile(step_corr,(N_samples,1)).T\n",
    "    step_corr = np.reshape(step_corr, [1,-1])[0,:]\n",
    "    cum_hist_vals_flat+= step_corr\n",
    "    linear_spaced = np.linspace(near, H*W, N_samples*H*W)\n",
    "    ans = np.interp(x=linear_spaced, xp=cum_hist_vals_flat, fp=linear_spaced)\n",
    "    ans -= step_corr\n",
    "    ans *= far\n",
    "    ans = np.abs(ans)\n",
    "    z_vals = np.reshape(ans, [H,W,N_samples,1])\n",
    "    # depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "    depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "    #~~~~~~~~~~~\n",
    "    \n",
    "    new_point_cloud_spherical = np.zeros([np.shape(depth)[0]*np.shape(depth)[1],3])\n",
    "    depth = tf.transpose(depth).numpy() #need this\n",
    "    depth = np.flip(depth, axis = 0) #needed\n",
    "\n",
    "    #scale back up to normal size\n",
    "    depth *= 200 #200 #50 #200\n",
    "    ray_drop = tf.transpose(ray_drop).numpy() #test\n",
    "    ray_drop = np.flip(ray_drop, axis = 0) #test\n",
    "    \n",
    "    count = 0\n",
    "    for w in range(W):\n",
    "        for h in range(H):\n",
    "# #             #draw all points\n",
    "#             new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "            # suppress ray dropped points\n",
    "            if ray_drop[w,h] > 0.95:\n",
    "                    new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "            else:\n",
    "                    new_point_cloud_spherical[count,0] = 0#100\n",
    "            new_point_cloud_spherical[count,1] = (w-(1024//(2*n_rots)))/(2048//(2*n_rots))*(2*np.pi/n_rots)   #was this\n",
    "            # new_point_cloud_spherical[count,1] = (-w+(1024//(2*n_rots)))/(2048//(2*n_rots))*(2*np.pi/n_rots) #test flipping azimuth angle            \n",
    "            #phi\n",
    "            #spherical\n",
    "            new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/(np.shape(depth_img)[1] - 1)) #[17.74,-15.59] #(correct)       \n",
    "            #TEST -- space linearly in elevation angle (not z)\n",
    "            # new_point_cloud_spherical[count,2] = np.pi/2 + np.arcsin(phimax - (phimax-phimin)*(h/(np.shape(depth_img)[1] - 1))) #[17.74,-15.59] #(correct)       \n",
    "            #cylindrical\n",
    "#             new_point_cloud_spherical[count,2] = (phimax_patch + phimin_patch)/2 - ((-j+((H-1)/2))/(H-1))*(phimax_patch-phimin_patch)\n",
    "\n",
    "            count+= 1\n",
    "\n",
    "    new_point_cloud_spherical[:,1] -= (np.pi/n_rots) - j*(2*np.pi/n_rots) #need this\n",
    "\n",
    "    new_point_cloud_spherical[:,2] -= (phimax+phimin)\n",
    "    \n",
    "    new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy() #was this\n",
    "    #below doesn't work for spherical or cylindrically trained methods\n",
    "#     new_point_cloud_cart  =cylindrical_to_cartesian(new_point_cloud_spherical).numpy()     \n",
    "#     new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z \n",
    "#     new_point_cloud_cart[:,1] = -new_point_cloud_cart[:,1] #flip another axis to get back to LHCS (synthetic data only?)\n",
    "\n",
    "#     disp.append(Points(new_point_cloud_cart, c = 'gray', r = 3, alpha = 0.5))\n",
    "    # rainbow by z height\n",
    "    zheight = 100*(np.sin(0.25*new_point_cloud_cart[:,2])+1)\n",
    "    cname = np.array([1-zheight, zheight, 1.5*zheight]).T.tolist()\n",
    "    disp.append(Points(new_point_cloud_cart, c = cname, r = 2, alpha = 0.5))\n",
    "    savepc = np.append(savepc, new_point_cloud_cart, axis = 0)\n",
    "\n",
    "# print(testpose)\n",
    "# print(\"\\n\", rotm)\n",
    "plt.show(disp, \"CDF with L1+L2 Loss, train on 64x8 patches\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2766ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate a bunch of point clouds at random locations\n",
    "\n",
    "# to_save = np.zeros([0,3])\n",
    "# to_save = np.append(to_save, savepc)\n",
    "\n",
    "# print(np.shape(to_save))\n",
    "# to_save = np.reshape(to_save, [-1,3])\n",
    "# np.save(\"lidar_nerf_demo/generated_pc3.npy\", to_save)\n",
    "\n",
    "# #LOAD [-15,17.5]x1000, @0.005\n",
    "# np.save(\"/home/derm/Desktop/poses.npy\", poses)\n",
    "# np.save(\"/home/derm/Desktop/images.npy\", images)\n",
    "# poses = np.load(\"/home/derm/Desktop/poses.npy\")\n",
    "# images = np.load(\"/home/derm/Desktop/images.npy\")\n",
    "#LOAD [-17.5,15]x1000, @0.005\n",
    "# np.save(\"/home/derm/Desktop/posesM17P15.npy\", poses)\n",
    "# np.save(\"/home/derm/Desktop/imagesM17P15.npy\", images)\n",
    "# poses = np.load(\"/home/derm/Desktop/posesM17P15.npy\")\n",
    "# images = np.load(\"/home/derm/Desktop/imagesM17P15.npy\")\n",
    "\n",
    "#LOAD [-15,17]x1000, 8x8 @ 0.005\n",
    "# np.save(\"/home/derm/Desktop/poses8x8.npy\", poses)\n",
    "# np.save(\"/home/derm/Desktop/images8x8.npy\", images)\n",
    "\n",
    "# #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "# rotm[:3,-1] *= 0.002 #0.005 #0.02 #0.05\n",
    "# images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.002 #0.005 #0.02 #0.005 #0.05\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e0a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(H)\n",
    "n_vert_patches = 8\n",
    "H = 8\n",
    "W = 2\n",
    "\n",
    "# phimin = np.deg2rad(-17.743) #TEST\n",
    "# phimax = np.deg2rad(15.593) #TEST\n",
    "phimin = np.deg2rad(-15.593) #TEST\n",
    "phimax = np.deg2rad(17.743) #TEST\n",
    "# phimin = np.deg2rad(-16) #TEST\n",
    "# phimax = np.deg2rad(16) #TEST\n",
    "phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "\n",
    "i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "\n",
    "for i in range(9):\n",
    "\n",
    "#     #bottom to top -- trying this out\n",
    "#     phimin_patch = phivals[(i%(n_vert_patches))*(64//n_vert_patches)]\n",
    "#     phimax_patch = phivals[((i+1)%(n_vert_patches))*(64//n_vert_patches)-1]\n",
    "#     top to bottom -- was this\n",
    "    idx_first=len(phivals) - (i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "    idx_second= (len(phivals)- ((i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "#     phimin_patch = phivals[idx_first]     #was this (wrong??)\n",
    "#     phimax_patch = phivals[idx_second]    #was this (wrong??)\n",
    "    phimin_patch = phivals[idx_second]     #test\n",
    "    phimax_patch = phivals[idx_first]    #test\n",
    "\n",
    "    #old (sign is opposite of what we want for small patches?)\n",
    "#     elev_ang = -((phimax_patch + phimin_patch)/2 - ((-j+((H-1)/2))/(H-1))*(phimax_patch-phimin_patch)) -np.pi/2\n",
    "    #new 7/5\n",
    "    elev_ang = -(-((phimax_patch + phimin_patch)/2 - ((-j+((H-1)/2))/(H-1))*(phimax_patch-phimin_patch)) + np.pi/2)\n",
    "    print(\"\\n phimin_patch\", np.rad2deg(phimin_patch))\n",
    "    print(\"phimax_patch\", np.rad2deg(phimax_patch))\n",
    "    print(\"elev_ang:\", np.shape(elev_ang), np.rad2deg(elev_ang)[:,0] + 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4fd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use density of returns along each ray in a coarse network to select test points for fine network\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d\n",
    "# %matplotlib notebook\n",
    "\n",
    "N_samples = 128 # 128\n",
    "near = 0.\n",
    "far = 1.\n",
    "draw_pose = 55\n",
    "\n",
    "#get rays from model\n",
    "rays_o, rays_d = get_rays(H, W, poses[draw_pose], vertical_bins[-2], vertical_bins[-1]) #constant validation image\n",
    "z_vals = tf.linspace(near, far, N_samples) \n",
    "# z_vals += 0.0001*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals += 1.*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals = z_vals[:,:,:,None]\n",
    "\n",
    "depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "\n",
    "#plot density along single pixel\n",
    "fig, ax = p.subplots(2,1)\n",
    "ax[0].set_title(\"Inferred Density Along Ray, n samples = %i\" % N_samples)\n",
    "ax[1].set_xlabel(\"Distance (m)\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "ax[0].plot(np.linspace(near, far, N_samples),weights[0,1,:], label = \"density from coarse network\")\n",
    "# ax[0].plot(np.linspace(near, far, N_samples),test[0,1,:], label = \"CDF from coarse network\")\n",
    "ax[0].scatter(depth[0,1], 0., color = 'red')\n",
    "\n",
    "#fit gaussian to density histogram\n",
    "x = np.linspace(near,far*50, N_samples)\n",
    "rolls = np.floor(1000*weights[:,:,:]).astype(int)\n",
    "mu = np.sum(rolls * np.linspace(near,far*50, N_samples), axis = 2)/1000\n",
    "sigma = np.sqrt(np.sum(rolls*(mu[:,:,None]-x[None,None,...])**2, axis = 2)/1000)\n",
    "# ax[0].plot(x, norm.pdf(x, mu[10,1], sigma[10,1]), label=\"single gaussian\");\n",
    "\n",
    "#apply 2-tap max and 2-tap blur filters used in Mip-NeRF\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "#pad weights with zeros\n",
    "# fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), weights, axis = -1)\n",
    "# rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), axis = -1)\n",
    "#use additional axis to calculate all at once\n",
    "# fwd_test = np.max(sliding_window_view(fwd, window_shape = 2, axis = 2), axis = -1)\n",
    "# rev_test = np.max(sliding_window_view(rev, window_shape = 2, axis = 2), axis = -1)\n",
    "fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), weights, axis = -1)\n",
    "rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 3]), axis = -1)\n",
    "fwd_test = np.max(sliding_window_view(fwd, window_shape = 4, axis = 2), axis = -1)\n",
    "rev_test = np.max(sliding_window_view(rev, window_shape = 4, axis = 2), axis = -1)\n",
    "\n",
    "#blur-pool as vectorized operation\n",
    "test2 = (fwd_test + rev_test) /2 #blur\n",
    "# test2 += 1/N_samples #shift up slightly\n",
    "test2 += 1/(3*N_samples) #shift up slightly\n",
    "test2 = test2 / np.sum(test2, axis = -1)[:,:,None] #renormalize\n",
    "ax[0].plot(np.linspace(near, far, N_samples), test2[0,1,:], label = \"2-tap blur-pool + epsilon\")\n",
    "ax[0].set_xlim([-0.1*far,1.1*far])\n",
    "ax[0].legend()\n",
    "\n",
    "#calculate and plot inverse distribution~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#resample z_vals for fine network according to the 2-tap blur-pool distribution\n",
    "st = time.time()\n",
    "\n",
    "cum_hist_vals = np.cumsum(test2, axis = -1)\n",
    "\n",
    "randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "# randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "# print(\"randy:\", np.shape(randy))\n",
    "\n",
    "# print(\"\\n cum_hist_vals:\", np.shape(cum_hist_vals))\n",
    "cum_hist_vals_flat = cum_hist_vals.flatten()\n",
    "\n",
    "#modify cum_hist_vals so it is monotonically increaseing (needed for interp)\n",
    "step_corr = np.linspace(0,W*H-1,W*H)\n",
    "step_corr = np.tile(step_corr,(N_samples,1)).T\n",
    "step_corr = np.reshape(step_corr, [1,-1])[0,:]\n",
    "cum_hist_vals_flat+= step_corr\n",
    "\n",
    "# linear_spaced = np.linspace(near, far*50, N_samples)\n",
    "# linear_spaced = np.tile(linear_spaced, (H*W))\n",
    "linear_spaced = np.linspace(near, H*W, N_samples*H*W)\n",
    "# print(\"\\n linear_spaced:\", np.shape(linear_spaced))\n",
    "# print(linear_spaced)\n",
    "\n",
    "ans = np.interp(x=linear_spaced, xp=cum_hist_vals_flat, fp=linear_spaced)\n",
    "ans -= step_corr\n",
    "ans *= far\n",
    "ans = np.abs(ans)\n",
    "\n",
    "print(\"took\", time.time() - st, \"s\")\n",
    "\n",
    "#~~~~~~~~~~~~~~~\n",
    "\n",
    "# z_vals = np.reshape(ans, [H,W,1,N_samples])\n",
    "z_vals = np.reshape(ans, [H,W,N_samples,1])\n",
    "# z_vals = ans.reshape([W,H,N_samples,1])\n",
    "# z_vals = np.transpose(z_vals, [1,0,2,3])\n",
    "print(\"z_vals\", np.shape(z_vals))\n",
    "\n",
    "# ax[1].scatter(ans[N_samples*count:N_samples*(count+1)], 0.1*np.ones(N_samples), s=2, alpha = 0.5, label = 'sampled points for fine network')\n",
    "ax[1].scatter(z_vals[0,1,:,0], 0.1*np.ones(N_samples), s=4, alpha = 0.25, label = 'sampled points for fine network')\n",
    "# ax[1].axis('off')\n",
    "ax[1].set_ylim([-1,1])\n",
    "ax[1].set_xlim([-0.1*far,1.1*far])\n",
    "ax[1].legend(loc='lower right')\n",
    "# print(z_vals[7,1,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc94375-e10e-472b-84fc-245d99029824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw nerf output with actual platform trajectory\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "\n",
    "disp_with_gt = []\n",
    "fix = np.array([-rotm[1,-1], rotm[2,-1], rotm[0,-1]])*50 \n",
    "fix += np.array([-initial_pose[0,-1], initial_pose[1,-1], initial_pose[2,-1]])\n",
    "nerf_in_mapframe = savepc - fix\n",
    "nerf_in_mapframe = nerf_in_mapframe @ R.from_euler('xyz', [0,0,np.pi/2]).as_matrix()\n",
    "disp_with_gt.append(Points(nerf_in_mapframe, c = 'gray', r = 3, alpha = 0.5))\n",
    "                    \n",
    "fn_gt = dir_name + experiment_name + \"ground_truth/registered_poses.csv\"\n",
    "#sec,nsec,x,y,z,qx,qy,qz,qw\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "sidx = 7700\n",
    "eidx = 8700\n",
    "traj = np.array([gt[sidx:eidx,2], gt[sidx:eidx,3], gt[sidx:eidx,4]]) \n",
    "traj = initial_pose[:3,:3] @ traj \n",
    "disp_with_gt.append(Points(traj, c = 'red', r = 4))\n",
    "# disp_with_gt.append(Points([[0,0,0]], c = 'purple', r = 10))\n",
    "\n",
    "plt.show(disp_with_gt, \"Newer College NeRF\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d6279",
   "metadata": {},
   "source": [
    "# Test: try probabilisitc rendering from density func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef200b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use density of returns along each ray in a coarse network to select test points for fine network\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d\n",
    "%matplotlib inline\n",
    "\n",
    "N_samples = 128 # 128\n",
    "near = 0.\n",
    "far = 2.\n",
    "draw_pose = 180\n",
    "\n",
    "#get rays from model\n",
    "rays_o, rays_d = get_rays(H, W, poses[draw_pose], vertical_bins[-2], vertical_bins[-1]) #constant validation image\n",
    "z_vals = tf.linspace(near, far, N_samples) \n",
    "# z_vals += 0.0001*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals += 1.*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals = z_vals[:,:,:,None]\n",
    "\n",
    "depth, acc, ray_drop, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "\n",
    "#plot density along single pixel\n",
    "fig, ax = p.subplots(2,1)\n",
    "ax[0].set_title(\"Inferred Density Along Ray, n samples = %i\" % N_samples)\n",
    "ax[1].set_xlabel(\"Distance (m)\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "ax[0].plot(np.linspace(near, far, N_samples),weights[0,1,:], label = \"density from coarse network\")\n",
    "ax[0].scatter(depth[0,1], 0., color = 'red', label = 'Image-NeRF Accumulation Depth Estimate Coarse')\n",
    "# ax[1].scatter(z_vals[0,1,:,0], 0.1*np.ones(N_samples), s=4, alpha = 0.25, label = 'sampled points for coarse network')\n",
    "\n",
    "#fit gaussian to density histogram\n",
    "x = np.linspace(near,far*50, N_samples)\n",
    "rolls = np.floor(1000*weights[:,:,:]).astype(int)\n",
    "mu = np.sum(rolls * np.linspace(near,far*50, N_samples), axis = 2)/1000\n",
    "sigma = np.sqrt(np.sum(rolls*(mu[:,:,None]-x[None,None,...])**2, axis = 2)/1000)\n",
    "# ax[0].plot(x, norm.pdf(x, mu[10,1], sigma[10,1]), label=\"single gaussian\");\n",
    "\n",
    "#apply 2-tap max and 2-tap blur filters used in Mip-NeRF\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "#pad weights with zeros\n",
    "fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), weights, axis = -1)\n",
    "rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), axis = -1)\n",
    "#use additional axis to calculate all at once\n",
    "fwd_test = np.max(sliding_window_view(fwd, window_shape = 2, axis = 2), axis = -1)\n",
    "rev_test = np.max(sliding_window_view(rev, window_shape = 2, axis = 2), axis = -1)\n",
    "\n",
    "#blur-pool as vectorized operation\n",
    "test2 = (fwd_test + rev_test) /2 #blur\n",
    "# test2 += 1/N_samples #shift up slightly\n",
    "test2 += 1/(3*N_samples) #shift up slightly\n",
    "test2 = test2 / np.sum(test2, axis = -1)[:,:,None] #renormalize\n",
    "ax[0].plot(np.linspace(near, far, N_samples), test2[0,1,:], label = \"2-tap blur-pool + epsilon after coarse\")\n",
    "ax[0].set_xlim([-0.1*far,1.1*far])\n",
    "\n",
    "#calculate and plot inverse distribution~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#resample z_vals for fine network according to the 2-tap blur-pool distribution\n",
    "st = time.time()\n",
    "\n",
    "cum_hist_vals = np.cumsum(test2, axis = -1)\n",
    "\n",
    "randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "print(\"randy:\", np.shape(randy))\n",
    "# print(randy)\n",
    "\n",
    "print(\"\\n cum_hist_vals:\", np.shape(cum_hist_vals))\n",
    "cum_hist_vals_flat = cum_hist_vals.flatten()\n",
    "\n",
    "#modify cum_hist_vals so it is monotonically increaseing (needed for interp)\n",
    "step_corr = np.linspace(0,W*H-1,W*H)\n",
    "step_corr = np.tile(step_corr,(N_samples,1)).T #was this\n",
    "step_corr = np.reshape(step_corr, [1,-1])[0,:]\n",
    "cum_hist_vals_flat+= step_corr\n",
    "\n",
    "# linear_spaced = np.linspace(near, far*50, N_samples)\n",
    "# linear_spaced = np.tile(linear_spaced, (H*W))\n",
    "linear_spaced = np.linspace(near, H*W, N_samples*H*W) #was this\n",
    "# linear_spaced = np.linspace(near, H*W, H*W) #test\n",
    "print(\"\\n linear_spaced:\", np.shape(linear_spaced))\n",
    "# print(linear_spaced)\n",
    "\n",
    "ans = np.interp(x=linear_spaced, xp=cum_hist_vals_flat, fp=linear_spaced)\n",
    "ans -= step_corr\n",
    "ans *= far\n",
    "ans = np.abs(ans)\n",
    "\n",
    "print(\"took\", time.time() - st, \"s\")\n",
    "\n",
    "#~~~~~~~~~~~~~~~\n",
    "\n",
    "z_vals = np.reshape(ans, [H,W,N_samples,1])\n",
    "# print(\"z_vals\", np.shape(z_vals))\n",
    "\n",
    "depth2, acc2, ray_drop2, weights2 = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "ax[0].scatter(depth2[0,1], 0., color = 'Blue', label = 'Image-NeRF Accumulation Depth Estimate Fine')\n",
    "\n",
    "#plot latent density of world representation according to fine pass through network\n",
    "#need to interpolate back to linspace though\n",
    "normalized_weights2 = np.interp(x=np.linspace(0, 2, N_samples), xp = z_vals[0,1,:,0], fp=weights2[0,1,:]) #test--single sample\n",
    "normalized_weights2 = normalized_weights2 / (np.sum(normalized_weights2)) #not needed, weights2 already normalized\n",
    "ax[0].plot(np.linspace(0, 2, N_samples), normalized_weights2, label = \"density from fine network\") #TEST\n",
    "\n",
    "# normalized_weights2 = np.interp(x=np.linspace(0, 2, N_samples), xp = z_vals, fp=weights2) #test--single sample\n",
    "# ax[0].plot(np.linspace(0, 2, N_samples), normalized_weights2, label = \"density from fine network\") #TEST\n",
    "\n",
    "# print(\"weights\", np.sum(weights[0,1,:]), weights[0,1,:])\n",
    "# print(\"weights2\", np.sum(weights2[0,1,:]), weights2[0,1,:])\n",
    "# print(\"norm weights2\", np.sum(normalized_weights2), normalized_weights2)\n",
    "\n",
    "ax[1].scatter(z_vals[0,1,:,0], 0.1*np.ones(N_samples), s=4, alpha = 0.25, label = 'sampled points fed to fine network')\n",
    "#randomly select a point from z_vals as our depth return for this ray\n",
    "spin = int(N_samples*np.random.rand())\n",
    "ax[1].scatter(z_vals[0,1,spin,0], 0., color = 'red', label = \"Randomly selected depth output from histogram\")\n",
    "\n",
    "# print(\"random depth:\", np.shape(z_vals[:,:,spin,0])) #, z_vals[:10,0,spin,0])\n",
    "# print(\"old depth output:\", np.shape(depth2)) #,depth2[:10,0])\n",
    "\n",
    "# ax[1].axis('off')\n",
    "ax[1].set_ylim([-1,1])\n",
    "ax[1].set_xlim([-0.1*far,1.1*far])\n",
    "ax[1].legend(loc='lower right')\n",
    "ax[0].legend()\n",
    "# print(z_vals[7,1,:,0])|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54784d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save generated point cloud\n",
    "# fig, ax = p.subplots()\n",
    "# ax.scatter(savepc[:,0], savepc[:,1])\n",
    "# np.save('lidar_nerf_demo/generated_pc1.npy', savepc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1-- L_embed = 15 (was 10 before?)\n",
    "# model.save_weights(\"models/NCv1.ckpt\")\n",
    "# model.save('models/NCv1.keras')\n",
    "\n",
    "#v2-- L_embed = 15, trained on 8x8 pixel patches\n",
    "# model.save_weights(\"models/NCv2.ckpt\")\n",
    "# model.save('models/NCv2.keras')\n",
    "\n",
    "#v3-- L_embed = 20, trained on 128,8 cylindrical patches\n",
    "# model.save_weights(\"models/NCv3.ckpt\")\n",
    "# model.save('models/NCv3.keras')\n",
    "\n",
    "#v4-- L_embed = 15, with distortion correction, \n",
    "#     trained on 128,8 cylindrical patches, using coarse and fine networks\n",
    "#     core model trained WITHOUT LiDAR-NeRF structural regularization\n",
    "#     frames 600:10:1100\n",
    "# model.save_weights(\"models/NCv4.ckpt\")\n",
    "# model.save('models/NCv4.keras')\n",
    "\n",
    "#v5-- L_embed = 18, with DC, frames 7700:10:8700\n",
    "#     coarse+fine networks\n",
    "# model.save_weights(\"models/NCv5.ckpt\")\n",
    "# model.save('models/NCv5.keras')#AD1056380\n",
    "\n",
    "#v6-- updated netowrk to process positional encoding seprate from view direction\n",
    "#     trained using spherical patches size [128x8]\n",
    "# model.save_weights(\"models/NCv6.ckpt\")\n",
    "# model.save('models/NCv6.keras')\n",
    "\n",
    "#v7-- larger network, hidden layer size 512, 14 pos embedding dims, \n",
    "#     trained using cylindrical patches size [128x8]\n",
    "#     testing out [-17.5,16] deg for lidar bounds in training data (100 scans)\n",
    "# model.save_weights(\"models/NCv7.ckpt\")\n",
    "# model.save('models/NCv7.keras')\n",
    "\n",
    "#v8-- Standard NeRF structure, patch size [128x8], phimin, max = [-17.75, 16]\n",
    "#     spherical pathces, accumulate_grad_steps = 32 --> noticiable improvement!\n",
    "# model.save_weights(\"models/NCv8.ckpt\")\n",
    "# model.save('models/NCv8.keras')\n",
    "\n",
    "#v9-- STANDARD NERF, used updated phi min/max \n",
    "# model.save_weights(\"models/NCv9.ckpt\")\n",
    "# model.save('models/NCv9.keras')\n",
    "\n",
    "#v10-- STANDARD NERF, fixed elevation angle double count\n",
    "# model.save_weights(\"models/NCv10.ckpt\")\n",
    "# model.save('models/NCv10.keras')\n",
    "\n",
    "#v11-- actually fixed double count (forgot to comment out on train script XD)\n",
    "#      trained from 1000 frames @ size [128,8], no SR,  \n",
    "# model.save_weights(\"models/NCv11.ckpt\")\n",
    "# model.save('models/NCv11.keras')\n",
    "\n",
    "# #v12-- removed intermediary euler conversion in training data -- cylindrical seems to work well now?!?\n",
    "## flipped bounds\n",
    "# model.save_weights(\"models/NCv12.ckpt\")\n",
    "# model.save('models/NCv12.keras')\n",
    "\n",
    "##v13 -- same as 12 but not flipped\n",
    "# model.save_weights(\"models/NCv13.ckpt\")\n",
    "# model.save('models/NCv13.keras')\n",
    "\n",
    "#synthetic (OG orientation, cylindrical, 30 easy training frames)\n",
    "# model.save_weights(\"models/sNCv1.ckpt\")\n",
    "# model.save('models/sNCv1.keras')\n",
    "\n",
    "#synthetic (Flipped orientation, cylindrical, 100 easy training frames), 14 pos embed dims\n",
    "# model.save_weights(\"models/sNCv2.ckpt\")\n",
    "# model.save('models/sNCv2.keras')\n",
    "\n",
    "#~~~~~BEST OLD~~~~~~~~~~~\n",
    "#synthetic, flipped orientation, SPHERCIAL (fixed), 100 easy frames, 14 pos embed dims\n",
    "# model.save_weights(\"models/sNCv3.ckpt\")\n",
    "# model.save('models/sNCv3.keras')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#testing cetering orientation\n",
    "# model.save_weights(\"models/sNCv4.ckpt\")\n",
    "# model.save('models/sNCv4.keras')\n",
    "\n",
    "#real data, de-skew attempt #1, no pinv in GT -- better\n",
    "# model.save_weights(\"models/NCv14.ckpt\")\n",
    "# model.save('models/NCv14.keras')\n",
    "\n",
    "#real data, de-skew attempt #1, with pinv and flipped trans in GT -- worse\n",
    "# model.save_weights(\"models/NCv15.ckpt\")\n",
    "# model.save('models/NCv15.keras')\n",
    "\n",
    "#first attempt at a depth-direct rendered NeRF\n",
    "# 8,512  18posembed 18angembed\n",
    "# model.save_weights(\"models/depthV1.ckpt\")\n",
    "# model.save('models/depthV1.keras')\n",
    "\n",
    "# # 8,64  18posembed 18angembed\n",
    "# model.save_weights(\"models/depthV2.ckpt\")\n",
    "# model.save('models/depthV2.keras')\n",
    "\n",
    "\n",
    "## MUCH BETTER ON REAL DATA (COURTYARD 1) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#OUTPUT PDF, LOSS AGAINST CDF, stochastic render, L1+L2 Loss \n",
    "## 4-tap blur pool, c2f with alpha as \"weights\", used weights for ray drop (not great...)\n",
    "# [-17.5,15] load data, [-17.5,15] train\n",
    "# 1000 training frames\n",
    "# 8, 256, 14/4\n",
    "# model.save_weights(\"models/pdfV1.ckpt\")\n",
    "# model.save('models/pdfV1.keras')\n",
    "\n",
    "#Notes:\n",
    "#  slight warping on ground plane\n",
    "#  able to capture peaks beyond windows\n",
    "#  better job capturing windows and rough surfaces than previous models\n",
    "#  slightly messy rings on ground plane\n",
    "\n",
    "#seems to work even better with [-15,17.5] load, [-17.5, 15.5] train \n",
    "# model.save_weights(\"models/pdfV2.ckpt\")\n",
    "# model.save('models/pdfV2.keras')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#trying same again with learning viewing angle-dependant density -- BEST SO FAR!\n",
    "# model.save_weights(\"models/pdfV3.ckpt\")\n",
    "# model.save('models/pdfV3.keras')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# [-17,15] load, 8,512 network\n",
    "# seems very fragile in training -- network size too big?\n",
    "# model.save_weights(\"models/pdfV4.ckpt\")\n",
    "# model.save('models/pdfV4.keras')\n",
    "\n",
    "# # [-17,15] load, 8,128 network\n",
    "# model.save_weights(\"models/pdfV5.ckpt\")\n",
    "# model.save('models/pdfV5.keras')\n",
    "\n",
    "# trainig on smaller 8x8 patches, messing with phimin_patch min/max\n",
    "# 15,5 embedding channels, 8,256 network size\n",
    "# model.save_weights(\"models/pdfV6.ckpt\")\n",
    "# model.save('models/pdfV6.keras')\n",
    "\n",
    "#Trying again with full height patches using new phimin/max patch convention... \n",
    "model.save_weights(\"models/pdfV7.ckpt\")\n",
    "model.save('models/pdfV7.keras')\n",
    "\n",
    "\n",
    "# model.load_weights('models/pdfV6.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "\n",
    "#old theata\n",
    "# (i - (1024//(2*n_rots)))  /(2048//(2*n_rots)) * (2*np.pi/n_rots) + np.pi\n",
    "#broken(?) theta\n",
    "# (i - (W//2))  /(W) * (2*np.pi/(1024//W)), #just use W\n",
    "# print(1024//(2*n_rots), (2048//(2*n_rots)), 2*np.pi/n_rots)\n",
    "# print(W//2, W, 2*np.pi/(1024//W))\n",
    "\n",
    "phimin_patch = np.deg2rad(-16) \n",
    "phimax_patch = np.deg2rad(17.75)\n",
    "\n",
    "#old phi\n",
    "# (phimax_patch + phimin_patch)/2 - ((-j+(32//n_vert_patches))/(64//n_vert_patches))*(phimax_patch-phimin_patch)\n",
    "# broken(?) phi\n",
    "# (phimax_patch + phimin_patch)/2 + ((-j+(H/2))/(H))*(phimax_patch-phimin_patch) #- np.pi/2\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8cc965",
   "metadata": {},
   "source": [
    "# Load and crop depth image data with arbitrary patch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eda5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remove_motion_basic import linear_correction_old as lc\n",
    "\n",
    "dir_name = \"/media/derm/06EF-127D4/Newer College Dataset/\"\n",
    "experiment_name = \"01_short_experiment-20230331T172433Z-009/01_short_experiment/\"\n",
    "fn_gt = dir_name + experiment_name + \"ground_truth/registered_poses.csv\"\n",
    "#sec,nsec,x,y,z,qx,qy,qz,qw\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "seconds = gt[:, 0]\n",
    "nano_seconds = gt[:, 1]\n",
    "xyz = gt[:, 2:5]\n",
    "qxyzw = gt[:, 5:]\n",
    "num_poses = qxyzw.shape[0]\n",
    "sensor_poses = np.eye(4, dtype=np.float64).reshape(1, 4, 4).repeat(num_poses, axis=0)\n",
    "sensor_poses[:, :3, :3] = R.from_quat(qxyzw).as_matrix()\n",
    "sensor_poses[:, :3, 3] = xyz\n",
    "T_CL = np.eye(4, dtype=np.float32)\n",
    "T_CL[:3, :3] = R.from_quat([0.0, 0.0, 0.924, 0.383]).as_matrix() #was this --1134.97 deg\n",
    "T_CL[:3, 3] = np.array([-0.084, -0.025, 0.050], dtype=np.float32) #was this\n",
    "sensor_poses = np.einsum(\"nij,jk->nik\", sensor_poses, T_CL)\n",
    "initial_pose = np.linalg.inv(sensor_poses[0]) \n",
    "poses_timestamps = seconds * 10e9 + nano_seconds\n",
    "sensor_poses = np.einsum(\"ij,njk->nik\", np.linalg.inv(sensor_poses[0]), sensor_poses) #TRY COMMENTING OUT...\n",
    "\n",
    "#get body frame vel to remove motion disortion from training data\n",
    "vel_world_frame = np.diff(sensor_poses[:,:3,-1], axis = 0)\n",
    "vel_body_frame = np.linalg.pinv(sensor_poses[1:,:3,:3]) @ vel_world_frame[:,:,None]\n",
    "vel_body_frame = vel_body_frame[:,:,0]\n",
    "#smooth out velocity estimates\n",
    "def moving_average(a, n=10):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "window=50\n",
    "MAx = moving_average(vel_body_frame[:,0], n = window)\n",
    "MAy = moving_average(vel_body_frame[:,1], n = window)\n",
    "MAz = moving_average(vel_body_frame[:,2], n = window)\n",
    "vel_body_frame = np.array([MAx, MAy, MAz]).T\n",
    "\n",
    "rot_vel_euls = np.diff(R.from_matrix(sensor_poses[:,:3,:3]).as_euler('xyz'), axis = 0)\n",
    "idx = np.argwhere(rot_vel_euls > (np.pi))\n",
    "rot_vel_euls[idx] = 0\n",
    "idx = np.argwhere(rot_vel_euls < (-np.pi))\n",
    "rot_vel_euls[idx] = 0\n",
    "\n",
    "pl = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply'\n",
    "HD_map = trimesh.load(pl).vertices\n",
    "show_nth = 5 #10\n",
    "submap = HD_map[::show_nth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619dca10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  undistort raw point clouds, define patch sizes,\n",
    "#  take patches about useful regions of the scene, and record poses for each patch \n",
    "\n",
    "from time import sleep\n",
    "#convert gt from xyzquat to homogenous rotation matrix\n",
    "n_images = 1000 #1000 #50 \n",
    "n_rots = 128 #128    #number of horizontal patches in 360 degrees\n",
    "n_vert_patches = 8 #8 #number of vertical patches between phimin and phimaxs\n",
    "\n",
    "# n_cols_to_skip = 0 #comment out for debug\n",
    "n_cols_to_skip = n_rots // 8 #remove this much from the beginning and end of each scan\n",
    "                             #   (need to remove parts of frame containing researcher carrying LIDAR)\n",
    "#Ouster OS1-64\n",
    "phimin = np.deg2rad(-15.594) #TEST 7/3\n",
    "phimax = np.deg2rad(17.743)\n",
    "# phimax = np.deg2rad(15.594) #flipped\n",
    "# phimin = np.deg2rad(-17.743)\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "\n",
    "poses = np.zeros([n_images*n_rots*n_vert_patches,4,4])\n",
    "images = np.ones([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 2]) #depth image and raydrop\n",
    "H, W = images.shape[1:3]\n",
    "\n",
    "# plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True)\n",
    "# disp = []\n",
    "# submap_in_map_frame =  (initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #was this\n",
    "# # submap_in_map_frame =  (np.append(submap, np.ones([len(submap),1]), axis =1).T).T #initial pose already baked in??\n",
    "# # submap_in_map_frame = submap_in_map_frame @ np.linalg.pinv(T_CL) #TEST\n",
    "# submap_in_map_frame = submap_in_map_frame[:,:3]\n",
    "# disp.append(Points(submap_in_map_frame, c = 'gray', r = 2, alpha = 0.25))\n",
    "\n",
    "redfix_hist = np.zeros([n_images,4,4])#DEBUG\n",
    "\n",
    "for i in range(n_images):\n",
    "    print(i) \n",
    "    #2nd courtyard\n",
    "#     idx = i*60 + 1500\n",
    "    #full loop first courtyard\n",
    "    idx = i + 7700 \n",
    "#     idx = i*10 + 7700\n",
    "    #test simple part of map\n",
    "#     idx = i*10 + 8400\n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "    \n",
    "#     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                      -vel_body_frame[idx,1],\n",
    "                      -vel_body_frame[idx,2],\n",
    "                      -rot_vel_euls[idx,0], #looks good\n",
    "                      -rot_vel_euls[idx,1],\n",
    "                      -rot_vel_euls[idx,2]\n",
    "#                       0,0,0 #rotational velocity is zero-centered (theoretically should cancel out with enough data)\n",
    "                     ])   \n",
    "    pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    pc1 = np.flip(pc1, axis = 0)# uncomment to flip and maintain CCW convention used in VICET\n",
    "\n",
    "    # TEST-- Register undistorted PC against HD Map using ICET to correct issues in ground truth------------------------\n",
    "    submap_in_pc1_frame = (np.linalg.pinv(sensor_poses[idx]) @ initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #test\n",
    "    submap_in_pc1_frame = submap_in_pc1_frame[:,:3]\n",
    "\n",
    "    initial_guess = tf.constant([0.,0.,0.,0.,0.,0.])\n",
    "    it = ICET(cloud1 = submap_in_pc1_frame, cloud2 = pc1, fid = 50, niter = 8, \n",
    "       draw = False, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "\n",
    "    pc1_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T #test\n",
    "    pc1_in_map_frame = pc1_in_map_frame[:,:3]\n",
    "#     disp.append(Points(pc1_in_map_frame, c = 'red', r = 3, alpha = 0.2))\n",
    "\n",
    "    pc1_corrected_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(it.cloud2_tensor.numpy(), np.ones([len(it.cloud2_tensor.numpy()),1]), axis =1).T).T #test\n",
    "    pc1_corrected_in_map_frame = pc1_corrected_in_map_frame[:,:3]    \n",
    "#     disp.append(Points(pc1_corrected_in_map_frame, c = 'blue', r =3, alpha = 0.2))\n",
    "\n",
    "    #draw red scan corrected by output of ICET\n",
    "    redFix = np.eye(4)\n",
    "    redFix[:3,-1] = it.X[:3]\n",
    "    redFix[:3,:3] = redFix[:3,:3] @ R.from_euler('xyz', [it.X[3], it.X[4], it.X[5]]).as_matrix()\n",
    "    redfix_hist[i] = redFix\n",
    "    \n",
    "    redScanFixed = (redFix @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "#     redScanFixed = (initial_pose @ sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "    redScanFixed = (sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "#     disp.append(Points(redScanFixed[:,:3], c = 'red', r =3, alpha = 0.2))    \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #convert to depth image\n",
    "    pc1_spherical = cartesian_to_spherical(pc1).numpy() #[r, theta, phi]\n",
    "    pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "    pcs = np.flip(pcs, axis = 1)\n",
    "    raw_data = pcs[:,:,:]\n",
    "    raw_data = np.transpose(pcs, [1,0,2])\n",
    "\n",
    "    #destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "    data = np.zeros([64, 1024])\n",
    "    for k in range(np.shape(data)[0]//4):\n",
    "# #         #shift left (nope)\n",
    "#         data[4*k,:-18] = raw_data[4*k,18:,0]\n",
    "#         data[4*k+1,:-12] = raw_data[4*k+1,12:,0]\n",
    "#         data[4*k+2,:-6] = raw_data[4*k+2,6:,0]\n",
    "#         data[4*k+3,:] = raw_data[4*k+3,:,0]\n",
    "# #         #shift right -- https://ouster.com/insights/blog/firmware-2-4-industry-standard-protocols-and-improved-alerts\n",
    "#         data[4*k,:] = raw_data[4*k,:,0]\n",
    "#         data[4*k+1,6:] = raw_data[4*k+1,:-6,0]\n",
    "#         data[4*k+2,12:] = raw_data[4*k+2,:-12,0]\n",
    "#         data[4*k+3,18:] = raw_data[4*k+3,:-18,0]\n",
    "        # keep centered\n",
    "        data[4*k,1:-8] = raw_data[4*k,9:,0]\n",
    "        data[4*k+1,1:-2] = raw_data[4*k+1,3:,0]\n",
    "        data[4*k+2,4:] = raw_data[4*k+2,:-4,0]\n",
    "        data[4*k+3,10:] = raw_data[4*k+3,:-10,0]\n",
    "#         #TEST-- no shift\n",
    "#         data = raw_data[:,:,0]\n",
    "    \n",
    "    data = np.flip(data, axis =1) #do not comment out\n",
    "\n",
    "    for j in range(n_rots):\n",
    "        for k in range(n_vert_patches):\n",
    "            #get cropped depth image ~~~~~~~~~~~~~~~~~~~~    \n",
    "            image_width = 1024//n_rots\n",
    "            image_height = 64//n_vert_patches\n",
    "            pcs = data[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width] #crop vertically and horizontally\n",
    "    \n",
    "            #save depth information to first channel\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] = pcs\n",
    "\n",
    "            #save raydrop mask to 2nd channel\n",
    "            a = np.argwhere(abs(pcs) < 1)\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches, a[:,0],a[:,1],1] = 0\n",
    "\n",
    "\n",
    "            #get transformation matrix ~~~~~~~~~~~~~~~~~~\n",
    "            #works(ish) but \"green\" axis is upside down, data poisoning from bad ground truth\n",
    "            # rotm = np.eye(4)\n",
    "            # rotm[1,3] = -gt[idx,2] #x\n",
    "            # rotm[2,3] = gt[idx,3] #y\n",
    "            # rotm[0,3] = -gt[idx,4] #z\n",
    "            # rotm[:3,:3] = R.from_quat(gt[idx,5:]).as_matrix() \n",
    "\n",
    "#             #use ICET results to improve ground truth\n",
    "#             rotm = np.eye(4)\n",
    "#             rotm[1,3] = -(gt[idx,2] + it.X[0]) #x\n",
    "#             rotm[2,3] = gt[idx,3] + it.X[1] #y\n",
    "#             rotm[0,3] = -(gt[idx,4] + it.X[2]) #z\n",
    "#             rotm[:3,:3] = R.from_quat(gt[idx,5:]).as_matrix() \n",
    "#             rotm[:3,:3] = rotm[:3,:3] @ R.from_euler('xyz', [it.X[3], it.X[4], it.X[5]]).as_matrix()\n",
    "\n",
    "            #TEST ALT GT\n",
    "#             rotm = initial_pose @ sensor_poses[idx] @ redFix #looks best in visualization (below)\n",
    "#             rotm = np.linalg.pinv(initial_pose) @ rotm #TEST 6/15\n",
    "\n",
    "            #centers origin at actual origin of HD map \n",
    "            #  need to comment out line in above cell normazlizing sensor_poses w.r.t. first pose\n",
    "            rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "            rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "\n",
    "            rotm[:3,-1] = np.array([-rotm[2,-1], -rotm[0,-1], rotm[1,-1]])\n",
    "\n",
    "            #orient yellow (-z) pointing forward\n",
    "            fix = np.array([[0,0,1],\n",
    "                            [1,0,0],\n",
    "                            [0,1,0]])\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ fix\n",
    "            \n",
    "            swap_axis_matrix = np.array([[0, 0, 1],\n",
    "                                         [1, 0, 0],\n",
    "                                         [0, 1, 0]])\n",
    "#             flip_axis_matrix = np.diag([-1,1,-1]) #was this\n",
    "            flip_axis_matrix = np.diag([1,1,-1]) # better ---> corrects flipping z issue when rendering\n",
    "            rotm[:3,:3] = flip_axis_matrix @ swap_axis_matrix @ rotm[:3,:3] \n",
    "\n",
    "            #center camera horizontally in each patch\n",
    "            crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "\n",
    "            #account for the fact that sensor points back and to the left\n",
    "            #used this rotation value on the VICET paper-- (I don't think their setup was a perfect 45deg as specified in their paper)\n",
    "#             crop_angle -= np.deg2rad(44.97)\n",
    "#             rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix()\n",
    "# # # #             #is crop angle already accounted for with redfix(?)\n",
    "            rotm_crop = R.from_euler('xyz', [0,-crop_angle,0]).as_matrix()\n",
    "\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "            #courtyard1\n",
    "            rotm[2,-1] += 45 #translate above xy plane\n",
    "            rotm[1,-1] += 30 #shift towards positive x\n",
    "#             rotm[0,-1] += 2 #TEST -- shift up just a little\n",
    "#             rotm[2,-1] += 120 #courtyard2\n",
    "\n",
    "            #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "            rotm[:3,-1] *= 0.005 #0.005 #0.02 #0.05\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.005 #0.005 #0.02 #0.005 #0.05\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            # recenter (when using x0.005)\n",
    "            rotm[2,-1] += 0.25 #translate above xy plane\n",
    "            rotm[1,-1] += 0.25 #shift towards positive x\n",
    "            rotm[0,-1] += 0.01 #TEST -- shift up just a little\n",
    "            \n",
    "#             poses[j+(i*n_rots)] = rotm\n",
    "            poses[k+(j+(i*n_rots))*n_vert_patches] = rotm\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "print(\"num poses:\", len(poses))\n",
    "\n",
    "# # Remove patches where sensor is occluded by person holding lidar ~~~~~~~~~~\n",
    "#calculte how many columns of patches we need to skip at the beginning and end of each scan to avoid\n",
    "print(\"n_rots:\", n_rots)\n",
    "# n_cols_to_skip = 0 #debug\n",
    "print(\"n_cols_to_skip:\", n_cols_to_skip)\n",
    "\n",
    "bad_idx = np.zeros([0,n_rots - 2*n_cols_to_skip])\n",
    "a = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "print(np.shape(a))\n",
    "for i in range(n_vert_patches*n_cols_to_skip):\n",
    "    bad_i_left = a[i::n_rots*n_vert_patches]\n",
    "    bad_idx = np.append(bad_idx, bad_i_left)\n",
    "#     print(\"\\n bad_idx_left:\", bad_i_left)\n",
    "\n",
    "    bad_i_right = a[(i+n_vert_patches*(n_rots-n_cols_to_skip))::n_rots*n_vert_patches]\n",
    "    bad_idx = np.append(bad_idx, bad_i_right)\n",
    "#     print(\"\\n bad_idx_right:\", bad_i_right)\n",
    "    \n",
    "bad_idx = np.sort(bad_idx)\n",
    "all_idx = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "good_idx = np.setdiff1d(all_idx, bad_idx).astype(int)\n",
    "\n",
    "# print(good_idx)\n",
    "\n",
    "images = images[good_idx,:,:,:]\n",
    "poses = poses[good_idx,:,:]\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# test on one only\n",
    "testimg, testpose = images[-1], poses[-1]\n",
    "images = images[:-1,...,:3]\n",
    "poses = poses[:-1]\n",
    "\n",
    "# plt.show(disp, \"01 Short Experiment Frame #\" + str(idx))\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e6f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#draw orientation of frames used for each patch in world frame\n",
    "phimin = np.deg2rad(-16) \n",
    "phimax = np.deg2rad(17.75)\n",
    "plt = Plotter(N = 1, axes = 8, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "for i in range(len(poses)):\n",
    "            \n",
    "    # #transform each to base frame using <poses>\n",
    "    # new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy()\n",
    "    # new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z -- does this indicate an error somewhere???\n",
    "\n",
    "    #draw frames for each sub-scan \n",
    "    alph = 1-(i%(n_rots)/n_rots) #change transparency during scan\n",
    "#     alph = 1 - i/(len(poses)+1) #change transparency between scans\n",
    "    #forward view direction (-z in NeRF c2w convention)\n",
    "    headings = poses[i,:3,:3] @ np.array([0,0,-0.03])\n",
    "    disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"yellow\", alpha = alph))\n",
    "    # x\n",
    "#     headings = poses[i,:3,:3] @ np.array([.03,0,0])\n",
    "#     disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"red\", alpha = alph))\n",
    "    #y\n",
    "    headings = poses[i,:3,:3] @ np.array([0,.03,0])\n",
    "    disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"green\", alpha = alph))\n",
    "    #z\n",
    "#     headings = poses[i,:3,:3] @ np.array([0,0,.03])\n",
    "#     disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"blue\", alpha = alph))\n",
    "    \n",
    "disp.append(Points(np.array([[0,0,0]]), r = 10, c = 'black'))\n",
    "plt.show(disp, \"Training Data Sample\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c49093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw subsequent scans aligned using poses with redfix\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "for i in range(10):\n",
    "    idx = i*100 + 7700\n",
    "#     idx = i*10 + 8400\n",
    "    \n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "#     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                      -vel_body_frame[idx,1],\n",
    "                      -vel_body_frame[idx,2],\n",
    "                      -rot_vel_euls[idx,0], #looks good\n",
    "                      -rot_vel_euls[idx,1],\n",
    "                      -rot_vel_euls[idx,2]\n",
    "#                       0,0,0 #rotational velocity is zero-centered (theoretically should cancel out with enough data)\n",
    "                     ])   \n",
    "    pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~        \n",
    "#     rotm = initial_pose @ sensor_poses[idx] @ redfix_hist[i]  #THIS IS IT -- need to comment out everything below(?)\n",
    "#     rotm = np.linalg.pinv(initial_pose) @ rotm #was this\n",
    "\n",
    "    #centers origin at actual origin of HD map \n",
    "    #  need to comment out line in above cell normazlizing sensor_poses w.r.t. first pose\n",
    "    rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "    rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "\n",
    "#     ##DEBUG-- use same transforms as in training data generatio-----------------\n",
    "# #     rotm[:3,-1] = np.array([-rotm[2,-1], -rotm[0,-1], rotm[1,-1]])\n",
    "# #     fix = np.array([[0,0,1],\n",
    "# #                     [1,0,0],\n",
    "# #                     [0,1,0]])\n",
    "# #     rotm[:3,:3] = rotm[:3,:3] @ fix\n",
    "\n",
    "# #     swap_axis_matrix = np.array([[0, 0, 1],\n",
    "# #                                  [1, 0, 0],\n",
    "# #                                  [0, 1, 0]])\n",
    "# # #             flip_axis_matrix = np.diag([-1,1,-1]) #was this\n",
    "# #     flip_axis_matrix = np.diag([1,1,-1]) # better ---> corrects flipping z issue when rendering\n",
    "# #     rotm[:3,:3] = flip_axis_matrix @ swap_axis_matrix @ rotm[:3,:3] \n",
    "\n",
    "#     #center camera horizontally in each patch\n",
    "#     crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "\n",
    "#     #account for the fact that sensor points back and to the left\n",
    "#     #used this rotation value on the VICET paper-- (I don't think their setup was a perfect 45deg as specified in their paper)\n",
    "# #             crop_angle -= np.deg2rad(44.97)\n",
    "# #             rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix()\n",
    "# # # #             #is crop angle already accounted for with redfix(?)\n",
    "#     rotm_crop = R.from_euler('xyz', [0,-crop_angle,0]).as_matrix()\n",
    "#     rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "#     #courtyard1\n",
    "#     rotm[2,-1] += 45 #translate above xy plane\n",
    "#     #--------------------------------------------------------------------------\n",
    "    \n",
    "    pc1_aligned = (rotm @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "    \n",
    "#     pc1_aligned = (np.linalg.pinv(initial_pose) @ pc1_aligned.T).T #TEST --> brings back to origin\n",
    "    \n",
    "    disp.append(Points(pc1_aligned[:,:3], c = 'r', r = 2.5, alpha = 0.25))\n",
    "    \n",
    "\n",
    "plt.show(disp, \"Training Data Sample\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41146201",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots(1,2)\n",
    "# ax[0].imshow(testimg[:,:,0])\n",
    "# ax[1].imshow(testimg[:,:,1], vmin=0, vmax=1)\n",
    "\n",
    "idx = 10\n",
    "ax[0].imshow(images[idx,:,:,0])\n",
    "ax[1].imshow(images[idx,:,:,1], vmin=0, vmax=1)\n",
    "\n",
    "# ax[0].imshow(testimg[:,:,0])\n",
    "# ax[1].imshow(testimg[:,:,1], vmin=0, vmax=1)\n",
    "\n",
    "# print(images[idx,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(poses))\n",
    "fig, ax = p.subplots()\n",
    "# ax.scatter(-poses[0,1,-1],poses[0,2,-1])\n",
    "ax.scatter(-poses[:,1,-1],poses[:,2,-1])\n",
    "# ax.scatter(-poses[:200,1,-1],poses[:200,2,-1])\n",
    "ax.set_aspect(\"equal\")\n",
    "print(np.shape(poses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a465ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(poses))\n",
    "fig, ax = p.subplots()\n",
    "ax.plot(poses[:,2,-1], poses[:,1,-1])\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02175af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate and visualize \"dirs\" points according to poses and patch specs\n",
    "#OLD- USING SPHERICAL POINT PROJECTION\n",
    "\n",
    "num_draw = 30 #128 #48 #number of patches to draw\n",
    "N_samples = 64 #only when visualizing all test points\n",
    "\n",
    "#Ouster OS1-64\n",
    "# phimin = np.deg2rad(-15.594)\n",
    "# phimax = np.deg2rad(17.743)\n",
    "phimin = np.deg2rad(-5) #debug\n",
    "phimax = np.deg2rad(27)\n",
    "# phimax = np.deg2rad(15.594) #test\n",
    "# phimin = np.deg2rad(-17.743)\n",
    "\n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "print(H, W)\n",
    "\n",
    "#test\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True, sharecam = False) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "for count in range(num_draw):\n",
    "    \n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    look_at_pose = count\n",
    "    c2w = poses[look_at_pose]\n",
    "    c2w = tf.cast(c2w, tf.float32)\n",
    "    near = 0.\n",
    "    far = 64.\n",
    "        \n",
    "    #was this\n",
    "#     phimin_temp = vertical_bins[count%n_vert_patches] \n",
    "#     phimax_temp = vertical_bins[count%n_vert_patches + 1]\n",
    "    #test -- send bins from top to bottom\n",
    "    phimin_temp = vertical_bins[len(vertical_bins) -1 - (count%n_vert_patches+1)] \n",
    "    phimax_temp = vertical_bins[len(vertical_bins) -1 - (count%n_vert_patches)]\n",
    "\n",
    "    #reformat for LiDAR depth measurements ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    vert_fov = np.rad2deg(phimax-phimin)\n",
    "    #[r, theta, phi]\n",
    "    dirs_test = tf.stack([-tf.ones_like(i), #r\n",
    "                          #theta\n",
    "                          (i - (1024//(2*n_rots)))  /(2048//(2*n_rots)) * (2*np.pi/n_rots), #for uninterpolated images\n",
    "                          #phi\n",
    "#                         (phimax_temp + phimin_temp)/2 + ((-j+(32//n_vert_patches))/(64//n_vert_patches))*(phimax_temp-phimin_temp) -np.pi/2\n",
    "                          #TEST-- linear ANGULAR spacing\n",
    "                          np.arcsin((phimax_temp + phimin_temp)/2 + ((-j+(32//n_vert_patches))/(64//n_vert_patches))*(phimax_temp-phimin_temp)) -np.pi/2\n",
    "                         ], -1)\n",
    "    dirs_test = tf.reshape(dirs_test,[-1,3])\n",
    "#     dirs_test = LC.s2c(LC, dirs_test)    #was this\n",
    "    dirs_test = spherical_to_cartesian(dirs_test)  #does the same thing\n",
    "    \n",
    "    #need to rotate red points into same frame as blue points \n",
    "#     rotm = R.from_euler('xyz', [0,-np.pi/2 + (phimax + phimin)/2,0]).as_matrix() #was this\n",
    "    rotm = R.from_euler('xyz', [0,-np.pi/2,0]).as_matrix() #test\n",
    "    dirs_test = dirs_test @ rotm\n",
    "    dirs_test = dirs_test @ tf.transpose(c2w[:3,:3])\n",
    "\n",
    "    dirs_test = dirs_test @ (c2w[:3,:3] \n",
    "                          @ R.from_euler('xyz', [0,0,np.pi/2]).as_matrix() #looked good but converged slightly off\n",
    "                          @ np.linalg.pinv(c2w[:3,:3]) )\n",
    "\n",
    "    rotm_fix = (c2w[:3,:3] \n",
    "                @ np.linalg.pinv(c2w[:3,:3]))\n",
    "    rays_d_test = tf.reduce_sum(dirs_test[..., np.newaxis, :] * rotm_fix, -1) #looks like I need to do this instead\n",
    "    rays_o_test = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d_test))\n",
    "    z_vals_test = tf.linspace(near, far, N_samples) \n",
    "    z_vals_test += tf.random.uniform(list(rays_o_test.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    #[image_height, image_width, batch_size, 3]\n",
    "    pts_test = rays_o_test[...,None,:] + rays_d_test[...,None,:] * z_vals_test[...,:,None]\n",
    "    pts_flat_test = tf.reshape(pts_test, [-1,3])\n",
    "\n",
    "#     #random color\n",
    "    cname = np.array([255*(np.random.rand()), 255*(np.random.rand()), 255*(np.random.rand())]).T.tolist()\n",
    "#     #use depth as color\n",
    "# #     d = images[count,:,:,0].flatten()\n",
    "#     d = images[30*num_draw + count,:,:,0].flatten()\n",
    "#     cname = np.array([d/1.5, d/1.5, d/1.5]).T.tolist()\n",
    "\n",
    "#     disp.append(Points(pts_flat_test, c = cname, r = 3, alpha = 0.5)) \n",
    "    disp.append(Points(dirs_test, c = cname, r = 3, alpha = 0.75))\n",
    "#     disp.append(Points(dirs_test, c = 'pink', r = 3, alpha = 0.8))\n",
    "    disp.append(Points(dirs_test[:10], c = 'red', r = 5, alpha = 0.8))\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    #draw frames first pose\n",
    "    #forward view direction (-z in NeRF c2w convention) \n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0,0,-0.3])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"yellow\"))\n",
    "    # x\n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0.3,0,0])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"red\"))\n",
    "    #y\n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0,0.3,0])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"green\"))\n",
    "    #z\n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0,0,0.3])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"blue\"))\n",
    "\n",
    "plt.show(disp, \"dirs\", at = 0)\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e7706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate and visualize \"dirs\" points according to poses and patch specs\n",
    "\n",
    "#TEST-- try using cylindrical point projection to generate dist\n",
    "\n",
    "num_draw = 16 #128 #48 #number of patches to draw\n",
    "N_samples = 64 #only when visualizing all test points\n",
    "#IMPORTANT-- this needs to match values used when setting up training data \n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "\n",
    "#Ouster OS1-64\n",
    "phimin = np.deg2rad(-15) \n",
    "phimax = np.deg2rad(17.75)\n",
    "# phimin = np.deg2rad(-17.75) \n",
    "# phimax = np.deg2rad(16)\n",
    "# phimin = np.deg2rad(-55) \n",
    "# phimax = np.deg2rad(55)\n",
    "\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True, sharecam = False) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "for count in range(num_draw):\n",
    "    \n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    look_at_pose = count\n",
    "    c2w = poses[look_at_pose]\n",
    "    c2w = tf.cast(c2w, tf.float32)\n",
    "    near = 0.\n",
    "    far = 2.\n",
    "        \n",
    "    #send bins from top to bottom\n",
    "    phimin_temp = vertical_bins[len(vertical_bins) -1 - (count%n_vert_patches+1)] \n",
    "    phimax_temp = vertical_bins[len(vertical_bins) -1 - (count%n_vert_patches)]\n",
    "\n",
    "    #reformat for LiDAR depth measurements ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    vert_fov = np.rad2deg(phimax-phimin)\n",
    "    #[r, theta, phi]\n",
    "    dirs_test = tf.stack([-tf.ones_like(i), #r\n",
    "                          #theta\n",
    "                          (i - (1024//(2*n_rots)))  /(2048//(2*n_rots)) * (2*np.pi/n_rots) + np.pi,\n",
    "                          #phi\n",
    "                          #OLD-- constant spacing vertical direction (not quite right) \n",
    "#                           (phimax_temp + phimin_temp)/2 - ((-j+(32//n_vert_patches))/(64//n_vert_patches))*(phimax_temp-phimin_temp) \n",
    "                          #NEW-- constant spacing in elevation ANGULAR direction\n",
    "                          np.arcsin((phimax_temp + phimin_temp)/2 - ((-j+(32//n_vert_patches))/(64//n_vert_patches))*(phimax_temp-phimin_temp))                          \n",
    "                         ], -1)\n",
    "    dirs_test = tf.reshape(dirs_test,[-1,3])\n",
    "    dirs_test = cylindrical_to_cartesian(dirs_test)\n",
    "\n",
    "    #need to rotate red points into same frame as blue points \n",
    "#     rotm = R.from_euler('xyz', [0,-np.pi/2 + (phimax + phimin)/2,0]).as_matrix() #was this\n",
    "    rotm = R.from_euler('xyz', [0,-np.pi/2,0]).as_matrix() #test\n",
    "    dirs_test = dirs_test @ rotm\n",
    "    dirs_test = dirs_test @ tf.transpose(c2w[:3,:3])\n",
    "    # aligns dirs, doesn't get pts_flat to work yet\n",
    "    dirs_test = dirs_test @ (c2w[:3,:3] \n",
    "                          @ R.from_euler('xyz', [0,0,np.pi/2]).as_matrix() #looked good but converged slightly off\n",
    "                          @ np.linalg.pinv(c2w[:3,:3]) )\n",
    "\n",
    "    rotm_fix = (c2w[:3,:3] \n",
    "                @ np.linalg.pinv(c2w[:3,:3]))\n",
    "    rays_d_test = tf.reduce_sum(dirs_test[..., np.newaxis, :] * rotm_fix, -1) #looks like I need to do this instead\n",
    "    rays_o_test = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d_test))\n",
    "    z_vals_test = tf.linspace(near, far, N_samples) \n",
    "    z_vals_test += tf.random.uniform(list(rays_o_test.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    #[image_height, image_width, batch_size, 3]\n",
    "    pts_test = rays_o_test[...,None,:] + rays_d_test[...,None,:] * z_vals_test[...,:,None]\n",
    "    pts_flat_test = tf.reshape(pts_test, [-1,3])\n",
    "\n",
    "    #random color\n",
    "    cname = np.array([255*(np.random.rand()), 255*(np.random.rand()), 255*(np.random.rand())]).T.tolist()\n",
    "    #use depth as color\n",
    "# #     d = images[count,:,:,0].flatten()\n",
    "#     d = images[30*num_draw + count,:,:,0].flatten()\n",
    "#     cname = np.array([d/1.5, d/1.5, d/1.5]).T.tolist()\n",
    "    \n",
    "#     print(np.shape(pts_flat_test), np.shape(poses[count,-1,:3][:,None]))\n",
    "\n",
    "    centered = pts_flat_test - poses[count,:3,-1]\n",
    "    \n",
    "#     disp.append(Points(pts_flat_test, c = cname, r = 3, alpha = 0.125)) \n",
    "#     disp.append(Points(centered, c = cname, r = 3, alpha = 0.125)) \n",
    "    disp.append(Points(dirs_test, c = cname, r = 3, alpha = 0.5))\n",
    "#     disp.append(Points(dirs_test, c = 'pink', r = 3, alpha = 0.8))\n",
    "    disp.append(Points(dirs_test[:10], c = 'red', r = 5, alpha = 0.8))\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    #draw frames first pose\n",
    "    #forward view direction (-z in NeRF c2w convention) \n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0,0,-0.3])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"yellow\"))\n",
    "    # x\n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0.3,0,0])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"red\"))\n",
    "    #y\n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0,0.3,0])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"green\"))\n",
    "    #z\n",
    "    headings = poses[look_at_pose,:3,:3] @ np.array([0,0,0.3])\n",
    "    disp.append(Arrows(np.zeros([3,1]), (np.zeros([3,1]) + headings), c = \"blue\"))\n",
    "\n",
    "plt.show(disp, \"dirs\", at = 0)\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots()\n",
    "delta_z = np.diff(np.deg2rad(dirs_test[::8,0]))\n",
    "ax.plot(delta_z)\n",
    "ax.set_title(\"change in z per elevation angle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837049f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug: view grid of patches\n",
    "n_vert_patches = 8\n",
    "view_scan_num = 8 #which scan to look at\n",
    "num_view_rots = 10\n",
    "\n",
    "fig, ax = p.subplots(n_vert_patches, num_view_rots)\n",
    "\n",
    "for i in range(num_view_rots):\n",
    "    for j in range(n_vert_patches):\n",
    "        ax[j,i].imshow(images[num_draw*view_scan_num + j + i*n_vert_patches,:,:,0])#, vmin = 0, vmax = 1)\n",
    "#         ax[j,i].imshow(np.flip(images[-(j + i*n_vert_patches),:,:,0], axis = 0), vmin = 0, vmax = 4)\n",
    "        ax[j,i].get_xaxis().set_visible(False)\n",
    "        ax[j,i].get_yaxis().set_visible(False)\n",
    "        ax[j,i].set_aspect(W/H)\n",
    "# p.subplots_adjust(wspace=0.1, hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbe138",
   "metadata": {},
   "outputs": [],
   "source": [
    "## view patches (assumes sigle n_vert_patches == 1)\n",
    "# %matplotlib notebook\n",
    "fig, ax = p.subplots(2,5)\n",
    "ax[0,0].set_title(\"depth image patches for training\")\n",
    "\n",
    "# ax[0,0].imshow(images[0,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,1].imshow(images[1,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,2].imshow(images[2,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,3].imshow(images[3,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,4].imshow(images[4,:,:,0])#, vmin=0, vmax=64)\n",
    "\n",
    "# ax[0,0].imshow(images[-20,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,1].imshow(images[-19,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,2].imshow(images[-18,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,3].imshow(images[-17,:,:,0])#, vmin=0, vmax=64)\n",
    "# ax[0,4].imshow(images[-16,:,:,0])#, vmin=0, vmax=64)\n",
    "\n",
    "ax[0,0].imshow(images[-4,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,1].imshow(images[-3,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,2].imshow(images[-2,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,3].imshow(images[-1,:,:,0])#, vmin=0, vmax=64)\n",
    "ax[0,4].imshow(testimg[:,:,0])#, vmin=0, vmax=64)\n",
    "\n",
    "ax[1,0].set_title(\"ray drop masks\")\n",
    "ax[1,0].imshow(images[-4,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,1].imshow(images[-3,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,2].imshow(images[-2,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,3].imshow(images[-1,:,:,1],cmap=\"gray\", vmin=0,vmax=1)\n",
    "ax[1,4].imshow(testimg[:,:,1],cmap=\"gray\", vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc14331",
   "metadata": {},
   "outputs": [],
   "source": [
    "phimin = np.deg2rad(-16) \n",
    "phimax = np.deg2rad(17.75)\n",
    "print(phimin, phimax)\n",
    "\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "print(vertical_bins, \"\\n\")\n",
    "\n",
    "for count in range(10):\n",
    "    phimin_temp = vertical_bins[count%n_vert_patches] \n",
    "    phimax_temp = vertical_bins[(count)%n_vert_patches + 1]\n",
    "    print(phimin_temp, phimax_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c2892",
   "metadata": {},
   "source": [
    "# Animate GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd9ae9-e01e-4c49-8c42-13a7766c0241",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#figure out translation using GT\n",
    "# fig, ax = p.subplots()\n",
    "sidx = 550\n",
    "eidx = 1000\n",
    "# ax.plot(gt[sidx:eidx,2], gt[sidx:eidx,3])\n",
    "# ax.set_aspect('equal')\n",
    "# print(gt[0,2:5]/50)\n",
    "print(rotm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c183c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_frames = 50\n",
    "num_view = 64 #128 #number of (rotational?) patches to draw\n",
    "n_rots = 64 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #number of vertical patches between phimin and phimax\n",
    "N_samples = 128 #64 #does not have to match what was used in training?? \n",
    "\n",
    "H = 64\n",
    "W = 1024 // n_rots\n",
    "\n",
    "for i in range(num_frames):\n",
    "    print(i)\n",
    "    plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), offscreen=True)\n",
    "    disp=[] \n",
    "    \n",
    "    for j in range(num_view):\n",
    "        rotm = np.eye(4)\n",
    "        # account for image crop in rotation -------------------\n",
    "#         crop_angle =  -(np.pi/n_rots) + j*(2*np.pi/n_rots) #old\n",
    "        crop_angle =  -(np.pi/n_rots) - j*(2*np.pi/n_rots) #test\n",
    "        rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix()\n",
    "        rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "        #also need to account for the fact that the LIDAR beam isn't actually centered at horizon\n",
    "        sensor_elevation_zero_rotm = R.from_euler('xyz', [(phimin+phimax)/2,0,0]).as_matrix()\n",
    "        rotm[:3,:3] = rotm[:3,:3] @ sensor_elevation_zero_rotm\n",
    "        # ------------------------------------------------------\n",
    "\n",
    "        # flip x and z axis\n",
    "        rotm[0,-1], rotm[2,-1] = rotm[2,-1], rotm[0,-1] \n",
    "\n",
    "        rotm[0:3,2] *= -1 # flip sign of y and z axis\n",
    "        rotm[0:3,1] *= -1\n",
    "        rotm = rotm[[1,0,2,3],:]\n",
    "        rotm[2,:] *= -1 # flip whole world upside down\n",
    "#         rotm[2,-1] = 0.25 + (i/100) #x in world frame output\n",
    "#         rotm[0,-1] = -0.02 #-0.003 #- (i/3) #z in world frame output\n",
    "#         rotm[1,-1] = .5 + (i/100) #y in world frame\n",
    "#         rotm[2,-1] = 0.5 #x in world frame output\n",
    "#         rotm[0,-1] = -0.02 #-0.003 #- (i/3) #z in world frame output\n",
    "#         rotm[1,-1] = .25 + (i/100) #y in world frame\n",
    "        rotm[2,-1] = 0.325 #x in world frame output\n",
    "        rotm[0,-1] = 0.01 #-0.003 #- (i/3) #z in world frame output\n",
    "        rotm[1,-1] = 0.325  + (i/400)\n",
    "\n",
    "        # #test using gt ~~~~~~~~~~\n",
    "        # # start: [-0.0671118   0.165084    0.00291402]\n",
    "        # rotm[1,-1] = gt[10*i+700,2]/50 #x in world frame output\n",
    "        # rotm[2,-1] = -gt[10*i+700,3]/50 #y in world frame -- need to account for how we translated training data\n",
    "        # rotm[0,-1] = -gt[10*i+700,4]/50 - 45/50 #z in world frame output\n",
    "        # print(rotm[:,-1])\n",
    "        # #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        rotm = rotm.astype(np.float32)\n",
    "\n",
    "        # phimin = np.deg2rad(-15.594) \n",
    "        # phimax = np.deg2rad(17.743)\n",
    "        phimax = np.deg2rad(15.594)#FLIPPED \n",
    "        phimin = np.deg2rad(-17.743)\n",
    "#         phimax = np.deg2rad(16)#centered (debug only) \n",
    "#         phimin = np.deg2rad(-16)\n",
    "        \n",
    "        vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "        phimin_patch = vertical_bins[img_i%n_vert_patches] \n",
    "        phimax_patch = vertical_bins[img_i%n_vert_patches + 1]\n",
    "\n",
    "        #call NeRF using specified novel rotm\n",
    "        rays_o, rays_d = get_rays(H, W, rotm, phimin_patch, phimax_patch)\n",
    "    #     depth, acc, ray_drop = render_rays(model, rays_o, rays_d, near=0., far=2., N_samples=N_samples)\n",
    "        z_vals = tf.linspace(near, far, N_samples) \n",
    "        z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "        z_vals = z_vals[:,:,:,None]\n",
    "        depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "\n",
    "        #~~~~~~~~~~~\n",
    "        #run fine pass through network\n",
    "        fwd = np.append(np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), weights, axis = -1)\n",
    "        rev = np.append(weights, np.zeros([np.shape(weights)[0], np.shape(weights)[1], 1]), axis = -1)\n",
    "        fwd_test = np.max(sliding_window_view(fwd, window_shape = 2, axis = 2), axis = -1)\n",
    "        rev_test = np.max(sliding_window_view(rev, window_shape = 2, axis = 2), axis = -1)\n",
    "        test2 = (fwd_test + rev_test) /2 #blur\n",
    "        test2 += 1/(3*N_samples) #shift up slightly\n",
    "        test2 = test2 / np.sum(test2, axis = -1)[:,:,None] #renormalize\n",
    "        cum_hist_vals = np.cumsum(test2, axis = -1)\n",
    "        randy = np.sort(0.1*np.random.randn(N_samples*W*H)) \n",
    "        cum_hist_vals_flat = cum_hist_vals.flatten()\n",
    "        step_corr = np.linspace(0,W*H-1,W*H)\n",
    "        step_corr = np.tile(step_corr,(N_samples,1)).T\n",
    "        step_corr = np.reshape(step_corr, [1,-1])[0,:]\n",
    "        cum_hist_vals_flat+= step_corr\n",
    "        linear_spaced = np.linspace(near, H*W, N_samples*H*W)\n",
    "        ans = np.interp(x=linear_spaced, xp=cum_hist_vals_flat, fp=linear_spaced)\n",
    "        ans -= step_corr\n",
    "#         ans *= 2\n",
    "        ans = np.abs(ans)\n",
    "        z_vals = np.reshape(ans, [H,W,N_samples,1])\n",
    "        depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        #~~~~~~~~~~~\n",
    "\n",
    "        new_point_cloud_spherical = np.zeros([np.shape(depth)[0]*np.shape(depth)[1],3])\n",
    "        depth = tf.transpose(depth).numpy() #need this\n",
    "        depth = np.flip(depth, axis = 0) #needed\n",
    "\n",
    "        #scale back up to normal size\n",
    "        depth *= 200 #60 #20\n",
    "        ray_drop = tf.transpose(ray_drop).numpy() #test\n",
    "        ray_drop = np.flip(ray_drop, axis = 0) #test\n",
    "\n",
    "        count = 0\n",
    "        for w in range(W):\n",
    "            for h in range(H):\n",
    "    #             #draw all points\n",
    "#                 new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "#                 suppress ray dropped points\n",
    "                if ray_drop[w,h] > 0.9:\n",
    "                        new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "                else:\n",
    "                        new_point_cloud_spherical[count,0] = 0#100\n",
    "                new_point_cloud_spherical[count,1] = (w-(1024//(2*n_rots)))/(2048//(2*n_rots))*(2*np.pi/n_rots)            \n",
    "\n",
    "                #space linearly in z\n",
    "                new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/(np.shape(depth_img)[1] - 1)) #BETTER(?)\n",
    "                #space linearly in elevation angle\n",
    "                # new_point_cloud_spherical[count,2] = np.pi/2 + np.arcsin(phimax - (phimax-phimin)*(h/(np.shape(depth_img)[1] - 1))) #[17.74,-15.59] #(correct)       \n",
    "    \n",
    "                count+= 1\n",
    "\n",
    "#         new_point_cloud_spherical[:,1] -= (np.pi/n_rots) - j*(2*np.pi/n_rots) #old\n",
    "        new_point_cloud_spherical[:,1] -= (np.pi/n_rots) + j*(2*np.pi/n_rots) #test\n",
    "\n",
    "        new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy()\n",
    "        new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z \n",
    "#         new_point_cloud_cart[:,1] = -new_point_cloud_cart[:,1] #for synthetic data\n",
    "        \n",
    "        #translate to keep camera fixed in place\n",
    "        new_point_cloud_cart[:,0] += -3.5 + 15*i/30\n",
    "#         new_point_cloud_cart[:,0] += 1.5 + i/2\n",
    "#         new_point_cloud_cart[:,0] += 15 + i/2\n",
    "#         new_point_cloud_cart[:,1] -= 20 - i/2\n",
    "    \n",
    "        # rainbow by z height\n",
    "        zheight = 65*(np.sin(0.25*new_point_cloud_cart[:,2])+1)\n",
    "        cname = np.array([1-zheight, zheight, 1.5*zheight]).T.tolist()\n",
    "        disp.append(Points(new_point_cloud_cart, c = cname, r = 2., alpha = 0.5))\n",
    "        \n",
    "    #for raw data\n",
    "    cam = dict(\n",
    "        pos=(37.30093, 95.07558, 94.30112),\n",
    "        focalPoint=(8.715815, 0.7997105, -0.04585656),\n",
    "        viewup=(-0.2068594, -0.6600254, 0.7222019),\n",
    "        distance=136.4053,\n",
    "        clippingRange=(53.80149, 240.4701),\n",
    "    )\n",
    "#     #synthetic data\n",
    "#     cam = dict(\n",
    "#     pos=(10.65918, -107.0537, 101.1803),\n",
    "#     focalPoint=(11.55028, -1.807423, 1.020487),\n",
    "#     viewup=(0.01507708, 0.6892402, 0.7243760),\n",
    "#     distance=145.2913,\n",
    "#     clippingRange=(85.29556, 214.5295),\n",
    "#     )\n",
    "\n",
    "    plt.show(disp, \"Novel Point Cloud From NeRF at [\" \n",
    "             + str(np.round(-rotm[2,-1]*20, decimals=2)) + \", \" + str(np.round(-rotm[1,-1]*20, decimals=2)) + \", \" + str(np.round(-rotm[0,-1]*20, decimals=2)) + \"]\",\n",
    "             camera= cam).screenshot(\"lidar_nerf_demo/Newer_College_V2_\" + str(i) + \".png\")\n",
    "#     plt.show(disp, \"Novel Point Cloud From NeRF at [\" \n",
    "#              + str(np.round(-rotm[2,-1]*20, decimals=2)) + \", \" + str(np.round(-rotm[1,-1]*20, decimals=2)) + \", \" + str(np.round(-rotm[0,-1]*20, decimals=2)) + \"]\").screenshot(\"lidar_nerf_demo/Newer_College_V2_\" + str(i) + \".png\")\n",
    "    plt.clear()\n",
    "    plt.close()\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3a5e5",
   "metadata": {},
   "source": [
    "# Remove motion distortion from raw point cloud data used to train NeRF\n",
    "\n",
    "I believe directly training on motion-distorted raw point clouds is responsible for the \"wiggly\" motion of some walls observed in the rendered GIFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8a012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load HD Map\n",
    "pl = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply'\n",
    "HD_map = trimesh.load(pl).vertices\n",
    "show_nth = 5 #10\n",
    "submap = HD_map[::show_nth]\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(submap, c = \"gray\", r = 2.5, alpha = 0.2)) \n",
    "plt.show(disp, \"HD Map\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7800 #1450 #700    \n",
    "fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "fn2 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx +1) + \".npy\"\n",
    "pc1 = np.load(fn1)\n",
    "pc2 = np.load(fn2)\n",
    "# pc1 = np.flip(pc1, axis = 0)# uncomment to flip and maintain CCW convention used in VICET\n",
    "# pc2 = np.flip(pc2, axis = 0)# uncomment to flip and maintain CCW convention used in VICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76234e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"/media/derm/06EF-127D4/Newer College Dataset/\"\n",
    "experiment_name = \"01_short_experiment-20230331T172433Z-009/01_short_experiment/\"\n",
    "fn_gt = dir_name + experiment_name + \"ground_truth/registered_poses.csv\"\n",
    "# print(fn_gt)\n",
    "\n",
    "#sec,nsec,x,y,z,qx,qy,qz,qw\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "\n",
    "seconds = gt[:, 0]\n",
    "nano_seconds = gt[:, 1]\n",
    "xyz = gt[:, 2:5]\n",
    "qxyzw = gt[:, 5:]\n",
    "num_poses = qxyzw.shape[0]\n",
    "sensor_poses = np.eye(4, dtype=np.float64).reshape(1, 4, 4).repeat(num_poses, axis=0)\n",
    "sensor_poses[:, :3, :3] = R.from_quat(qxyzw).as_matrix()\n",
    "sensor_poses[:, :3, 3] = xyz\n",
    "T_CL = np.eye(4, dtype=np.float32)\n",
    "T_CL[:3, :3] = R.from_quat([0.0, 0.0, 0.924, 0.383]).as_matrix() #was this --1134.97 deg\n",
    "T_CL[:3, 3] = np.array([-0.084, -0.025, 0.050], dtype=np.float32) #was this\n",
    "sensor_poses = np.einsum(\"nij,jk->nik\", sensor_poses, T_CL)\n",
    "initial_pose = np.linalg.inv(sensor_poses[0]) \n",
    "poses_timestamps = seconds * 10e9 + nano_seconds\n",
    "sensor_poses = np.einsum(\"ij,njk->nik\", np.linalg.inv(sensor_poses[0]), sensor_poses)\n",
    "\n",
    "# print(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629675d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "#TODO: get body-frame euler angles from ground truth\n",
    "fig, ax = p.subplots(4,2)\n",
    "start_idx = 500\n",
    "end_idx = 800\n",
    "\n",
    "ax[0,0].set_title(\"frames from ground truth\")\n",
    "ax[0,0].plot(sensor_poses[start_idx:end_idx,0,-1], sensor_poses[start_idx:end_idx,1,-1])\n",
    "ax[0,0].set_aspect(1)\n",
    "\n",
    "#plot velocity in world frame\n",
    "vel_world_frame = np.diff(sensor_poses[:,:3,-1], axis = 0)\n",
    "ax[1,0].set_title(\"x vel in world frame\")\n",
    "ax[1,0].plot(vel_world_frame[start_idx:end_idx,0])\n",
    "ax[1,1].set_title(\"y vel in world frame\")\n",
    "ax[1,1].plot(vel_world_frame[start_idx:end_idx,1])\n",
    "\n",
    "#get velocity in body frame\n",
    "# rotm = R.from_euler('xyz',[0,0,3*np.pi/4]).as_matrix()\n",
    "rotm = R.from_euler('xyz',[0,0,0]).as_matrix()\n",
    "# vel_body_frame = poses[1:,:3,:3] @ rotm @ vel_world_frame[:,:,None]\n",
    "vel_body_frame = np.linalg.pinv(sensor_poses[1:,:3,:3]) @ rotm @ vel_world_frame[:,:,None]\n",
    "\n",
    "vel_body_frame = vel_body_frame[:,:,0]\n",
    "ax[2,0].set_title(\"x vel body frame\")\n",
    "ax[2,0].plot(vel_body_frame[start_idx:end_idx,0])\n",
    "ax[2,1].set_title(\"y vel body frame\")\n",
    "ax[2,1].plot(vel_body_frame[start_idx:end_idx,1])\n",
    "\n",
    "#smooth out velocity estimates\n",
    "def moving_average(a, n=10):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "window=50\n",
    "MAx = moving_average(vel_body_frame[:,0], n = window)\n",
    "ax[3,0].plot(MAx[start_idx:end_idx+window-1])\n",
    "ax[3,0].set_title(\"smoothed x vel (body frame)\")\n",
    "MAy = moving_average(vel_body_frame[:,1], n = window)\n",
    "ax[3,1].plot(MAy[start_idx:end_idx+window-1])\n",
    "ax[3,1].set_title(\"smoothed y vel (body frame)\")\n",
    "MAz = moving_average(vel_body_frame[:,2], n = window)\n",
    "\n",
    "vel_body_frame = np.array([MAx, MAy, MAz]).T\n",
    "\n",
    "#plot heading on map\n",
    "for i in range(start_idx,end_idx,100):\n",
    "    heading = np.array([5,0,0]) @ np.linalg.pinv(sensor_poses[i, :3, :3]) @ rotm\n",
    "    end = sensor_poses[i, :3, -1] + heading\n",
    "    ax[0,0].plot([sensor_poses[i,0,-1], end[0]], [sensor_poses[i,1,-1], end[1]], color='red' )\n",
    "\n",
    "    heading = np.array([0,5,0]) @ np.linalg.pinv(sensor_poses[i, :3, :3]) @ rotm\n",
    "    end = sensor_poses[i, :3, -1] + heading\n",
    "    ax[0,0].plot([sensor_poses[i,0,-1], end[0]], [sensor_poses[i,1,-1], end[1]], color='green' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6427cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get rotational velocity\n",
    "#get straight diff (was this)-- not going to work?\n",
    "rot_vel_euls = np.diff(R.from_matrix(sensor_poses[:,:3,:3]).as_euler('xyz'), axis = 0)\n",
    "\n",
    "# rot_vel_euls = np.zeros([len(poses)-1,3])\n",
    "# for i in range(1,len(poses)):\n",
    "#     pose_i_in_last_frame = np.linalg.pinv(poses[i-1,:3,:3]) @ poses[i,:3,:3]\n",
    "#     end = R.from_matrix(sensor_pose_i_in_last_frame).as_euler('xyz')\n",
    "#     rot_vel_euls[i-1] = end - R.from_matrix(poses[i-1,:3,:3]).as_euler('xyz')\n",
    "# rot_vel_euls = np.diff(rot_vel_euls, axis = 0)\n",
    "\n",
    "fig, ax = p.subplots(3)\n",
    "ax[0].plot(rot_vel_euls[start_idx:end_idx,0])\n",
    "ax[0].set_label(\"roll\")\n",
    "ax[1].plot(rot_vel_euls[start_idx:end_idx,1])\n",
    "ax[1].set_label(\"pitch\")\n",
    "ax[2].plot(rot_vel_euls[start_idx:end_idx,2])\n",
    "ax[2].set_label(\"yaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                  -vel_body_frame[idx,1],\n",
    "                  -vel_body_frame[idx,2],\n",
    "                  -rot_vel_euls[idx,0],\n",
    "                  -rot_vel_euls[idx,1],\n",
    "                  -rot_vel_euls[idx,2]\n",
    "                  # 0,0,0\n",
    "                 ])\n",
    "# from old version of VICET (very slow)\n",
    "# from remove_motion_basic import linear_correction_old as lc\n",
    "# rectified_pc1 = lc(pc1, m_hat, period_lidar=1.)\n",
    "#much faster\n",
    "rectified_pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "\n",
    "pc1 = np.flip(pc1, axis = 0)# uncomment at the end to get image projection to work\n",
    "rectified_pc1 = np.flip(rectified_pc1, axis = 0)# uncomment at the end to get image projection to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0af98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "#transform map to pc1 frame (for debug)\n",
    "# submap_in_pc1_frame = (np.linalg.pinv(sensor_poses[idx]) @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T\n",
    "\n",
    "submap_in_pc1_frame = (np.linalg.pinv(sensor_poses[idx]) @ initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #test\n",
    "\n",
    "submap_in_pc1_frame = submap_in_pc1_frame[:,:3]\n",
    "\n",
    "disp.append(Points(submap_in_pc1_frame, c = \"black\", r = 3, alpha = 0.1)) ##CB2314\n",
    "\n",
    "\n",
    "# DRAW SCANS 1, 2\n",
    "disp.append(Points(pc1, c = '#a65852', r = 3)) #red\n",
    "# disp.append(Points(rectified_pc1, c = '#2c7c94', r = 3)) #blue\n",
    "## purple -> green\n",
    "color = 255*np.linspace(0,1,len(rectified_pc1)) \n",
    "cname = np.array([255-color, color, 255-color]).T.tolist()\n",
    "disp.append(Points(rectified_pc1, c=cname,  r = 3.5, alpha =0.5))\n",
    "\n",
    "\n",
    "plt.show(disp, \"01 Short Experiment Frame #\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32edd2",
   "metadata": {},
   "source": [
    "# Generate fake LIDAR scans from HD Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_scan_from_map(hd_map, p, res = [64, 1024], \n",
    "                      phimin = np.pi/2 + np.deg2rad(-17.743), \n",
    "                      phimax = np.pi/2 + np.deg2rad(15.594), \n",
    "                      tol = 0.001, use_IP = True):\n",
    "    \"\"\"p = pose, homogemous coordinates\"\"\"\n",
    "        \n",
    "    #align hd map about origin according to pose\n",
    "    if use_IP:\n",
    "        centered_map = (np.linalg.pinv(p) @ initial_pose @ np.append(hd_map, np.ones([len(hd_map),1]), axis =1).T).T\n",
    "    else:\n",
    "        centered_map = (np.linalg.pinv(p) @ np.append(hd_map, np.ones([len(hd_map),1]), axis =1).T).T\n",
    "    centered_map_s = cartesian_to_spherical(centered_map)\n",
    "    \n",
    "    #remove points outside vertical fov\n",
    "    centered_map_s = centered_map_s[centered_map_s[:,2] > phimin]\n",
    "    centered_map_s = centered_map_s[centered_map_s[:,2] < phimax]\n",
    "    centered_map_s = centered_map_s[centered_map_s[:,0]< 100]\n",
    "    \n",
    "    #test looking at narrow azimuth range\n",
    "    #sort by azimuth angle\n",
    "    centered_map_s = centered_map_s.numpy()\n",
    "    sorted_indices = centered_map_s[:,1].argsort() #[-pi, pi]\n",
    "    centered_map_s = centered_map_s[sorted_indices]\n",
    "\n",
    "    #just keep points that are within tol of a phi angle\n",
    "    scan = np.zeros([0,3])\n",
    "    gp = np.linspace(phimin, phimax, res[0]) #good phis\n",
    "\n",
    "    #loop through each horizontal angle\n",
    "    for j in range(res[1]):\n",
    "        centered_map_s_slice = centered_map_s[centered_map_s[:,1] > (-np.pi + (2*np.pi*j/res[1]))]\n",
    "        centered_map_s_slice = centered_map_s_slice[centered_map_s_slice[:,1] < (-np.pi + (2*np.pi*(j+1)/res[1]))]\n",
    "#         print(j)\n",
    "        \n",
    "        #loop through each elevation angle\n",
    "        for i in range(res[0]):\n",
    "            tol_temp = tol\n",
    "            good = np.zeros([0,3])\n",
    "            count = 0\n",
    "            #gradually up tolerance about sampling angle until sufficient number of points are captured in scan line\n",
    "            # or increasing tolerance no longer helps\n",
    "            while (np.shape(good)[0] < (3*1024)//(res[1])):\n",
    "                good = centered_map_s_slice[abs(centered_map_s_slice[:,2] - gp[i]) < tol_temp ]\n",
    "                tol_temp *= 1.5\n",
    "                if count > 5:\n",
    "                    np.zeros([0,3])\n",
    "                    break\n",
    "                count += 1\n",
    "\n",
    "            #add closest point to scan, give it theoretical target elevation and azimuth\n",
    "            if len(good) >= 1:\n",
    "                best_r = min(good[:,0])\n",
    "            else:\n",
    "                best_r = 0\n",
    "            best_point_s = np.array([[best_r, -np.pi + np.pi/res[1] + (2*np.pi*j/res[1]), gp[i]]]) #[r, elev, azim]\n",
    "            scan = np.append(scan, best_point_s, axis = 0)\n",
    "        \n",
    "    scan = spherical_to_cartesian(scan)\n",
    "    return scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_scan(HD_map, scan_dims = [64,1024], phimin = np.deg2rad(-15.594), phimax = np.deg2rad(17.743)):\n",
    "    phimin += np.pi/2 \n",
    "    phimax += np.pi/2\n",
    "    \n",
    "    newPose = np.eye(4)\n",
    "    #[-53, -5]x, [-10,10]y, [0.5,3]z\n",
    "    trans = np.array([-43,-5,0.5]) + np.array([28,10,2.5])*np.random.rand(3) #just center of courtyard\n",
    "#     trans = np.array([-53,-10,0.5]) + np.array([48,20,2.5])*np.random.rand(3) #full space\n",
    "    trans_mapframe = R.from_euler('xyz', [0,0,np.pi/4]).as_matrix() @ trans #rotate to map coordinate system\n",
    "    newPose[0:3,-1] = trans_mapframe\n",
    "    simulated_scan = gen_scan_from_map(HD_map, newPose, res = scan_dims, phimin = phimin, phimax = phimax)[:,:3]\n",
    "    # simulated_scan = gen_scan_from_map(HD_map, newPose, res = scan_dims, phimin = np.pi/2 + np.deg2rad(-20), phimax = np.pi/2 + np.deg2rad(10))[:,:3] #debug\n",
    "    \n",
    "#     simulated_scan = None #temp for debug only\n",
    "    \n",
    "    return(newPose, simulated_scan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7218b4-3e97-4da6-ab7a-e416ecf4d311",
   "metadata": {},
   "source": [
    "# Need to get better ground truth for LIDAR scans\n",
    "\n",
    "* Remove translational motion distortion from raw scans using smoothed gt velocity\n",
    "* Downsample HD Map using growing cones strategy\n",
    "* Register undistorted PC against HD map using ICET\n",
    "* Use output of ICET to update gt\n",
    "* Train NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e287e-77af-4666-8bf1-0984e1dfda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample HD Map to resemble LIDAR scan\n",
    "newPose = np.eye(4)\n",
    "simulated_scan = gen_scan_from_map(submap_in_pc1_frame, newPose, res = [64,128], use_IP = False)[:,:3]\n",
    "\n",
    "initial_guess = tf.constant([0.,0.,0.,0.,0.,0.])\n",
    "#resutlts with full cloud: [ 0.27173612  0.07726155 -0.02524593  0.00388683  0.0106992  -0.02185947]\n",
    "it = ICET(cloud1 = submap_in_pc1_frame, cloud2 = pc1, fid = 70, niter = 10, \n",
    "       draw = False, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "#result with simulated scan: [ 0.2829418   0.07808943 -0.00657902  0.00399441  0.01081101 -0.02118503] (pretty much the same)\n",
    "# it = ICET(cloud1 = simulated_scan, cloud2 = pc1, fid = 70, niter = 10, \n",
    "#        draw = False, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "disp.append(Points(pc1, c = 'red', r =3))\n",
    "disp.append(Points(it.cloud2_tensor.numpy(), c = 'blue', r =3))\n",
    "disp.append(Points(simulated_scan, c = 'black', r = 3, alpha = 0.5))\n",
    "disp.append(Points(submap_in_pc1_frame, c = 'gray', r = 2, alpha = 0.25))\n",
    "# disp.append(Points(submap, c = 'purple', r = 2, alpha = 0.1))\n",
    "plt.show(disp, \"01 Short Experiment Frame #\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a34028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 7900 #7800\n",
    "# newPose = sensor_poses[idx].copy()\n",
    "# newPose = newPose @ np.linalg.pinv(initial_pose)\n",
    "# newPose = initial_pose.copy()\n",
    "# newPose[:3,:3] = newPose[:3,:3] @ R.from_euler('xyz', [0,0,np.pi/4]).as_matrix() #rotate 45 deg about z\n",
    "# newPose[0,-1] = -15 #-30 + np.random.rand()*15 #[-5,-30]\n",
    "# newPose[1,-1] = 0 #-25 + np.random.rand()*10 #[-15, -25]\n",
    "# newPose[2,-1] = 0.5 + np.random.rand()*2 #[1,3]\n",
    "\n",
    "p1, s1 = create_random_scan(HD_map, scan_dims = [64, 128], phimin = np.deg2rad(-15.594), phimax = np.deg2rad(17.743))\n",
    "p2, s2 = create_random_scan(HD_map, scan_dims = [64, 128], phimin = np.deg2rad(-5), phimax = np.deg2rad(25))\n",
    "p3, s3 = create_random_scan(HD_map, scan_dims = [64, 128])\n",
    "\n",
    "# gt_submap = (np.linalg.pinv(newPose) @ initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T\n",
    "gt_submap = (initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T\n",
    "# gt_submap = (np.linalg.pinv(newPose) @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T\n",
    "# gt_submap = (np.linalg.pinv(newPose) @ np.append(HD_map_rotated, np.ones([len(HD_map_rotated),1]), axis =1).T).T\n",
    "# gt_submap = (np.linalg.pinv(newPose) @ initial_pose @ np.append(HD_map, np.ones([len(HD_map),1]), axis =1).T).T\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "color = 255*np.linspace(0,1,len(s1)) \n",
    "cname = np.array([255-color, color, 255-color]).T.tolist()\n",
    "disp.append(Points(p1[0:3,-1] + s1, c=cname,  r = 3.5, alpha =0.5))\n",
    "disp.append(Points(p2[0:3,-1] + s2, c='red', r = 3.5, alpha = 0.5))\n",
    "disp.append(Points(p3[0:3,-1] + s3, c='blue', r = 3.5, alpha = 0.5))\n",
    "\n",
    "disp.append(Points(gt_submap[:,:3], c = \"black\", r = 3, alpha = 0.1)) ##CB2314\n",
    "# disp.append(Points(HD_map[:,:3], c = \"black\", r = 3, alpha = 0.1)) ##CB2314\n",
    "plt.show(disp, \"simulated scan from HD map using pose #\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24725693-d4c5-4a8f-96da-bdae37b34143",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_spherical = cartesian_to_spherical(s2)\n",
    "s2_spherical = s2_spherical[~np.isnan(s2_spherical).any(axis=1)]\n",
    "print(90-np.rad2deg(np.max(s2_spherical[:,2])))\n",
    "print(90-np.rad2deg(np.min(s2_spherical[:,2])))\n",
    "\n",
    "#newer college sensor:\n",
    "# print(90-np.rad2deg(np.max(pc1_spherical[:,2]))) #-15.59\n",
    "# print(90-np.rad2deg(np.min(pc1_spherical[:,2]))) #17.74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b85be",
   "metadata": {},
   "source": [
    "# generate training data from virtual scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52e36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_images = 10 #50 \n",
    "n_rots = 128 #128    #number of horizontal patches in 360 degrees\n",
    "n_vert_patches = 1 #8 #number of vertical patcehs between phimin and phimaxs\n",
    "scan_w = 1024 #1024 #needs to be 1024 for actual training\n",
    "\n",
    "n_cols_to_skip = 0 #comment out for debug\n",
    "# n_cols_to_skip = n_rots // 8 #remove this much from the beginning and end of each scan\n",
    "                             #   (do this to remove data with researcher carrying LIDAR)\n",
    "#Ouster OS1-64\n",
    "# phimin = np.deg2rad(-15.594) #OG\n",
    "# phimax = np.deg2rad(17.743)  #OG\n",
    "# phimax = np.deg2rad(15.594)    #flipped\n",
    "# phimin = np.deg2rad(-17.743)   #flipped\n",
    "# phimin = np.deg2rad(-16) #test\n",
    "# phimax = np.deg2rad(16)  #test\n",
    "phimin = np.deg2rad(-5) #test\n",
    "phimax = np.deg2rad(25)  #test\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "\n",
    "poses = np.zeros([n_images*n_rots*n_vert_patches,4,4])\n",
    "images = np.ones([n_images*n_rots*n_vert_patches, 64//n_vert_patches, scan_w//n_rots, 2]) #depth image and raydrop\n",
    "H, W = images.shape[1:3]\n",
    "\n",
    "for i in range(n_images):\n",
    "    print(i)\n",
    "\n",
    "    newPose, pc1 = create_random_scan(HD_map, scan_dims = [64, scan_w], phimin = phimin, phimax = phimax)\n",
    "    \n",
    "    pc1 = np.flip(pc1, axis = 0) #had this before, but it made the map scan mirrored(?)\n",
    "\n",
    "    #convert to depth image\n",
    "    pc1_spherical = cartesian_to_spherical(pc1).numpy() #[r, theta, phi]\n",
    "    pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "#     pcs = np.flip(pcs, axis = 1) #TESTING UNCOMMENTING -- nope\n",
    "    raw_data = pcs[:,:,:]\n",
    "    raw_data = np.transpose(pcs, [1,0,2])\n",
    "\n",
    "    #destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "    data = np.zeros([64, scan_w])\n",
    "    for k in range(np.shape(data)[0]//4):\n",
    "        #no shift\n",
    "        data = raw_data[:,:,0]\n",
    "    data = np.flip(data, axis =1)\n",
    "\n",
    "    for j in range(n_rots):\n",
    "        for k in range(n_vert_patches):\n",
    "            #get cropped depth image ~~~~~~~~~~~~~~~~~~~~    \n",
    "            image_width = scan_w//n_rots\n",
    "            image_height = 64//n_vert_patches\n",
    "            pcs = data[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width] #crop vertically and horizontally\n",
    "    \n",
    "            #save depth information to first channel\n",
    "#             images[j+(i*n_rots),:,:,0] = pcs #for full vertical\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] = pcs #TODO-- fix this?\n",
    "#             print(k+(j+(i*n_rots))*n_vert_patches)\n",
    "\n",
    "            #save raydrop mask to 2nd channel\n",
    "            a = np.argwhere(abs(pcs) < 1)\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches, a[:,0],a[:,1],1] = 0 \n",
    "\n",
    "\n",
    "            #get transformation matrix ~~~~~~~~~~~~~~~~~~\n",
    "#             rotm = newPose.copy() ##TODO-- figure out how to use this...\n",
    "            rotm = np.eye(4)\n",
    "#             rotm[1,3] = -gt[idx+100*i,2] #x\n",
    "#             rotm[2,3] = gt[idx+100*i,3] #y\n",
    "#             rotm[0,3] = -gt[idx+100*i,4] #z\n",
    "#             rotm[:3,:3] = R.from_quat(gt[idx+100*i,5:]).as_matrix() \n",
    "\n",
    "#             #for synthetic data(?) -- not quite\n",
    "#             rotm[1,3] = newPose[1,-1] #x\n",
    "#             rotm[2,3] = -newPose[0,-1] #y\n",
    "#             rotm[0,3] = -newPose[2, -1] #z\n",
    "\n",
    "            #test\n",
    "            rotm[1,3] = -newPose[1,-1] #x\n",
    "            rotm[2,3] = newPose[0,-1] #y\n",
    "            rotm[0,3] = -newPose[2, -1] #z\n",
    "            \n",
    "            #orient yellow (-z) pointing forward\n",
    "            fix1 = R.from_euler('xyz', [0,-np.pi/2,0]).as_matrix()\n",
    "            fix2 = R.from_euler('xyz', [np.pi/2,0,0]).as_matrix()\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ fix1 @ fix2\n",
    "#             swap_axis_matrix = np.array([[0, 0, 1],\n",
    "#                                          [1, 0, 0],\n",
    "#                                          [0, 1, 0]])\n",
    "\n",
    "            #account for image crop in rotation using non-symmetric FOVcd /path/to/your/catkin_workspace\n",
    "            crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "\n",
    "            rotm_crop = R.from_euler('xyz', [0, -crop_angle + np.pi/2,0]).as_matrix() #had this, it mirrored the map\n",
    "#             rotm_crop = R.from_euler('xyz', [0, crop_angle + np.pi/2,0]).as_matrix() #test\n",
    "\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "#             #TODO-- I think I'm double counting this\n",
    "#             #also need to account for the fact that the LIDAR beam isn't actually centered at horizon\n",
    "#             sensor_elevation_zero_rotm = R.from_euler('xyz', [(phimin+phimax)/2,0,0]).as_matrix() \n",
    "#             rotm[:3,:3] = rotm[:3,:3] @ sensor_elevation_zero_rotm\n",
    "            #translate all frames above xy plane\n",
    "            rotm[2,-1] += 45 #courtyard1\n",
    "#             rotm[2,-1] += 15 #test for simulated data\n",
    "#             rotm[1,-1] += 30 #60 #shift towards positive x\n",
    "\n",
    "            #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "#             print(\"\\n before \\n\", rotm)\n",
    "            rotm[:3,-1] *= 0.02 #0.0067 #0.02 #0.05\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.02 #0.0067 #0.02 #0.05\n",
    "#             print(\"after \\n\", rotm, \"\\n\")\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            \n",
    "#             poses[j+(i*n_rots)] = rotm\n",
    "            poses[k+(j+(i*n_rots))*n_vert_patches] = rotm\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "print(\"num poses:\", len(poses))\n",
    "\n",
    "# test on one only\n",
    "testimg, testpose = images[-1], poses[-1]\n",
    "images = images[:-1,...,:3]\n",
    "poses = poses[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('trainingData/poses_equal.npy', poses)\n",
    "# np.save('trainingData/images_equal.npy', images)\n",
    "# np.save('trainingData/testpose_equal.npy', testpose)\n",
    "# np.save('trainingData/testimg_equal.npy', testimg)\n",
    "\n",
    "poses = np.load('trainingData/poses_equal.npy')\n",
    "images = np.load('trainingData/images_equal.npy')\n",
    "testpose = np.load('trainingData/testpose_equal.npy')\n",
    "testimg = np.load('trainingData/testimg_equal.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da64b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw orientation of frames used for each patch in world frame\n",
    "phimin = np.deg2rad(-16) \n",
    "phimax = np.deg2rad(17.75)\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "for i in range(len(poses)):\n",
    "            \n",
    "    #transform each to base frame using <poses>\n",
    "    new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy()\n",
    "    new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z -- does this indicate an error somewhere???\n",
    "\n",
    "    #draw frames for each sub-scan \n",
    "    alph = 1-(i%(n_rots)/n_rots) #change transparency during scan\n",
    "#     alph = 1 - i/(len(poses)+1) #change transparency between scans\n",
    "    #forward view direction (-z in NeRF c2w convention)\n",
    "    headings = poses[i,:3,:3] @ np.array([0,0,-0.03])\n",
    "    disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"yellow\", alpha = alph))\n",
    "    # x\n",
    "#     headings = poses[i,:3,:3] @ np.array([.03,0,0])\n",
    "#     disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"red\", alpha = alph))\n",
    "    #y\n",
    "    headings = poses[i,:3,:3] @ np.array([0,.03,0])\n",
    "    disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"green\", alpha = alph))\n",
    "#     #z\n",
    "#     headings = poses[i,:3,:3] @ np.array([0,0,.03])\n",
    "#     disp.append(Arrows(poses[i,:3,-1][None,:], (poses[i,:3,-1] + headings)[None,:], c = \"blue\", alpha = alph))\n",
    "    \n",
    "disp.append(Points(np.array([[0,0,0]]), r = 10, c = 'black'))\n",
    "plt.show(disp, \"Training Data Sample\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5883ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "# disp.append(Points(simulated_scan, r = 3, c = 'red'))\n",
    "color = 255*np.linspace(0,1,len(pc1)) \n",
    "cname = np.array([255-color, color, 255-color]).T.tolist()\n",
    "disp.append(Points(pc1, c=cname,  r = 3.5, alpha =0.5))\n",
    "\n",
    "plt.show(disp, \"simulated scan from HD map using pose #\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566330ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(poses))\n",
    "fig, ax = p.subplots()\n",
    "# ax.scatter(-poses[0,1,-1],poses[0,2,-1])\n",
    "ax.scatter(-poses[:,1,-1],poses[:,2,-1])\n",
    "# ax.scatter(-poses[127::128,1,-1],poses[127::128,2,-1]) #TODO--- bug is here????\n",
    "# ax.scatter(-poses[15::128,1,-1],poses[15::128,2,-1])\n",
    "ax.set_aspect(\"equal\")\n",
    "# print(np.shape(poses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = 1\n",
    "idx = 50\n",
    "\n",
    "testy = images[idx,:,:]\n",
    "for i in range(1,32):\n",
    "    testy = np.append(testy, images[idx + i,:,:], axis = 1)\n",
    "\n",
    "print(np.shape(testy))\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "ax.imshow(testy[:,:,0], aspect = aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de39795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"A\"\n",
    "ord(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pcl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec2094",
   "metadata": {},
   "source": [
    "# Exploring alternate rendering integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1162ce",
   "metadata": {},
   "source": [
    "### Attempt #1: Network directly estimates surface opacity at every z value, render this directly\n",
    "* Simple implementation\n",
    "* Very sensitive to sampling locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf_1_opacity = 0.5\n",
    "# surf_2_opacity = 0.2\n",
    "# surf_3_opacity = 1.0...\n",
    "surface_opacities = np.array([0.25, 0.01, 0.01, 0.8, 1.0, 0.0])\n",
    "# surface_opacities = 0.1*np.linspace(0,10,128)\n",
    "\n",
    "num_pts = 2_000\n",
    "\n",
    "pt_dists = np.zeros(num_pts) +1 \n",
    "still_going = np.ones(num_pts)\n",
    "for surf_opacity in surface_opacities:\n",
    "    hit_surf_i = np.random.rand(num_pts)\n",
    "    pt_dists[hit_surf_i > surf_opacity] += 1*still_going[hit_surf_i > surf_opacity]\n",
    "    still_going[hit_surf_i < surf_opacity] = 0\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "ax.scatter(pt_dists,np.linspace(0,num_pts-1,num_pts), alpha = 0.05)\n",
    "ax.set_xlim([0,len(surface_opacities)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807c909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reproducing the above code using TensorFlow so it can be run on many pixels at once\n",
    "# Goal: given map of reflectivity chance at each point (output by network),\n",
    "#       stochastically render returns from each laser beam\n",
    "\n",
    "N_samples = 128 #128\n",
    "near=0.\n",
    "far=2.\n",
    "z_vals = tf.linspace(near, far, N_samples)\n",
    "z_vals += 0.01*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals = z_vals[:,:,:,None]\n",
    "ray_pos = rays_o[...,None,:] + rays_d[...,None,:] * z_vals\n",
    "\n",
    "#define periodic opacity pattern in x and y, randomize each in z\n",
    "#  \"x\" and \"y\" axis would be the azimuthal and elevation angles of lidar sensor, \"z\" is radial depth\n",
    "#  (this is what the output of the network is going to look like)\n",
    "so = tf.tile(tf.random.uniform([1,1,100]), [10,10,1])  #surface opacity\n",
    "\n",
    "rp_flat = tf.reshape(ray_pos, [-1,3])\n",
    "dummy_opacity = ((1+(np.cos(20*rp_flat[:,1] )*np.cos(10*rp_flat[:,0]) ) [:,None])/2)[:,0]\n",
    "\n",
    "#scale clockwise\n",
    "# dummy_opacity *= np.linspace(0,1,len(dummy_opacity)) \n",
    "\n",
    "#sort by distance from starting point, scale opacity accordingly\n",
    "dist = tf.math.sqrt(tf.math.reduce_sum(rp_flat**2, axis = 1))\n",
    "in_order = tf.argsort(dist)\n",
    "dummy_opacity = tf.gather(dummy_opacity, in_order)\n",
    "rp_flat = tf.gather(rp_flat, in_order)\n",
    "\n",
    "# dummy_opacity *= np.linspace(0,1,len(dummy_opacity)) #scale clockwise\n",
    "# dummy_opacity = dummy_opacity**2\n",
    "# dummy_opacity = 2*tf.nn.relu(dummy_opacity - 0.5)\n",
    "\n",
    "colors = np.array([dummy_opacity, dummy_opacity, dummy_opacity])\n",
    "colors = colors.T.tolist()\n",
    "\n",
    "do = tf.reshape(dummy_opacity, [ray_pos.shape[0], ray_pos.shape[1], -1])\n",
    "# print(np.shape(do))\n",
    "\n",
    "num_pts = 128\n",
    "# print(num_pts)\n",
    "\n",
    "roll = tf.random.uniform(tf.shape(do))\n",
    "\n",
    "hit_surfs = tf.argmax(roll < do, axis = -1)\n",
    "# print(\"\\n hit_surfs:\", hit_surfs)\n",
    "# print(\"\\n hit_surfs:\", np.shape(hit_surfs))\n",
    "\n",
    "# test = tf.gather_nd(z_vals[:,:,:,0], hit_surfs[:,:,None], batch_dims = 2)\n",
    "rendered_points = tf.gather_nd(ray_pos, hit_surfs[:,:,None], batch_dims = 2)\n",
    "rendered_points_flat = tf.reshape(rendered_points, [-1,3])\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "disp.append(Points(rp_flat, c=colors, r = 3.5, alpha = 0.5))\n",
    "disp.append(Points(rendered_points_flat, c='red', r = 5))\n",
    "\n",
    "plt.show(disp, \"Test Render-- Simulating Network Opacity Predictions \")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c995a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "# disp=[]\n",
    "# for i in range(100):\n",
    "#     do = tf.reshape(dummy_opacity, [ray_pos.shape[0], ray_pos.shape[1], -1])\n",
    "#     # do = do [0,0,:]\n",
    "#     roll = tf.random.uniform(tf.shape(do))\n",
    "#     hit_surfs = tf.argmax(roll < do, axis = -1)\n",
    "#     rendered_points = tf.gather_nd(ray_pos, hit_surfs[:,:,None], batch_dims = 2)\n",
    "#     rendered_points_flat = tf.reshape(rendered_points, [-1,3])\n",
    "#     disp.append(Points(rendered_points_flat, c='red', r = 5, alpha = 0.1))\n",
    "# plt.show(disp, \"Test Render-- Simulating Network Opacity Predictions \")\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa0127",
   "metadata": {},
   "source": [
    "## Attempt #2: probability of reflection up to a given point\n",
    "\n",
    "### Modify rendering code to include randomized reflection, leave loss function intact\n",
    "\n",
    "#### Process:\n",
    "1) Pass rays and test point locations (z_vals) to the network\n",
    "2) Network outputs CDF at each test point location\n",
    "3) CDF is converted to discrete probability of reflectance at each test point\n",
    "4) Follow similar process as Attempt #1 to render point cloud from discrete opacity map\n",
    "\n",
    "<span style=\"font-size:2.5em;\">\n",
    "$$\n",
    "P_\\text{reflect} = P(r_m - \\Delta) (1 - e^{\\int_{r_m - \\Delta}^{r_m } \\alpha \\text{ ds}})\n",
    "$$\n",
    "</span>\n",
    "\n",
    "#### Notes:\n",
    "* Getting pdf from derivative of CDF can result in numerical issues if first few samples of CDF are extremely large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy cdf (this is output by the network at queried z values)\n",
    "CDF = tf.constant([[[0.0, 0.5, 0.6, 1.0],\n",
    "                 [0.0, 0.6, 0.6, 1.0]],\n",
    "                \n",
    "                [[0.0, 0.5, 0.6, 1.0],\n",
    "                 [0.0, 0.6, 0.6, 1.0]]])\n",
    "\n",
    "opacity = (CDF[:,:,1:]-CDF[:,:,:-1])/(1-CDF[:,:,:-1])\n",
    "#pad the beginning with zeros to maintain the same shape beteen input and output\n",
    "#  this means we are evaluting the region of length delta ending at r_m\n",
    "pad = tf.zeros_like(opacity[:,:,0])[:,:,None]\n",
    "opacity = tf.concat([pad, opacity], axis = -1)\n",
    "\n",
    "#We don't need to weight by sampling density/ material thickness here\n",
    "# since it's accounted for in diff of the CDF\n",
    "\n",
    "print(opacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454d2b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create dummy CDF (as would be output by the network)\n",
    "old_pdf = tf.reshape(dummy_opacity, [ray_pos.shape[0], ray_pos.shape[1], -1,1])/3\n",
    "CDF = 1-tf.math.cumprod((1-old_pdf[...,0]), axis = -1)\n",
    "print(\" \\n old pdf: \", np.shape(old_pdf), \" \\n\", old_pdf[10,0,:,0])\n",
    "print(\" \\n CDF: \", np.shape(CDF), \" \\n\", CDF[10,0,:])\n",
    "\n",
    "opacity = (CDF[:,:,1:]-CDF[:,:,:-1])/(1-CDF[:,:,:-1])\n",
    "pad = tf.zeros_like(opacity[:,:,0])[:,:,None]\n",
    "opacity = tf.concat([pad, opacity], axis = -1)\n",
    "print(\"\\n opacity:\", np.shape(opacity), \" \\n\", opacity[10,0,:])\n",
    "\n",
    "#do rendering similar to stratgegy #1\n",
    "roll = tf.random.uniform(tf.shape(opacity))\n",
    "hit_surfs = tf.argmax(roll < opacity, axis = -1)\n",
    "rendered_points = tf.gather_nd(ray_pos, hit_surfs[:,:,None], batch_dims = 2)\n",
    "rendered_points_flat = tf.reshape(rendered_points, [-1,3])\n",
    "\n",
    "rp_flat = tf.reshape(ray_pos, [-1,3])\n",
    "print(\"rp_flat\", np.shape(rp_flat))\n",
    "CDF_flat = tf.reshape(CDF, [-1])\n",
    "colors = np.array([CDF_flat, CDF_flat, CDF_flat])\n",
    "colors = colors.T.tolist()\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "disp.append(Points(rp_flat, c=colors, r = 3.5, alpha = 0.5))\n",
    "disp.append(Points(rendered_points_flat, c = 'red'))\n",
    "\n",
    "plt.show(disp, \"Test Render-- Simulating Network Opacity Predictions \")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c49bc-5630-4dc1-846f-6c485be93dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots()\n",
    "ax.plot(CDF[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(ray_pos))\n",
    "print(np.shape(dummy_opacity))\n",
    "# print(np.shape(rays_o))\n",
    "# print(np.shape(rays_d))\n",
    "print(np.shape(z_vals))\n",
    "# print(np.shape(rays_o[...,None,:]))\n",
    "\n",
    "#Network output shape: (patch height, patch width, num z_vals, num output channels)\n",
    "# ex: np.shape(raw) = (64, 8, 128, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(z_vals[:,:,:,0]))\n",
    "# print(np.shape(hit_surfs))\n",
    "test = tf.gather_nd(z_vals[:,:,:,0], hit_surfs[:,:,None], batch_dims = 2)\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5,15,10)\n",
    "# x = np.random.randn(6)\n",
    "softplus_x = np.log(1+np.e**x)\n",
    "print(x)\n",
    "print(softplus_x)\n",
    "# print(tf.nn.relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b5571-4f2e-4265-8b6e-8b6d1a489f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
