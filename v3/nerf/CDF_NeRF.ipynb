{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c43a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load requirements for working with PCs\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "import sys\n",
    "import os\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "sys.path.append(parent_directory+\"/point_cloud_rectification\")\n",
    "from ICET_spherical import ICET\n",
    "from linear_corrector import LC\n",
    "\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import trimesh\n",
    "\n",
    "from pillow_heif import register_heif_opener\n",
    "from matplotlib import pyplot as p\n",
    "from colmapParsingUtils import *\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cv2\n",
    "from lidar_nerf_utils import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75697f0f",
   "metadata": {},
   "source": [
    "# Load and crop depth image data with arbitrary patch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remove_motion_basic import linear_correction_old as lc\n",
    "\n",
    "dir_name = \"/media/derm/06EF-127D4/Newer College Dataset/\"\n",
    "experiment_name = \"01_short_experiment-20230331T172433Z-009/01_short_experiment/\"\n",
    "fn_gt = dir_name + experiment_name + \"ground_truth/registered_poses.csv\"\n",
    "#sec,nsec,x,y,z,qx,qy,qz,qw\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "seconds = gt[:, 0]\n",
    "nano_seconds = gt[:, 1]\n",
    "xyz = gt[:, 2:5]\n",
    "qxyzw = gt[:, 5:]\n",
    "num_poses = qxyzw.shape[0]\n",
    "sensor_poses = np.eye(4, dtype=np.float64).reshape(1, 4, 4).repeat(num_poses, axis=0)\n",
    "sensor_poses[:, :3, :3] = R.from_quat(qxyzw).as_matrix()\n",
    "sensor_poses[:, :3, 3] = xyz\n",
    "T_CL = np.eye(4, dtype=np.float32)\n",
    "T_CL[:3, :3] = R.from_quat([0.0, 0.0, 0.924, 0.383]).as_matrix() #was this --1134.97 deg\n",
    "T_CL[:3, 3] = np.array([-0.084, -0.025, 0.050], dtype=np.float32) #was this\n",
    "sensor_poses = np.einsum(\"nij,jk->nik\", sensor_poses, T_CL)\n",
    "initial_pose = np.linalg.inv(sensor_poses[0]) \n",
    "poses_timestamps = seconds * 10e9 + nano_seconds\n",
    "sensor_poses = np.einsum(\"ij,njk->nik\", np.linalg.inv(sensor_poses[0]), sensor_poses) #TRY COMMENTING OUT...\n",
    "\n",
    "#get body frame vel to remove motion disortion from training data\n",
    "vel_world_frame = np.diff(sensor_poses[:,:3,-1], axis = 0)\n",
    "vel_body_frame = np.linalg.pinv(sensor_poses[1:,:3,:3]) @ vel_world_frame[:,:,None]\n",
    "vel_body_frame = vel_body_frame[:,:,0]\n",
    "#smooth out velocity estimates\n",
    "def moving_average(a, n=10):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "window=50\n",
    "MAx = moving_average(vel_body_frame[:,0], n = window)\n",
    "MAy = moving_average(vel_body_frame[:,1], n = window)\n",
    "MAz = moving_average(vel_body_frame[:,2], n = window)\n",
    "vel_body_frame = np.array([MAx, MAy, MAz]).T\n",
    "\n",
    "rot_vel_euls = np.diff(R.from_matrix(sensor_poses[:,:3,:3]).as_euler('xyz'), axis = 0)\n",
    "idx = np.argwhere(rot_vel_euls > (np.pi))\n",
    "rot_vel_euls[idx] = 0\n",
    "idx = np.argwhere(rot_vel_euls < (-np.pi))\n",
    "rot_vel_euls[idx] = 0\n",
    "\n",
    "show_nth = 10\n",
    "pl = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply'\n",
    "mapPt1 = trimesh.load(pl).vertices\n",
    "submap1 = mapPt1[::show_nth]\n",
    "mapPt2 = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-2ndSection.ply'\n",
    "mapPt2 = trimesh.load(mapPt2).vertices\n",
    "submap2 = mapPt2[::show_nth] \n",
    "# disp.append(Points(submap2, c = 'gray', alpha = 0.03))\n",
    "mapPt3 = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-3rdSection.ply'\n",
    "mapPt3 = trimesh.load(mapPt3).vertices\n",
    "submap3 = mapPt3[::show_nth] \n",
    "# disp.append(Points(submap3, c = 'gray', alpha = 0.03))\n",
    "mapPt4 = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-4thSection.ply'\n",
    "mapPt4 = trimesh.load(mapPt4).vertices\n",
    "submap4 = mapPt4[::show_nth] \n",
    "# disp.append(Points(submap4, c = 'gray', alpha = 0.03))\n",
    "mapPt5 = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-5thSection.ply'\n",
    "mapPt5 = trimesh.load(mapPt5).vertices\n",
    "submap5 = mapPt5[::show_nth] \n",
    "# disp.append(Points(submap5, c = 'gray', alpha = 0.03))\n",
    "# submap = np.concatenate((submap1, submap2, submap3, submap4, submap5), axis = 0)\n",
    "submap = submap1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c97d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebe01e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  undistort raw point clouds, define patch sizes,\n",
    "#  take patches about useful regions of the scene, and record poses for each patch \n",
    "\n",
    "from time import sleep\n",
    "#convert gt from xyzquat to homogenous rotation matrix\n",
    "n_images = 5 #1000 #50 \n",
    "n_rots = 128 #128    #number of horizontal patches in 360 degrees\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimaxs\n",
    "\n",
    "# n_cols_to_skip = 0 #comment out for debug\n",
    "n_cols_to_skip = n_rots // 8 #remove this much from the beginning and end of each scan\n",
    "                             #   (need to remove parts of frame containing researcher carrying LIDAR)\n",
    "#Ouster OS1-64\n",
    "phimin = np.deg2rad(-15.594) #TEST 7/3\n",
    "phimax = np.deg2rad(17.743)\n",
    "# phimax = np.deg2rad(15.594) #flipped\n",
    "# phimin = np.deg2rad(-17.743)\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "\n",
    "poses = np.zeros([n_images*n_rots*n_vert_patches,4,4])\n",
    "images = np.ones([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 2]) #depth image and raydrop\n",
    "H, W = images.shape[1:3]\n",
    "\n",
    "# plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True)\n",
    "# disp = []\n",
    "# submap_in_map_frame =  (initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #was this\n",
    "# # submap_in_map_frame =  (np.append(submap, np.ones([len(submap),1]), axis =1).T).T #initial pose already baked in??\n",
    "# # submap_in_map_frame = submap_in_map_frame @ np.linalg.pinv(T_CL) #TEST\n",
    "# submap_in_map_frame = submap_in_map_frame[:,:3]\n",
    "# disp.append(Points(submap_in_map_frame, c = 'gray', r = 2, alpha = 0.25))\n",
    "\n",
    "redfix_hist = np.zeros([n_images,4,4])#DEBUG\n",
    "\n",
    "for i in range(n_images):\n",
    "    print(i) \n",
    "    #2nd courtyard\n",
    "#     idx = i*60 + 1500\n",
    "    #full loop first courtyard\n",
    "#     idx = i + 7800 \n",
    "    idx = i*10 + 7700\n",
    "    #test woods\n",
    "#     idx = i*1000 + 9500\n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "    \n",
    "#     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                      -vel_body_frame[idx,1],\n",
    "                      -vel_body_frame[idx,2],\n",
    "                      -rot_vel_euls[idx,0], #looks good\n",
    "                      -rot_vel_euls[idx,1],\n",
    "                      -rot_vel_euls[idx,2]\n",
    "#                       0,0,0 #rotational velocity is zero-centered (theoretically should cancel out with enough data)\n",
    "                     ])   \n",
    "    pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    pc1 = np.flip(pc1, axis = 0)# uncomment to flip and maintain CCW convention used in VICET\n",
    "\n",
    "    #Register undistorted PC against HD Map using ICET to correct issues in ground truth------------------------\n",
    "    submap_in_pc1_frame = (np.linalg.pinv(sensor_poses[idx]) @ initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #test\n",
    "    submap_in_pc1_frame = submap_in_pc1_frame[:,:3]\n",
    "\n",
    "    initial_guess = tf.constant([0.,0.,0.,0.,0.,0.])\n",
    "    it = ICET(cloud1 = submap_in_pc1_frame, cloud2 = pc1, fid = 50, niter = 8, \n",
    "       draw = False, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "\n",
    "    pc1_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T #test\n",
    "    pc1_in_map_frame = pc1_in_map_frame[:,:3]\n",
    "#     disp.append(Points(pc1_in_map_frame, c = 'red', r = 3, alpha = 0.2))\n",
    "\n",
    "    pc1_corrected_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(it.cloud2_tensor.numpy(), np.ones([len(it.cloud2_tensor.numpy()),1]), axis =1).T).T #test\n",
    "    pc1_corrected_in_map_frame = pc1_corrected_in_map_frame[:,:3]    \n",
    "#     disp.append(Points(pc1_corrected_in_map_frame, c = 'blue', r =3, alpha = 0.2))\n",
    "\n",
    "    #draw red scan corrected by output of ICET\n",
    "    redFix = np.eye(4)\n",
    "    redFix[:3,-1] = it.X[:3]\n",
    "    redFix[:3,:3] = redFix[:3,:3] @ R.from_euler('xyz', [it.X[3], it.X[4], it.X[5]]).as_matrix()\n",
    "    redfix_hist[i] = redFix\n",
    "    \n",
    "    redScanFixed = (redFix @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "#     redScanFixed = (initial_pose @ sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "    redScanFixed = (sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "#     disp.append(Points(redScanFixed[:,:3], c = 'red', r =3, alpha = 0.2))    \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #convert to depth image\n",
    "    pc1_spherical = cartesian_to_spherical(pc1).numpy() #[r, theta, phi]\n",
    "    pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "    pcs = np.flip(pcs, axis = 1)\n",
    "    raw_data = pcs[:,:,:]\n",
    "    raw_data = np.transpose(pcs, [1,0,2])\n",
    "\n",
    "    #destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "    data = np.zeros([64, 1024])\n",
    "    for k in range(np.shape(data)[0]//4):\n",
    "# #         #shift left (nope)\n",
    "#         data[4*k,:-18] = raw_data[4*k,18:,0]\n",
    "#         data[4*k+1,:-12] = raw_data[4*k+1,12:,0]\n",
    "#         data[4*k+2,:-6] = raw_data[4*k+2,6:,0]\n",
    "#         data[4*k+3,:] = raw_data[4*k+3,:,0]\n",
    "# #         #shift right -- https://ouster.com/insights/blog/firmware-2-4-industry-standard-protocols-and-improved-alerts\n",
    "#         data[4*k,:] = raw_data[4*k,:,0]\n",
    "#         data[4*k+1,6:] = raw_data[4*k+1,:-6,0]\n",
    "#         data[4*k+2,12:] = raw_data[4*k+2,:-12,0]\n",
    "#         data[4*k+3,18:] = raw_data[4*k+3,:-18,0]\n",
    "        # keep centered\n",
    "        data[4*k,1:-8] = raw_data[4*k,9:,0]\n",
    "        data[4*k+1,1:-2] = raw_data[4*k+1,3:,0]\n",
    "        data[4*k+2,4:] = raw_data[4*k+2,:-4,0]\n",
    "        data[4*k+3,10:] = raw_data[4*k+3,:-10,0]\n",
    "#         #TEST-- no shift\n",
    "#         data = raw_data[:,:,0]\n",
    "    \n",
    "    data = np.flip(data, axis =1) #do not comment out\n",
    "\n",
    "    for j in range(n_rots):\n",
    "        for k in range(n_vert_patches):\n",
    "            #get cropped depth image ~~~~~~~~~~~~~~~~~~~~    \n",
    "            image_width = 1024//n_rots\n",
    "            image_height = 64//n_vert_patches\n",
    "            pcs = data[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width] #crop vertically and horizontally\n",
    "            #save depth information to first channel\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] = pcs\n",
    "            #save raydrop mask to 2nd channel\n",
    "            a = np.argwhere(abs(pcs) < 1)\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches, a[:,0],a[:,1],1] = 0\n",
    "\n",
    "            #get transformation matrix ~~~~~~~~~~~~~~~~~~\n",
    "            #centers origin at actual origin of HD map \n",
    "            #  need to comment out line in above cell normazlizing sensor_poses w.r.t. first pose\n",
    "            rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "            rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "\n",
    "            rotm[:3,-1] = np.array([-rotm[2,-1], -rotm[0,-1], rotm[1,-1]])\n",
    "\n",
    "            #orient yellow (-z) pointing forward\n",
    "            fix = np.array([[0,0,1],\n",
    "                            [1,0,0],\n",
    "                            [0,1,0]])\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ fix\n",
    "            \n",
    "            swap_axis_matrix = np.array([[0, 0, 1],\n",
    "                                         [1, 0, 0],\n",
    "                                         [0, 1, 0]])\n",
    "#             flip_axis_matrix = np.diag([-1,1,-1]) #was this\n",
    "            flip_axis_matrix = np.diag([1,1,-1]) # better ---> corrects flipping z issue when rendering\n",
    "            rotm[:3,:3] = flip_axis_matrix @ swap_axis_matrix @ rotm[:3,:3] \n",
    "\n",
    "            #center camera horizontally in each patch\n",
    "            crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "\n",
    "            #account for the fact that sensor points back and to the left\n",
    "            rotm_crop = R.from_euler('xyz', [0,-crop_angle,0]).as_matrix()\n",
    "\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "            #courtyard1\n",
    "            rotm[2,-1] += 45 #translate above xy plane\n",
    "            rotm[1,-1] += 30 #shift towards positive x\n",
    "#             rotm[0,-1] += 2 #TEST -- shift up just a little\n",
    "#             rotm[2,-1] += 120 #courtyard2\n",
    "\n",
    "            #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "            rotm[:3,-1] *= 0.005 #0.005 #0.02 #0.05\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.005 #0.02 #0.005 #0.05\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            # recenter (when using x0.005)\n",
    "            rotm[2,-1] += 0.25 #translate above xy plane\n",
    "            rotm[1,-1] += 0.25 #shift towards positive x\n",
    "            rotm[0,-1] += 0.01 #TEST -- shift up just a little\n",
    "            \n",
    "#             poses[j+(i*n_rots)] = rotm\n",
    "            poses[k+(j+(i*n_rots))*n_vert_patches] = rotm\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "print(\"num poses:\", len(poses))\n",
    "\n",
    "# # Remove patches where sensor is occluded by person holding lidar ~~~~~~~~~~\n",
    "#calculte how many columns of patches we need to skip at the beginning and end of each scan to avoid\n",
    "print(\"n_rots:\", n_rots)\n",
    "# n_cols_to_skip = 0 #debug\n",
    "print(\"n_cols_to_skip:\", n_cols_to_skip)\n",
    "\n",
    "bad_idx = np.zeros([0,n_rots - 2*n_cols_to_skip])\n",
    "a = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "print(np.shape(a))\n",
    "for i in range(n_vert_patches*n_cols_to_skip):\n",
    "    bad_i_left = a[i::n_rots*n_vert_patches]\n",
    "    bad_idx = np.append(bad_idx, bad_i_left)\n",
    "#     print(\"\\n bad_idx_left:\", bad_i_left)\n",
    "\n",
    "    bad_i_right = a[(i+n_vert_patches*(n_rots-n_cols_to_skip))::n_rots*n_vert_patches]\n",
    "    bad_idx = np.append(bad_idx, bad_i_right)\n",
    "#     print(\"\\n bad_idx_right:\", bad_i_right)\n",
    "    \n",
    "bad_idx = np.sort(bad_idx)\n",
    "all_idx = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "good_idx = np.setdiff1d(all_idx, bad_idx).astype(int)\n",
    "\n",
    "# print(good_idx)\n",
    "\n",
    "images = images[good_idx,:,:,:]\n",
    "poses = poses[good_idx,:,:]\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# test on one only\n",
    "testimg, testpose = images[-1], poses[-1]\n",
    "images = images[:-1,...,:3]\n",
    "poses = poses[:-1]\n",
    "\n",
    "# plt.show(disp, \"01 Short Experiment Frame #\" + str(idx))\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0cafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw subsequent scans aligned using poses with redfix\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'blue']\n",
    "\n",
    "for i in range(3):\n",
    "    idx = i*10 + 7700\n",
    "#     idx = i*10 + 1200\n",
    "\n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "#     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                      -vel_body_frame[idx,1],\n",
    "                      -vel_body_frame[idx,2],\n",
    "                      -rot_vel_euls[idx,0], #looks good\n",
    "                      -rot_vel_euls[idx,1],\n",
    "                      -rot_vel_euls[idx,2]\n",
    "#                       0,0,0 #rotational velocity is zero-centered (theoretically should cancel out with enough data)\n",
    "                     ])   \n",
    "    pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~        \n",
    "    #centers origin at actual origin of HD map \n",
    "    #  need to comment out line in above cell normazlizing sensor_poses w.r.t. first pose\n",
    "    rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "#     rotm = np.linalg.pinv(sensor_poses[7700]) @ rotm #look in terms of keyframe\n",
    "    rotm = np.linalg.pinv(sensor_poses[7700]) @ rotm\n",
    "#     rotm = np.linalg.pinv(initial_pose) @ rotm #look in terms of world origin\n",
    "    \n",
    "    \n",
    "    pc1_aligned = (rotm @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T    \n",
    "        \n",
    "    disp.append(Points(pc1_aligned[:,:3], c = colors[i], r = 3.5, alpha = 0.25))\n",
    "    \n",
    "    disp.append(Points(rotm[:3,-1][None,:], c = 'k', r = 5))\n",
    "\n",
    "plt.show(disp, \"Training Data Sample\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45530d",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* For each \"keyframe\" scan:\n",
    "    * align $n$ previous scans using ICET\n",
    "    * cast cones about each point in scan, get radial distances from all points that fall within cone\n",
    "    * use distances to construct CDF\n",
    "    * use CDF to train NeRF\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aade88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    start_idx = 7800\n",
    "    idx = i + start_idx\n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "    print(np.shape(pc1))\n",
    "#     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                      -vel_body_frame[idx,1],\n",
    "                      -vel_body_frame[idx,2],\n",
    "                      -rot_vel_euls[idx,0], #looks good\n",
    "                      -rot_vel_euls[idx,1],\n",
    "                      -rot_vel_euls[idx,2]\n",
    "                     ])   \n",
    "    pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~        \n",
    "    #centers origin at actual origin of HD map \n",
    "    rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "    rotm = np.linalg.pinv(sensor_poses[start_idx]) @ rotm #look in terms of keyframe\n",
    "#     rotm = np.linalg.pinv(initial_pose) @ rotm #look in terms of world origin\n",
    "    \n",
    "    pc1_aligned = (rotm @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T    \n",
    "    \n",
    "    disp.append(Points(pc1_aligned[:,:3], c = colors[i], r = 3.5, alpha = 0.25))\n",
    "    \n",
    "    disp.append(Points(rotm[:3,-1][None,:], c = 'k', r = 5))\n",
    "\n",
    "    if i == 0:\n",
    "        scan1 = pc1_aligned[:,:3]\n",
    "    if i == 1:\n",
    "        scan2 = pc1_aligned[:,:3]\n",
    "    if i == 2:\n",
    "        scan3 = pc1_aligned[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed765a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "disp.append(Points(scan1, c='red', r = 3, alpha = 0.5))\n",
    "disp.append(Points(scan2, c='green', r = 3, alpha = 0.5))\n",
    "disp.append(Points(scan3, c='blue', r = 3, alpha = 0.5))\n",
    "\n",
    "plt.show(disp, \"aligned scans\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_scan_from_map(hd_map, p, res = [64, 1024], \n",
    "                      phimin = np.pi/2 + np.deg2rad(-17.743), \n",
    "                      phimax = np.pi/2 + np.deg2rad(15.594), \n",
    "                      tol = 0.001, use_IP = True):\n",
    "    \"\"\"p = pose, homogemous coordinates\"\"\"\n",
    "        \n",
    "    #align hd map about origin according to pose\n",
    "    if use_IP:\n",
    "        centered_map = (np.linalg.pinv(p) @ initial_pose @ np.append(hd_map, np.ones([len(hd_map),1]), axis =1).T).T\n",
    "    else:\n",
    "        centered_map = (np.linalg.pinv(p) @ np.append(hd_map, np.ones([len(hd_map),1]), axis =1).T).T\n",
    "    centered_map_s = cartesian_to_spherical(centered_map)\n",
    "    \n",
    "    #remove points outside vertical fov\n",
    "    centered_map_s = centered_map_s[centered_map_s[:,2] > phimin]\n",
    "    centered_map_s = centered_map_s[centered_map_s[:,2] < phimax]\n",
    "    centered_map_s = centered_map_s[centered_map_s[:,0]< 100]\n",
    "    \n",
    "    #test looking at narrow azimuth range\n",
    "    #sort by azimuth angle\n",
    "    centered_map_s = centered_map_s.numpy()\n",
    "    sorted_indices = centered_map_s[:,1].argsort() #[-pi, pi]\n",
    "    centered_map_s = centered_map_s[sorted_indices]\n",
    "\n",
    "    #just keep points that are within tol of a phi angle\n",
    "    scan = np.zeros([0,3])\n",
    "    gp = np.linspace(phimin, phimax, res[0]) #good phis\n",
    "\n",
    "    #loop through each horizontal angle\n",
    "    for j in range(res[1]):\n",
    "        centered_map_s_slice = centered_map_s[centered_map_s[:,1] > (-np.pi + (2*np.pi*j/res[1]))]\n",
    "        centered_map_s_slice = centered_map_s_slice[centered_map_s_slice[:,1] < (-np.pi + (2*np.pi*(j+1)/res[1]))]\n",
    "#         print(j)\n",
    "        \n",
    "        #loop through each elevation angle\n",
    "        for i in range(res[0]):\n",
    "            tol_temp = tol\n",
    "            good = np.zeros([0,3])\n",
    "            count = 0\n",
    "            #gradually up tolerance about sampling angle until sufficient number of points are captured in scan line\n",
    "            # or increasing tolerance no longer helps\n",
    "            while (np.shape(good)[0] < (3*1024)//(res[1])):\n",
    "                good = centered_map_s_slice[abs(centered_map_s_slice[:,2] - gp[i]) < tol_temp ]\n",
    "                tol_temp *= 1.3\n",
    "                if count > 5:\n",
    "                    np.zeros([0,3])\n",
    "                    break\n",
    "                count += 1\n",
    "\n",
    "            #add closest point to scan, give it theoretical target elevation and azimuth\n",
    "            if len(good) >= 1:\n",
    "                best_r = min(good[:,0])\n",
    "            else:\n",
    "                best_r = 0\n",
    "            best_point_s = np.array([[best_r, -np.pi + np.pi/res[1] + (2*np.pi*j/res[1]), gp[i]]]) #[r, elev, azim]\n",
    "            scan = np.append(scan, best_point_s, axis = 0)\n",
    "        \n",
    "    scan = spherical_to_cartesian(scan)\n",
    "    return scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_scan(HD_map, scan_dims = [64,1024], phimin = np.deg2rad(-15.594), phimax = np.deg2rad(17.743)):\n",
    "    phimin += np.pi/2 \n",
    "    phimax += np.pi/2\n",
    "    \n",
    "    newPose = np.eye(4)\n",
    "    #[-53, -5]x, [-10,10]y, [0.5,3]z\n",
    "    trans = np.array([-43,-5,0.5]) + np.array([28,10,2.5])*np.random.rand(3) #just center of courtyard\n",
    "#     trans = np.array([-53,-10,0.5]) + np.array([48,20,2.5])*np.random.rand(3) #full space\n",
    "    trans_mapframe = R.from_euler('xyz', [0,0,np.pi/4]).as_matrix() @ trans #rotate to map coordinate system\n",
    "    newPose[0:3,-1] = trans_mapframe\n",
    "    simulated_scan = gen_scan_from_map(HD_map, newPose, res = scan_dims, phimin = phimin, phimax = phimax)[:,:3]\n",
    "    # simulated_scan = gen_scan_from_map(HD_map, newPose, res = scan_dims, phimin = np.pi/2 + np.deg2rad(-20), phimax = np.pi/2 + np.deg2rad(10))[:,:3] #debug\n",
    "    \n",
    "#     simulated_scan = None #temp for debug only\n",
    "    \n",
    "    return(newPose, simulated_scan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d145f5",
   "metadata": {},
   "source": [
    "# cone cast scan2 in scan1 frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(scan2))\n",
    "# print(np.shape(scan3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPose = np.eye(4)\n",
    "# newPose[:3,:3] = 0\n",
    "# scan2 = scan2[abs(scan2[:,0]) > 0.1]#remove points at the origin\n",
    "\n",
    "simulated_scan = gen_scan_from_map(scan2, newPose, res = [64,1024], use_IP = False)[:,:3]\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "disp.append(Points(scan1, c = 'red', r =3))\n",
    "disp.append(Points(scan2, c = 'green', r =3))\n",
    "disp.append(Points(simulated_scan, c = 'black', r = 4, alpha = 1.))\n",
    "plt.show(disp, \"ray casting scan2 in scan1 frame\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to depth image\n",
    "pc1_spherical = cartesian_to_spherical(scan1).numpy() #[r, theta, phi]\n",
    "# pc1_spherical = cartesian_to_spherical(scan2).numpy() #[r, theta, phi] #DEBUG\n",
    "pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "pcs = np.flip(pcs, axis = 1)\n",
    "raw_data = pcs[:,:,:]\n",
    "raw_data = np.transpose(pcs, [1,0,2])\n",
    "#destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "data = np.zeros([64, 1024])\n",
    "for k in range(np.shape(data)[0]//4):\n",
    "    data[4*k,1:-8] = raw_data[4*k,9:,0]\n",
    "    data[4*k+1,1:-2] = raw_data[4*k+1,3:,0]\n",
    "    data[4*k+2,4:] = raw_data[4*k+2,:-4,0]\n",
    "    data[4*k+3,10:] = raw_data[4*k+3,:-10,0]\n",
    "scan1_image = np.flip(data, axis =1) #do not comment out\n",
    "# scan1_image = np.flip(scan1_image, axis = 0) #test\n",
    "\n",
    "#convert simulated scan as well\n",
    "ss_spherical = cartesian_to_spherical(simulated_scan)\n",
    "pcs = np.reshape(ss_spherical, [-1,64,3])\n",
    "pcs = np.flip(pcs, axis = 1)\n",
    "ss_image = np.transpose(pcs, [1,0,2])\n",
    "ss_image = np.nan_to_num(ss_image, nan=0.0)[:,:,0]\n",
    "#get ss_image to start at the same rotation angle as keyframe scan\n",
    "#account for shift from staggering\n",
    "# right_half = np.append(ss_image[:,8:512].copy(), np.zeros([64, 8]), axis = 1)\n",
    "# left_half = np.append(np.zeros([64, 8]), ss_image[:,512:-8].copy(), axis = 1)\n",
    "right_half = ss_image[:,:512].copy()\n",
    "left_half = ss_image[:,512:].copy()\n",
    "\n",
    "ss_image[:,512:] = right_half\n",
    "ss_image[:,:512] = left_half\n",
    "print(np.shape(ss_image))\n",
    "print(np.shape(scan1_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a99ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots(2,1)\n",
    "ax[0].set_title(\"Scan n\")\n",
    "ax[1].set_title(\"Scan (n-1) raycast into frame of scan n\")\n",
    "\n",
    "# ax[0].imshow(scan1_image)\n",
    "# ax[1].imshow(ss_image)\n",
    "# ax[0].imshow(np.flip(scan1_image[:,512:1024], axis = 0))\n",
    "# ax[1].imshow(np.flip(ss_image[:,512:1024], axis = 0))\n",
    "ax[0].imshow(np.flip(scan1_image[:,800:850], axis = 0))\n",
    "ax[1].imshow(np.flip(ss_image[:,800:850], axis = 0))\n",
    "# ax[2].imshow(np.flip(scan1_image[:,500:550]-ss_image[:,500:550], axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1286c31",
   "metadata": {},
   "source": [
    "# Suppress additional returns if angle is too oblique (hurts ground plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf488fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "horiz_grad = np.gradient(ss_image)[1] \n",
    "vert_grad = np.gradient(ss_image)[0] \n",
    "\n",
    "horiz_grad2 = np.gradient(np.gradient(ss_image)[1])[1] \n",
    "horiz_grad2 = horiz_grad2 > 0.1\n",
    "\n",
    "mask = (1 - (horiz_grad > 0.5)) * (1 - (vert_grad > 0.3)) + horiz_grad2\n",
    "mask = mask >= 1\n",
    "\n",
    "#hard fix-- remove ring around base via threshold\n",
    "mask[:15,:] = 0 \n",
    "\n",
    "fig, ax = p.subplots(2)\n",
    "# ax[0].imshow(np.flip(mask[:,300:600], axis = 0))\n",
    "# ax[1].imshow(np.flip(ss_image*mask, axis = 0)[:,300:600])\n",
    "ax[0].imshow(np.flip(mask[:,:], axis = 0))\n",
    "ax[1].imshow(np.flip(ss_image*mask, axis = 0)[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8725f4",
   "metadata": {},
   "source": [
    "## Construct CDF function for each pixel in scan n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan1_image[20,500])\n",
    "print((mask*ss_image)[20,500])\n",
    "\n",
    "#LOAD [-17.5,15]x1000, @0.005\n",
    "# np.save(\"/home/derm/Desktop/posesM17P15.npy\", poses)\n",
    "# np.save(\"/home/derm/Desktop/imagesM17P15.npy\", images)\n",
    "poses = np.load(\"/home/derm/Desktop/posesM17P15.npy\")\n",
    "images = np.load(\"/home/derm/Desktop/imagesM17P15.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa37604",
   "metadata": {},
   "outputs": [],
   "source": [
    "near = 0\n",
    "far = 1\n",
    "N_samples = 128\n",
    "\n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "\n",
    "phimin = np.deg2rad(-17.743) #flipped-- used for best synthetic-- WAS using this for best real data\n",
    "phimax = np.deg2rad(15.594) #flipped\n",
    "phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "img_i = np.random.randint(images.shape[0])\n",
    "idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "phimin_patch = phivals[idx_first]\n",
    "phimax_patch = phivals[idx_second]    \n",
    "\n",
    "pose = tf.cast(poses[0], tf.float32)\n",
    "\n",
    "#get ray origins and ray directions\n",
    "rays_o, rays_d = get_rays(H, W, pose, phimin_patch, phimax_patch)\n",
    "\n",
    "s1 = scan1_image * 0.005\n",
    "\n",
    "z_vals = tf.linspace(near, far, N_samples)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "z_vals = tf.cast(z_vals, tf.float32)\n",
    "z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "z_vals = z_vals[:,:,:,None]#manually expand dimensions before passing in to coarse network (all pixels will share the same z_vals)\n",
    "\n",
    "print(np.shape(z_vals))\n",
    "# print(z_vals[0,0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a402e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop scan 1 image and see where it falls wrt each z val \n",
    "scan1_image_cropped = scan1_image[:, 800:808]*0.005\n",
    "ss_image_cropped = ss_image[:, 800:808]*0.005\n",
    "# ss_image_cropped = mask[:, 800:808]*ss_image[:, 800:808]*0.005\n",
    "\n",
    "# print(np.shape(scan1_image_cropped))\n",
    "fig, ax = p.subplots(1,2)\n",
    "ax[0].imshow(np.flip(scan1_image_cropped, axis = 0))\n",
    "ax[1].imshow(np.flip(ss_image_cropped, axis = 0))\n",
    "\n",
    "cdf1 = scan1_image_cropped[:,:,None] < z_vals[:,:,:,0]\n",
    "cdf2 = ss_image_cropped[:,:,None] < z_vals[:,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87727f25",
   "metadata": {},
   "source": [
    "# Combine multiple range images into single PDF\n",
    "\n",
    "#### Need to be careful dealing with non-returns from cone-cast scans!\n",
    "* subtract starting val to ignore rays at 0, and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46516ce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(np.shape(cdf1[0,0,:]))\n",
    "combined = tf.cast(cdf1[25:40,:,:], tf.float32) + tf.cast(cdf2[25:40,:,:], tf.float32)\n",
    "\n",
    "#subtract out initial value of cdf2 to remove rays that didn't get a collision from prev scan\n",
    "# print(np.shape(combined))\n",
    "# print(np.shape(tf.cast(cdf2[:,:,0][:,:,None], tf.float32)))\n",
    "combined -= tf.cast(cdf2[25:40,:,0][:,:,None], tf.float32)\n",
    "\n",
    "#re-normalize to [0,1]\n",
    "num_useful_returns = (tf.math.reduce_max(combined, axis = -1))[:,:,None]\n",
    "# print(np.shape(num_useful_returns), num_useful_returns)\n",
    "combined = combined/num_useful_returns\n",
    "combined = tf.reshape(combined, [-1,128])\n",
    "\n",
    "# print(np.shape(combined))\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "ax.set_title(\"CDFs of multiple rays along a each look direction\")\n",
    "ax.set_xlabel(\"range (m)\")\n",
    "ax.set_ylabel(\"CDF\")\n",
    "ax.plot(np.linspace(0,100,128),combined.numpy().T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa6584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063d016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
