{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348a4524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 15:25:48.605403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-30 15:25:48.702208: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-30 15:25:49.026967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/lib:\n",
      "2024-09-30 15:25:49.027032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/lib:\n",
      "2024-09-30 15:25:49.027037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_graphics as tfg\n",
    "from tensorflow_graphics.nn.loss import chamfer_distance\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "from matplotlib import pyplot as p\n",
    "\n",
    "import torch\n",
    "from chamferdist import ChamferDistance\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "883a67e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54393, 3)\n",
      "(54019, 3)\n"
     ]
    }
   ],
   "source": [
    "# nerf_pc = np.load(\"lidar_nerf_demo/generated_pc_at_start.npy\")\n",
    "# real_pc = np.load(\"lidar_nerf_demo/real_pc_at_start.npy\")\n",
    "# nerf_pc = np.random.randn(1000,3)\n",
    "# real_pc = np.random.randn(1000,3)\n",
    "# nerf_pc = np.load(\"generatedPointClouds/7710NeRF.npy\")\n",
    "# real_pc = np.load(\"generatedPointClouds/7710real.npy\")\n",
    "nerf_pc = np.load(\"generatedPointClouds/7750NeRF.npy\")\n",
    "real_pc = np.load(\"generatedPointClouds/7750real.npy\")\n",
    "# nerf_pc = np.load(\"generatedPointClouds/7950NeRF.npy\")\n",
    "# real_pc = np.load(\"generatedPointClouds/7950real.npy\")\n",
    "# nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput.npy\")\n",
    "# real_pc = np.load(\"generatedPointClouds/MaiCityReal.npy\")\n",
    "\n",
    "#train set\n",
    "# nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_frame_10.npy\") \n",
    "# real_pc = np.load(\"generatedPointClouds/MaiCityReal_frame_10.npy\")\n",
    "# # #test set\n",
    "# nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_v2_frame_0.npy\") \n",
    "# real_pc = np.load(\"generatedPointClouds/MaiCityReal_v2_frame_0.npy\")\n",
    "\n",
    "# #remove ground plane\n",
    "# real_pc = real_pc[real_pc[:,2] > -1]\n",
    "# nerf_pc = nerf_pc[nerf_pc[:,2] > -1]\n",
    "\n",
    "# #debug: create simple pc\n",
    "# nerf_pc = np.array([[0,0,0], \n",
    "#                     [1,1,1]])\n",
    "# real_pc = np.array([[0,0,0], \n",
    "#                     [0,0,0]])\n",
    "\n",
    "#crop real PC down the same as NeRF output so bidirectional CD doesn't punish non-overlaps\n",
    "# real_pc = real_pc[len(real_pc)//8:7*len(real_pc)//8,:]\n",
    "real_pc = real_pc[len(real_pc)//8:31*len(real_pc)//32,:]\n",
    "\n",
    "\n",
    "#remove points too close to origin\n",
    "d = np.sqrt(np.sum(nerf_pc**2, axis = 1))\n",
    "good  = np.argwhere(d > 2.)[:,0]\n",
    "nerf_pc = nerf_pc[good]\n",
    "#remove points too close to origin\n",
    "d = np.sqrt(np.sum(real_pc**2, axis = 1))\n",
    "good  = np.argwhere(d > 2.)[:,0]\n",
    "real_pc = real_pc[good]\n",
    "\n",
    "#for NC only\n",
    "# nerf_pc = np.flip(nerf_pc, axis = 0)\n",
    "\n",
    "# #remove points out of range of sensor (only needed for Mai City)\n",
    "# d = np.sqrt(np.sum(nerf_pc**2, axis = 1))\n",
    "# good = np.argwhere(d < 100)[:,0]\n",
    "# nerf_pc = nerf_pc[good]\n",
    "\n",
    "# nerf_pc = nerf_pc[::3,:]\n",
    "# real_pc = real_pc[::3,:]\n",
    "# nerf_pc = nerf_pc[:len(nerf_pc)//8,:]\n",
    "# real_pc = real_pc[:len(real_pc)//8,:]\n",
    "\n",
    "# spin_part = 2\n",
    "# splits = 3 #8\n",
    "# nerf_pc = nerf_pc[spin_part*len(real_pc)//splits:(spin_part+1)*len(nerf_pc)//splits,:]\n",
    "# real_pc = real_pc[spin_part*len(real_pc)//splits:(spin_part+1)*len(real_pc)//splits,:]\n",
    "\n",
    "print(np.shape(nerf_pc))\n",
    "print(np.shape(real_pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae15ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38dac8bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd069bd1ad1748a5b289feef2e185474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real_pc = np.linspace(0,9,10)[:,None]*np.array([1.,0.,0.])\n",
    "# nerf_pc = np.linspace(0,9,10)[:,None]*np.array([1.,1.,0.]) + np.array([0.,1.,0])\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "disp.append(Points(real_pc[:,:], c = \"red\", r = 5))\n",
    "disp.append(Points(nerf_pc[:,:], c = \"blue\", r = 5))\n",
    "\n",
    "plt.show(disp, \"testing CD\")\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14436ae7",
   "metadata": {},
   "source": [
    "# manually calcluate CD with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "946bc226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd: tensor(0.1537)\n",
      "accuracy: tensor(0.1507)\n",
      "completeness: tensor(0.1568)\n"
     ]
    }
   ],
   "source": [
    "points1 = torch.tensor(nerf_pc.copy(), dtype=torch.float32)\n",
    "points2 = torch.tensor(real_pc.copy(), dtype=torch.float32)\n",
    "\n",
    "dists = torch.cdist(points1, points2)\n",
    "# print(dists)\n",
    "# Find the minimum distances\n",
    "min_dists1 = dists.min(dim=1)[0]  # from points1 to points2\n",
    "min_dists2 = dists.min(dim=0)[0]  # from points2 to points1\n",
    "# print(min_dists1, min_dists1.mean())\n",
    "# print(min_dists2, min_dists2.mean())\n",
    "\n",
    "#chamfer distance\n",
    "cd = (min_dists1.mean() + min_dists2.mean())/2\n",
    "print(\"cd:\", cd)\n",
    "\n",
    "#Accuracy--\n",
    "#\"The accuracy metric is defined as the mean distance of points on the output \n",
    "#   mesh to their nearest neighbors on the ground truth mesh.\" --\n",
    "accuracy = min_dists1.mean()\n",
    "print(\"accuracy:\", accuracy)\n",
    "\n",
    "#completeness--\n",
    "# The completeness metric is defined similarly, but in opposite direction.\n",
    "completeness = min_dists2.mean()\n",
    "print(\"completeness:\", completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12c2778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.225"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(15.59+6.86)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43025c05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd_hist = []\n",
    "accuracy_hist = []\n",
    "completeness_hist = []\n",
    "good1_hist = []\n",
    "good2_hist = []\n",
    "\n",
    "for frame_idx in range(1): #25\n",
    "    print(\"frame: \", frame_idx, \"---------------\")\n",
    "\n",
    "    for spin_part in range(8):\n",
    "#         nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_frame_\" + str(frame_idx) + \".npy\")\n",
    "#         real_pc = np.load(\"generatedPointClouds/MaiCityReal_frame_\" + str(frame_idx) + \".npy\")\n",
    "        nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_v2_frame_\" + str(frame_idx) + \".npy\")\n",
    "        real_pc = np.load(\"generatedPointClouds/MaiCityReal_v2_frame_\" + str(frame_idx) + \".npy\")\n",
    "\n",
    "        # #remove ground plane\n",
    "        # real_pc = real_pc[real_pc[:,2] > -1]\n",
    "        # nerf_pc = nerf_pc[nerf_pc[:,2] > -1]\n",
    "\n",
    "        # #debug: create simple pc\n",
    "        # nerf_pc = np.array([[0,0,0], \n",
    "        #                     [1,1,1]])\n",
    "        # real_pc = np.array([[0,0,0], \n",
    "        #                     [0,0,0]])\n",
    "\n",
    "        #crop real PC down the same as NeRF output so bidirectional CD doesn't punish non-overlaps\n",
    "        # real_pc = real_pc[len(real_pc)//8:7*len(real_pc)//8,:]\n",
    "        # real_pc = real_pc[len(real_pc)//8:29*len(real_pc)//32,:]\n",
    "\n",
    "\n",
    "        #remove points too close to origin\n",
    "        d = np.sqrt(np.sum(nerf_pc**2, axis = 1))\n",
    "        good  = np.argwhere(d > 1)[:,0]\n",
    "        nerf_pc = nerf_pc[good]\n",
    "\n",
    "        # #remove points out of range of sensor (only needed for Mai City)\n",
    "        # d = np.sqrt(np.sum(nerf_pc**2, axis = 1))\n",
    "        # good = np.argwhere(d < 100)[:,0]\n",
    "        # nerf_pc = nerf_pc[good]\n",
    "\n",
    "        nerf_pc = nerf_pc[spin_part*len(real_pc)//8:(spin_part+1)*len(nerf_pc)//8,:]\n",
    "        real_pc = real_pc[spin_part*len(real_pc)//8:(spin_part+1)*len(real_pc)//8,:]\n",
    "\n",
    "        points1 = torch.tensor(nerf_pc)\n",
    "        points2 = torch.tensor(real_pc)\n",
    "\n",
    "        dists = torch.cdist(points1, points2)\n",
    "        # print(dists)\n",
    "        # Find the minimum distances\n",
    "        min_dists1 = dists.min(dim=1)[0]  # from points1 to points2\n",
    "        min_dists2 = dists.min(dim=0)[0]  # from points2 to points1\n",
    "\n",
    "    #     print(min_dists1, min_dists1.mean())\n",
    "    #     print(min_dists2, min_dists2.mean())\n",
    "\n",
    "        cd = (min_dists1.mean() + min_dists2.mean())/2        \n",
    "        accuracy = min_dists2.mean() #TEST-- try flipping these values...\n",
    "        completeness = min_dists1.mean()\n",
    "        print(\"\\n cd:\", cd, \"  accuracy: \", accuracy, \" completeness:\", completeness)\n",
    "\n",
    "        cd_hist = np.append(cd_hist, cd)\n",
    "        accuracy_hist = np.append(accuracy_hist, accuracy)\n",
    "        completeness_hist = np.append(completeness_hist, completeness)\n",
    "        \n",
    "        good1 = np.where(min_dists1 < 0.1)[0]\n",
    "        good1 = len(good1)/len(min_dists1)\n",
    "\n",
    "        good2 = np.where(min_dists2 < 0.1)[0]\n",
    "        good2 = len(good2)/len(min_dists2)\n",
    "\n",
    "        good1_hist = np.append(good1_hist, good1)\n",
    "        good2_hist = np.append(good2_hist, good2)\n",
    "        print(\"good1, good2:\", good1, good2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495aa59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = p.subplots()\n",
    "# ax.plot(cd_hist, label = \"CD\")\n",
    "# ax.plot(completeness_hist, label = \"completeness\")\n",
    "# ax.plot(accuracy_hist, label = \"accuracy\")\n",
    "ax.plot(good1_hist, label = \"gh1\")\n",
    "ax.plot(good2_hist, label = \"gh2\")\n",
    "ax.plot( np.mean(good1_hist**2)*np.ones([400]))\n",
    "\n",
    "cutoff = 5000\n",
    "\n",
    "print(np.mean(cd_hist[:cutoff]))\n",
    "print(np.mean(accuracy_hist[:cutoff]))\n",
    "print(np.mean(completeness_hist[:cutoff]))\n",
    "print(np.mean((good1_hist)[:cutoff])) #too high to be F-score...?\n",
    "print(np.mean((good2_hist)[:cutoff])) #too high to be F-score...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ec2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*93*90.6/(93+90.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG ONLY-- look at data distribution witout tails\n",
    "\n",
    "bidx = np.linspace(0,3,100)\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "d1 = min_dists1.numpy()\n",
    "d1_good_only = d1[d1 < 0.2]\n",
    "\n",
    "d2 = min_dists2.numpy()\n",
    "d2_good_only = d2[d2 < 0.2]\n",
    "\n",
    "ax.hist(min_dists1, bins = bidx, alpha = 0.5);\n",
    "ax.hist(d1_good, bins = bidx, alpha = 0.5);\n",
    "\n",
    "print(np.mean(d1))\n",
    "print(np.mean(d1_good_only))\n",
    "\n",
    "print(np.mean(d2))\n",
    "print(np.mean(d2_good_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a6327",
   "metadata": {},
   "source": [
    "# TEST: Get F-Score using torch cdists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd08931",
   "metadata": {},
   "outputs": [],
   "source": [
    "points1 = torch.tensor(nerf_pc)\n",
    "points2 = torch.tensor(real_pc)\n",
    "\n",
    "dists = torch.cdist(points1, points2)\n",
    "# print(dists)\n",
    "# Find the minimum distances\n",
    "min_dists1 = dists.min(dim=1)[0]  # from points1 to points2\n",
    "min_dists2 = dists.min(dim=0)[0]  # from points2 to points1\n",
    "print(min_dists1, min_dists1.mean())\n",
    "\n",
    "good1 = np.where(min_dists1 < 0.1)[0]\n",
    "print(len(good1)/len(min_dists1))\n",
    "\n",
    "good2 = np.where(min_dists2 < 0.1)[0]\n",
    "print(len(good2)/len(min_dists2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d4ddf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_pc = torch.tensor(real_pc)\n",
    "nerf_pc = torch.tensor(nerf_pc)\n",
    "\n",
    "if len(real_pc.shape) == 2:\n",
    "    real_pc = real_pc.unsqueeze(0)  # Add batch dimension\n",
    "if len(nerf_pc.shape) == 2:\n",
    "    nerf_pc = nerf_pc.unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "# Convert to float\n",
    "real_pc = real_pc.float()\n",
    "nerf_pc = nerf_pc.float()\n",
    "print(nerf_pc.shape)\n",
    "\n",
    "chamferDist = ChamferDistance()\n",
    "dist_forward = chamferDist(nerf_pc, real_pc)\n",
    "print(dist_forward)\n",
    "# print(dist_forward/ nerf_pc.shape[1])\n",
    "# dist_bidirectional = chamferDist(nerf_pc, real_pc, bidirectional=True)\n",
    "# print(dist_bidirectional)\n",
    "# print(dist_bidirectional/ nerf_pc.shape[1])\n",
    "\n",
    "# #TEST -- modify chamfer.py to produce output for calculating F-scores\n",
    "# # dist_forward = chamferDist(nerf_pc, real_pc, reduction = 'fscore')\n",
    "# dist_forward = chamferDist(nerf_pc, real_pc, reduction = 'fscore', reverse = True)\n",
    "# # dist_forward is actually a SQUARED distance, so I need to take the sqrt first\n",
    "# print(dist_forward)\n",
    "# dist_forward = torch.sqrt(dist_forward)\n",
    "# print(dist_forward)\n",
    "\n",
    "# bad = np.argwhere(dist_forward > 0.2)\n",
    "\n",
    "# print(np.shape(dist_forward)[1])\n",
    "# print(np.shape(bad)[1])\n",
    "\n",
    "# print(1 - np.shape(bad)[1] / np.shape(dist_forward)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b28309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate map accuracy\n",
    "good = np.argwhere(dist_forward < 0.2)[1,:]\n",
    "print(len(good))\n",
    "print(len(dist_forward[0]))\n",
    "a = torch.mean(dist_forward[0][good])\n",
    "# a = torch.mean(dist_forward[0])\n",
    "print(a)\n",
    "\n",
    "# print(dist_forward[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0.9341 #true positives\n",
    "fp = 1 - 0.9341 #false positives\n",
    "\n",
    "#false negatives -- no estimated point close enough\n",
    "fn = 1-0.9286 #use reverse nn distnaces here\n",
    "\n",
    "\n",
    "# precision\n",
    "p = tp/(tp+fp)\n",
    "\n",
    "#recall\n",
    "r = tp/(tp+fn)\n",
    "\n",
    "f_score = 2*(p*r)/(p+r)\n",
    "print(f_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(savepc)\n",
    "# print(pc1_aligned)\n",
    "# print(dist_forward/ np.shape(nerf_pc)[1])\n",
    "\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "#crop real PC down the same as NeRF output so bidirectional CD doesn't punish non-overlaps\n",
    "# test = real_pc[0,len(real_pc[0,:,:])//8:7*len(real_pc[0,:,:])//8,:]\n",
    "# print(np.shape(test))\n",
    "# print(len(real_pc[0,:,:])//8)\n",
    "# disp.append(Points(test, c = \"red\", r = 5))\n",
    "\n",
    "disp.append(Points(real_pc[0,:,:], c = \"red\", r = 5))\n",
    "disp.append(Points(nerf_pc[0,:,:], c = \"blue\", r = 5))\n",
    "\n",
    "plt.show(disp, \"testing CD\")\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ed52c",
   "metadata": {},
   "source": [
    "# calculate chamfer distance between NeRF output true distance for 25 frames Mai City Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb639ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CD_hist = []\n",
    "chamferDist = ChamferDistance()\n",
    "\n",
    "for frame_idx in range(25):\n",
    "    print(frame_idx)\n",
    "    nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_frame_\" + str(frame_idx) + \".npy\")\n",
    "    real_pc = np.load(\"generatedPointClouds/MaiCityReal_frame_\" + str(frame_idx) + \".npy\")\n",
    "\n",
    "    #remove points too close to origin\n",
    "    d = np.sqrt(np.sum(nerf_pc**2, axis = 1))\n",
    "    good  = np.argwhere(d > 1)[:,0]\n",
    "    nerf_pc = nerf_pc[good]\n",
    "\n",
    "    #remove points out of range of sensor (only needed for Mai City)\n",
    "    d = np.sqrt(np.sum(nerf_pc**2, axis = 1))\n",
    "    good = np.argwhere(d < 100)[:,0]\n",
    "    nerf_pc = nerf_pc[good]\n",
    "    \n",
    "#     print(np.shape(nerf_pc))\n",
    "#     nerf_pc = nerf_pc[::3,:]\n",
    "#     real_pc = real_pc[::3,:]\n",
    "#     print(np.shape(nerf_pc))\n",
    "\n",
    "    real_pc = torch.tensor(real_pc)\n",
    "    nerf_pc = torch.tensor(nerf_pc)\n",
    "\n",
    "    if len(real_pc.shape) == 2:\n",
    "        real_pc = real_pc.unsqueeze(0)  # Add batch dimension\n",
    "    if len(nerf_pc.shape) == 2:\n",
    "        nerf_pc = nerf_pc.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Convert to float\n",
    "    real_pc = real_pc.float()\n",
    "    nerf_pc = nerf_pc.float()\n",
    "    \n",
    "#     dist_bidirectional = chamferDist(nerf_pc, real_pc, bidirectional=True)\n",
    "#     dist_bidirectional /= nerf_pc.shape[1]\n",
    "#     print(dist_bidirectional)\n",
    "#     CD_hist = np.append(CD_hist, dist_bidirectional)\n",
    "\n",
    "\n",
    "    dist_forward = chamferDist(nerf_pc, real_pc)\n",
    "#     dist_forward /= nerf_pc.shape[1]\n",
    "    print(dist_forward)\n",
    "    CD_hist = np.append(CD_hist, dist_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as p \n",
    "\n",
    "print(np.mean(CD_hist))\n",
    "# np.save(\"generatedPointClouds/MaiCity_CD_hist.npy\", CD_hist)\n",
    "# CD_hist = np.load(\"generatedPointClouds/MaiCity_CD_hist.npy\")\n",
    "# print(CD_hist)\n",
    "fig, ax = p.subplots()\n",
    "ax.plot(CD_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40609085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as p\n",
    "\n",
    "# CD_hist_2 = CD_hist.copy()\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "ax.set_title(\"Chamfer Distance for Mai City Dataset\")\n",
    "# ax.plot(CD_hist_15, label = \"sample every 15th\")\n",
    "# ax.plot(CD_hist_10, label = \"sample every 10th\")\n",
    "# ax.plot(CD_hist_5, label = \"sample every 5th\")\n",
    "# ax.plot(CD_hist_2, label = \"sample every 2nd\")\n",
    "ax.plot(CD_hist, label = \"CD\")\n",
    "ax.set_xlabel(\"test frame index\")\n",
    "ax.set_ylabel(\"Chamfer Distance (cm)\")\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e91e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine all NeRF outputs to single point cloud to render with open3d\n",
    "combined_pc = np.zeros([0,3])\n",
    "for frame_idx in range(50): #25\n",
    "    print(frame_idx)\n",
    "#     nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_frame_\" + str(frame_idx) + \".npy\") #\n",
    "    nerf_pc = np.load(\"generatedPointClouds/MaiCityNeRFOutput_velodyne_format_frame_\" + str(frame_idx) + \".npy\") #OS1 projections\n",
    "#     nerf_pc = np.load(\"generatedPointClouds/MaiCityReal_frame_\" + str(frame_idx) + \".npy\") #DEBUG -- true scans\n",
    "\n",
    "    #remove near zero points\n",
    "#     nerf_pc = nerf_pc*200\n",
    "    dists = np.sqrt(nerf_pc[:,0]**2 + nerf_pc[:,1]**2 + nerf_pc[:,2]**2)\n",
    "    good = np.argwhere(dists > 2)[:,0]\n",
    "#     print(good)\n",
    "    nerf_pc = nerf_pc[good]\n",
    "\n",
    "    nerf_pc = nerf_pc + np.array([frame_idx*.5,0.,0.])\n",
    "#     nerf_pc = nerf_pc + np.array([frame_idx*1.,0.,0.])\n",
    "    \n",
    "    combined_pc = np.append(combined_pc, nerf_pc, axis = 0)\n",
    "\n",
    "# print(np.shape(combined_pc))\n",
    "\n",
    "# #crop to help with marching cubes??\n",
    "# combined_pc = combined_pc[abs(combined_pc[:,0]) < 20]\n",
    "# combined_pc = combined_pc[abs(combined_pc[:,1]) < 20]\n",
    "# np.save(\"generatedPointClouds/CombinedMaiCity.npy\", combined_pc)\n",
    "\n",
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(combined_pc)\n",
    "o3d.io.write_point_cloud(\"MaiCityNeRF.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f788dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST -- load and crop HD Map to test marching cubes\n",
    "import trimesh\n",
    "pl = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply'\n",
    "raw_points = trimesh.load(pl).vertices\n",
    "# points[:,2] = -points[:,2] #flip z\n",
    "# points = points[::10,:] #downsample\n",
    "points = raw_points.copy()\n",
    "\n",
    "points = points[points[:,0]>0]\n",
    "points = points[points[:,1]> - 2]\n",
    "\n",
    "combined_pc = points\n",
    "# np.save(\"generatedPointClouds/NCTestMap.npy\", combined_pc)\n",
    "\n",
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(combined_pc)\n",
    "o3d.io.write_point_cloud(\"NCTestMap.ply\", pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "disp.append(Points(combined_pc, c = \"red\", r = 2.5, alpha = 0.3))\n",
    "disp.append(Points(raw_points, c = \"black\", r = 2.5, alpha = 0.1))\n",
    "\n",
    "plt.show(disp, \"testing CD\")\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80657c",
   "metadata": {},
   "source": [
    "### Load 100 raw frames from Mai City sequence 01 and combine to a single point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3627ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test = np.loadtxt(\"/media/derm/06EF-127D4/mai_city/txt/01/000000\")\n",
    "\n",
    "combined_pc = np.zeros([0,3])\n",
    "for idx1 in range(100):\n",
    "    print(idx1)\n",
    "    pcfn = \"/media/derm/06EF-127D4/mai_city/txt/01/\" +  f\"{idx1:06}\"\n",
    "    \n",
    "    pc = np.loadtxt(pcfn)\n",
    "    pc += np.array([1.*idx1, 0.,0.])\n",
    "    pc = pc[::2]\n",
    "    \n",
    "    combined_pc = np.append(combined_pc, pc, axis = 0)\n",
    "\n",
    "print(combined_pc)\n",
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(combined_pc)\n",
    "o3d.io.write_point_cloud(\"MaiCityGTMap.ply\", pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259bc96",
   "metadata": {},
   "source": [
    "# Calculate CD using pytorch3d chafer_distance() loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868d7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
