{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import tensorflow as tf\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 12*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import run_nerf\n",
    "\n",
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basedir = './logs'\n",
    "# basedir = '/home/derm/nerf/logs' #pull data from desktop (too big to store on git repo)\n",
    "basedir = '/home/derm/ASAR/v3/nerf/tiny_nerf/logs'\n",
    "# expname = 'fern_example'\n",
    "expname = 'bike_test'\n",
    "\n",
    "config = os.path.join(basedir, expname, 'config.txt')\n",
    "print('Args:')\n",
    "print(open(config, 'r').read())\n",
    "parser = run_nerf.config_parser()\n",
    "\n",
    "# args = parser.parse_args('--config {} --ft_path {}'.format(config, os.path.join(basedir, expname, 'model_200000.npy')))\n",
    "args = parser.parse_args('--config {} --ft_path {}'.format(config, os.path.join(basedir, expname, 'model_270000.npy')))\n",
    "print('loaded args')\n",
    "\n",
    "images, poses, bds, render_poses, i_test = load_llff_data(args.datadir, args.factor, \n",
    "                                                          recenter=True, bd_factor=.75, \n",
    "                                                          spherify=args.spherify)\n",
    "H, W, focal = poses[0,:3,-1].astype(np.float32)\n",
    "\n",
    "H = int(H)\n",
    "W = int(W)\n",
    "hwf = [H, W, focal]\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "if args.no_ndc:\n",
    "    near = tf.reduce_min(bds) * .9\n",
    "    far = tf.reduce_max(bds) * 1.\n",
    "else:\n",
    "    near = 0.\n",
    "    far = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(render_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nerf model\n",
    "_, render_kwargs_test, start, grad_vars, models = run_nerf.create_nerf(args)\n",
    "\n",
    "bds_dict = {\n",
    "    'near' : tf.cast(near, tf.float32),\n",
    "    'far' : tf.cast(far, tf.float32),\n",
    "}\n",
    "render_kwargs_test.update(bds_dict)\n",
    "\n",
    "print('Render kwargs:')\n",
    "pprint.pprint(render_kwargs_test)\n",
    "\n",
    "\n",
    "down = 1 #4\n",
    "render_kwargs_fast = {k : render_kwargs_test[k] for k in render_kwargs_test}\n",
    "render_kwargs_fast['N_importance'] = 0\n",
    "\n",
    "c2w = np.eye(4)[:3,:4].astype(np.float32) # identity pose matrix\n",
    "# c2w[2,-1] = -2 #slide back a bit\n",
    "test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w, **render_kwargs_fast)\n",
    "img = np.clip(test[0],0,1)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#debug render poses\n",
    "poses = render_poses[::1].copy()\n",
    "poses[:,:,3] = poses[:,:,3]*1.6\n",
    "poses[:,:3,:3] = np.eye(3)\n",
    "poses[:,:2,3] = poses[:,:2,3]*0. \n",
    "print(poses)\n",
    "\n",
    "headings = poses[:,:3,:3] @ np.array([0,0,-1]) #old\n",
    "\n",
    "\n",
    "\n",
    "# from vedo import *\n",
    "# from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "\n",
    "# plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True)\n",
    "# disp=[]\n",
    "# disp.append(Points(poses[:,:3,-2], c = \"#CB2314\"))\n",
    "# disp.append(Arrows(poses[:,:3,-2], poses[:,:3,-2] + headings[:,:3], c = \"#CB2314\"))\n",
    "# disp.append(Points(np.array([[0,0,0]]), c = 'black'))\n",
    "\n",
    "# plt.show(disp, \"camera poses\")\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "down = 1 #8 # trade off resolution+aliasing for render speed to make this video faster\n",
    "frames = []\n",
    "# for i, c2w in enumerate(render_poses):\n",
    "for i, c2w in enumerate(poses):\n",
    "    if i%1==0: print(i)\n",
    "    test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w[:3,:4], **render_kwargs_fast)\n",
    "    frames.append((255*np.clip(test[0],0,1)).astype(np.uint8))\n",
    "    \n",
    "print('done, saving')\n",
    "f = 'bike_example_video_long.mp4'\n",
    "imageio.mimwrite(f, frames, fps=30, quality=8)\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(f, height=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive, widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def f(x, y, z):\n",
    "    \n",
    "    c2w = tf.convert_to_tensor([\n",
    "        [1,0,0,x],\n",
    "        [0,1,0,y],\n",
    "        [0,0,1,z],\n",
    "        [0,0,0,1],\n",
    "    ], dtype=tf.float32)\n",
    "    \n",
    "    test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w, **render_kwargs_fast)\n",
    "    img = np.clip(test[0],0,1)\n",
    "    \n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "sldr = lambda : widgets.FloatSlider(\n",
    "    value=0.,\n",
    "    min=-3.,\n",
    "    max=3.,\n",
    "    step=.01,\n",
    ")\n",
    "\n",
    "names = ['x', 'y', 'z']\n",
    "    \n",
    "interactive_plot = interactive(f, **{n : sldr() for n in names})\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
