{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf2524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load requirements for working with PCs\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 20*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "import sys\n",
    "import os\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "sys.path.append(parent_directory+\"/point_cloud_rectification\")\n",
    "from ICET_spherical import ICET\n",
    "from linear_corrector import LC\n",
    "\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import trimesh\n",
    "\n",
    "from pillow_heif import register_heif_opener\n",
    "from matplotlib import pyplot as p\n",
    "from colmapParsingUtils import *\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cv2\n",
    "from lidar_nerf_utils import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579ed6d",
   "metadata": {},
   "source": [
    "# Manually Load and Crop Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remove_motion_basic import linear_correction_old as lc\n",
    "\n",
    "dir_name = \"/media/derm/06EF-127D4/Newer College Dataset/\"\n",
    "experiment_name = \"01_short_experiment-20230331T172433Z-009/01_short_experiment/\"\n",
    "fn_gt = dir_name + experiment_name + \"ground_truth/registered_poses.csv\"\n",
    "#sec,nsec,x,y,z,qx,qy,qz,qw\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "seconds = gt[:, 0]\n",
    "nano_seconds = gt[:, 1]\n",
    "xyz = gt[:, 2:5]\n",
    "qxyzw = gt[:, 5:]\n",
    "num_poses = qxyzw.shape[0]\n",
    "sensor_poses = np.eye(4, dtype=np.float64).reshape(1, 4, 4).repeat(num_poses, axis=0)\n",
    "sensor_poses[:, :3, :3] = R.from_quat(qxyzw).as_matrix()\n",
    "sensor_poses[:, :3, 3] = xyz\n",
    "T_CL = np.eye(4, dtype=np.float32)\n",
    "T_CL[:3, :3] = R.from_quat([0.0, 0.0, 0.924, 0.383]).as_matrix() #was this --1134.97 deg\n",
    "T_CL[:3, 3] = np.array([-0.084, -0.025, 0.050], dtype=np.float32) #was this\n",
    "sensor_poses = np.einsum(\"nij,jk->nik\", sensor_poses, T_CL)\n",
    "initial_pose = np.linalg.inv(sensor_poses[0]) \n",
    "poses_timestamps = seconds * 10e9 + nano_seconds\n",
    "sensor_poses = np.einsum(\"ij,njk->nik\", np.linalg.inv(sensor_poses[0]), sensor_poses) #TRY COMMENTING OUT...\n",
    "\n",
    "#get body frame vel to remove motion disortion from training data\n",
    "vel_world_frame = np.diff(sensor_poses[:,:3,-1], axis = 0)\n",
    "vel_body_frame = np.linalg.pinv(sensor_poses[1:,:3,:3]) @ vel_world_frame[:,:,None]\n",
    "vel_body_frame = vel_body_frame[:,:,0]\n",
    "#smooth out velocity estimates\n",
    "def moving_average(a, n=10):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "window=50\n",
    "MAx = moving_average(vel_body_frame[:,0], n = window)\n",
    "MAy = moving_average(vel_body_frame[:,1], n = window)\n",
    "MAz = moving_average(vel_body_frame[:,2], n = window)\n",
    "vel_body_frame = np.array([MAx, MAy, MAz]).T\n",
    "\n",
    "rot_vel_euls = np.diff(R.from_matrix(sensor_poses[:,:3,:3]).as_euler('xyz'), axis = 0)\n",
    "idx = np.argwhere(rot_vel_euls > (np.pi))\n",
    "rot_vel_euls[idx] = 0\n",
    "idx = np.argwhere(rot_vel_euls < (-np.pi))\n",
    "rot_vel_euls[idx] = 0\n",
    "\n",
    "pl = '/media/derm/06EF-127D4/Newer College Dataset/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply'\n",
    "HD_map = trimesh.load(pl).vertices\n",
    "show_nth = 5 #10\n",
    "submap = HD_map[::show_nth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba56701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patch(rays_o, rays_d, image):    \n",
    "    \"\"\"given rays_o and rays_d, and a training image, \n",
    "        display the corresponding point cloud in the world frame\"\"\"\n",
    "    \n",
    "    #flatten first\n",
    "    rays_d_flat = np.reshape(rays_d, [-1,3])\n",
    "    \n",
    "    #convert to spherical\n",
    "    rays_d_spherical = cartesian_to_spherical(rays_d_flat).numpy()\n",
    "\n",
    "    #reshape rays_d to same size as image\n",
    "    rays_d_spherical = np.reshape(rays_d_spherical, [np.shape(rays_d)[0], np.shape(rays_d)[1], 3])\n",
    "    rays_d_spherical[:,:,0] *= image\n",
    "    rays_d_spherical = np.reshape(rays_d_spherical, [-1,3])\n",
    "    xyz = spherical_to_cartesian(rays_d_spherical)\n",
    "    \n",
    "    xyz += np.reshape(rays_o, [-1,3])\n",
    "    \n",
    "    return xyz\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d19d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  undistort raw point clouds, define patch sizes,\n",
    "#  take patches about useful regions of the scene, and record poses for each patch \n",
    "\n",
    "from time import sleep\n",
    "#convert gt from xyzquat to homogenous rotation matrix\n",
    "n_images = 10 #220 #1000 #50 \n",
    "n_rots = 16 #128    #number of horizontal patches in 360 degrees\n",
    "n_vert_patches = 4 #1 #number of vertical patches between phimin and phimaxs\n",
    "useICET = True #need to turn off when working with the foliage dataset???\n",
    "image_width = 1024//n_rots\n",
    "image_height = 64//n_vert_patches\n",
    "            \n",
    "\n",
    "# n_cols_to_skip = 0 #comment out for debug\n",
    "n_cols_to_skip = n_rots // 8 #remove this much from the beginning and end of each scan\n",
    "                             #   (need to remove parts of frame containing researcher carrying LIDAR)\n",
    "#Ouster OS1-64\n",
    "phimin = np.deg2rad(-15.594) #took forever to figure this out...\n",
    "phimax = np.deg2rad(17.743)\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "\n",
    "poses = np.zeros([n_images*n_rots*n_vert_patches,4,4])\n",
    "images = np.ones([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 2]) #depth and raydrop channels\n",
    "# [n total \"patches\", patch height, patch width, xyz]\n",
    "rays_o_all = np.zeros([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 3]) \n",
    "rays_d_all = np.zeros([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 3]) \n",
    "\n",
    "H, W = images.shape[1:3]\n",
    "redfix_hist = np.zeros([n_images,4,4]) #holds on to the corrective transforms we get from ICET \n",
    "\n",
    "for i in range(n_images):\n",
    "    print(i) \n",
    "    #2nd courtyard\n",
    "#     idx = i*60 + 1500\n",
    "    #full loop first courtyard\n",
    "#     idx = i + 7700 \n",
    "    idx = i*100 + 7700\n",
    "#     #test forest\n",
    "#     idx = i*40 + 11000\n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "    \n",
    "#     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    m_hat = np.array([-vel_body_frame[idx,0],\n",
    "                      -vel_body_frame[idx,1],\n",
    "                      -vel_body_frame[idx,2],\n",
    "                      -rot_vel_euls[idx,0], #looks good\n",
    "                      -rot_vel_euls[idx,1],\n",
    "                      -rot_vel_euls[idx,2]\n",
    "#                       0,0,0 #rotational velocity is zero-centered (theoretically should cancel out with enough data)\n",
    "                     ])   \n",
    "    pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    pc1 = np.flip(pc1, axis = 0)# uncomment to flip and maintain CCW convention used in VICET\n",
    "\n",
    "    if useICET:\n",
    "        #Register undistorted PC against HD Map using ICET to correct issues in ground truth------------------------\n",
    "        submap_in_pc1_frame = (np.linalg.pinv(sensor_poses[idx]) @ initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #test\n",
    "        submap_in_pc1_frame = submap_in_pc1_frame[:,:3]\n",
    "\n",
    "        initial_guess = tf.constant([0.,0.,0.,0.,0.,0.])\n",
    "        it = ICET(cloud1 = submap_in_pc1_frame, cloud2 = pc1, fid = 50, niter = 8, \n",
    "           draw = False, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "\n",
    "        pc1_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T #test\n",
    "        pc1_in_map_frame = pc1_in_map_frame[:,:3]\n",
    "    #     disp.append(Points(pc1_in_map_frame, c = 'red', r = 3, alpha = 0.2))\n",
    "\n",
    "        pc1_corrected_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(it.cloud2_tensor.numpy(), np.ones([len(it.cloud2_tensor.numpy()),1]), axis =1).T).T #test\n",
    "        pc1_corrected_in_map_frame = pc1_corrected_in_map_frame[:,:3]    \n",
    "    #     disp.append(Points(pc1_corrected_in_map_frame, c = 'blue', r =3, alpha = 0.2))\n",
    "\n",
    "        #draw red scan corrected by output of ICET\n",
    "        redFix = np.eye(4)\n",
    "        redFix[:3,-1] = it.X[:3]\n",
    "        redFix[:3,:3] = redFix[:3,:3] @ R.from_euler('xyz', [it.X[3], it.X[4], it.X[5]]).as_matrix()\n",
    "        redfix_hist[i] = redFix\n",
    "\n",
    "        redScanFixed = (redFix @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "    #     redScanFixed = (initial_pose @ sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "        redScanFixed = (sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "    #     disp.append(Points(redScanFixed[:,:3], c = 'red', r =3, alpha = 0.2))    \n",
    "        #----------------------------------------------------------------------------------------------------------------\n",
    "    else:\n",
    "        redFix = np.eye(4)\n",
    "        redfix_hist[i] = redFix\n",
    "        redScanFixed = (redFix @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "        redScanFixed = (sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "        \n",
    "    #convert to depth image\n",
    "    pc1_spherical = cartesian_to_spherical(pc1).numpy() #[r, theta, phi]\n",
    "    pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "    pcs = np.flip(pcs, axis = 1)\n",
    "    raw_data = pcs[:,:,:]\n",
    "    raw_data = np.transpose(pcs, [1,0,2])\n",
    "\n",
    "    #destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "    data = np.zeros([64, 1024])\n",
    "    for k in range(np.shape(data)[0]//4):\n",
    "# #         #shift right -- https://ouster.com/insights/blog/firmware-2-4-industry-standard-protocols-and-improved-alerts\n",
    "#         data[4*k,:] = raw_data[4*k,:,0]\n",
    "#         data[4*k+1,6:] = raw_data[4*k+1,:-6,0]\n",
    "#         data[4*k+2,12:] = raw_data[4*k+2,:-12,0]\n",
    "#         data[4*k+3,18:] = raw_data[4*k+3,:-18,0]\n",
    "        # keep centered -- this is working best, though I feel like NC should have used the old firmware\n",
    "        data[4*k,1:-8] = raw_data[4*k,9:,0]\n",
    "        data[4*k+1,1:-2] = raw_data[4*k+1,3:,0]\n",
    "        data[4*k+2,4:] = raw_data[4*k+2,:-4,0]\n",
    "        data[4*k+3,10:] = raw_data[4*k+3,:-10,0]\n",
    "    data = np.flip(data, axis =1) #do not comment out\n",
    "    \n",
    "    #NEW--- get rays_o and rays_d directly inside data generation loop ~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#     ro, rd = get_rays_from_point_cloud(pc1, m_hat, redFix) #old\n",
    "    \n",
    "    #test -- do frame manipulations to pc1 here...\n",
    "    tempPC = np.flip(pcs, axis = 0)\n",
    "    tempPC = np.reshape(tempPC, [-1,3])\n",
    "    \n",
    "    rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "    rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "    rotm[:3,-1] = np.array([-rotm[2,-1], -rotm[0,-1], rotm[1,-1]])\n",
    "    #orient yellow (-z) pointing forward\n",
    "    fix = np.array([[0,0,1],\n",
    "                    [1,0,0],\n",
    "                    [0,1,0]])\n",
    "    rotm[:3,:3] = rotm[:3,:3] @ fix\n",
    "    swap_axis_matrix = np.array([[0, 0, 1],\n",
    "                                 [1, 0, 0],\n",
    "                                 [0, 1, 0]])\n",
    "    flip_axis_matrix = np.diag([1,1,-1]) # better ---> corrects flipping z issue when rendering\n",
    "    rotm[:3,:3] = flip_axis_matrix @ swap_axis_matrix @ rotm[:3,:3] \n",
    "\n",
    "#     #center camera horizontally in each patch\n",
    "#     crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "#     rotm_crop = R.from_euler('xyz', [0,-crop_angle,0]).as_matrix()\n",
    "\n",
    "#     rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "    \n",
    "    \n",
    "#     ro, rd = get_rays_from_point_cloud(tempPC, m_hat, sensor_poses[idx] @ redFix)\n",
    "    ro, rd = get_rays_from_point_cloud(tempPC, m_hat, rotm)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    for j in range(n_rots):\n",
    "        for k in range(n_vert_patches):\n",
    "            #get cropped depth image ~~~~~~~~~~~~~~~~~~~~    \n",
    "            #crop vertically and horizontally\n",
    "            pcs = data[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width] \n",
    "    \n",
    "            #save depth information to first channel\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] = pcs\n",
    "#             images[(n_vert_patches - 1 - k)+(j+(i*n_rots))*n_vert_patches,:,:,0] = pcs #TEST -- nope\n",
    "\n",
    "            #save raydrop mask to 2nd channel\n",
    "            a = np.argwhere(abs(pcs) < 1)\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches, a[:,0],a[:,1],1] = 0\n",
    "#             images[(n_vert_patches - 1 - k)+(j+(i*n_rots))*n_vert_patches, a[:,0],a[:,1],1] = 0 #TEST -- nope\n",
    "\n",
    "            #get transformation matrix ~~~~~~~~~~~~~~~~~~\n",
    "            #centers origin at actual origin of HD map \n",
    "            rotm = sensor_poses[idx] @ redfix_hist[i] #old\n",
    "            rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "            rotm[:3,-1] = np.array([-rotm[2,-1], -rotm[0,-1], rotm[1,-1]])\n",
    "            #orient yellow (-z) pointing forward\n",
    "            fix = np.array([[0,0,1],\n",
    "                            [1,0,0],\n",
    "                            [0,1,0]])\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ fix\n",
    "            swap_axis_matrix = np.array([[0, 0, 1],\n",
    "                                         [1, 0, 0],\n",
    "                                         [0, 1, 0]])\n",
    "            flip_axis_matrix = np.diag([1,1,-1]) # better ---> corrects flipping z issue when rendering\n",
    "            rotm[:3,:3] = flip_axis_matrix @ swap_axis_matrix @ rotm[:3,:3] \n",
    "\n",
    "            #center camera horizontally in each patch\n",
    "            crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "            rotm_crop = R.from_euler('xyz', [0,-crop_angle,0]).as_matrix()\n",
    "\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "\n",
    "            #courtyard1\n",
    "            rotm[2,-1] += 45 #translate above xy plane #COURTYARD\n",
    "#             rotm[2,-1] += 300 #FOR FOREST ONLY!\n",
    "            rotm[1,-1] += 30 #shift towards positive x\n",
    "\n",
    "            #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "            rotm[:3,-1] *= 0.005 #0.005 #0.02 #0.05 #COURTYARD\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.005 #0.005 #0.02 #0.005 #0.05\n",
    "#             rotm[:3,-1] *= 0.001 #FOREST ONLY\n",
    "#             images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.001 #FOREST ONLY\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            # recenter (when using x0.005)\n",
    "            rotm[2,-1] += 0.25 #translate above xy plane\n",
    "            rotm[1,-1] += 0.25 #shift towards positive x\n",
    "            rotm[0,-1] += 0.01 #TEST -- shift up just a little\n",
    "            \n",
    "            poses[k+(j+(i*n_rots))*n_vert_patches] = rotm \n",
    "            \n",
    "            #store rays_o and rays_d info\n",
    "            #TODO: transforming rays_o[cell] and rays_d[cell] by rotm??\n",
    "            rd_in_patch = rd[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width, :]\n",
    "            rays_d_all[k+(j+(i*n_rots))*n_vert_patches,:,:,:] = rd_in_patch\n",
    "            \n",
    "            ro_in_patch = ro[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width, :]\n",
    "#             rays_o_all[k+(j+(i*n_rots))*n_vert_patches,:,:,:] = ro_in_patch\n",
    "            rays_o_all[k+(j+(i*n_rots))*n_vert_patches,:,:,:] = rotm[:3,-1]            \n",
    "            \n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "print(\"num poses:\", len(poses))\n",
    "\n",
    "# # # Remove patches where sensor is occluded by person holding lidar ~~~~~~~~~~\n",
    "# #calculte how many columns of patches we need to skip at the beginning and end of each scan to avoid\n",
    "# print(\"n_rots:\", n_rots)\n",
    "# # n_cols_to_skip = 0 #debug\n",
    "# print(\"n_cols_to_skip:\", n_cols_to_skip)\n",
    "\n",
    "# bad_idx = np.zeros([0,n_rots - 2*n_cols_to_skip])\n",
    "# a = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "# print(np.shape(a))\n",
    "# for i in range(n_vert_patches*n_cols_to_skip):\n",
    "#     bad_i_left = a[i::n_rots*n_vert_patches]\n",
    "#     bad_idx = np.append(bad_idx, bad_i_left)\n",
    "# #     print(\"\\n bad_idx_left:\", bad_i_left)\n",
    "\n",
    "#     bad_i_right = a[(i+n_vert_patches*(n_rots-n_cols_to_skip))::n_rots*n_vert_patches]\n",
    "#     bad_idx = np.append(bad_idx, bad_i_right)\n",
    "# #     print(\"\\n bad_idx_right:\", bad_i_right)\n",
    "    \n",
    "# bad_idx = np.sort(bad_idx)\n",
    "# all_idx = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "# good_idx = np.setdiff1d(all_idx, bad_idx).astype(int)\n",
    "\n",
    "# # print(good_idx)\n",
    "\n",
    "# images = images[good_idx,:,:,:]\n",
    "# poses = poses[good_idx,:,:]\n",
    "# # #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# # test on one only\n",
    "# testimg, testpose = images[-1], poses[-1]\n",
    "# images = images[:-1,...,:3]\n",
    "# poses = poses[:-1]\n",
    "\n",
    "# plt.show(disp, \"01 Short Experiment Frame #\" + str(idx))\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa5369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def interpolate_missing_angles(pc1):\n",
    "    \"\"\"pc1 = cartesian coordinates of point cloud AFTER distortion correction has been applied\"\"\"\n",
    "\n",
    "    pc1_spherical = cartesian_to_spherical(pc1).numpy()\n",
    "    #test moving wrap around to center -- reduce NaNs??\n",
    "    pc1_spherical[:,1] += np.pi\n",
    "    pc1_spherical = tf.cast(pc1_spherical, tf.float32)\n",
    "    \n",
    "    ray_drops = tf.where(pc1_spherical[:,0]<0.001)\n",
    "    non_ray_drops = tf.where(pc1_spherical[:,0]>0.001)\n",
    "\n",
    "    # Generate a regular 2D grid (source grid)\n",
    "    source_grid_x, source_grid_y = np.meshgrid(np.linspace(0, 63, 64), np.linspace(0, 1023, 1024))\n",
    "    source_points = np.column_stack((source_grid_x.flatten(), source_grid_y.flatten()))\n",
    "    warped_points = pc1_spherical[:,1:].numpy()\n",
    "#     print(\"warped_points\", np.shape(warped_points))\n",
    "\n",
    "    # Select known warped points (subset for interpolation)\n",
    "    known_indices = non_ray_drops[:,0]\n",
    "    known_source_points = source_points[known_indices]\n",
    "    known_warped_points = warped_points[known_indices]\n",
    "\n",
    "    # Interpolate missing points on the warped grid\n",
    "    missing_indices = np.setdiff1d(np.arange(len(source_points)), known_indices)  # Remaining points\n",
    "    missing_source_points = source_points[missing_indices]\n",
    "\n",
    "    # Use griddata to estimate locations of missing points on the warped grid\n",
    "    interpolated_points = griddata(known_source_points, known_warped_points, missing_source_points, method='cubic')\n",
    "#     interpolated_points = np.nan_to_num(interpolated_points, 0)\n",
    "#     print(\"\\n interpolated_points\", np.shape(interpolated_points), interpolated_points)\n",
    "\n",
    "    #fill interpolated points back in to missing locations\n",
    "    full_points_spherical = tf.zeros_like(pc1_spherical).numpy()[:,:2]\n",
    "    #combine via mask old and new interpolated points\n",
    "    full_points_spherical[non_ray_drops[:,0]] = known_warped_points\n",
    "    full_points_spherical[ray_drops[:,0]] = interpolated_points\n",
    "\n",
    "    full_points_spherical = np.append(np.ones([len(full_points_spherical), 1]), full_points_spherical, axis = 1)\n",
    "    full_points = spherical_to_cartesian(full_points_spherical)\n",
    "#     print(\"\\n full_points_spherical\", np.shape(full_points_spherical), tf.math.reduce_sum(full_points_spherical))\n",
    "\n",
    "    p.figure(figsize=(10, 6))\n",
    "    p.scatter(*zip(*known_warped_points[::10]), color='blue', label='Known Warped Points')\n",
    "    p.scatter(*zip(*interpolated_points[::10]), color='red', label='Interpolated Points')\n",
    "    p.legend()\n",
    "    p.title(\"Warped Grid with Known and Interpolated Points\")\n",
    "    p.show()\n",
    "\n",
    "    print(interpolated_points)\n",
    "\n",
    "    return full_points\n",
    "\n",
    "idx = 8200\n",
    "fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "pc1 = np.load(fn1)\n",
    "m_hat = np.array([1.,0,0,0,0,0.])\n",
    "pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "full_points = interpolate_missing_angles(pc1)\n",
    "\n",
    "# plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "# disp=[]          \n",
    "# disp.append(Points(full_points, c = 'grey', r = 3, alpha = 0.5))\n",
    "# plt.show(disp, \"debugging rays_o and rays_d\")\n",
    "# ViewInteractiveWidget(plt.window)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d145e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trying again, much more simplified...\n",
    "\n",
    "from time import sleep\n",
    "#convert gt from xyzquat to homogenous rotation matrix\n",
    "n_images = 20 #220 #1000 #50 \n",
    "n_rots = 128 #128    #number of horizontal patches in 360 degrees\n",
    "n_vert_patches = 1 #1 #number of vertical patches between phimin and phimaxs\n",
    "useICET = True #need to turn off when working with the foliage dataset???\n",
    "image_width = 1024//n_rots\n",
    "image_height = 64//n_vert_patches\n",
    "\n",
    "# n_cols_to_skip = 0 #comment out for debug\n",
    "n_cols_to_skip = n_rots // 8 #remove this much from the beginning and end of each scan\n",
    "                             #   (need to remove parts of frame containing researcher carrying LIDAR)\n",
    "#Ouster OS1-64\n",
    "phimin = np.deg2rad(-15.594) #took forever to figure this out...\n",
    "phimax = np.deg2rad(17.743)\n",
    "vert_fov = np.rad2deg(phimax-phimin)\n",
    "\n",
    "poses = np.zeros([n_images*n_rots*n_vert_patches,4,4])\n",
    "images = np.ones([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 2]) #depth and raydrop channels\n",
    "# [n total \"patches\", patch height, patch width, xyz]\n",
    "rays_o_all = np.zeros([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 3]) \n",
    "rays_d_all = np.zeros([n_images*n_rots*n_vert_patches, 64//n_vert_patches, 1024//n_rots, 3]) \n",
    "\n",
    "H, W = images.shape[1:3]\n",
    "redfix_hist = np.zeros([n_images,4,4]) #holds on to the corrective transforms we get from ICET \n",
    "\n",
    "for i in range(n_images):\n",
    "    print(i) \n",
    "    #full loop first courtyard\n",
    "#     idx = i*5 + 7650 \n",
    "    idx = i*60 + 7650\n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "    \n",
    "# #     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#     m_hat = np.array([-vel_body_frame[idx,0],\n",
    "#                       -vel_body_frame[idx,1],\n",
    "#                       -vel_body_frame[idx,2],\n",
    "# #                       -rot_vel_euls[idx,0], #looks good\n",
    "# #                       -rot_vel_euls[idx,1],\n",
    "# #                       -rot_vel_euls[idx,2]\n",
    "#                       0.,0.,0.\n",
    "#                      ])   \n",
    "# #     m_hat = np.array([0.,0.,0.,0.,0.,0.])\n",
    "#     pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "# #     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    pc1 = np.flip(pc1, axis = 0)# uncomment to flip and maintain CCW convention used in VICET\n",
    "\n",
    "    if useICET:\n",
    "        #Register undistorted PC against HD Map using ICET to correct issues in ground truth------------------------\n",
    "        submap_in_pc1_frame = (np.linalg.pinv(sensor_poses[idx]) @ initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T #test\n",
    "        submap_in_pc1_frame = submap_in_pc1_frame[:,:3]\n",
    "\n",
    "        initial_guess = tf.constant([0.,0.,0.,0.,0.,0.])\n",
    "        it = ICET(cloud1 = submap_in_pc1_frame, cloud2 = pc1, fid = 50, niter = 8, \n",
    "           draw = False, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "\n",
    "        pc1_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T #test\n",
    "        pc1_in_map_frame = pc1_in_map_frame[:,:3]\n",
    "\n",
    "        pc1_corrected_in_map_frame = (initial_pose @ sensor_poses[idx] @ np.append(it.cloud2_tensor.numpy(), np.ones([len(it.cloud2_tensor.numpy()),1]), axis =1).T).T #test\n",
    "        pc1_corrected_in_map_frame = pc1_corrected_in_map_frame[:,:3]    \n",
    "\n",
    "        #draw red scan corrected by output of ICET\n",
    "        redFix = np.eye(4)\n",
    "        redFix[:3,-1] = it.X[:3]\n",
    "        redFix[:3,:3] = redFix[:3,:3] @ R.from_euler('xyz', [it.X[3], it.X[4], it.X[5]]).as_matrix()\n",
    "        redfix_hist[i] = redFix\n",
    "\n",
    "        redScanFixed = (redFix @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "        redScanFixed = (sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "        #----------------------------------------------------------------------------------------------------------------\n",
    "    else:\n",
    "        redFix = np.eye(4)\n",
    "        redfix_hist[i] = redFix\n",
    "        redScanFixed = (redFix @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "        redScanFixed = (sensor_poses[idx] @ np.append(redScanFixed[:,:3], np.ones([len(redScanFixed),1]), axis =1).T).T\n",
    "        \n",
    "    #convert to depth image\n",
    "    pc1_spherical = cartesian_to_spherical(pc1).numpy() #[r, theta, phi]\n",
    "    pcs = np.reshape(pc1_spherical, [-1,64,3])\n",
    "    pcs = np.flip(pcs, axis = 1)\n",
    "    raw_data = pcs[:,:,:]\n",
    "    raw_data = np.transpose(pcs, [1,0,2])\n",
    "\n",
    "    #destagger depth images (OS1 unit has delay in sensor return bus)\n",
    "    data = np.zeros([64, 1024])\n",
    "    for k in range(np.shape(data)[0]//4):\n",
    "#         #         #shift left (nope)\n",
    "#         data[4*k,:-18] = raw_data[4*k,18:,0]\n",
    "#         data[4*k+1,:-12] = raw_data[4*k+1,12:,0]\n",
    "#         data[4*k+2,:-6] = raw_data[4*k+2,6:,0]\n",
    "#         data[4*k+3,:] = raw_data[4*k+3,:,0]\n",
    "# # #         #shift right -- https://ouster.com/insights/blog/firmware-2-4-industry-standard-protocols-and-improved-alerts\n",
    "#         data[4*k,:] = raw_data[4*k,:,0]\n",
    "#         data[4*k+1,6:] = raw_data[4*k+1,:-6,0]\n",
    "#         data[4*k+2,12:] = raw_data[4*k+2,:-12,0]\n",
    "#         data[4*k+3,18:] = raw_data[4*k+3,:-18,0]\n",
    "        #keep centered\n",
    "        data[4*k,1:-8] = raw_data[4*k,9:,0]\n",
    "        data[4*k+1,1:-2] = raw_data[4*k+1,3:,0]\n",
    "        data[4*k+2,4:] = raw_data[4*k+2,:-4,0]\n",
    "        data[4*k+3,10:] = raw_data[4*k+3,:-10,0]\n",
    "    data = np.flip(data, axis =1) #do not comment out\n",
    "\n",
    "# #     #test not correcting bus-delay induced skew in raw data\n",
    "#     data = np.flip(raw_data, axis =1)[:,:,0] #do not comment out\n",
    "    \n",
    "    #NEW--- get rays_o and rays_d directly inside data generation loop ~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "    rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "\n",
    "    #courtyard1\n",
    "    rotm[2,-1] += 15 \n",
    "    rotm[1,-1] += 30\n",
    "    rotm[0,-1] += 30\n",
    "    rotm[:3,-1] *= 0.005 #0.005 #0.02 #0.05 #COURTYARD\n",
    "    # recenter (when using x0.005)\n",
    "    rotm[2,-1] += 0.25 #translate above xy plane\n",
    "    rotm[1,-1] += 0.25 #shift towards positive x\n",
    "    rotm[0,-1] += 0.01 #TEST -- shift up just a little\n",
    "        \n",
    "    ro, rd = get_rays_from_point_cloud(pc1, m_hat, rotm)\n",
    "#     print(\"rd\", rd)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    for j in range(n_rots):\n",
    "        for k in range(n_vert_patches):\n",
    "            \n",
    "            #store rays_o and rays_d info\n",
    "            rd_in_patch = rd[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width, :]\n",
    "            rays_d_all[k+(j+(i*n_rots))*n_vert_patches,:,:,:] = rd_in_patch\n",
    "            ro_in_patch = ro[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width, :]\n",
    "            rays_o_all[k+(j+(i*n_rots))*n_vert_patches,:,:,:] = ro_in_patch            \n",
    "            \n",
    "            #get cropped depth image ~~~~~~~~~~~~~~~~~~~~    \n",
    "            #crop vertically and horizontally\n",
    "            pcs = data[k*image_height:(k+1)*image_height,j*image_width:(j+1)*image_width] \n",
    "    \n",
    "            #save depth information to first channel\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] = pcs\n",
    "            #save raydrop mask to 2nd channel\n",
    "            a = np.argwhere(abs(pcs) < 1)\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches, a[:,0],a[:,1],1] = 0\n",
    "\n",
    "            #get transformation matrix ~~~~~~~~~~~~~~~~~~\n",
    "            #centers origin at actual origin of HD map \n",
    "            rotm = sensor_poses[idx] @ redfix_hist[i] #old\n",
    "            rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "#             rotm[:3,-1] = np.array([-rotm[2,-1], -rotm[0,-1], rotm[1,-1]])\n",
    "#             #orient yellow (-z) pointing forward\n",
    "#             fix = np.array([[0,0,1],\n",
    "#                             [1,0,0],\n",
    "#                             [0,1,0]])\n",
    "#             rotm[:3,:3] = rotm[:3,:3] @ fix\n",
    "#             swap_axis_matrix = np.array([[0, 0, 1],\n",
    "#                                          [1, 0, 0],\n",
    "#                                          [0, 1, 0]])\n",
    "#             flip_axis_matrix = np.diag([1,1,-1]) # better ---> corrects flipping z issue when rendering\n",
    "#             rotm[:3,:3] = flip_axis_matrix @ swap_axis_matrix @ rotm[:3,:3] \n",
    "\n",
    "            #center camera horizontally in each patch\n",
    "            crop_angle = j*(2*np.pi/n_rots) + (np.pi/n_rots)\n",
    "            rotm_crop = R.from_euler('xyz', [0,-crop_angle,0]).as_matrix()\n",
    "\n",
    "            rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "            \n",
    "            #courtyard1\n",
    "            rotm[2,-1] += 15 \n",
    "            rotm[1,-1] += 30\n",
    "            rotm[0,-1] += 30\n",
    "            rotm[:3,-1] *= 0.005 #0.005 #0.02 #0.05 #COURTYARD\n",
    "            images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.005 #0.005 #0.02 #0.005 #0.05\n",
    "            # recenter (when using x0.005)\n",
    "            rotm[2,-1] += 0.25 #translate above xy plane\n",
    "            rotm[1,-1] += 0.25 #shift towards positive x\n",
    "            rotm[0,-1] += 0.01 #TEST -- shift up just a little\n",
    "\n",
    "            poses[k+(j+(i*n_rots))*n_vert_patches] = rotm \n",
    "\n",
    "# # Remove patches where sensor is occluded by person holding lidar ~~~~~~~~~~\n",
    "#calculte how many columns of patches we need to skip at the beginning and end of each scan to avoid\n",
    "# print(\"n_rots:\", n_rots)\n",
    "# n_cols_to_skip = 0 #debug\n",
    "# print(\"n_cols_to_skip:\", n_cols_to_skip)\n",
    "\n",
    "bad_idx = np.zeros([0,n_rots - 2*n_cols_to_skip])\n",
    "a = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "# print(np.shape(a))\n",
    "for i in range(n_vert_patches*n_cols_to_skip):\n",
    "    bad_i_left = a[i::n_rots*n_vert_patches]\n",
    "    bad_idx = np.append(bad_idx, bad_i_left)\n",
    "#     print(\"\\n bad_idx_left:\", bad_i_left)\n",
    "\n",
    "    bad_i_right = a[(i+n_vert_patches*(n_rots-n_cols_to_skip))::n_rots*n_vert_patches]\n",
    "    bad_idx = np.append(bad_idx, bad_i_right)\n",
    "#     print(\"\\n bad_idx_right:\", bad_i_right)\n",
    "    \n",
    "bad_idx = np.sort(bad_idx)\n",
    "all_idx = np.linspace(0,n_rots*n_images*n_vert_patches-1,n_rots*n_images*n_vert_patches)\n",
    "good_idx = np.setdiff1d(all_idx, bad_idx).astype(int)\n",
    "\n",
    "# print(good_idx)\n",
    "\n",
    "images = images[good_idx,:,:,:]\n",
    "poses = poses[good_idx,:,:]\n",
    "rays_d_all = rays_d_all[good_idx,:,:,:]\n",
    "rays_o_all = rays_o_all[good_idx,:,:,:]\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "            \n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5463853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_frame_from_rays(disp, n_rots=128, n_vert_patches=1, frameIdx=0, color = 'red'):\n",
    "\n",
    "    phimin = np.deg2rad(-15.594) #took forever to figure this out...\n",
    "    phimax = np.deg2rad(17.743)\n",
    "    H = 64 // n_vert_patches\n",
    "    W = 1024 // n_rots\n",
    "    vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)  \n",
    "    phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "    n_cols_to_skip = n_rots // 8\n",
    "    \n",
    "    pts1 = np.zeros([1,3])\n",
    "    for p in range(frameIdx*(n_rots - 2*n_cols_to_skip), (frameIdx + 1 )*(n_rots - 2*n_cols_to_skip)):\n",
    "        for i in range(n_vert_patches):\n",
    "            img_i = i\n",
    "            idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "            idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "            phimin_patch = phivals[idx_first]\n",
    "            phimax_patch = phivals[idx_second]\n",
    "\n",
    "            pose = poses[i + p*n_vert_patches]\n",
    "            rays_o = rays_o_all[i + p*n_vert_patches]\n",
    "            rays_d = rays_d_all[i + p*n_vert_patches]\n",
    "            \n",
    "            inMap1 = add_patch(rays_o, rays_d, images[i+p*n_vert_patches,:,:,0])\n",
    "\n",
    "            pts1 = np.append(pts1, inMap1, axis = 0)\n",
    "        disp.append(Points(rays_o[0,:1,:], r = 15, c = 'purple')) #DEBUG \n",
    "\n",
    "    vizPts1 = Points(pts1, c = color, r = 3., alpha = 0.125)\n",
    "    disp.append(vizPts1)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]          \n",
    "\n",
    "# colors = ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet', 'red']\n",
    "colors = np.linspace(0.1,0.3,n_images)[:,None] * np.array([[1,1,1]])\n",
    "for i in range(len(colors)):\n",
    "# for i in range(5):\n",
    "    print(i)\n",
    "    draw_frame_from_rays(disp, n_rots = 128, n_vert_patches=1, frameIdx = i, color=colors[i])\n",
    "\n",
    "plt.show(disp, \"Drawing training data from depth images, rays_o, and rays_d\")\n",
    "ViewInteractiveWidget(plt.window)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c1568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as p\n",
    "fig, ax = p.subplots()\n",
    "angs = R.from_matrix(poses[:,:3,:3]).as_euler('xyz');\n",
    "ax.plot(angs[:400,:]); #rotation angles xyz\n",
    "# ax.plot(poses[:,:3,-1]); #location xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[7700, 8700, x100] n_rots=128, n_vert_patches=1\n",
    "# np.save(\"/home/derm/Desktop/imagesUndistorted.npy\", images)\n",
    "# np.save(\"/home/derm/Desktop/posesUndistorted.npy\", poses)\n",
    "# np.save(\"/home/derm/Desktop/rays_oUndistorted.npy\", rays_o_all)\n",
    "# np.save(\"/home/derm/Desktop/rays_dUndistorted.npy\", rays_d_all)\n",
    "# #[7650, 8850, x240] n_rots=128, n_vert_patches=1\n",
    "# np.save(\"/home/derm/Desktop/imagesUndistortedV2.npy\", images)\n",
    "# np.save(\"/home/derm/Desktop/posesUndistortedV2.npy\", poses)\n",
    "# np.save(\"/home/derm/Desktop/rays_oUndistortedV2.npy\", rays_o_all)\n",
    "# np.save(\"/home/derm/Desktop/rays_dUndistortedV2.npy\", rays_d_all)\n",
    "\n",
    "images = np.load(\"/home/derm/Desktop/imagesUndistortedV2.npy\")\n",
    "poses = np.load(\"/home/derm/Desktop/posesUndistortedV2.npy\")\n",
    "rays_o_all = np.load(\"/home/derm/Desktop/rays_oUndistortedV2.npy\")\n",
    "rays_d_all = np.load(\"/home/derm/Desktop/rays_dUndistortedV2.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce537e6e",
   "metadata": {},
   "source": [
    "# Debug rays_o, rays_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a96a78",
   "metadata": {},
   "source": [
    "### NEW-- get rays_o and rays_d directly from distortion corrected point cloud\n",
    "#### old method of assuming rays based on lidar index was preventing motion distortion correction from working!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c86e04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#draw subsequent scans aligned using poses with redfix\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "for i in range(30):\n",
    "    idx = i*10 + 7700\n",
    "#     idx = i*100 + 11000\n",
    "    \n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)\n",
    "# #     # distortion correction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#      #looks great!\n",
    "#     m_hat = np.array([-vel_body_frame[idx,0],\n",
    "#                       -vel_body_frame[idx,1],\n",
    "#                       -vel_body_frame[idx,2],\n",
    "#                       -rot_vel_euls[idx,0],\n",
    "#                       -rot_vel_euls[idx,1],\n",
    "#                       -rot_vel_euls[idx,2]\n",
    "#                      ])   \n",
    "#     pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "# #     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~        \n",
    "\n",
    "    #centers origin at actual origin of HD map \n",
    "    rotm = sensor_poses[idx] @ redfix_hist[i]\n",
    "    rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "    \n",
    "    #rescale\n",
    "    rotm[2,-1] += 15 \n",
    "    rotm[1,-1] += 30\n",
    "    rotm[0,-1] += 30\n",
    "    rotm[:3,-1] *= 0.005 #0.005 #0.02 #0.05 #COURTYARD\n",
    "    rotm[2,-1] += 0.25 #translate above xy plane\n",
    "    rotm[1,-1] += 0.25 #shift towards positive x\n",
    "    rotm[0,-1] += 0.01 #TEST -- shift up just a little\n",
    "    pc1 *= 0.005\n",
    "    \n",
    "    pc1_aligned = (rotm @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "        \n",
    "    disp.append(Points(pc1_aligned[:,:3], c = 'r', r = 2.5, alpha = 0.125))\n",
    "    \n",
    "plt.show(disp, \"Training Data with VICET correction\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d34f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#debug applying motion profile to rays_d-- \n",
    "# need to get it to match how we are applying it to pc1\n",
    "from lidar_nerf_utils import get_rays_from_point_cloud\n",
    "\n",
    "idx = 7750\n",
    "fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "pc1 = np.load(fn1)\n",
    "\n",
    "# m_hat = np.array([-vel_body_frame[idx,0],\n",
    "#                   -vel_body_frame[idx,1],\n",
    "#                   -vel_body_frame[idx,2],\n",
    "#                   -rot_vel_euls[idx,0],\n",
    "#                   -rot_vel_euls[idx,1],\n",
    "#                   -rot_vel_euls[idx,2]\n",
    "#                  ])   \n",
    "m_hat = np.array([-1,0,0,0,0,0])\n",
    "pc1 = apply_motion_profile(pc1, m_hat, period_lidar=1.)\n",
    "\n",
    "c2w = tf.cast(np.eye(4), tf.float32) #DEBUG ONLY\n",
    "ro, rd = get_rays_from_point_cloud(pc1, m_hat, c2w)\n",
    "\n",
    "#draw\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "# disp.append(Points(pc1[:30000], c = 'r', r = 2.5, alpha = 0.125))   \n",
    "disp.append(Points(pc1, c = 'r', r = 2.5, alpha = 0.125))   \n",
    "disp.append(Points(tf.reshape(rd, [-1,3]), c = 'b', r = 2.5, alpha = 0.125))   \n",
    "disp.append(Points(tf.reshape(rd, [-1,3])[:200], c = 'r', r = 10, alpha = 0.125))   \n",
    "plt.show(disp, \"getting rays_d from raw point cloud\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f415c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#draw subsequent scans aligned using poses without redfix\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "for i in range(10):\n",
    "    idx = i*100 + 7700\n",
    "#     idx = i*100 + 11000\n",
    "    \n",
    "    fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "    pc1 = np.load(fn1)      \n",
    "\n",
    "    #centers origin at actual origin of HD map \n",
    "    rotm = sensor_poses[idx]\n",
    "    rotm = np.linalg.pinv(initial_pose) @ rotm\n",
    "\n",
    "    pc1_aligned = (rotm @ np.append(pc1, np.ones([len(pc1),1]), axis =1).T).T\n",
    "        \n",
    "    disp.append(Points(pc1_aligned[:,:3], c = 'b', r = 2.5, alpha = 0.125))\n",
    "    \n",
    "plt.show(disp, \"Training Data with raw \\\"ground truth\\\" poses\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1831011",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "H = 64\n",
    "W = 1024\n",
    "phimax_patch = np.deg2rad(-15.594) #works best flipped\n",
    "phimin_patch = np.deg2rad(17.743)\n",
    "\n",
    "i, j = tf.meshgrid(tf.range(1024, dtype=tf.float32), tf.range(64, dtype=tf.float32), indexing='xy')\n",
    "test = (-(i - ((W-1)/2))  /(W) * (2*np.pi/(1024//(W))) - 2*np.pi )  % (2*np.pi) - np.pi\n",
    "# test = (i - ((W-1)/2))  /(W) * (2*np.pi/(1024//(W))) - np.pi\n",
    "print(test)\n",
    "\n",
    "idx  = 7800\n",
    "fn1 = \"/media/derm/06EF-127D4/Newer College Dataset/01_Short_Experiment/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "pc1 = np.load(fn1)\n",
    "pc1_spherical = cartesian_to_spherical(pc1)\n",
    "\n",
    "fig, ax = p.subplots(2,1)\n",
    "ax[0].plot(test[0,:])\n",
    "# ax[0].plot(np.flip(test, axis = 1)[0,:])\n",
    "ax[1].plot(pc1_spherical[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55de187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD [-15,17.5]x1000, @0.005\n",
    "# poses = np.load(\"/home/derm/Desktop/poses.npy\") # <--- used these for best NeRF training\n",
    "# images = np.load(\"/home/derm/Desktop/images.npy\")\n",
    "# poses = np.load(\"/home/derm/Desktop/posesEval.npy\") # <--- every 5th frame, [7700:8800] for benchmarking\n",
    "# images = np.load(\"/home/derm/Desktop/imagesEval.npy\")\n",
    "\n",
    "# #forest sample\n",
    "# poses = np.load(\"/home/derm/Desktop/posesForest.npy\")\n",
    "# images = np.load(\"/home/derm/Desktop/imagesForest.npy\")\n",
    "\n",
    "# # #LOAD [-15,17]x1000, 8x8 @ 0.005\n",
    "# poses = np.load(\"/home/derm/Desktop/poses8x8.npy\")\n",
    "# images = np.load(\"/home/derm/Desktop/images8x8.npy\")\n",
    "\n",
    "# #Linearly scale down translations and ranges ~~~~~~~~~~~~~~~~~~~\n",
    "# rotm[:3,-1] *= 0.002 #0.005 #0.02 #0.05\n",
    "# images[k+(j+(i*n_rots))*n_vert_patches,:,:,0] *= 0.002 #0.005 #0.02 #0.005 #0.05\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a918216",
   "metadata": {},
   "source": [
    "# Train NeRF using old single-network strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae39b32",
   "metadata": {},
   "source": [
    "### TODO: Bug is in here! For some reason, changing patch sizes is changing rotation angles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be66c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cols_to_draw = 5\n",
    "phimin = np.deg2rad(-15.594) #observed in raw data \n",
    "phimax = np.deg2rad(17.743) #observed in raw data\n",
    "# phimax = np.deg2rad(15.594) #debug \n",
    "# phimin = np.deg2rad(-17.743) #debug\n",
    "\n",
    "plt = Plotter(N = 1, axes = 12, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[] \n",
    "\n",
    "#get rays_o and rays_d for a \"novel\" sensor pose\n",
    "for p in range(num_cols_to_draw):\n",
    "    n_rots = 64 #128 #number of horizontal patches per 2*pi\n",
    "    n_vert_patches = 1 #8 #1 #number of vertical patches between phimin and phimax\n",
    "    H = 64 // n_vert_patches\n",
    "    W = 1024 // n_rots\n",
    "    vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)  \n",
    "    phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "    for i in range(n_vert_patches):\n",
    "        img_i = i\n",
    "        #top to bottom (correct)\n",
    "        idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "        idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "        phimin_patch = phivals[idx_first]\n",
    "        phimax_patch = phivals[idx_second]\n",
    "\n",
    "#         #bottom to top (incorrect)\n",
    "#         idx_first = (img_i + 1) * (64 // n_vert_patches) - 1\n",
    "#         idx_second = img_i * (64 // n_vert_patches)\n",
    "#         idx_first %= len(phivals)\n",
    "#         idx_second %= len(phivals)\n",
    "#         phimin_patch = phivals[idx_first]\n",
    "#         phimax_patch = phivals[idx_second]\n",
    "\n",
    "    #     pose = tf.cast(np.eye(4), tf.float32)\n",
    "        pose = poses[i + p*n_vert_patches]\n",
    "        rays_o, rays_d, rays_d_OG = get_rays(H, W, pose, phimin_patch, phimax_patch, debug=True)\n",
    "    \n",
    "        disp.append(Points(tf.reshape(rays_d.numpy(), [-1,3]), c = 'green', alpha = (p+1)/num_cols_to_draw, r = 3.5))\n",
    "        disp.append(Points(tf.reshape(rays_d.numpy(), [-1,3])[:10,:], c = 'red', r = 3.5, alpha =  0.6))\n",
    "        \n",
    "#         disp.append(Points(tf.reshape(rays_d_OG, [-1,3]), c = 'g', r = 3.5, alpha = 0.5))\n",
    "\n",
    "#draw what the corresponding rays_o and rays_d actually look like at that same sensor pose\n",
    "#  (it was actually part of the training data)\n",
    "for i in range(num_cols_to_draw*n_vert_patches):\n",
    "    rays_o_i = rays_o_all[i]\n",
    "    rays_d_i = rays_d_all[i]    \n",
    "\n",
    "#     patch_for_i = tf.reshape(rays_d_i, [-1,3]) + tf.reshape(rays_o_i, [-1,3])\n",
    "    patch_for_i = tf.reshape(rays_d_i, [-1,3])\n",
    "#     patch_for_i = tf.reshape(rays_d_i, [-1,3]) @ tf.cast(tf.linalg.pinv(poses[i,:3,:3]), tf.double)\n",
    "#     patch_for_i = tf.reshape(rays_d_i, [-1,3]) @ rot_corr.T\n",
    "    disp.append(Points(patch_for_i, c = 'blue', r = 3.5, alpha = (i+2)/(2*n_vert_patches*num_cols_to_draw+1)))\n",
    "    disp.append(Points(patch_for_i[:10], c = 'r', r = 5, alpha = 0.6))\n",
    "    \n",
    "plt.show(disp, \"64x8 patches\")\n",
    "ViewInteractiveWidget(plt.window)\n",
    "# print(rays_d[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5d99e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lidar_nerf_utils import *\n",
    "\n",
    "# model = init_model()\n",
    "# optimizer = tf.keras.optimizers.Adam(5e-4) #default tiny-NeRF\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "# optimizer = tf.keras.optimizers.Adam(5e-5) #anneal to this (LiDAR NeRF)\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "# optimizer = tf.keras.optimizers.Adam(5e-6) #anneal to this (Mip-NeRF)\n",
    "# optimizer = tf.keras.optimizers.Adam(1e-6) #TEST\n",
    "\n",
    "N_samples = 128 #256\n",
    "near=0.\n",
    "far= 1.\n",
    "N_iters = 5_000_000\n",
    "psnrs = []\n",
    "iternums = []\n",
    "i_plot = 64\n",
    "accumulate_gradients_steps = 1 #32\n",
    "\n",
    "#IMPORTANT-- this needs to match values used when setting up training data \n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #1 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "testimg = images[12]\n",
    "testpose = poses[12]\n",
    "\n",
    "phimin = np.deg2rad(-15.594) #observed in raw data \n",
    "phimax = np.deg2rad(17.743) #observed in raw data\n",
    "\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)  \n",
    "phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "\n",
    "gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
    "accumulated_loss = 0.0\n",
    "\n",
    "for i in range(N_iters+1):\n",
    "    img_i = np.random.randint(images.shape[0])\n",
    "#     img_i = i #DEBUG\n",
    "    target = images[img_i,:,:,:1]\n",
    "    target_drop_mask = images[img_i,:,:,1:]\n",
    "    pose = poses[img_i]\n",
    "    rays_d = rays_d_all[img_i]\n",
    "    rays_o = rays_o_all[img_i]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # run coarse network~~~~~~~~~~~~~~~~~\n",
    "        z_vals = tf.linspace(near, far, N_samples)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "        z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "#         z_vals += 0.001*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "        z_vals = z_vals[:,:,:,None]#manually expand dimensions before passing in to coarse network (all pixels will share the same z_vals)\n",
    "        depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals, fine = False)\n",
    "        depth = depth[:,:,None]\n",
    "        ray_drop = ray_drop[:,:,None]\n",
    "        gtCDF = z_vals[:,:,:,0] > target[:,:,:]\n",
    "        gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "        loss_coarse = calculate_loss(depth, ray_drop, target, target_drop_mask, CDF = CDF, gtCDF = gtCDF) #punish similar depth returns\n",
    "        loss = loss_coarse\n",
    "                  \n",
    "        #NEW--prevent NaN gradients from crashing training routine(?) -- needed for monotonically increasing outputs?\n",
    "        current_gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        current_gradients = [grad if grad is not None else tf.zeros_like(var) for grad, var in zip(current_gradients, model.trainable_variables)]\n",
    "        gradients = [grad_accum + current_grad for grad_accum, current_grad in zip(gradients, current_gradients)]        \n",
    "\n",
    "#         #OLD-- not working with CDF stuff\n",
    "#         current_gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#         gradients = [grad_accum + current_grad for grad_accum, current_grad in zip(gradients, current_gradients)]    \n",
    "        \n",
    "        accumulated_loss += loss\n",
    "    \n",
    "    if i%accumulate_gradients_steps==0:    \n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        accumulated_loss = 0.0\n",
    "        gradients = [tf.zeros_like(var) for var in model.trainable_variables]\n",
    "        accumulated_loss = 0\n",
    "    \n",
    "    if i%i_plot==0:\n",
    "#         rays_o, rays_d = get_rays(H, W, testpose, vertical_bins[-2], vertical_bins[-1]) #constant validation image\n",
    "        z_vals = tf.linspace(near, far, N_samples) \n",
    "        z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "        z_vals = z_vals[:,:,:,None]\n",
    "        depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals)\n",
    "        depth = depth[:,:,None]\n",
    "        ray_drop = ray_drop[:,:,None]\n",
    "        target = testimg[:,:,:1]\n",
    "        target_drop_mask = testimg[:,:,1:]\n",
    "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "        psnrs.append(psnr.numpy())\n",
    "        iternums.append(i)\n",
    "        p.figure(figsize=(10,4))\n",
    "        p.subplot(131)\n",
    "        p.imshow(depth,cmap = \"gray\")#, norm='log')\n",
    "        p.title(f'Estimated Depth at Iteration: {i}')\n",
    "        p.subplot(133)\n",
    "        p.plot(iternums, psnrs)\n",
    "        p.title('PSNR')\n",
    "        p.subplot(132)\n",
    "        p.imshow(ray_drop, cmap=\"gray\")#, norm = 'log')\n",
    "        p.title(\"estimated ray drop mask\")\n",
    "        p.show()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e56f26",
   "metadata": {},
   "source": [
    "# reproduce first training scan using network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa5d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "N_samples = 128\n",
    "\n",
    "for j in range(n_rots * n_vert_patches - 2*n_cols_to_skip*n_vert_patches):\n",
    "    pose = poses[j]\n",
    "    rays_d = rays_d_all[j]\n",
    "    rays_o = rays_o_all[j]\n",
    "    \n",
    "    z_vals = tf.linspace(near, far, N_samples) \n",
    "    z_vals += 1.0*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    z_vals = z_vals[:,:,:,None]\n",
    "    \n",
    "    depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals, fine = False)\n",
    "    \n",
    "    new_point_cloud_spherical = np.zeros([np.shape(depth)[0]*np.shape(depth)[1],3])\n",
    "    depth = tf.transpose(depth).numpy() #need this\n",
    "    depth = np.flip(depth, axis = 0) #needed\n",
    "\n",
    "    #scale back up to normal size\n",
    "    depth *= 200 #courtyard only\n",
    "    ray_drop = tf.transpose(ray_drop).numpy()\n",
    "    ray_drop = np.flip(ray_drop, axis = 0)\n",
    "    \n",
    "    count = 0\n",
    "    for w in range(W):\n",
    "        for h in range(H):\n",
    "#             new_point_cloud_spherical[count,0] = depth[w,h] #radius #draw all points\n",
    "            if ray_drop[w,h] > 0.9:             \n",
    "                    new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "            else:\n",
    "                    new_point_cloud_spherical[count,0] = 0#100 # suppress ray dropped points\n",
    "            new_point_cloud_spherical[count,1] = (w-(1024//(2*n_rots)))/(2048//(2*n_rots))*(2*np.pi/n_rots)   #was this\n",
    "            new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/(H - 1)) #[17.74,-15.59] #(correct)       \n",
    "            count+= 1\n",
    "\n",
    "#     new_point_cloud_spherical[:,1] -= (np.pi/n_rots) - j*(2*np.pi/n_rots) + np.pi #was this\n",
    "    new_point_cloud_spherical[:,1] -= (np.pi/n_rots) + j*(2*np.pi/n_rots) + np.pi #test\n",
    "    new_point_cloud_spherical[:,2] -= (phimax+phimin)\n",
    "    \n",
    "    new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy() #was this\n",
    "    new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z \n",
    "#     new_point_cloud_cart[:,1] = -new_point_cloud_cart[:,1] #flip another axis to get back to LHCS (synthetic data only?)\n",
    "\n",
    "    disp.append(Points(new_point_cloud_cart, c = 'gray', r = 3, alpha = 0.5))\n",
    "#     disp.append(Points(rays_d[:10,0,:], c = 'blue', r = 10))\n",
    "#     disp.append(Points(np.random.randn(10,3), c = 'red', r = 3))\n",
    "    \n",
    "plt.show(disp, \"reproducing first training scan using network\")\n",
    "ViewInteractiveWidget(plt.window)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc791e",
   "metadata": {},
   "source": [
    "# Infer cloud at novel frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2ae7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_view = 128 #128 #number of (rotational?) patches to draw\n",
    "N_samples = 256 #128 #2048 #does not have to match what was used in training\n",
    "near=0.\n",
    "far= 1.\n",
    "n_rots = 128 #128 #number |of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #number of vertical patches between phimin and phimax\n",
    "\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "phimin = np.deg2rad(-15.593) #was this\n",
    "phimax = np.deg2rad(17.743)\n",
    "# phimin = np.deg2rad(-17.743) #TEST\n",
    "# phimax = np.deg2rad(15.593) #TEST\n",
    "\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)  \n",
    "phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "savepc = np.zeros([0,3]) #to save poitn cloud to external file\n",
    "\n",
    "for j in range(num_view):\n",
    "#    #get sensor transformation matrix\n",
    "#     rotm = poses[0]\n",
    "    rotm = poses[1280]\n",
    "    rotm[:3,:3] = np.eye(3)\n",
    "    \n",
    "    # account for image crop in rotation\n",
    "    crop_angle =  (np.pi/n_rots) - j*(2*np.pi/n_rots)\n",
    "    rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix() #why does this work??\n",
    "    rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "    rotm = rotm.astype(np.float32)\n",
    "    \n",
    "    vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "    phimin_patch = vertical_bins[img_i%n_vert_patches] \n",
    "    phimax_patch = vertical_bins[img_i%n_vert_patches + 1]\n",
    "\n",
    "    #call NeRF using specified novel rotm\n",
    "    rays_o, rays_d = get_rays(H, W, rotm, phimin_patch, phimax_patch)\n",
    "    \n",
    "    z_vals = tf.linspace(near, far, N_samples) \n",
    "    z_vals += 1.0*tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    z_vals = z_vals[:,:,:,None]\n",
    "    \n",
    "    depth, ray_drop, CDF, weights = render_rays(model, rays_o, rays_d,  z_vals, fine = False)\n",
    "    \n",
    "    new_point_cloud_spherical = np.zeros([np.shape(depth)[0]*np.shape(depth)[1],3])\n",
    "    depth = tf.transpose(depth).numpy() #need this\n",
    "    depth = np.flip(depth, axis = 0) #needed\n",
    "\n",
    "    #scale back up to normal size\n",
    "    depth *= 200 #courtyard only\n",
    "    ray_drop = tf.transpose(ray_drop).numpy()\n",
    "    ray_drop = np.flip(ray_drop, axis = 0)\n",
    "    \n",
    "    count = 0\n",
    "    for w in range(W):\n",
    "        for h in range(H):\n",
    "#             new_point_cloud_spherical[count,0] = depth[w,h] #radius #draw all points\n",
    "            if ray_drop[w,h] > 0.9:             \n",
    "                    new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "            else:\n",
    "                    new_point_cloud_spherical[count,0] = 0#100 # suppress ray dropped points\n",
    "            new_point_cloud_spherical[count,1] = (-w+(1024//(2*n_rots)))/(2048//(2*n_rots))*(2*np.pi/n_rots)   #was this\n",
    "            new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/(H - 1)) #[17.74,-15.59] #(correct)       \n",
    "            count+= 1\n",
    "\n",
    "#     new_point_cloud_spherical[:,1] -= (np.pi/n_rots) - j*(2*np.pi/n_rots) + np.pi #was this\n",
    "    new_point_cloud_spherical[:,1] -= (np.pi/n_rots) + j*(2*np.pi/n_rots) + np.pi #test\n",
    "    new_point_cloud_spherical[:,2] -= (phimax+phimin)\n",
    "    \n",
    "    new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy() #was this\n",
    "    new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z \n",
    "#     new_point_cloud_cart[:,1] = -new_point_cloud_cart[:,1] #flip another axis to get back to LHCS (synthetic data only?)\n",
    "\n",
    "    disp.append(Points(new_point_cloud_cart, c = 'gray', r = 3, alpha = 0.5))\n",
    "#     # rainbow by z height\n",
    "#     zheight = 100*(np.sin(0.25*new_point_cloud_cart[:,2])+1)\n",
    "#     cname = np.array([1-zheight, zheight, 1.5*zheight]).T.tolist()\n",
    "#     disp.append(Points(new_point_cloud_cart, c = cname, r = 2, alpha = 0.5))\n",
    "\n",
    "plt.show(disp, \"genterating point cloud at novel frame\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros([np.shape(images)[1],0])\n",
    "print(np.shape(temp))\n",
    "for img_i in range(0,50):\n",
    "    temp = np.append(temp,images[img_i,:,:,0], axis = 1)\n",
    "\n",
    "fig, ax = p.subplots(3,1)\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(temp)\n",
    "ax[0].set_title(\"Depth Image\")\n",
    "\n",
    "thresh_horiz = 0.05 #test \n",
    "thresh_vert = 0.005 #test\n",
    "temp = temp[:,:,None]\n",
    "mask = np.ones(np.shape(temp[:,:,0]))\n",
    "vertical_grad_target = np.gradient(temp[:,:,0])[0] \n",
    "vertical_past_thresh = np.argwhere(tf.abs(vertical_grad_target) > thresh_vert) #old\n",
    "mask[vertical_past_thresh[:,0], vertical_past_thresh[:,1]] = 0 #1\n",
    "horizontal_grad_target = np.gradient(target[:,:,0])[1]\n",
    "horizontal_past_thresh = np.argwhere(tf.abs(horizontal_grad_target) > thresh_horiz) #old\n",
    "mask[horizontal_past_thresh[:,0], horizontal_past_thresh[:,1]] = 0 #1\n",
    "\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title(\"Gradient Mask\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "# #TEST ~~~ prevent gradient mask from getting rid of double returns in windows, etc.\n",
    "save_non_ground = tf.zeros_like(mask).numpy()\n",
    "save_non_ground[:40,:] = 1 #prevent anything in the top ~3/4 of image from getting masked\n",
    "save_non_groud = tf.convert_to_tensor(save_non_ground)\n",
    "together = tf.concat([save_non_groud[:,:,None], mask[:,:,None]], axis = -1)\n",
    "mask = tf.math.reduce_max(together, axis = -1)\n",
    "mask = tf.cast(mask, tf.float32)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "ax[2].imshow(mask)\n",
    "ax[2].set_title(\"Gradient Mask, Preserving High 2nd Derivatives\")\n",
    "ax[2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4627d",
   "metadata": {},
   "source": [
    "# Test creating arbitrary bins for coarse and fine network outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157b0c0",
   "metadata": {},
   "source": [
    "### Left Riemann Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins_coarse = 7\n",
    "bins_coarse = np.linspace(0,1,n_bins_coarse)\n",
    "# bins_coarse = bins_coarse**2#TEST\n",
    "w_coarse = np.gradient(bins_coarse)\n",
    "print(bins_coarse)\n",
    "print(w_coarse)\n",
    "w_coarse[-1] = 0\n",
    "vals_coarse = abs(1/(0.6 - bins_coarse))\n",
    "vals_coarse = vals_coarse/np.sum(vals_coarse*w_coarse)\n",
    "\n",
    "n_bins_fine = 30\n",
    "bins_fine = np.linspace(0,1,n_bins_fine)**0.5\n",
    "# bins_fine = np.sin(np.linspace(0,1,n_bins_fine))\n",
    "vals_fine = abs(1/((0.6 - bins_fine)*(0.9 - bins_fine)))\n",
    "w_fine = np.diff(bins_fine)\n",
    "w_fine = np.append(w_fine, 0)\n",
    "vals_fine = vals_fine/np.sum(vals_fine*w_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as p\n",
    "fig, ax = p.subplots()\n",
    "\n",
    "ax.bar(bins_coarse+w_coarse/2, vals_coarse , width = w_coarse, \n",
    "       color ='red', edgecolor = 'black', label = \"coarse (normalized)\", alpha = 0.5);\n",
    "ax.bar(bins_fine+w_fine/2, vals_fine, width = w_fine, color = 'blue', \n",
    "       label = \"fine\", edgecolor = 'black', alpha = 0.5);\n",
    "ax.scatter(bins_coarse, vals_coarse, color = 'red')\n",
    "ax.scatter(bins_fine, vals_fine, color = 'blue')\n",
    "\n",
    "ax.set_xlabel(\"s\")\n",
    "ax.set_ylabel(\"R(s)\")\n",
    "ax.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate loss for a given region in the coarse histogram\n",
    "# print(bins_coarse)\n",
    "# print(bins_fine)\n",
    "# print(np.sum(vals_coarse), np.sum(vals_fine))\n",
    "\n",
    "L = np.zeros(len(bins_coarse))\n",
    "for i in range(len(bins_coarse) - 1):\n",
    "    #get sample locations in fine distribution that fall within bin i of coarse distribution\n",
    "    small_enough_idx = np.where(bins_fine < bins_coarse[i+1])\n",
    "    big_enough_idx = np.where(bins_fine >= bins_coarse[i])\n",
    "    idx_in_range = np.intersect1d(small_enough_idx, big_enough_idx)\n",
    "\n",
    "    fine_in_bin = np.sum(vals_fine[idx_in_range]*w_fine[idx_in_range])\n",
    "#     print(\"\\n coarse at i: \", vals_coarse[i]*w_coarse[i])\n",
    "#     print(\"val fine in bin i:\", fine_in_bin)\n",
    "#     print(\"fine at i:\", fine_in_bin)\n",
    "  \n",
    "    L[i] = max(0, fine_in_bin -  vals_coarse[i]*w_coarse[i])\n",
    "    print(\"L[i]\", L[i])\n",
    "print(np.sum(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926b801",
   "metadata": {},
   "source": [
    "### With centered bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e74dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins_coarse = 10\n",
    "bins_coarse = np.linspace(0,1,n_bins_coarse)\n",
    "\n",
    "# # bins_coarse = bins_coarse**2\n",
    "# bins_coarse = np.cumsum(abs(np.sin(10*bins_coarse)))\n",
    "# bins_coarse /= bins_coarse[-1]\n",
    "\n",
    "w_coarse = np.diff(bins_coarse)\n",
    "w_coarse = np.append(w_coarse, 0)\n",
    "bins_coarse = bins_coarse+w_coarse/2\n",
    "# w_coarse[-1] = 0\n",
    "vals_coarse = abs(1/(0.6 - bins_coarse))\n",
    "vals_coarse = vals_coarse/np.sum(vals_coarse*w_coarse)\n",
    "\n",
    "print(\"bins_coarse:\\n\", bins_coarse)\n",
    "print(\"w_coarse:\\n\", w_coarse)\n",
    "\n",
    "n_bins_fine = 30\n",
    "bins_fine = np.linspace(0,1,n_bins_fine)**0.5\n",
    "# bins_fine = np.sin(np.linspace(0,1,n_bins_fine))\n",
    "vals_fine = abs(1/((0.6 - bins_fine)*(0.9 - bins_fine)))\n",
    "w_fine = np.diff(bins_fine)\n",
    "w_fine = np.append(w_fine, 0)\n",
    "bins_fine = bins_fine+w_fine/2\n",
    "vals_fine = vals_fine/np.sum(vals_fine*w_fine)\n",
    "\n",
    "from matplotlib import pyplot as p\n",
    "fig, ax = p.subplots()\n",
    "\n",
    "ax.bar(bins_coarse, vals_coarse , width = w_coarse, \n",
    "       color ='red', edgecolor = 'black', label = \"coarse (normalized)\", alpha = 0.5);\n",
    "ax.bar(bins_fine, vals_fine, width = w_fine, color = 'blue', \n",
    "       label = \"fine\", edgecolor = 'black', alpha = 0.5);\n",
    "ax.scatter(bins_coarse, vals_coarse, color = 'red')\n",
    "ax.scatter(bins_fine, vals_fine, color = 'blue')\n",
    "\n",
    "ax.set_xlabel(\"s\")\n",
    "ax.set_ylabel(\"R(s)\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "L = np.zeros(len(bins_coarse))\n",
    "for i in range(len(bins_coarse) - 1):\n",
    "    #get sample locations in fine distribution that fall within bin i of coarse distribution    \n",
    "#     print(bins_coarse[i]-(w_coarse[i]/2), (bins_coarse[i]+(w_coarse[i+1]/2)))\n",
    "    small_enough_idx = np.where(bins_fine < (bins_coarse[i]+(w_coarse[i+1]/2)))\n",
    "    big_enough_idx = np.where(bins_fine >= bins_coarse[i]-(w_coarse[i]/2))\n",
    "\n",
    "    idx_in_range = np.intersect1d(small_enough_idx, big_enough_idx)\n",
    "\n",
    "    fine_in_bin = np.sum(vals_fine[idx_in_range]*w_fine[idx_in_range])\n",
    "#     print(\"\\n coarse at i: \", vals_coarse[i]*w_coarse[i])\n",
    "#     print(\"val fine in bin i:\", fine_in_bin)\n",
    "#     print(\"fine at i:\", fine_in_bin)\n",
    "  \n",
    "    L[i] = max(0, fine_in_bin -  vals_coarse[i]*w_coarse[i])\n",
    "    print(\"L[i]\", L[i])\n",
    "print(np.sum(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be6dbd",
   "metadata": {},
   "source": [
    "# Recreating the above process in parallel using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "#make arbitrary fine distributions (what the fine netork of the scene)\n",
    "#  these vary in inferred density as well as sampling location\n",
    "H = 64\n",
    "W = 8\n",
    "n_bins_fine = 64\n",
    "n_bins_coarse = 8\n",
    "\n",
    "#create random sinusoidal peaks\n",
    "randy = np.pi*tf.random.uniform([H,W, 2])\n",
    "randy2 = np.pi*tf.cast(tf.random.uniform([H,W, 2]),tf.float32) \n",
    "\n",
    "# print(np.shape(randy))\n",
    "lin = tf.cast(tf.linspace(0,1,n_bins_fine), tf.float32)\n",
    "lin = tf.tile(lin[None,None,:,None], [H,W,1,1])\n",
    "weights_fine = (tf.math.sin(randy[...,:1,None]*np.pi*lin + randy[...,1:2,None]) +1)/2\n",
    "\n",
    "z_vals_coarse = tf.cast(tf.linspace(0,1,n_bins_coarse), tf.float32)\n",
    "#TEST -- nonlinear z values for coarse network -- looks like it works!\n",
    "# z_vals_coarse = z_vals_coarse**2 \n",
    "# z_vals_coarse = tf.math.sin(z_vals_coarse)\n",
    "z_vals_coarse = tf.tile(z_vals_coarse[None,None,:,None], [H,W,1,1])\n",
    "# print(np.shape(z_vals_coarse))\n",
    "weights_coarse = (tf.math.sin(randy[...,:1,None]*np.pi*z_vals_coarse + randy[...,1:2,None]) +1)/2\n",
    "weights_coarse = weights_coarse/tf.math.reduce_sum(weights_coarse, axis = 2)[:,:,:,None] #normalize to sum to 1\n",
    "# print(np.shape(weights_coarse))\n",
    "# print(np.shape(weights_fine))\n",
    "\n",
    "w_coarse = tf.experimental.numpy.diff(z_vals_coarse, axis = 2)\n",
    "padding_config = [[0, 0],[0, 0],[0, 1],[0, 0]]\n",
    "w_coarse = tf.pad(w_coarse, padding_config, constant_values=0.001)\n",
    "#shift definition of z_vals to the center (for centered Riemann Sums)\n",
    "\n",
    "#init z_vals [h, w, n_samples, 1]\n",
    "#create inconsistant spacing for z vals in fine rays\n",
    "#same as \"bins_fine\" in previous\n",
    "z_vals_fine = (tf.math.sin(3*np.pi*randy2[...,:1,None]*lin + randy2[...,1:,None]) + 2 ) /3\n",
    "# z_vals = (tf.math.sin(np.pi*randy2[:,:1]*lin + randy2[:,1:]) + 1 ) /2\n",
    "z_vals_fine = tf.cumsum(z_vals_fine, axis = -2)\n",
    "# print(\"z_vals\", np.shape(z_vals))\n",
    "z_vals_fine -= z_vals_fine[:,:,:1,:]\n",
    "z_vals_fine /= z_vals_fine[:,:,-1:,:]\n",
    "# print(\"test\", np.shape(z_vals_fine[:,:,-1:,:]))\n",
    "# print(z_vals[0,0,:,0])\n",
    "\n",
    "\n",
    "w_fine = tf.experimental.numpy.diff(z_vals_fine, axis = 2)\n",
    "padding_config = [[0, 0],[0, 0],[0, 1],[0, 0]]\n",
    "w_fine = tf.pad(w_fine, padding_config, constant_values=0.001)\n",
    "\n",
    "#shift z_vals def to the center\n",
    "z_vals_coarse = z_vals_coarse + w_coarse/2 \n",
    "z_vals_fine = z_vals_fine + w_fine/2 \n",
    "\n",
    "# #TEST -- renormalize fine widths ~~~~~~~\n",
    "# w_fine = tf.experimental.numpy.diff(z_vals_fine, axis = 2)\n",
    "# padding_config = [[0, 0],[0, 0],[0, 1],[0, 0]]\n",
    "# w_fine = tf.pad(w_fine, padding_config, constant_values=0.001)\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#correct weights so area under the curve is 1\n",
    "area_fine = tf.math.reduce_sum(weights_fine * w_fine, axis = 2)[:,:,:,None]\n",
    "weights_fine = weights_fine/area_fine\n",
    "# print(tf.math.reduce_sum(weights_fine*w_fine, axis = 2))\n",
    "\n",
    "area_coarse = tf.math.reduce_sum(weights_coarse * w_coarse, axis =2)[:,:,:,None]\n",
    "weights_coarse = weights_coarse/area_coarse\n",
    "# print(tf.math.reduce_sum(weights_coarse*w_coarse, axis = 2))\n",
    "\n",
    "print(w_coarse[0,0,:,0])\n",
    "print(tf.experimental.numpy.diff(z_vals_coarse, axis = 2)[0,0,:,0]) #<--- slightly different at very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gradient_tf(a):\n",
    "    rght = tf.concat((a[..., 1:], tf.expand_dims(a[..., -1], -1)), -1)\n",
    "    left = tf.concat((tf.expand_dims(a[...,0], -1), a[..., :-1]), -1)\n",
    "    ones = tf.ones_like(rght[..., 2:], tf.float32)\n",
    "    one = tf.expand_dims(ones[...,0], -1)\n",
    "    divi = tf.concat((one, ones*2, one), -1)\n",
    "#     print(left[0,0,:])\n",
    "#     print(rght[0,0,:])\n",
    "\n",
    "    test = tf.concat((a[...,1:], tf.ones_like(a[:,:,:1])), axis = -1) - a\n",
    "    print(test[0,0,:])\n",
    "    \n",
    "    return (rght-left) / divi\n",
    "\n",
    "g = my_gradient_tf(z_vals_coarse[:,:,:,0])\n",
    "print(g[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "look_at = 0\n",
    "\n",
    "#left riemann sums (old)\n",
    "# zc = z_vals_coarse[look_at,0,:,0] \n",
    "zf = z_vals_fine[look_at,0,:,0]\n",
    "#shift for centered riemann sums -- see if center of fine fits within left and right limits of coarse \n",
    "zc = z_vals_coarse[look_at,0,:,0] - w_coarse[look_at,0,:,0]/2 \n",
    "zf = z_vals_fine[look_at,0,:,0]\n",
    "\n",
    "# print(\"zc \\n\", zc)\n",
    "# print(\"zf \\n\", zf)\n",
    "\n",
    "#get index of which bin in coarse each bar in fine belongs inside of\n",
    "indices = tf.searchsorted(zc, zf, side='right')-1\n",
    "# print(\"idx: \\n\", indices)\n",
    "\n",
    "#need to scale L_i by width of coarse bins\n",
    "fine_sum = tf.math.segment_sum(weights_fine[look_at,0,:,0]*w_fine[look_at,0,:,0], indices)/w_coarse[look_at,0,:,0]\n",
    "mask = tf.cast(fine_sum > weights_coarse[look_at,0,:,0], tf.float32)\n",
    "L_i = tf.math.reduce_sum((mask*(fine_sum-weights_coarse[look_at,0,:,0])*w_coarse[look_at,0,:,0]))\n",
    "L_along_ray = mask*((fine_sum-weights_coarse[look_at,0,:,0])) #don's scale (for plotting only)\n",
    "\n",
    "print(\"fine_sum:\", fine_sum)\n",
    "# print(\"mask:\", mask)\n",
    "print(\"L_i:\", L_i.numpy())\n",
    "print(\"L_along_ray scaled \\n\", L_along_ray*w_coarse[look_at,0,:,0])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "\n",
    "ax.scatter(z_vals_coarse[0,0,:,0],  weights_coarse[0,0,:,0], color  = 'green')\n",
    "ax.scatter(z_vals_fine[0,0,:,0],  weights_fine[0,0,:,0], color = 'orange')\n",
    "# ax.scatter(z_vals_coarse[0,0,:,0],  weights_coarse[0,0,:,0] *  (n_bins_coarse/n_bins_fine) )\n",
    "#     ax.scatter(z_vals_fine[0,j,:,0],  weights_fine[0,j,:,0])\n",
    "#     ax.plot(z_vals_fine[0,j,:,0],  weights_fine[0,j,:,0])\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], weights_coarse[look_at,0,:,0], \n",
    "       width = w_coarse[look_at,0,:,0],label = \"predicted ouput of fine network\", edgecolor = 'black', \n",
    "       alpha = 0.5, hatch = '\\\\', color = 'green');\n",
    "# ax.bar(z_vals_coarse[0,j,:,0]+w_coarse[0,j,:,0]/2, weights_coarse[0,j,:,0], width = w_coarse[0,j,:,0], \n",
    "#    label = \"coarse (scaled)\", edgecolor = 'black', alpha = 0.5);\n",
    "ax.bar(z_vals_fine[look_at,0,:,0], weights_fine[look_at,0,:,0], width = w_fine[look_at,0,:,0], \n",
    "   label = \"output of fine network\", alpha = 0.5, color = 'orange') #, edgecolor = 'black');\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], fine_sum, width = w_coarse[look_at,0,:,0], \n",
    "   label = \"fine output in coarse bins\", color = \"blue\", edgecolor = 'black', hatch = '//', alpha = 0.2);\n",
    "\n",
    "# #stacked bar chart for loss\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], L_along_ray,\n",
    "       width = w_coarse[look_at,0,:,0], bottom = weights_coarse[look_at,0,:,0] ,\n",
    "       label = \"loss of coarse network\", color = 'red', edgecolor = 'black', alpha = 0.35);\n",
    "\n",
    "ax.set_xlabel(\"s\")\n",
    "ax.set_ylabel(\"R(s)\")\n",
    "ax.legend(loc = 'lower left')\n",
    "# print(\"fine_sum\", fine_sum)\n",
    "# print(fine_sum > weights_coarse[0,0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.math.reduce_sum(w_coarse[look_at,0,:]))\n",
    "print(tf.math.reduce_sum(w_fine[look_at,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG: why are center reimann sums producing different results?\n",
    "\n",
    "def safe_segment_sum(data, segment_ids, num_segments):\n",
    "    # Initialize an array to store the segment sums\n",
    "    segment_sums = tf.zeros((num_segments,), dtype=data.dtype)\n",
    "    # Compute the segment sums using tensor_scatter_nd_add\n",
    "    segment_sums = tf.tensor_scatter_nd_add(segment_sums, tf.expand_dims(segment_ids, 1), data)\n",
    "    return segment_sums\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "# print(z_vals_coarse[0,0])\n",
    "# print(w_coarse[0,0]/2)\n",
    "\n",
    "zc = z_vals_coarse[i,j,:,0] - w_coarse[i,j,:,0]/2 \n",
    "zf = z_vals_fine[i, j,:,0]\n",
    "wc = weights_coarse[i, j,:,0]\n",
    "wf = weights_fine[i, j,:,0]\n",
    "width_fine_for_ray = w_fine[i,j,:,0] \n",
    "width_coarse_for_ray = w_coarse[i,j,:,0]\n",
    "\n",
    "idx = tf.searchsorted(zc, zf, side='right') - 1\n",
    "# print(idx)\n",
    "# print(wf*width_fine_for_ray)\n",
    "# print(len(zc))\n",
    "\n",
    "fine_sum = safe_segment_sum(wf*width_fine_for_ray, idx, len(zc))/width_coarse_for_ray   \n",
    "print(\"fine_sum \\n\", fine_sum)\n",
    "\n",
    "mask = tf.cast(fine_sum > wc , tf.float32)\n",
    "print(\"mask \\n\", mask)\n",
    "\n",
    "# L_i = tf.math.reduce_sum(mask*(fine_sum-weights_coarse[look_at,0,:,0])*w_coarse[look_at,0,:,0]) #scale by coarse bin widths \n",
    "L_i = tf.math.reduce_sum((mask*(fine_sum-weights_coarse[i,j,:,0])*w_coarse[i,j,:,0]))\n",
    "print(\"L_i \\n\", L_i)\n",
    "# print(\"weights_coarse[i,j]\", weights_coarse[i,j,:,0])\n",
    "# print(\"w_coarse\", w_coarse[i,j,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f00c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss_coarse_network(z_vals_coarse, z_vals_fine, weights_coarse, weights_fine):\n",
    "    '''Calculate loss for coarse network. Given histograms for scene density outptut by fine network,\n",
    "    see how close the density estimated by the coarse network got us.'''\n",
    "    \n",
    "    def safe_segment_sum(data, segment_ids, num_segments):\n",
    "        # Initialize an array to store the segment sums\n",
    "        segment_sums = tf.zeros((num_segments,), dtype=data.dtype)\n",
    "        # Compute the segment sums using tensor_scatter_nd_add\n",
    "        segment_sums = tf.tensor_scatter_nd_add(segment_sums, tf.expand_dims(segment_ids, 1), data)\n",
    "        return segment_sums\n",
    "    \n",
    "#     print(\"\\n calculate loss coarse network \\n\")\n",
    "#     print(\" z_vals_coarse \\n\", np.shape(z_vals_coarse))\n",
    "#     print(\" z_vals_fine \\n\", np.shape(z_vals_fine))\n",
    "#     print(\" weights_coarse \\n\",np.shape(weights_coarse))\n",
    "#     print(\" weights_fine\\n\",np.shape(weights_fine))\n",
    "    \n",
    "    def run_on_ray(index): \n",
    "        i, j = index\n",
    "#         zc = z_vals_coarse[i, j]\n",
    "        zc = z_vals_coarse[i,j] - width_coarse[i,j]/2 \n",
    "#         zc = z_vals_coarse[i,j] - w_coarse[i,j,:,0]/2 \n",
    "#         print(\"zc: \", zc)\n",
    "        zf = z_vals_fine[i, j]\n",
    "        wc = weights_coarse[i, j]\n",
    "        wf = weights_fine[i, j]\n",
    "#         width_fine_for_ray = w_fine[i,j,:,0] \n",
    "#         width_coarse_for_ray = w_coarse[i,j,:,0]\n",
    "        width_fine_for_ray = width_fine[i,j] \n",
    "        width_coarse_for_ray = width_coarse[i,j]            \n",
    "    \n",
    "        # Get index of which bin in coarse each bar in fine belongs inside of\n",
    "        idx = tf.searchsorted(zc, zf, side='right') - 1\n",
    "\n",
    "#         fine_sum = tf.math.segment_sum(wf*width_fine_for_ray, idx)/width_coarse_for_ray\n",
    "        fine_sum = safe_segment_sum(wf*width_fine_for_ray, idx, len(zc))/width_coarse_for_ray        \n",
    "        mask = tf.cast(fine_sum > wc , tf.float32)\n",
    "#         L_i = tf.math.reduce_sum(mask*(fine_sum-wc)) #old\n",
    "#         L_i = tf.math.reduce_sum(mask*(fine_sum-wc)*w_coarse) #scale by coarse bin widths \n",
    "#         L_i = tf.math.reduce_sum((mask*(fine_sum-weights_coarse[i,j,:,0])*w_coarse[i,j,:,0]))\n",
    "        L_i = tf.math.reduce_sum((mask*(fine_sum-weights_coarse[i,j])*w_coarse[i,j,:,0]))\n",
    "\n",
    "        if i == 0 and j == 0:\n",
    "#             print(\"\\n zc \\n\", zc)\n",
    "#             print(\"loss along ray: \\n\", mask*(fine_sum-wc)*width_coarse_for_ray)\n",
    "#             print(\"fine_sum: \\n\", fine_sum)\n",
    "#             print(\"L_i \\n\", L_i)\n",
    "#             print(\"mask \\n\", mask)\n",
    "#             print(\"weights_coarse[i,j] \\n\", weights_coarse[i,j])\n",
    "            print(\"w_coarse[i,j] \\n\", w_coarse[i,j,:,0]) #for some reason it works if we use this (generated externally)\n",
    "#             print(np.shape(width_coarse))\n",
    "#             print(\"idx: \\n\", idx) #looks like a match so far...\n",
    "#             print(\"zc\", np.shape(zc))\n",
    "#             print(\"z_vals_coarse\", np.shape(z_vals_coarse))\n",
    "#             print(\"width_coarse\", np.shape(width_coarse))\n",
    "#             print(\"w_coarse\", np.shape(w_coarse))\n",
    "            \n",
    "        return L_i\n",
    "    \n",
    "    #get spacing between subsequent z measurements in z_vals_fine to weight contributions\n",
    "    width_fine = tf.experimental.numpy.diff(z_vals_fine, axis = 2)\n",
    "#     print(np.shape(width_fine))\n",
    "    padding_config = [[0, 0],[0, 0],[0, 1]]\n",
    "    width_fine = tf.pad(width_fine, padding_config, constant_values=0.001)\n",
    "#     print(np.shape(width_fine))\n",
    "    \n",
    "    width_coarse = tf.experimental.numpy.diff(z_vals_coarse, axis = 2) #not quite??\n",
    "    padding_config = [[0, 0],[0, 0],[0, 1]]\n",
    "    width_coarse = tf.pad(width_coarse, padding_config, constant_values=0.001)\n",
    "#     print(np.shape(width_coarse))\n",
    "    print(\"width_coarse[i,j]\", width_coarse[i,j])\n",
    "\n",
    "    #normalize coarse and fine to contain an area of 1\n",
    "#     area_coarse = tf.math.reduce_sum(weights_coarse * w_coarse[:,:,:,0], axis =2)[:,:,None]\n",
    "#     print(\"width_coarse\", np.shape(width_coarse))\n",
    "    area_coarse = tf.math.reduce_sum(weights_coarse * width_coarse, axis =2)[:,:,None]\n",
    "    weights_coarse = weights_coarse/area_coarse\n",
    "#     area_fine = tf.math.reduce_sum(weights_fine * w_fine[:,:,:,0], axis =2)[:,:,None]\n",
    "    area_fine = tf.math.reduce_sum(weights_fine * width_fine, axis =2)[:,:,None]\n",
    "    weights_fine = weights_fine/area_fine\n",
    "    #print(tf.math.reduce_sum(weights_coarse * w_coarse[:,:,:,0], axis = 2)) #will be all ones if norm'd correctly\n",
    "    #print(tf.math.reduce_sum(weights_fine * w_fine[:,:,:,0], axis = 2)) #will be all ones if norm'd correctly\n",
    "\n",
    "    #map over each batch dimension\n",
    "    indices = tf.stack(tf.meshgrid(tf.range(z_vals_coarse.shape[0]), tf.range(z_vals_coarse.shape[1]), indexing='ij'), axis=-1)\n",
    "    indices = tf.reshape(indices, (-1, 2))\n",
    "    \n",
    "    # Use tf.map_fn to apply the run_on_ray() in parallel over batch dimensions    \n",
    "    L = tf.map_fn(run_on_ray, indices, fn_output_signature=tf.float32)\n",
    "    L = tf.reshape(L, (z_vals_coarse.shape[0], z_vals_coarse.shape[1]))\n",
    "    \n",
    "    return L\n",
    "\n",
    "L = calculate_loss_coarse_network(z_vals_coarse[...,0], z_vals_fine[...,0], weights_coarse[...,0], weights_fine[...,0])\n",
    "print(L[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coarse_network_utils import * \n",
    "\n",
    "fast = calculate_loss_coarse_network(z_vals_coarse[:,:,:,0] - w_coarse[:,:,:,0]/2, z_vals_fine[:,:,:,0], \n",
    "                                     weights_coarse[:,:,:,0], weights_fine[:,:,:,0],\n",
    "                                     w_coarse[:,:,:,0], w_fine[:,:,:,0] )\n",
    "print(\"fast: \\n\", np.shape(fast), fast[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571387a3",
   "metadata": {},
   "source": [
    "# Upsampling from coarse to fine distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "look_at = 0 #0\n",
    "zc = z_vals_coarse[look_at,0,:,0] - w_coarse[look_at,0,:,0]/2\n",
    "zf = z_vals_fine[look_at,0,:,0]\n",
    "wc = weights_coarse[look_at,0,:,0]\n",
    "wf = weights_fine[look_at,0,:,0]\n",
    "width_coarse = w_coarse[look_at,0,:,0]\n",
    "width_fine = w_fine[look_at,0,:,0]\n",
    "\n",
    "fig, ax = p.subplots(2,1)\n",
    "ax[0].bar(zc + width_coarse/2, wc, width = width_coarse, \n",
    "   label = \"predicted density\", edgecolor = 'black', alpha = 0.5);\n",
    "ax[0].scatter(zc,  tf.zeros_like(wc))\n",
    "\n",
    "n_resample = 100\n",
    "wc = tf.pad(wc[:,None], [[1,0], [0,0]] )[:-1,0]\n",
    "# print(wc)\n",
    "wc_cdf = tf.math.cumsum(wc/tf.math.reduce_sum(wc))\n",
    "# print(\"wc_cdf: \\n\", wc_cdf.numpy())\n",
    "randy = tf.sort(tf.random.uniform([n_resample]))\n",
    "# print(\"randy: \\n \", randy.numpy())\n",
    "idx = tf.searchsorted(wc_cdf, randy, side='right')\n",
    "# print(\"idx: \\n\", idx)\n",
    "\n",
    "cdf_left = tf.gather(wc_cdf, idx - 1)\n",
    "# print(\"cdf_left:\\n\", cdf_left.numpy())\n",
    "cdf_right = tf.gather(wc_cdf, idx)\n",
    "values_left = tf.gather(zc, idx - 1)\n",
    "# print(\"values_left:\\n\", values_left.numpy())\n",
    "values_right = tf.gather(zc, idx)\n",
    "\n",
    "weights = (randy - cdf_left) / (cdf_right - cdf_left)\n",
    "# print(\"weights \\n\", weights)\n",
    "continuous_samples = values_left + weights * (values_right - values_left)\n",
    "# print(continuous_samples)\n",
    "\n",
    "ax[1].plot(wc_cdf)\n",
    "ax[0].scatter(continuous_samples, tf.zeros_like(continuous_samples), alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42dd83b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from coarse_network_utils import resample_z_vals\n",
    "\n",
    "continuous_samples, width_z = resample_z_vals(z_vals_coarse - w_coarse/2, weights_coarse, w_coarse)\n",
    "print(z_vals_coarse[0,0,:,0] - w_coarse[0,0,:,0]/2)\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "look_at = 0\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], weights_coarse[look_at,0,:,0], \n",
    "       width = w_coarse[look_at,0,:,0], label = \"predicted density\", edgecolor = 'black', alpha = 0.5);\n",
    "ax.scatter(continuous_samples[look_at,0,:], tf.zeros_like(continuous_samples[look_at,0,:]), alpha = 0.5)\n",
    "\n",
    "# ax.plot(z_vals_fine[look_at,0,:,0], weights_fine[look_at,0,:]) #/tf.math.reduce_sum(weights_fine[0,0,:]*np.gradient(z_vals_fine[0,0,:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d28b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.math.reduce_sum(continuous_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51499361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just confirming that the masking isn't killing our double returns on our new coordinate system...\n",
    "thresh_horiz = 0.05 #test \n",
    "thresh_vert = 0.005 #test\n",
    "mask = np.ones(np.shape(target[:,:,0]))\n",
    "depth_nondrop = tf.math.multiply(depth, target_drop_mask)\n",
    "target_nondrop = tf.math.multiply(target, target_drop_mask)\n",
    "L_dist = tf.reduce_mean(tf.abs(depth_nondrop - target_nondrop))\n",
    "\n",
    "vertical_grad_target = np.gradient(target[:,:,0])[0] \n",
    "vertical_past_thresh = np.argwhere(tf.abs(vertical_grad_target) > thresh_vert) #old\n",
    "\n",
    "mask[vertical_past_thresh[:,0], vertical_past_thresh[:,1]] = 0 #1\n",
    "horizontal_grad_target = np.gradient(target[:,:,0])[1]\n",
    "horizontal_past_thresh = np.argwhere(tf.abs(horizontal_grad_target) > thresh_horiz) #old\n",
    "# #test for double gradient\n",
    "# horizontal_grad_target2 = np.gradient(horizontal_grad_target)[1]  \n",
    "# horizontal_past_thresh = np.argwhere(tf.abs(horizontal_grad_target2) > thresh_horiz)\n",
    "mask[horizontal_past_thresh[:,0], horizontal_past_thresh[:,1]] = 0 #1\n",
    "\n",
    "vertical_grad_inference = np.gradient(depth[:,:,0])[0]\n",
    "horizontal_grad_inference = np.gradient(depth[:,:,0])[1]\n",
    "# mag_difference = tf.math.sqrt((vertical_grad_target-vertical_grad_inference)**2 + (horizontal_grad_target-horizontal_grad_inference)**2)\n",
    "#DEBUG -- use struct reg. to amplify LR in sharp corners \n",
    "mag_difference = tf.reduce_mean(tf.abs(depth_nondrop - target_nondrop)) \n",
    "\n",
    "#suppress ray drop areas (for distance and gradient loss)\n",
    "L_reg = np.multiply(mag_difference, mask)\n",
    "L_reg = L_reg[:,:,None]\n",
    "L_reg = tf.reduce_mean(tf.math.multiply(L_reg, target_drop_mask))\n",
    "L_reg = tf.cast(L_reg, tf.float32)         \n",
    "\n",
    "#if we're using CDF for loss instead of distance error ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "CDFdiff = tf.abs(CDF - gtCDF)\n",
    "CDFdiff = tf.math.multiply(CDFdiff, target_drop_mask)\n",
    "\n",
    "# ~~~ prevent gradient mask from getting rid of double returns in windows, etc.\n",
    "save_non_ground = tf.zeros_like(mask).numpy()\n",
    "#NEED TO TURN OFF WHEN WE HAVE MULTIPLE VERTICAL PATCHES \n",
    "save_non_ground[:40,:] = 1 #prevent anything in the top ~3/4 of image from getting masked\n",
    "save_non_groud = tf.convert_to_tensor(save_non_ground)\n",
    "together = tf.concat([save_non_groud[:,:,None], mask[:,:,None]], axis = -1)\n",
    "mask = tf.math.reduce_max(together, axis = -1)\n",
    "mask = tf.cast(mask, tf.float32)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "fig, ax = p.subplots(1,3)\n",
    "ax[0].imshow(depth)\n",
    "ax[1].imshow(target)\n",
    "ax[2].imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60f9c8",
   "metadata": {},
   "source": [
    "# Train Dual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e642a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lidar_nerf_utils import *\n",
    "from coarse_network_utils import*\n",
    "tf.config.run_functions_eagerly(True) #loss function won't work properly in graph mode\n",
    "\n",
    "# model_coarse = init_model_proposal()\n",
    "# model_fine = init_model()\n",
    "# model_fine = model #warm start from previous training loop\n",
    "\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-3)\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-4)\n",
    "optimizer_coarse = tf.keras.optimizers.Adam(5e-5)\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-5)\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-6)\n",
    "\n",
    "# optimizer_fine = tf.keras.optimizers.Adam(5e-4)\n",
    "# optimizer_fine = tf.keras.optimizers.Adam(1e-4)\n",
    "optimizer_fine = tf.keras.optimizers.Adam(5e-5)\n",
    "# optimizer_fine = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "n_bins_fine = 256 #128\n",
    "n_bins_coarse = 16 #32\n",
    "near=0.\n",
    "far=1.\n",
    "N_iters = 1_000_000 #5_000\n",
    "psnrs = []\n",
    "iternums = []\n",
    "i_plot = 64 #256\n",
    "\n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 8 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "\n",
    "vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)  \n",
    "phivals = np.linspace(phimin, phimax, 64)#new (correct) way to bin elevation angles\n",
    "\n",
    "for i in range(N_iters):\n",
    "    img_i = np.random.randint(images.shape[0])\n",
    "#     img_i = 10\n",
    "    target = images[img_i,:,:,:1]\n",
    "    target_drop_mask = images[img_i,:,:,1:]\n",
    "    pose = poses[img_i]\n",
    "    rays_d = rays_d_all[img_i]\n",
    "    rays_o = rays_o_all[img_i]\n",
    "    \n",
    "    idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "    idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "    phimin_patch = phivals[idx_first]\n",
    "    phimax_patch = phivals[idx_second]\n",
    "\n",
    "    with tf.GradientTape() as tape_coarse, tf.GradientTape() as tape_fine:\n",
    "#     with tf.GradientTape() as tape_coarse:\n",
    "        #run coarse network first to get locations to evaluate fine model at ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        z_vals_coarse = tf.linspace(near, far - (far/n_bins_coarse), n_bins_coarse)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "        z_vals_coarse += 0.0*tf.random.uniform(list(rays_o.shape[:-1]) + [n_bins_coarse]) * (far-near)/n_bins_coarse\n",
    "        #DEBUG:\n",
    "#         z_vals_coarse += 1.0*tf.random.uniform(list(rays_o.shape[:-1]) + [n_bins_coarse]) * (far-near)/n_bins_coarse\n",
    "        z_vals_coarse = z_vals_coarse[:,:,:,None]#manually expand dimensions before passing in to coarse network (all pixels will share the same z_vals)\n",
    "        #move z vals coarse to center of histogram bins ~~~~~~~~~~~\n",
    "        width_coarse = tf.experimental.numpy.diff(z_vals_coarse, axis=2)\n",
    "        width_coarse = tf.concat([width_coarse, 1.- z_vals_coarse[:,:,-1][:,:,None] ], axis=2)    \n",
    "        z_vals_coarse = z_vals_coarse + width_coarse/2\n",
    "\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   \n",
    "        z_vals_fine, width_fine, weights_coarse = run_coarse_network(model_coarse, z_vals_coarse, width_coarse, \n",
    "                                                                     rays_o, rays_d, n_resample = n_bins_fine) #,\n",
    "                                                                     #repeat_coarse = False)    \n",
    "        \n",
    "        z_vals_fine = z_vals_fine[:, :, :, None]\n",
    "        weights_coarse = weights_coarse[:, :, :, None]\n",
    "                \n",
    "        # run fine network to get actual scene density ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~        \n",
    "        depth, ray_drop, CDF, weights_fine = render_rays(model_fine, rays_o, rays_d,  z_vals_fine, fine = False)\n",
    "        depth = depth[:,:,None]\n",
    "        ray_drop = ray_drop[:,:,None]\n",
    "        gtCDF = z_vals_fine[:,:,:,0] > target[:,:,:]\n",
    "        gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "        \n",
    "        #weights of zero will produce zero area, leading to NaN loss\n",
    "#         area_fine = tf.reduce_sum(weights_fine * width_fine, axis=2, keepdims=True)\n",
    "#         print(\"weights fine before fix: \\n\", (weights_fine/area_fine)[0,0,:].numpy())             \n",
    "        epsilon = 1e-6\n",
    "#         padded_area_by_bin = weights_fine * width_fine + epsilon*tf.ones_like(width_fine) #was this\n",
    "        padded_area_by_bin = (weights_fine + epsilon*tf.ones_like(width_fine)) * width_fine #slightly closer?\n",
    "        area_fine = tf.reduce_sum(padded_area_by_bin, axis=2, keepdims=True)       \n",
    "        weights_fine /= area_fine\n",
    "#         print(\"weights fine after fix: \\n\", weights_fine[0,0,:].numpy())\n",
    "#         print(\"min(area_fine)\", tf.math.reduce_min(area_fine))\n",
    "\n",
    "        #per mip-nerf 360, calculate fine losss first\n",
    "        loss_fine = calculate_loss(depth, ray_drop, target, target_drop_mask, CDF = CDF, gtCDF = gtCDF)\n",
    "        weights_fine_stopped = tf.stop_gradient(weights_fine)\n",
    "\n",
    "        loss_coarse, fine_sum = calculate_loss_coarse_network(z_vals_coarse[:,:,:,0], \n",
    "                                                                z_vals_fine[:,:,:,0], \n",
    "                                                                weights_coarse[:,:,:,0], \n",
    "                                                                weights_fine_stopped, \n",
    "                                                                width_coarse[:,:,:,0],\n",
    "                                                                width_fine[:,:,:],\n",
    "                                                                debug = True)\n",
    "\n",
    "        #TODO-- see if training works better without \n",
    "#         loss_coarse = loss_coarse * target_drop_mask[:,:,0] #suppress pixels with ray drop\n",
    "        loss_coarse = tf.math.reduce_sum(loss_coarse)\n",
    "        \n",
    "        # Compute gradients and apply them\n",
    "        gradients_fine = tape_fine.gradient(loss_fine, model_fine.trainable_variables)\n",
    "        optimizer_fine.apply_gradients(zip(gradients_fine, model_fine.trainable_variables))        \n",
    "        \n",
    "        gradients_coarse = tape_coarse.gradient(loss_coarse, model_coarse.trainable_variables)\n",
    "        optimizer_coarse.apply_gradients(zip(gradients_coarse, model_coarse.trainable_variables))\n",
    "\n",
    "\n",
    "    if i % i_plot == 0:\n",
    "        #rescale weights_coarse before plotting ~~~~~~~~\n",
    "        eps = 1e-3 #1e-3\n",
    "        weights_coarse = weights_coarse + eps*tf.ones_like(weights_coarse)\n",
    "        weights_coarse = weights_coarse/ tf.math.reduce_sum(width_coarse*weights_coarse, axis = 2)[:,:,None]\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        print(\"\\n iteration:\", i)            \n",
    "        print(\"loss_coarse:\", loss_coarse)\n",
    "        print(\"loss_fine:\", loss_fine)    \n",
    "        mask = tf.cast(fine_sum > weights_coarse[:,:,:,0], tf.float32)\n",
    "        L_along_ray = mask * (fine_sum - weights_coarse[:,:,:,0]) * width_coarse[:,:,:,0]\n",
    "#         print(\"weights_coarse outside\", weights_coarse[0,0,:,0])\n",
    "#         print(\"weights_fine\", weights_fine[0,0,:])\n",
    "#         print(\"fine_sum outside\", fine_sum[0,0,:])\n",
    "#         print(\"L along ray\", L_along_ray[0,0,:])\n",
    "#         print(\"mask outside: \\n\", mask[0,0,:])\n",
    "#         print(\"z_vals_coarse \\n\", z_vals_coarse[0,0,:,0])\n",
    "#         print(\"width_coarse \\n\", width_coarse[0,0,:,0])\n",
    "#         print(\"z_vals_fine \\n\", z_vals_fine[0,0,:,0])\n",
    "#         print(\"width_fine \\n\", width_fine[0,0,:])\n",
    "\n",
    "        look_at = 0\n",
    "        p.figure(figsize=(10,4))\n",
    "        p.subplot(131)\n",
    "        p.imshow(depth,cmap = \"gray\")#, norm='log')\n",
    "        p.title(f'Estimated Depth at Iteration: {i}')\n",
    "        p.subplot(133)\n",
    "        p.bar(z_vals_coarse[look_at,0,:,0], weights_coarse[look_at,0,:,0], width=width_coarse[look_at,0,:,0],\n",
    "             alpha = 0.4, label = 'coarse network output', hatch = '\\\\', edgecolor = 'black')\n",
    "\n",
    "        p.bar(z_vals_coarse[look_at,0,:,0], fine_sum[look_at,0,:], width=width_coarse[look_at,0,:,0],\n",
    "             alpha = 0.4, label = 'fine sum', hatch = '//', edgecolor = 'black')\n",
    "\n",
    "        p.bar(z_vals_fine[look_at,0,:,0], weights_fine[look_at,0,:], width=width_fine[look_at,0,:],\n",
    "             alpha = 0.4, label= 'fine network output')\n",
    "        p.bar(z_vals_coarse[look_at,0,:,0], L_along_ray[look_at,0,:]/width_coarse[look_at,0,:,0], width=width_coarse[look_at,0,:,0],\n",
    "              bottom = weights_coarse[look_at,0,:,0], alpha = 0.4, color = 'red', \n",
    "              label= 'loss of coarse')    \n",
    "        p.ylim([0,25])\n",
    "        p.title('coarse network weights for ray')\n",
    "        p.legend(loc=\"best\")\n",
    "        p.subplot(132)\n",
    "        p.imshow(ray_drop, cmap=\"gray\")#, norm = 'log')\n",
    "        p.title(\"estimated ray drop mask\")\n",
    "        p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43adfb38",
   "metadata": {},
   "source": [
    "# Use Two Networks To Genrate Point Cloud At Novel Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0dbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_view = 128 #128 #number of (rotational?) patches to draw\n",
    "n_bins_coarse = 16 #16\n",
    "n_bins_fine = 256\n",
    "\n",
    "near=0.\n",
    "far= 1.\n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #number of vertical patches between phimin and phimax\n",
    "\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "phimin = np.deg2rad(-15.593) #observed in raw data\n",
    "phimax = np.deg2rad(17.743)\n",
    "# phimax = np.deg2rad(15.593) #test\n",
    "# phimin = np.deg2rad(-17.743)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "savepc = np.zeros([0,3]) #to save point cloud to external file\n",
    "\n",
    "very_beginning = time.time()\n",
    "\n",
    "for j in range(num_view):\n",
    "\n",
    "    #get sensor transformation matrix\n",
    "#     rotm = poses[0]\n",
    "#     rotm = poses[1280]\n",
    "    \n",
    "    rotm = poses[len(poses)//2].copy() #copy existing pose to get rotations roughly correct\n",
    "#     rotm[0,-1] += 0.04  #shift a bit in x and y\n",
    "#     rotm[1,-1] -= 0.12  \n",
    "    \n",
    "    rotm[:3,:3] = np.eye(3)\n",
    "    # account for image crop in rotation\n",
    "    crop_angle =  (np.pi/n_rots) - j*(2*np.pi/n_rots)\n",
    "    rotm_crop = R.from_euler('xyz', [0,-crop_angle + np.pi/2,0]).as_matrix()\n",
    "    rotm[:3,:3] = rotm[:3,:3] @ rotm_crop\n",
    "    rotm = rotm.astype(np.float32)\n",
    "    vertical_bins = np.linspace(phimin, phimax, n_vert_patches+1)\n",
    "    phimin_patch = vertical_bins[img_i%n_vert_patches] \n",
    "    phimax_patch = vertical_bins[img_i%n_vert_patches + 1]\n",
    "    \n",
    "    #RUN COARSE NETWORK\n",
    "    rays_o, rays_d = get_rays(H, W, rotm, phimin_patch, phimax_patch)\n",
    "    z_vals_coarse = tf.linspace(near, far - (far/n_bins_coarse), n_bins_coarse)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "    z_vals_coarse += 0.00*tf.random.uniform(list(rays_o.shape[:-1]) + [n_bins_coarse]) * (far-near)/n_bins_coarse\n",
    "    z_vals_coarse = z_vals_coarse[:,:,:,None]#manually expand dimensions before passing in to coarse network (all pixels will share the same z_vals)\n",
    "    #move z vals coarse to center of histogram bins ~~~~~~~~~~~\n",
    "    width_coarse = tf.experimental.numpy.diff(z_vals_coarse, axis=2)\n",
    "    width_coarse = tf.concat([width_coarse, 1.- z_vals_coarse[:,:,-1][:,:,None] ], axis=2)    \n",
    "    z_vals_coarse = z_vals_coarse + width_coarse/2\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     \n",
    "    z_vals_fine, width_fine, weights_coarse = run_coarse_network(model_coarse, z_vals_coarse, width_coarse, \n",
    "                                                                 rays_o, rays_d, n_resample = n_bins_fine) #,\n",
    "                                                                 #repeat_coarse=False)    \n",
    "    eps = 1e-3 #1e-3\n",
    "    weights_coarse_scaled = weights_coarse + eps*tf.ones_like(weights_coarse)\n",
    "    weights_coarse_scaled = weights_coarse_scaled[:,:,:,None]/ tf.math.reduce_sum(width_coarse*weights_coarse_scaled[:,:,:,None], axis = 2)[:,:,None]\n",
    "    \n",
    "    z_vals_fine = z_vals_fine[:, :, :, None]\n",
    "    weights_coarse = weights_coarse[:, :, :, None]\n",
    "        \n",
    "    #RUN FINE NETWORK\n",
    "    depth, ray_drop, CDF, weights_fine = render_rays(model_fine, rays_o, rays_d,  z_vals_fine, fine = False)    \n",
    "    \n",
    "    new_point_cloud_spherical = np.zeros([np.shape(depth)[0]*np.shape(depth)[1],3])\n",
    "    depth = tf.transpose(depth).numpy() #need this\n",
    "    depth = np.flip(depth, axis = 0) #needed\n",
    "    #scale back up to normal size\n",
    "    depth *= 200 #50 #200\n",
    "    ray_drop = tf.transpose(ray_drop).numpy() #test\n",
    "    ray_drop = np.flip(ray_drop, axis = 0) #test\n",
    "    count = 0\n",
    "    for w in range(W):\n",
    "        for h in range(H):\n",
    "#             new_point_cloud_spherical[count,0] = depth[w,h] #radius #draw all points\n",
    "            if ray_drop[w,h] > 0.9:             \n",
    "                    new_point_cloud_spherical[count,0] = depth[w,h] #radius\n",
    "            else:\n",
    "                    new_point_cloud_spherical[count,0] = 0#100 # suppress ray dropped points\n",
    "            new_point_cloud_spherical[count,1] = (-w+(1024//(2*n_rots)))/(2048//(2*n_rots))*(2*np.pi/n_rots)   #was this\n",
    "            new_point_cloud_spherical[count,2] = np.pi/2 + phimax - (phimax-phimin)*(h/(H - 1)) #[17.74,-15.59] #(correct)       \n",
    "            count+= 1\n",
    "\n",
    "    new_point_cloud_spherical[:,1] -= (np.pi/n_rots) + j*(2*np.pi/n_rots) + np.pi #test\n",
    "    new_point_cloud_spherical[:,2] -= (phimax+phimin)\n",
    "    \n",
    "    new_point_cloud_cart = LC.s2c(LC,new_point_cloud_spherical).numpy() #was this\n",
    "    new_point_cloud_cart[:,2] = -new_point_cloud_cart[:,2] #need to flip z \n",
    "    disp.append(Points(new_point_cloud_cart, c = 'gray', r = 3, alpha = 0.5))\n",
    "\n",
    "plt.show(disp, \"MIP-NeRF 360 Coarse to Fine Approach\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f785",
   "metadata": {},
   "source": [
    "# Try two passes through proposal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf316e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lidar_nerf_utils import *\n",
    "from coarse_network_utils import*\n",
    "tf.config.run_functions_eagerly(True) #loss function won't work properly in graph mode\n",
    "\n",
    "model_coarse = init_model_proposal()\n",
    "model_fine = init_model()\n",
    "# model_fine = model #warm start from previous training loop\n",
    "\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-3)\n",
    "optimizer_coarse = tf.keras.optimizers.Adam(1e-4)\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(5e-5)\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-5)\n",
    "# optimizer_coarse = tf.keras.optimizers.Adam(1e-6)\n",
    "\n",
    "# optimizer_fine = tf.keras.optimizers.Adam(5e-4)\n",
    "optimizer_fine = tf.keras.optimizers.Adam(1e-4)\n",
    "# optimizer_fine = tf.keras.optimizers.Adam(5e-5)\n",
    "# optimizer_fine = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "#MUST BE POWERS OF 2\n",
    "n_bins_first_proposal = 8 #32\n",
    "n_bins_second_proposal = 32 #32\n",
    "n_bins_fine = 128 #256 #128 \n",
    "near=0.\n",
    "far=1.\n",
    "N_iters = 100_000 #5_000\n",
    "psnrs = []\n",
    "iternums = []\n",
    "i_plot = 64 #256\n",
    "\n",
    "n_rots = 128 #128 #number of horizontal patches per 2*pi\n",
    "n_vert_patches = 1 #8 #number of vertical patches between phimin and phimax\n",
    "H = 64 // n_vert_patches\n",
    "W = 1024 // n_rots\n",
    "\n",
    "for i in range(N_iters):\n",
    "    #select random training pose\n",
    "    img_i = np.random.randint(images.shape[0])\n",
    "    target = images[img_i,:,:,:1]\n",
    "    target_drop_mask = images[img_i,:,:,1:]\n",
    "    pose = poses[img_i]\n",
    "    \n",
    "    #get min and max elevation values (if training on images < full height of sensor)\n",
    "    idx_first=len(phivals) - (img_i%(n_vert_patches))*(64//n_vert_patches)-1\n",
    "    idx_second= (len(phivals)- ((img_i+1)%(n_vert_patches))*(64//n_vert_patches))%len(phivals)\n",
    "    phimin_patch = phivals[idx_first]\n",
    "    phimax_patch = phivals[idx_second]\n",
    "\n",
    "    #get ray origins and ray directions\n",
    "    rays_o, rays_d = get_rays(H, W, pose, phimin_patch, phimax_patch)\n",
    "    \n",
    "    with tf.GradientTape() as tape_coarse, tf.GradientTape() as tape_fine:\n",
    "#     with tf.GradientTape() as tape_coarse:\n",
    "        #run first proposal network ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        z_vals_first_proposal = tf.linspace(near, far - (far/n_bins_first_proposal), n_bins_first_proposal)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "        z_vals_first_proposal += 0.0*tf.random.uniform(list(rays_o.shape[:-1]) + [n_bins_first_proposal]) * (far-near)/n_bins_first_proposal\n",
    "        z_vals_first_proposal = z_vals_first_proposal[:,:,:,None]\n",
    "        #move z vals coarse to center of histogram bins \n",
    "        width_first_proposal = tf.experimental.numpy.diff(z_vals_first_proposal, axis=2)\n",
    "        width_first_proposal = tf.concat([width_first_proposal, 1.- z_vals_first_proposal[:,:,-1][:,:,None] ], axis=2)    \n",
    "        z_vals_first_proposal = z_vals_first_proposal + width_first_proposal/2           \n",
    "        z_vals_fine_from_first, width_fine_first, weights_first_proposal = run_coarse_network(model_coarse, \n",
    "                                                                                        z_vals_first_proposal, \n",
    "                                                                                        width_first_proposal, \n",
    "                                                                                        rays_o, rays_d, \n",
    "                                                                                        n_resample = n_bins_fine//2, \n",
    "                                                                                        repeat_coarse = False)    \n",
    "        z_vals_fine_from_first = z_vals_fine_from_first[:, :, :, None]\n",
    "        weights_first_proposal = weights_first_proposal[:, :, :, None]\n",
    "#         print(\"z_vals_fine_from_first\", np.shape(z_vals_fine_from_second), z_vals_fine_from_first[0,0,:,0])\n",
    "        \n",
    "        #run second proposal network ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        z_vals_second_proposal = tf.linspace(near, far - (far/n_bins_second_proposal), n_bins_second_proposal)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "        z_vals_second_proposal += 0.0*tf.random.uniform(list(rays_o.shape[:-1]) + [n_bins_second_proposal]) * (far-near)/n_bins_second_proposal\n",
    "        z_vals_second_proposal = z_vals_second_proposal[:,:,:,None]\n",
    "        #move z vals coarse to center of histogram bins \n",
    "        width_second_proposal = tf.experimental.numpy.diff(z_vals_second_proposal, axis=2)\n",
    "        width_second_proposal = tf.concat([width_second_proposal, 1.- z_vals_second_proposal[:,:,-1][:,:,None] ], axis=2)    \n",
    "        z_vals_second_proposal = z_vals_second_proposal + width_second_proposal/2           \n",
    "        z_vals_fine_from_second, width_fine_second, weights_second_proposal = run_coarse_network(model_coarse, \n",
    "                                                                                        z_vals_second_proposal, \n",
    "                                                                                        width_second_proposal, \n",
    "                                                                                        rays_o, rays_d, \n",
    "                                                                                        n_resample = n_bins_fine//2, \n",
    "                                                                                        repeat_coarse = False)    \n",
    "        z_vals_fine_from_second = z_vals_fine_from_second[:, :, :, None]\n",
    "        weights_second_proposal = weights_second_proposal[:, :, :, None]        \n",
    "#         print(\"z_vals_fine_from_second\", np.shape(z_vals_fine_from_second), z_vals_fine_from_second[0,0,:,0])\n",
    "        \n",
    "        # combine output of two passes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        z_vals_fine = tf.concat([z_vals_fine_from_first, z_vals_fine_from_second], axis = 2)\n",
    "        z_vals_fine = tf.sort(z_vals_fine, axis = 2)#[:,:,:,0]\n",
    "#         print(\"z_vals_fine\", np.shape(z_vals_fine), z_vals_fine[0,0,:,0])\n",
    "#         print(\"rays_d\", np.shape(rays_d))\n",
    "        \n",
    "        #recalculate widths\n",
    "        z_vals_fine = z_vals_fine - z_vals_fine[:,:,:1,:]\n",
    "        width_fine = tf.experimental.numpy.diff(z_vals_fine, axis=2)\n",
    "        width_fine = tf.concat([width_fine, 1.- z_vals_fine[:,:,-1][:,:,None] ], axis=2)\n",
    "        z_vals_fine = z_vals_fine + width_fine/2\n",
    "#         print(\"z_vals_fine\", np.shape(z_vals_fine), z_vals_fine[0,0,:,0])\n",
    "#         print(\"width_fine\", width_fine[0,0,:,0])\n",
    "        width_fine = width_fine[:,:,:,0]\n",
    "    \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        # run fine network to get actual scene density        \n",
    "        depth, ray_drop, CDF, weights_fine = render_rays(model_fine, rays_o, rays_d,  \n",
    "                                                         z_vals_fine, fine = False)\n",
    "        depth = depth[:,:,None]\n",
    "        ray_drop = ray_drop[:,:,None]\n",
    "        gtCDF = z_vals_fine[:,:,:,0] > target[:,:,:]\n",
    "        gtCDF = tf.cast(gtCDF, tf.float32)\n",
    "        \n",
    "#         print(np.shape(width_fine))\n",
    "#         print(np.shape(weights_fine))\n",
    "        \n",
    "        #weights of zero will produce zero area, leading to NaN loss\n",
    "        epsilon = 1e-6\n",
    "        padded_area_by_bin = (weights_fine + epsilon*tf.ones_like(width_fine)) * width_fine #slightly closer?\n",
    "        area_fine = tf.reduce_sum(padded_area_by_bin, axis=2, keepdims=True)       \n",
    "        weights_fine /= area_fine\n",
    "\n",
    "        #per mip-nerf 360: \"fine network leads, coarse network follows\"\n",
    "        loss_fine = calculate_loss(depth, ray_drop, target, target_drop_mask, CDF = CDF, gtCDF = gtCDF)\n",
    "        weights_fine_stopped = tf.stop_gradient(weights_fine)\n",
    "        \n",
    "        loss_coarse, fine_sum = calculate_loss_coarse_network(z_vals_coarse[:,:,:,0], \n",
    "                                                              z_vals_fine[:,:,:,0], \n",
    "                                                              weights_coarse[:,:,:,0], \n",
    "                                                              weights_fine_stopped, \n",
    "                                                              width_coarse[:,:,:,0],\n",
    "                                                              width_fine[:,:,:],\n",
    "                                                              debug = True)\n",
    "        loss_coarse = loss_coarse * target_drop_mask[:,:,0] #suppress pixels with ray drop\n",
    "        loss_coarse = tf.math.reduce_sum(loss_coarse)\n",
    "        \n",
    "        # Compute gradients and apply them\n",
    "        gradients_fine = tape_fine.gradient(loss_fine, model_fine.trainable_variables)\n",
    "        optimizer_fine.apply_gradients(zip(gradients_fine, model_fine.trainable_variables))        \n",
    "        \n",
    "        gradients_coarse = tape_coarse.gradient(loss_coarse, model_coarse.trainable_variables)\n",
    "        optimizer_coarse.apply_gradients(zip(gradients_coarse, model_coarse.trainable_variables))\n",
    "\n",
    "\n",
    "    if i % i_plot == 0:\n",
    "        #rescale weights_coarse before plotting ~~~~~~~~\n",
    "        eps = 1e-3 #1e-3\n",
    "        weights_coarse = weights_coarse + eps*tf.ones_like(weights_coarse)\n",
    "        weights_coarse = weights_coarse/ tf.math.reduce_sum(width_coarse*weights_coarse, axis = 2)[:,:,None]\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#         print(\"\\n iteration:\", i)            \n",
    "#         print(\"loss_coarse:\", loss_coarse)\n",
    "#         print(\"loss_fine:\", loss_fine)    \n",
    "        mask = tf.cast(fine_sum > weights_coarse[:,:,:,0], tf.float32)\n",
    "        L_along_ray = mask * (fine_sum - weights_coarse[:,:,:,0]) * width_coarse[:,:,:,0]\n",
    "#         print(\"weights_coarse outside\", weights_coarse[0,0,:,0])\n",
    "#         print(\"fine_sum outside\", fine_sum[0,0,:])\n",
    "#         print(\"L along ray\", L_along_ray[0,0,:])\n",
    "#         print(\"mask outside: \\n\", mask[0,0,:])\n",
    "#         print(\"z_vals_coarse \\n\", z_vals_coarse[0,0,:,0])\n",
    "#         print(\"width_coarse \\n\", width_coarse[0,0,:,0])\n",
    "#         print(\"z_vals_fine \\n\", z_vals_fine[0,0,:,0])\n",
    "#         print(\"width_fine \\n\", width_fine[0,0,:])\n",
    "\n",
    "        look_at = 0\n",
    "        p.figure(figsize=(10,4))\n",
    "        p.subplot(131)\n",
    "        p.imshow(depth,cmap = \"gray\")#, norm='log')\n",
    "        p.title(f'Estimated Depth at Iteration: {i}')\n",
    "        p.subplot(133)\n",
    "        p.bar(z_vals_coarse[look_at,0,:,0], weights_coarse[look_at,0,:,0], width=width_coarse[look_at,0,:,0],\n",
    "             alpha = 0.4, label = 'coarse network output', hatch = '\\\\', edgecolor = 'black')\n",
    "        p.bar(z_vals_coarse[look_at,0,:,0], fine_sum[look_at,0,:], width=width_coarse[look_at,0,:,0],\n",
    "             alpha = 0.4, label = 'fine sum', hatch = '//', edgecolor = 'black')\n",
    "        p.bar(z_vals_fine[look_at,0,:,0], weights_fine[look_at,0,:], width=width_fine[look_at,0,:],\n",
    "             alpha = 0.4, label= 'fine network output')\n",
    "        p.bar(z_vals_coarse[look_at,0,:,0], L_along_ray[look_at,0,:]/width_coarse[look_at,0,:,0], width=width_coarse[look_at,0,:,0],\n",
    "              bottom = weights_coarse[look_at,0,:,0], alpha = 0.4, color = 'red', \n",
    "              label= 'loss of coarse')    \n",
    "        p.ylim([0,25])\n",
    "        p.title('coarse network weights for ray')\n",
    "        p.legend(loc=\"best\")\n",
    "        p.subplot(132)\n",
    "        p.imshow(ray_drop, cmap=\"gray\")#, norm = 'log')\n",
    "        p.title(\"estimated ray drop mask\")\n",
    "        p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test applying gaussian smoothing to coarse network outputs--\n",
    "# this allows \"near misses\" to still be rewarded by the loss function\n",
    "\n",
    "def gaussian_smoothing(weights, sigma=1.0):\n",
    "    kernel = tf.exp(-0.5 * (tf.range(-2, 3, dtype=tf.float32) ** 2) / sigma ** 2)\n",
    "    kernel /= tf.reduce_sum(kernel)\n",
    "    smoothed_weights = tf.nn.conv1d(weights[None, :, None], kernel[:, None, None], stride=1, padding='SAME')[0, :, 0]\n",
    "    return smoothed_weights\n",
    "\n",
    "print(weights_coarse[0,0,:,0])\n",
    "\n",
    "smoothed_weights_coarse = gaussian_smoothing(weights_coarse)\n",
    "print(smoothed_weights_coarse[0,0,:,0])\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "# ax.plot(weights_coarse[0,0,:,0])\n",
    "# ax.plot(smoothed_weights_coarse[0,0,:,0])\n",
    "\n",
    "before = tf.zeros_like(weights_coarse).numpy()\n",
    "before[:,:,3,0] = 0.5\n",
    "before[:,:,6:8] = 0.25\n",
    "before[1:,:,:,:] = 0\n",
    "# print(np.shape(weights_coarse))\n",
    "\n",
    "# print(before)\n",
    "after = gaussian_smoothing(before, 1)\n",
    "ax.plot(before[0,0,:,0])\n",
    "ax.plot(after[0,0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST SO FAR\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#[D=8, W=256] 18 pos enc 6 ang enc\n",
    "model_fine.save_weights(\"models/fine1.ckpt\")\n",
    "model_fine.save('models/fine1.keras')\n",
    "#[D=8, W=256] 10 pos enc 5 ang enc\n",
    "model_coarse.save_weights(\"models/coarse1.ckpt\")\n",
    "model_coarse.save('models/coarse1.keras')\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# model_coarse.load_weights('models/coarse1.ckpt')\n",
    "# model_fine.load_weights('models/fine1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7be5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots()\n",
    "\n",
    "# for i in range(64):\n",
    "#     ax.plot(z_vals_fine[i,0,:,0]*200, weights_fine[i,0,:])\n",
    "\n",
    "# print(weights_coarse)\n",
    "\n",
    "print(np.shape(weights_fine))\n",
    "print(np.shape(width_fine))\n",
    "print(np.shape(tf.math.reduce_sum(weights_fine* width_fine, axis = 2) ))\n",
    "\n",
    "\n",
    "i = 63\n",
    "\n",
    "# ax.plot(z_vals_coarse[i,0,:,0]*200, weights_coarse[i,0,:])\n",
    "ax.plot(z_vals_coarse[i,0,:,0]*200, weights_coarse_scaled[i,0,:])\n",
    "# s = tf.math.reduce_sum(weights_fine* width_fine, axis = 2)[i,0,None]\n",
    "s = 1 #debug\n",
    "ax.plot(z_vals_fine[i,0,:,0]*200, weights_fine[i,0,:]/s) \n",
    "# print(z_vals_fine[0,0,:,0])\n",
    "print(weights_coarse_scaled[0,0,:,0])\n",
    "\n",
    "# ax.set_xlim([0,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = p.subplots()\n",
    "test = np.append(0,np.cumsum(weights_coarse_scaled[i,0,:]))\n",
    "# ax.plot(np.linspace(0,100,len(test)),test/test[-1])\n",
    "ax.plot(test/test[-1], np.linspace(0,100,len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o, rays_d = get_rays(H, W, rotm, phimin_patch, phimax_patch)\n",
    "z_vals_coarse = tf.linspace(near, far - (far/n_bins_coarse), n_bins_coarse)  #IMPORTANT NOTE: z_vals must be in ascending order \n",
    "z_vals_coarse += 0.00*tf.random.uniform(list(rays_o.shape[:-1]) + [n_bins_coarse]) * (far-near)/n_bins_coarse\n",
    "z_vals_coarse = z_vals_coarse[:,:,:,None]#manually expand dimensions before passing in to coarse network (all pixels will share the same z_vals)\n",
    "print(\"before\", z_vals_coarse[look_at,0,:,0])\n",
    "\n",
    "#move z vals coarse to center of histogram bins ~~~~~~~~~~~\n",
    "# w_coarse = tf.experimental.numpy.diff(z_vals_coarse, axis = 2)\n",
    "# padding_config = [[0, 0],[0, 0],[0, 1],[0, 0]]\n",
    "# w_coarse = tf.pad(w_coarse, padding_config, constant_values=0.001) #TODO-- issue here??\n",
    "# z_vals_coarse = z_vals_coarse + w_coarse/2\n",
    "# print(\"w_coarse\", w_coarse[look_at,0,:,0])\n",
    "w_coarse = tf.experimental.numpy.diff(z_vals_coarse, axis=2)\n",
    "w_coarse = tf.concat([w_coarse, 1.- z_vals_coarse[:,:,-1][:,:,None] ], axis=2)    \n",
    "print(\"w_coarse\", w_coarse[look_at,0,:,0])\n",
    "z_vals_coarse = z_vals_coarse + w_coarse/2\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   \n",
    "\n",
    "print(\"after\", z_vals_coarse[look_at,0,:,0])\n",
    "# print(\"after\", z_vals_coarse[look_at,0,:,0] + w_coarse[look_at, 0, :, 0]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbbba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from coarse_network_utils import resample_z_vals\n",
    "\n",
    "print(weights_coarse[0,0,:,0])\n",
    "\n",
    "look_at = 2\n",
    "z_vals_fine, width_fine = resample_z_vals(z_vals_coarse - width_coarse/2, \n",
    "                                          weights_coarse,\n",
    "#                                           weights_coarse + np.ones_like(weights_coarse),\n",
    "                                          width_coarse,\n",
    "                                          n_resample=n_bins_fine)\n",
    "z_vals_fine = z_vals_fine[:,:,:,None]\n",
    "# print(width_fine[look_at,0,:])\n",
    "# print(tf.math.reduce_sum(width_fine[look_at,0,:])) #make sure this adds up to exactly 1\n",
    "# print(z_vals_coarse[look_at,0,:,0])\n",
    "# print(z_vals_fine[look_at,0,:,0])\n",
    "# print(width_fine[look_at,0,:]/2)\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], weights_coarse[look_at,0,:,0], \n",
    "       width = width_coarse[look_at,0,:,0], label = \"predicted density\", edgecolor = 'black', alpha = 0.5);\n",
    "ax.scatter(z_vals_fine[look_at,0,:,0], tf.ones_like(z_vals_fine[look_at,0,:,0]), alpha = 0.5)\n",
    "ax.bar(z_vals_fine[look_at,0,:,0], tf.ones_like(z_vals_fine[look_at,0,:,0]), \n",
    "       width = width_fine[look_at,0,:], label = \"predicted density\", edgecolor = 'black', alpha = 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2603e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "look_at = 0\n",
    "#look how actual network computes loss\n",
    "depth, ray_drop, CDF, weights_fine = render_rays(model_fine, rays_o, rays_d,  z_vals_fine, fine = False)\n",
    "\n",
    "#normalized area of each bar segment\n",
    "area_fine = tf.math.reduce_sum(weights_fine * width_fine, axis = 2) #/ tf.math.reduce_sum(weights_fine * width_fine, axis = 2)[:,:,None]\n",
    "weights_fine = weights_fine / area_fine[:,:,None]\n",
    "\n",
    "loss_coarse, fine_sum = calculate_loss_coarse_network(z_vals_coarse[:,:,:,0], \n",
    "                                                        z_vals_fine[:,:,:,0], \n",
    "                                                        weights_coarse[:,:,:,0], \n",
    "                                                        weights_fine, \n",
    "                                                        width_coarse[:,:,:,0],\n",
    "                                                        width_fine[:,:,:],\n",
    "                                                        debug = True)\n",
    "\n",
    "print(\"fine_sum\", fine_sum[0,0,:])\n",
    "mask = tf.cast(fine_sum > weights_coarse[:,:,:,0], tf.float32)\n",
    "L_along_ray = mask * (fine_sum - weights_coarse[:,:,:,0]) * width_coarse[:,:,:,0]\n",
    "test = tf.math.reduce_sum(L_along_ray, axis = 2)\n",
    "print(\"why does this not match \\n\", test[look_at,0])\n",
    "print(\"this \\n\", loss_coarse[look_at,0])\n",
    "print(L_along_ray[look_at,0,:])\n",
    "# test = tf.math.reduce_sum(weights_fine * w_fine, axis = 2)\n",
    "# print(test[look_at,0])\n",
    "# print(tf.math.reduce_sum(weights_fine[look_at,0,:] * width_fine[look_at,0,:])/ test[look_at, 0])\n",
    "# print(weights_fine[look_at,0,:])\n",
    "\n",
    "fig, ax = p.subplots()\n",
    "# ax.scatter(z_vals_coarse[look_at,0,:,0],  weights_coarse[look_at,0,:,0], color  = 'green')\n",
    "# ax.scatter(z_vals_fine[look_at,0,:],  weights_fine[look_at,0,:], color = 'orange')\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], weights_coarse[look_at,0,:,0], \n",
    "       width = width_coarse[look_at,0,:,0],label = \"predicted ouput of fine network\", edgecolor = 'black', \n",
    "       alpha = 0.5, hatch = '\\\\', color = 'green');\n",
    "ax.bar(z_vals_fine[look_at,0,:,0], weights_fine[look_at,0,:], width = width_fine[look_at,0,:], \n",
    "   label = \"output of fine network\", alpha = 0.5, color = 'orange', edgecolor = 'black');\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], fine_sum[look_at,0,:], width = width_coarse[look_at,0,:,0], \n",
    "   label = \"fine output in coarse bins\", color = \"blue\", edgecolor = 'black', hatch = '//', alpha = 0.2);\n",
    "#stacked bar chart for loss\n",
    "ax.bar(z_vals_coarse[look_at,0,:,0], L_along_ray[look_at, 0,:] /width_coarse[look_at,0,:,0],\n",
    "       width = width_coarse[look_at,0,:,0], bottom = weights_coarse[look_at,0,:,0],\n",
    "       label = \"loss of coarse network\", color = 'red', edgecolor = 'black', alpha = 0.35);\n",
    "ax.set_xlabel(\"s\")\n",
    "ax.set_ylabel(\"R(s)\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "#THESE NEED TO ADD UP TO EXACTLY 1!\n",
    "# print(tf.math.reduce_sum(width_coarse[look_at,0,:]))\n",
    "# print(tf.math.reduce_sum(width_fine[look_at,0,:]))\n",
    "# print(tf.math.reduce_sum(width_fine[look_at,0,:] * weights_fine[look_at,0,:]))\n",
    "w_coarse = w_coarse[:,:,:,None] #bring back to same size as in training loop for consistancy\n",
    "w_fine = w_fine[:,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d98b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_vals_coarse[0,0,:,0]+width_coarse[0,0,:,0]/2)\n",
    "print(tf.math.reduce_sum(weights_fine[look_at,0,:9] * width_fine[look_at,0,:9])/1.25)\n",
    "print(width_fine[0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc616df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple fix for very sparse fine bins-- require resample bins function to repeat the \n",
    "# random sample locations in addition to the importance sampling\n",
    "\n",
    "a = 2*tf.random.uniform([3,4])\n",
    "b = tf.ones_like(a)\n",
    "\n",
    "a = tf.concat([a,b], axis = 0 )\n",
    "a = tf.sort(a, axis = 0)\n",
    "print(a)\n",
    "print(a.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea-- do something about \"realized density\" in our importance sampling strategy here??\n",
    "#  points > 0.5 for this scene are almost always going to be occluded. Deep inside buildings, etc. \n",
    "\n",
    "# Our fine network will output a density of 1 there, (which will lead the coarse network to resample there)\n",
    "# but the rendering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f3a95",
   "metadata": {},
   "source": [
    "# TODO:  \n",
    "1. expand z_vals to correct dimensions\n",
    "2. get widths_fine with TF\n",
    "3. Make dummy coarse data\n",
    "4. get loss function working in parallel with TF\n",
    "5. do inverse sampling from coarse network\n",
    "6. get inverse sampling working efficiently in parallel\n",
    "\n",
    "* create coarse network\n",
    "* figure out stop gradient order\n",
    "* create train loop\n",
    "* tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_fine.summary())\n",
    "# print(model_coarse.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix segment_sum dimension reduction bug\n",
    "##AAAAAaaaaAAAAaaaHHHhhHHhhhhh!\n",
    "# def safe_segment_sum(data, segment_ids, num_segments):\n",
    "#     # Initialize an array to store the segment sums\n",
    "#     segment_sums = tf.zeros((num_segments,), dtype=data.dtype)\n",
    "#     # Compute the segment sums using tensor_scatter_nd_add\n",
    "#     segment_sums = tf.tensor_scatter_nd_add(segment_sums, tf.expand_dims(segment_ids, 1), data)\n",
    "#     return segment_sums\n",
    "# def safe_segment_sum(data, segment_ids, num_segments):\n",
    "#     segment_ids = tf.expand_dims(segment_ids, axis=-1)\n",
    "#     segment_sums = tf.tensor_scatter_nd_add(tf.zeros((num_segments,), dtype=data.dtype), segment_ids, data)\n",
    "#     return segment_sums\n",
    "\n",
    "\n",
    "def safe_segment_sum(data, segment_ids, num_segments):\n",
    "    # Extract dimensions\n",
    "    batch_size, num_rays, num_samples = tf.shape(data)\n",
    "    \n",
    "    # Flatten data and segment_ids\n",
    "    data_flat = tf.reshape(data, [-1])\n",
    "    segment_ids_flat = tf.reshape(segment_ids, [-1])\n",
    "    \n",
    "    # Calculate indices\n",
    "    indices = tf.stack([\n",
    "        tf.range(batch_size * num_rays * num_samples),  # Flat indices\n",
    "        segment_ids_flat\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Initialize segment_sums tensor\n",
    "    segment_sums = tf.zeros([batch_size * num_rays, num_segments], dtype=data.dtype)\n",
    "    \n",
    "    # Scatter the data\n",
    "    segment_sums = tf.tensor_scatter_nd_add(segment_sums, indices, data_flat)\n",
    "    \n",
    "    # Reshape segment_sums to match original shape\n",
    "    segment_sums = tf.reshape(segment_sums, [batch_size, num_rays, num_segments])\n",
    "    \n",
    "    return segment_sums\n",
    "\n",
    "zf = tf.linspace(0.1,.79,32)\n",
    "zc = tf.linspace(0.,1., 8)\n",
    "# print(\"zf: \\n\", zf.numpy())\n",
    "zf = tf.tile(zf[None,None,:], [5,2,1])\n",
    "zc = tf.tile(zc[None,None,:], [5,2,1])\n",
    "# print(\"zf: \\n\", zf.numpy())\n",
    "\n",
    "print(\"zf: \\n\", np.shape(zf))\n",
    "print(\"zc: \\n\", np.shape(zc))#, zc.numpy())\n",
    "\n",
    "idx = tf.searchsorted(zc, zf, side='right') - 1\n",
    "print(\"\\n idx: \\n\", np.shape(idx)) #,idx)\n",
    "\n",
    "test = safe_segment_sum(tf.ones_like(zf), idx, zc.shape[2])\n",
    "print(\"\\n test: \\n\", np.shape(test))\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab92eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(inputs):\n",
    "    x, y = inputs\n",
    "    out = tf.math.reduce_sum(x) + y\n",
    "    return out\n",
    "\n",
    "# Define a function that processes each element using foo\n",
    "def map_fn(index):\n",
    "    return foo((d[index[0], index[1]], y[index[0], index[1]]))\n",
    "\n",
    "a = tf.constant([[1, 2, 3, 1], [1, 2, 3, 0]])\n",
    "b = tf.constant([[4, 5, 6, 1], [1, 2, 8, 1]])\n",
    "c = tf.constant([[7, 8, 9, 1], [1, 2, 3, 1]])\n",
    "d = tf.stack([a, b, c])\n",
    "y = tf.constant([[1, 1], [1, 1], [1, 1]])  # Shape (3, 2)\n",
    "\n",
    "# Create indices to map over\n",
    "indices = tf.stack(tf.meshgrid(tf.range(d.shape[0]), tf.range(d.shape[1]), indexing='ij'), axis=-1)\n",
    "indices = tf.reshape(indices, (-1, 2))\n",
    "\n",
    "# Use tf.map_fn to apply the function over indices\n",
    "results = tf.map_fn(map_fn, indices, fn_output_signature=tf.int32)\n",
    "results = tf.reshape(results, (d.shape[0], d.shape[1]))\n",
    "\n",
    "# Test outputs\n",
    "print(results)\n",
    "print(results[2, 1])\n",
    "print(foo((d[2, 1], y[2, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ff974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb58374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Generate a regular 2D grid (source grid)\n",
    "grid_size = 10  # Size of the grid\n",
    "source_grid_x, source_grid_y = np.meshgrid(np.linspace(0, 1, grid_size), np.linspace(0, 1, grid_size))\n",
    "source_points = np.column_stack((source_grid_x.flatten(), source_grid_y.flatten()))\n",
    "\n",
    "# Create a warp transformation (e.g., simple non-linear warp)\n",
    "def warp_function(x, y):\n",
    "    # Example warp: simple distortion\n",
    "    return x + 0.1 * np.sin(2 * np.pi * y), y + 0.1 * np.sin(2 * np.pi * x)\n",
    "\n",
    "# Warp some of the points\n",
    "warped_points = np.array([warp_function(x, y) for x, y in source_points])\n",
    "\n",
    "# Select known warped points (subset for interpolation)\n",
    "known_indices = np.random.choice(len(source_points), size=20, replace=False)\n",
    "known_source_points = source_points[known_indices]\n",
    "known_warped_points = warped_points[known_indices]\n",
    "\n",
    "# Interpolate missing points on the warped grid\n",
    "missing_indices = np.setdiff1d(np.arange(len(source_points)), known_indices)  # Remaining points\n",
    "missing_source_points = source_points[missing_indices]\n",
    "\n",
    "# Use griddata to estimate locations of missing points on the warped grid\n",
    "interpolated_points = griddata(known_source_points, known_warped_points, missing_source_points, method='cubic')\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(*zip(*known_warped_points), color='blue', label='Known Warped Points')\n",
    "plt.scatter(*zip(*interpolated_points), color='red', label='Interpolated Points')\n",
    "plt.scatter(*zip(*warped_points), color='green', marker='x', alpha=0.4, label='True Warped Points (Ground Truth)')\n",
    "plt.legend()\n",
    "plt.title(\"Warped Grid with Known and Interpolated Points\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6831f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "# Known grid points with irregular spacing\n",
    "known_points = np.array([[0, 0], [2, 0], [1.3,1.2], [1, 1], [0, 2], [2, 2]])\n",
    "\n",
    "# Missing points (you want to determine their positions)\n",
    "missing_indices = 2 * np.random.rand(10, 2)\n",
    "\n",
    "# Perform Delaunay triangulation\n",
    "tri = Delaunay(known_points)\n",
    "\n",
    "# Plot the triangulation\n",
    "fig, ax = plt.subplots()\n",
    "ax.triplot(known_points[:, 0], known_points[:, 1], tri.simplices)\n",
    "ax.scatter(known_points[:, 0], known_points[:, 1], color='blue', label='Known Points')\n",
    "ax.scatter(missing_indices[:, 0], missing_indices[:, 1], color='red', label='Missing Points')\n",
    "\n",
    "# Interpolating positions within the triangles could be done here\n",
    "# This requires finding which triangle the missing points fall into\n",
    "for point in missing_indices:\n",
    "    simplex = tri.find_simplex(point)\n",
    "    if simplex >= 0:\n",
    "        vertices = tri.simplices[simplex]\n",
    "        interpolated_position = np.mean(known_points[vertices], axis=0)  # Simple averaging for demo\n",
    "        ax.scatter(*interpolated_position, color='green', marker='x', label='Interpolated Position')\n",
    "\n",
    "# ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
