{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a48c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "# tf.config.set_visible_devices([], 'GPU') #run on CPU only -- seems to actually execute main parts of code faster here...\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "from ICET_spherical import ICET\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c133c9",
   "metadata": {},
   "source": [
    "# Select which drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18af893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #big hill and church:\n",
    "drive = \"20200721_144638_part36_1956_2229\"\n",
    "\n",
    "# # straight road, narrow with pedestrians and shops \n",
    "# drive = \"20200617_191627_part12_1614_1842\"\n",
    "\n",
    "#suburban neighborhood, trees, houses and parked cars\n",
    "# drive = \"20200706_161206_part22_670_950\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test- raw Pixell data?\n",
    "# prefix = \"/media/derm/06EF-127D2/leddartech/20200721_144638_part36_1956_2229/pixell_bfc_ech/\" #test\n",
    "prefix = \"/media/derm/06EF-127D3/leddartech/\" + drive + \"/pixell_bfc_ech/\" #test\n",
    "fn1 = prefix + \"00000150.pkl\"\n",
    "with open(fn1, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "# print(data)\n",
    "data = data['data'] #just want to hold on to Pixell measurements\n",
    "# print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f201c3",
   "metadata": {},
   "source": [
    "# Compare frames for evidence of rotation distortion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pioneer.das.api.platform import Platform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "#extract ground truth vehicle motion from GNSS/ INS -------------------------------------------\n",
    "dataset_path = \"/media/derm/06EF-127D3/leddartech/\" + drive\n",
    "config_path = \"/media/derm/06EF-127D3/leddartech/\" + drive + \"/platform.yml\"\n",
    "pf = Platform(dataset_path, config_path)\n",
    "GNSS = pf.sensors['sbgekinox_bcc']\n",
    "\n",
    "from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "test = emp(pf, GNSS['navposvel'], GNSS['ekfeuler'])\n",
    "timestamps = test.get_timestamps()\n",
    "print(len(timestamps))\n",
    "T1 = test.get_transform(timestamps[1])\n",
    "T2 = test.get_transform(timestamps[2])\n",
    "\n",
    "gt_vec = np.zeros([len(timestamps)-1,6])\n",
    "\n",
    "for i in range(1,len(timestamps)-skips):\n",
    "    #get translations from GNSS/INS baseline\n",
    "    gt_vec[i-1,0] = test.get_transform(timestamps[i+1])[1,3] - test.get_transform(timestamps[i])[1,3]\n",
    "    gt_vec[i-1,1] = test.get_transform(timestamps[i+1])[0,3] - test.get_transform(timestamps[i])[0,3]\n",
    "    gt_vec[i-1,2] = test.get_transform(timestamps[i+1])[2,3] - test.get_transform(timestamps[i])[2,3]\n",
    "    #get rotations\n",
    "    T1 = test.get_transform(timestamps[i])\n",
    "    T2 = test.get_transform(timestamps[i+1])\n",
    "    r1 = R.from_matrix(T1[:3,:3])\n",
    "    r2 = R.from_matrix(T2[:3,:3])\n",
    "#     gt_vec[i-1,3:] = (r2.as_euler('xyz', degrees=False) - r1.as_euler('xyz', degrees=False)) #was this\n",
    "    gt_vec[i-1,3:] = (r2.as_euler('yxz', degrees=False) - r1.as_euler('yxz', degrees=False)) #test\n",
    "\n",
    "vf = np.sqrt(gt_vec[:,0]**2 + gt_vec[:,1]**2)\n",
    "gt_vec[:,0] = vf\n",
    "gt_vec[:,1] = 0\n",
    "# print(gt_vec)\n",
    "# gt_vec[:,2] = 0\n",
    "gt_vec = gt_vec * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouster OS1-64 mechanical LiDAR + FLIR\n",
    "#test\n",
    "dataset_path = \"/media/derm/06EF-127D3/leddartech/\" + drive\n",
    "config_path = \"/media/derm/06EF-127D3/leddartech/\" + drive + \"/platform.yml\"\n",
    "pf = Platform(dataset_path, config_path)\n",
    "idx = 220 #turn\n",
    "# idx  =  150\n",
    "skips = 1\n",
    "undistort = False\n",
    "# undistort = True\n",
    "data1 = pf['ouster64_bfc_xyzit'][idx].get_point_cloud(undistort = undistort)\n",
    "lidar_time1 = pf['ouster64_bfc_xyzit'][idx].get_field('t')\n",
    "lidar_time1 = lidar_time1 - lidar_time1[0]\n",
    "lidar_time1 = np.asarray(lidar_time1 / max(lidar_time1))\n",
    "data1 = np.asarray(data1.tolist())[:,:3]\n",
    "\n",
    "data2 = pf['ouster64_bfc_xyzit'][idx+skips].get_point_cloud(undistort = undistort)\n",
    "lidar_time2 = pf['ouster64_bfc_xyzit'][idx+skips].get_field('t')\n",
    "lidar_time2 = lidar_time2 - lidar_time2[0]\n",
    "lidar_time2 = np.asarray(lidar_time2 / max(lidar_time2))\n",
    "data2 = np.asarray(data2.tolist())[:,:3]\n",
    "\n",
    "# data1 = data1[data1[:,2] > -0.75] #ignore ground plane\n",
    "# data2 = data2[data2[:,2] > -0.75] #ignore ground plane\n",
    "\n",
    "#get ground truth from GNSS data\n",
    "#get transformations for all sequential scans in skips\n",
    "x0 = tf.zeros(6)\n",
    "# print(x0)\n",
    "for j in range(skips):\n",
    "    # loop through all GNSS timestamps, stop when larger than ts_lidar and use previous index\n",
    "    ts_lidar = pf['ouster64_bfc_xyzit'][idx+j].timestamp\n",
    "    for c in range(len(timestamps)):\n",
    "        ts_gnss = timestamps[c]\n",
    "        if ts_gnss > ts_lidar:\n",
    "          break\n",
    "    x0 = tf.convert_to_tensor(gt_vec[c], dtype = tf.float32)\n",
    "    rot = R_tf(x0[3:])\n",
    "#     rot = R_tf(np.array([0,0,x0[-1]], np.float32))\n",
    "#     data2 = data2 @ rot + x0[:3]\n",
    "    data2 = (data2 + x0[:3]) @ rot\n",
    "\n",
    "\n",
    "print(\"\\n idx:\", idx, \"\\n x0:\", x0.numpy())\n",
    "\n",
    "# print(rot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697c8f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "# data1 = data1[data1[:,2] > -0.55] #remove ground plane\n",
    "\n",
    "# #draw single scan (rainbow by z height)\n",
    "# zheight = 100*(np.sin(0.5*data1[:,2])+1)\n",
    "# print(len(zheight))\n",
    "# cname = np.array([zheight, 100*(np.sin(0.5*data1[:,2]+256)+1), 128*np.ones(len(zheight))]).T.tolist()\n",
    "# print(cname[:10])\n",
    "\n",
    "#color by time (individual scan)\n",
    "# print(len(lidar_time1))\n",
    "cname1 = np.array([1-lidar_time1, lidar_time1, lidar_time1]).T.tolist()\n",
    "cname2 = np.array([1-lidar_time2, lidar_time2, lidar_time2]).T.tolist()\n",
    "# points_object1 = Points(data1, c = cname1, r = 2.5, alpha = 1)\n",
    "# disp.append(points_object1)\n",
    "# points_object2 = Points(data2, c = cname2, r = 2.5, alpha = 1)\n",
    "# disp.append(points_object2)\n",
    "\n",
    "disp.append(Points(data1, c = 'red', r = 2.5, alpha = 1))\n",
    "disp.append(Points(data2, c = 'blue', r = 2.5, alpha = 1))\n",
    "\n",
    "plt1.show(disp, \"Fig LedderTech\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f9561",
   "metadata": {},
   "source": [
    "# Run ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a14c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(x0)\n",
    "it = ICET(cloud1 = data1, cloud2 = data2, fid = 50, niter = 10, \n",
    "           draw = False, group = 2, RM = False, DNN_filter = False)#, cheat = x0)\n",
    "# ViewInteractiveWidget(it.plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a5ad3",
   "metadata": {},
   "source": [
    "#  Get mean timestamp of points from scan1, scan2 in each voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f29a2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "npts = 100\n",
    "#Get ragged tensor containing all points from each scan inside each sufficient voxel\n",
    "in1 = it.inside1\n",
    "npts1 = it.npts1\n",
    "in2 = it.inside2\n",
    "npts2 = it.npts2\n",
    "corr = it.corr\n",
    "\n",
    "# print(it.corr)\n",
    "#get indices of rag with enough elements\n",
    "ncells = tf.shape(corr)[0].numpy() #num of voxels with sufficent number of points\n",
    "print(\"ncells\", ncells)\n",
    "# print(tf.gather(npts2, corr))\n",
    "enough1 = tf.gather(in1, corr)\n",
    "enough2 = tf.gather(in2, corr)\n",
    "\n",
    "idx1 = np.zeros([ncells ,npts])\n",
    "idx2 = np.zeros([ncells ,npts])\n",
    "\n",
    "#loop through each element of ragged tensor\n",
    "for i in range(ncells):\n",
    "    idx1[i,:] = tf.random.shuffle(enough1[i])[:npts].numpy() #shuffle order and take first 25 elements\n",
    "    idx2[i,:] = tf.random.shuffle(enough2[i])[:npts].numpy() #shuffle order and take first 25 elements\n",
    "\n",
    "#get indices of points corresponding to which occupied voxel they fall into\n",
    "idx1 = tf.cast(tf.convert_to_tensor(idx1), tf.int32).numpy() #indices in scan 1 of points we've selected\n",
    "idx2 = tf.cast(tf.convert_to_tensor(idx2), tf.int32).numpy()\n",
    "\n",
    "lidar_time1 = pf['ouster64_bfc_xyzit'][idx].get_field('t')\n",
    "# lidar_time1 = lidar_time1 - lidar_time1[0]\n",
    "# lidar_time1 = np.asarray(lidar_time1 / max(lidar_time1))\n",
    "lidar_time2 = pf['ouster64_bfc_xyzit'][idx+skips].get_field('t')\n",
    "# lidar_time2 = lidar_time2 - lidar_time2[0]\n",
    "# lidar_time2 = np.asarray(lidar_time2 / max(lidar_time2))\n",
    "\n",
    "\n",
    "\n",
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "# D = np.zeros(ncells)#debug\n",
    "for i in range(ncells):\n",
    "    point1_locations = tf.gather(it.cloud1_tensor, idx1[i,:])\n",
    "    point2_locations = tf.gather(it.cloud2_tensor, idx2[i,:])\n",
    "    #color by lidar timestamp, relative to start of scan  \n",
    "#     LT1_i = np.mean(lidar_time1[idx1[i,:]])\n",
    "#     print(LT_i)\n",
    "#     col1 = np.array([1-LT1_i, LT1_i, LT1_i]).T.tolist()\n",
    "\n",
    "\n",
    "    #color by difference in mean time\n",
    "    LT1_i = np.mean(lidar_time1[idx1[i,:]])\n",
    "    LT2_i = np.mean(lidar_time2[idx2[i,:]])\n",
    "#     print((LT2_i - LT1_i - 100_000) / 5_000 + 0.4) \n",
    "#     print((LT2_i - LT1_i - 100_000))\n",
    "#     D[i] = LT2_i - LT1_i\n",
    "    d = (LT2_i - LT1_i - 100_000) / 5_000 + 0.4 #get difference + do some scaling\n",
    "#     print(d)\n",
    "    if d > 1:\n",
    "        d = 1\n",
    "    if d < 0:\n",
    "        d = 0\n",
    "    col1 = np.array([d, 1- d, d]).T.tolist()\n",
    "\n",
    "    disp.append(Points(point1_locations, c = col1, r = 3, alpha = 1))\n",
    "#     disp.append(Points(point2_locations, c = col1, r = 3, alpha = 1))\n",
    "    \n",
    "plt1.show(disp, \"Fig LedderTech\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64549409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.set_title(\"Voxel ID vs Difference in Mean Timstamp\")\n",
    "# ax.set_ylabel(\"Difference in Mean Timestamp\")\n",
    "# ax.set_xlabel(\"Voxel ID\")\n",
    "# ax.plot(UD, label = \"Undistorted\")\n",
    "# ax.plot(D, label = \"Distorted\")\n",
    "# ax.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba32c3",
   "metadata": {},
   "source": [
    "# Get true transform using EgomotionProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.linspace(0,100,101)\n",
    "print(test[::20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e175de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "provider = pf.egomotion_provider\n",
    "# type(provider)\n",
    "# frame_idx = 220\n",
    "# time_range = pf['ouster64_bfc_xyzit'][frame_idx].get_field('t')\n",
    "\n",
    "# print(provider.get_timestamps())\n",
    "time_range = provider.get_timestamps()\n",
    "subsample = 1\n",
    "traj1 = provider.get_trajectory(time_range, subsampling = subsample) #subsampling is inverted (100 is LOWER resolution)\n",
    "# print(np.shape(traj1))\n",
    "time_range = time_range[::subsample] #need to reduce time range if we subsample\n",
    "print(np.shape(time_range))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.plot(traj1[:,0,-1], traj1[:,1,-1])\n",
    "\n",
    "T = np.eye(4)\n",
    "x_hist_gt = np.zeros([len(traj1), 6])\n",
    "for idx, i in enumerate(traj1):\n",
    "#     print(i)\n",
    "    T = T * i\n",
    "#     print(T)\n",
    "    x_hist_gt[idx,0] = T[0,-1] #E\n",
    "    x_hist_gt[idx,1] = T[1,-1] #N\n",
    "    x_hist_gt[idx,2] = T[2,-1] #U\n",
    "    #get euler angles from rotation matrix\n",
    "    euls = R.from_matrix(i[:3,:3]).as_euler('xyz', degrees=False)\n",
    "    x_hist_gt[idx,3:] = euls\n",
    "    \n",
    "\n",
    "# print(x_hist_gt[:,-1])\n",
    "# ax.plot(np.diff(x_hist_gt[:,-1])) #yaw\n",
    "# ax.plot(np.sqrt(np.diff(traj1[:,0,-1])**2 + np.diff(traj1[:,1,-1])**2) ) #fwd\n",
    "\n",
    "# ax.plot(x_hist_gt[:,0], x_hist_gt[:,1])\n",
    "# ax.plot(ICET_ENU[:,0], ICET_ENU[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a280ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TEST- get ground truth bf movement\n",
    "# prefix = \"/home/derm/Downloads/20200721_144638_part36_1956_2229/peakcan_fcc_Speed/\"\n",
    "# prefix = \"/home/derm/Downloads/20200721_144638_part36_1956_2229/sbgekinox_bcc_navposvel/\"\n",
    "# prefix = \"/home/derm/Downloads/20200721_144638_part36_1956_2229/sbgekinox_bcc_ekfeuler/\"\n",
    "\n",
    "prefix = \"/media/derm/06EF-127D3/leddartech/\" + drive + \"/sbgekinox_bcc_gps1pos/\"\n",
    "# prefix = \"/home/derm/Downloads/20200721_144638_part36_1956_2229/sbgekinox_bcc_gps1pos/\" #what we want\n",
    "# prefix = \"/home/derm/Downloads/20200721_144638_part36_1956_2229/sbgekinox_bcc_gps1vel/\"\n",
    "\n",
    "fn1 = prefix + \"00000000.pkl\"\n",
    "with open(fn1, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# print(np.shape(data))\n",
    "print(data[0])\n",
    "\n",
    "# data = np.asarray(data.tolist())\n",
    "# print(np.shape(data))\n",
    "# print(data[238])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ece087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get timestamp of first range return in LIDAR trajectory\n",
    "ts_lidar = np.zeros(len(x_hist))\n",
    "for c in range(len(x_hist)):\n",
    "    ts_lidar[c] = pf['ouster64_bfc_xyzit'][c].get_field('t')[-1]\n",
    "# print(ts_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1974ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "# x_hist = np.loadtxt(\"leddartech_ICET_estimates.txt\")\n",
    "# pred_stds = np.loadtxt(\"leddartech_ICET_pred_stds.txt\")\n",
    "\n",
    "x_hist = np.loadtxt(\"results/leddartech_ICET_estimates_v2.txt\")\n",
    "pred_stds = np.loadtxt(\"results/leddartech_ICET_pred_stds_v2.txt\") \n",
    "x_hist_NDT = np.loadtxt(\"results/leddartech_NDT_estimates.txt\")\n",
    "\n",
    "\n",
    "print(pred_stds[0])\n",
    "ax[0].plot(ts_lidar, x_hist[:,0], label = 'ICET')\n",
    "# ax[0].plot(ts_lidar, x_hist_NDT[:,0], label = 'NDT')\n",
    "ax[0].fill_between(ts_lidar, x_hist[:,0]+ 2*pred_stds[:,0], x_hist[:,0] - 2*pred_stds[:,0], \n",
    "                 color = (0.5,0.5,0.5,0.4), label = 'ICET Predicted 2σ Error Bounds')\n",
    "ax[0].plot(time_range[:-1], (5/subsample)*np.sqrt(np.diff(traj1[:,0,-1])**2 + np.diff(traj1[:,1,-1])**2),'k-', label = 'ground truth' ) #fwd\n",
    "ax[0].set_title(\"forward translation\")\n",
    "ax[0].legend(loc = 'best')\n",
    "\n",
    "ax[1].plot(time_range[1:], (5/subsample)*np.diff(x_hist_gt[:,-1]), 'k-', label = 'ground truth') #yaw\n",
    "ax[1].fill_between(ts_lidar, x_hist[:,-1]+ 2*pred_stds[:,-1], x_hist[:,-1] - 2*pred_stds[:,-1], \n",
    "                 color = (0.5,0.5,0.5,0.4), label = 'ICET Predicted 2σ Error Bounds')\n",
    "ax[1].plot(ts_lidar, x_hist[:,5], label = 'ICET')\n",
    "ax[1].set_title(\"yaw\")\n",
    "ax[1].legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "20 * np.tan(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e49d5",
   "metadata": {},
   "source": [
    "# Exploring Leddertech Pixset with pioneer-das-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pioneer.das.api.platform import Platform\n",
    "\n",
    "# dataset_path = \"/media/derm/06EF-127D2/leddartech/20200721_144638_part36_1956_2229\"\n",
    "# config_path = \"/media/derm/06EF-127D2/leddartech/20200721_144638_part36_1956_2229/platform.yml\"\n",
    "dataset_path = \"/media/derm/06EF-127D3/leddartech/\" + drive\n",
    "config_path = \"/media/derm/06EF-127D3/leddartech/\" + drive + \"/platform.yml\"\n",
    "pf = Platform(dataset_path, config_path)\n",
    "# pf.add_egomotion_provider #TODO- figure out if I need this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2e53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TEST - pioneer das api UNDISTORT FUNCTION???\n",
    "frame = 100\n",
    "#LeddarTech Echo sample\n",
    "ech_sample = pf['pixell_bfc_ech'][frame]\n",
    "point_cloud = ech_sample.get_point_cloud()\n",
    "# print(np.shape(point_cloud))\n",
    "\n",
    "# Ouster PC\n",
    "lidar_unit = pf['ouster64_bfc_xyzit'][frame]\n",
    "print(lidar_unit.timestamp)\n",
    "pc_undistorted = lidar_unit.get_point_cloud(undistort=True)\n",
    "pc_distorted = lidar_unit.get_point_cloud(undistort=False)\n",
    "print(np.shape(pc_test))\n",
    "\n",
    "sync = pf.synchronized()\n",
    "print(sync)\n",
    "\n",
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "disp.append(Points(pc_distorted, r = 2, c = 'red'))\n",
    "disp.append(Points(pc_undistorted, r = 2, c = 'blue'))\n",
    "# disp.append(Points(data1, r = 5, alpha = 0.2, c = 'gray')) #What I was using\n",
    "\n",
    "\n",
    "plt1.show(disp, \"Fig LedderTech\")\n",
    "ViewInteractiveWidget(plt1.window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b421b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pioneer.das.api as api\n",
    "# api.sensors.imu_sbg_ekinox.IMUEgomotionProvider.(GNSS, pf)\n",
    "test = pf.add_egomotion_provider\n",
    "test = pf.egomotion_provider\n",
    "# print(test.ekfeuler)\n",
    "print(len(test.get_timestamps()))\n",
    "test.get_first_inverse_transform()\n",
    "print(\"\\n forward transform: \\n\", test.get_transform(10))\n",
    "# print(\"\\n inverse transform: \\n\", test.get_inverse_transform(10))\n",
    "# https://github.com/leddartech/pioneer.das.api/blob/master/pioneer/das/api/egomotion/egomotion_provider.py\n",
    "# from pioneer.das.api import egomotion\n",
    "# from abc import ABC, abstractclassmethod\n",
    "# from pioneer.das.api.egomotion import EgomotionProvider as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n pf keys: \\n\",pf.sensors.keys())\n",
    "GNSS = pf.sensors['sbgekinox_bcc']\n",
    "print(\"\\n GNSS keys: \\n\", GNSS.keys())\n",
    "ground_truth = GNSS['ekfeuler']\n",
    "# ground_truth = GNSS['gps1pos']\n",
    "# print(ground_truth)\n",
    "# len(list(ground_truth))\n",
    "LIDAR = pf.sensors['ouster64_bfc']\n",
    "print(\"\\n LIDAR keys: \\n\", LIDAR.keys())\n",
    "print(\"\\n\",LIDAR['xyzit'])\n",
    "# ground_truth.sample_factory(0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13620dff",
   "metadata": {},
   "source": [
    "### Get LIDAR and GNSS/INS timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d51d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test.get_timestamps())\n",
    "num_frames = 274\n",
    "lidar_time = np.zeros([num_frames])\n",
    "for i in range(num_frames):\n",
    "    #church, old Montreal\n",
    "#     prefix = \"/media/derm/06EF-127D2/leddartech/20200721_144638_part36_1956_2229/ouster64_bfc_xyzit/\"\n",
    "    prefix = \"/media/derm/06EF-127D3/leddartech/\"+ drive + \"/ouster64_bfc_xyzit/\"\n",
    "    fn1 = prefix + '%08d.pkl' %(i)\n",
    "    with open(fn1, 'rb') as f:\n",
    "        data1 = pickle.load(f)\n",
    "    lidar_time[i] = np.asarray(data1.tolist())[0,-1]\n",
    "#     data1 = np.asarray(data1.tolist())[:,:3]\n",
    "# print(lidar_time[1] - lidar_time[0])\n",
    "# print(len(timestamps))\n",
    "\n",
    "x_hist = np.loadtxt(\"results/leddartech_ICET_estimates_v2.txt\") #old church\n",
    "# x_hist = np.loadtxt(\"results/leddartech_ICET_estimates_suburb.txt\") #old pc gathernig method\n",
    "# x_hist = np.loadtxt(\"results/leddartech_ICET_estimates_suburb_undistorted.txt\") #new strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d4ea9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "from scipy.spatial.transform import Rotation as R\n",
    "name = pf\n",
    "test = emp(name, GNSS['navposvel'], GNSS['ekfeuler'])\n",
    "timestamps = test.get_timestamps()\n",
    "T1 = test.get_transform(timestamps[1])\n",
    "T2 = test.get_transform(timestamps[2])\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "gt_vec = np.zeros([1800-1,6])\n",
    "\n",
    "for i in range(1,1800):\n",
    "    #get translations from GNSS/INS baseline\n",
    "    gt_vec[i-1,0] = test.get_transform(timestamps[i])[1,3] - test.get_transform(timestamps[i-1])[1,3]\n",
    "    gt_vec[i-1,1] = test.get_transform(timestamps[i])[0,3] - test.get_transform(timestamps[i-1])[0,3]\n",
    "    gt_vec[i-1,2] = test.get_transform(timestamps[i])[2,3] - test.get_transform(timestamps[i-1])[2,3]\n",
    "    #get rotations\n",
    "    T1 = test.get_transform(timestamps[i-1])\n",
    "    T2 = test.get_transform(timestamps[i])\n",
    "    r1 = R.from_matrix(T1[:3,:3])\n",
    "    r2 = R.from_matrix(T2[:3,:3])\n",
    "    gt_vec[i-1,3:] = (r2.as_euler('xyz', degrees=False) - r1.as_euler('xyz', degrees=False))\n",
    "    \n",
    "vf = np.sqrt(gt_vec[:,0]**2 + gt_vec[:,1]**2)\n",
    "gt_vec[:,0] = vf\n",
    "gt_vec[:,1] = 0\n",
    "gt_vec[:,2] = 0\n",
    "\n",
    "gt_vec = gt_vec*5\n",
    "\n",
    "# ax.plot(x_hist[:,0], label = \"ICET\")\n",
    "# ax.plot(5*gt, label = \"ground truth\")\n",
    "ax[0].set_title(\"Forward Translation\")\n",
    "ax[0].plot(lidar_time, x_hist[:,0], label = \"ICET\")\n",
    "ax[0].plot(timestamps[:-1], gt_vec[:,0], label = \"ground truth\")\n",
    "ax[0].legend(loc='best')\n",
    "ax[1].set_title(\"yaw\")\n",
    "ax[1].plot(lidar_time, x_hist[:,5], label = \"ICET\")\n",
    "ax[1].plot(timestamps[:-1], gt_vec[:,5], label = 'ground truth')\n",
    "# ax[1].scatter(lidar_time[idx], x_hist[idx,5], color = 'r', label = \"Point of linearization\")\n",
    "\n",
    "ax[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81795ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get closest partof \n",
    "yaw_error = closest_gt_yaw - x_hist[:,5]\n",
    "yaw_thresh = 0.0025\n",
    "bad_yaw_idx = np.argwhere(np.abs(yaw_error) > yaw_thresh)\n",
    "\n",
    "\n",
    "x_error = closest_gt_x - x_hist[:,1]\n",
    "x_thresh = 0.08\n",
    "bad_x_idx = np.argwhere(np.abs(x_error) > x_thresh)\n",
    "# print(bad_x_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For trainig data generation script: \n",
    "#given lidar index, <idx>, find solution vector for closest corresponding timestamp in GNSS/INS \n",
    "\n",
    "idx = 100\n",
    "prefix = \"/media/derm/06EF-127D3/leddartech/\"+ drive + \"/ouster64_bfc_xyzit/\"\n",
    "fn1 = prefix + '%08d.pkl' %(idx)\n",
    "with open(fn1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "ts_lidar = np.asarray(data1.tolist())[0,-1]\n",
    "print(ts_lidar)\n",
    "\n",
    "# loop through all GNSS timestamps, stop when larger than ts_lidar and use previous index\n",
    "for c in range(len(timestamps)):\n",
    "    ts_gnss = timestamps[c]\n",
    "    if ts_gnss > ts_lidar:\n",
    "        break\n",
    "x0 = tf.convert_to_tensor(gt_vec[c], dtype = tf.float32)\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb648255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sample idx vs time\"\n",
    "fig, ax = plt.subplots()\n",
    "for idx in range(1,100,10):\n",
    "    prefix = \"/media/derm/06EF-127D3/leddartech/\"+ drive + \"/ouster64_bfc_xyzit/\"\n",
    "    fn1 = prefix + '%08d.pkl' %(idx)\n",
    "    with open(fn1, 'rb') as f:\n",
    "        data1 = pickle.load(f)\n",
    "    ts_lidar = np.asarray(data1.tolist())[0,-1]\n",
    "    print(ts_lidar)\n",
    "\n",
    "    #NOT A STRAIGHT LINE!\n",
    "    ax.plot(np.asarray(data1.tolist())[:,4] - np.asarray(data1.tolist())[0,4]  ) \n",
    "    ax.set_xlabel(\"scan point processed\")\n",
    "    ax.set_ylabel(\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9afe93",
   "metadata": {},
   "source": [
    "## Plot ICET vs Ground Truth on LeddarTech PixSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ca3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(\"East\")\n",
    "ax.set_ylabel(\"North\")\n",
    "ax.set_title(\"LeddarTech PixSet\")\n",
    "\n",
    "ground_truth_ENU = np.zeros([len(test.get_timestamps()),3])\n",
    "for i in range(len(test.get_timestamps())):\n",
    "    ground_truth_ENU[i,0] = -test.get_transform(timestamps[i])[1,3]\n",
    "    ground_truth_ENU[i,1] = test.get_transform(timestamps[i])[0,3]\n",
    "    ground_truth_ENU[i,2] = test.get_transform(timestamps[i])[2,3] #test\n",
    "    \n",
    "#truncate ground truth to length of LIDAR data\n",
    "ground_truth_ENU = ground_truth_ENU[140:,:]\n",
    "# ground_truth_ENU = ground_truth_ENU[:-265,:] #old\n",
    "ground_truth_ENU = ground_truth_ENU[:-250,:] #test\n",
    "\n",
    "#convert sequential ICET estimates to ENU\n",
    "ICET_cum = np.zeros(np.shape(x_hist))\n",
    "NDT_cum = np.zeros(np.shape(x_hist_NDT))\n",
    "for k in range(len(x_hist)):\n",
    "    ICET_cum[k] = np.sum(x_hist[:k], axis=0)\n",
    "    NDT_cum[k] = np.sum(x_hist_NDT[:k], axis=0)\n",
    "\n",
    "ICET_cum[:,5] += 0.8 #correct total yaw to line up with ENU at initial pose\n",
    "# NDT_cum[:,5] += 0.8\n",
    "\n",
    "ICET_ENU = np.zeros([len(x_hist), 3])\n",
    "NDT_ENU = np.zeros([len(x_hist), 3])\n",
    "for j in range(1,len(x_hist)):\n",
    "    ICET_ENU[j, 0] = ICET_ENU[j-1, 0] + x_hist[j,0]*np.cos(ICET_cum[j,5])\n",
    "    ICET_ENU[j, 1] = ICET_ENU[j-1, 1] + x_hist[j,0]*np.sin(ICET_cum[j,5])\n",
    "    \n",
    "    NDT_ENU[j, 0] = NDT_ENU[j-1, 0] + x_hist_NDT[j,0]*np.cos(NDT_cum[j,5])\n",
    "    NDT_ENU[j, 1] = NDT_ENU[j-1, 1] + x_hist_NDT[j,0]*np.sin(NDT_cum[j,5])\n",
    "    \n",
    "    \n",
    "ground_truth_ENU[:,:] -= ground_truth_ENU[0,:] #zero out start\n",
    "ax.plot(ground_truth_ENU[:-20,0], ground_truth_ENU[:-20,1], 'k--', label = \"ground truth\")\n",
    "\n",
    "ax.plot(ICET_ENU[:,0], ICET_ENU[:,1], label = 'ICET')\n",
    "# ax.plot(NDT_ENU[:,0], NDT_ENU[:,1], label = 'NDT')\n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "# print(ICET_ENU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5b82f",
   "metadata": {},
   "source": [
    "### Plot 3D trajectory of ICET estimates vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c9195",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import R_tf\n",
    "\n",
    "axlabel  = {\"xtitle\": \"East (m)\",\n",
    "            \"ytitle\": \"North (m)\",\n",
    "            \"ztitle\": \"Up (m)\"}\n",
    "plt2 = Plotter(N = 1, bg = (1, 1, 1), interactive = True)\n",
    "# plt2 = Plotter(N = 1, bg = (0.2, 0.2, 0.2), interactive = True) \n",
    "# plt2 = Plotter(N = 1, axes = 0, bg = (1, 1, 1), interactive = True) #axes = 1\n",
    "disp = []\n",
    "\n",
    "#snail trail for ICET estimates and HD-Map\n",
    "snail_trail_ICET = np.zeros([1,3])\n",
    "snail_trail_NDT = np.zeros([1,3])\n",
    "# HD_map = np.zeros([1,3])\n",
    "for i in range(len(x_hist)):\n",
    "#     print(i)\n",
    "    snail_trail_ICET += x_hist[i,:3]\n",
    "    rot = R_tf(np.array([x_hist[i,3], x_hist[i,4], -x_hist[i,5]])).numpy()\n",
    "    snail_trail_ICET = snail_trail_ICET.dot(rot)    \n",
    "    snail_trail_ICET = np.append(np.zeros([1,3]), snail_trail_ICET, axis = 0)\n",
    "\n",
    "    snail_trail_NDT += x_hist_NDT[i,:3]\n",
    "    rot_NDT = R_tf(np.array([x_hist_NDT[i,3], x_hist_NDT[i,4], -x_hist_NDT[i,5]])).numpy()\n",
    "    snail_trail_NDT = snail_trail_NDT.dot(rot_NDT)    \n",
    "    snail_trail_NDT = np.append(np.zeros([1,3]), snail_trail_NDT, axis = 0)\n",
    "    \n",
    "#     #loop through all point clouds to make single mega cloud\n",
    "#     prefix = \"/home/derm/Downloads/20200721_144638_part36_1956_2229/ouster64_bfc_xyzit/\" #very good quality\n",
    "#     fn1 = prefix + '%08d.pkl' %(i)\n",
    "#     with open(fn1, 'rb') as f:\n",
    "#         data1 = pickle.load(f)\n",
    "#         local_PC = np.asarray(data1.tolist())[:,:3]    \n",
    "#         local_PC = local_PC[np.random.choice(len(local_PC), size = 20000)]  #downsample\n",
    "\n",
    "#     HD_map -= x_hist[i,:3]\n",
    "#     rot_map = R_tf(np.array([-x_hist[i,3], -x_hist[i,4], -x_hist[i,5]])).numpy()\n",
    "#     HD_map = HD_map.dot(rot_map)\n",
    "#     HD_map = np.append(local_PC, HD_map, axis = 0)\n",
    "    \n",
    "snail_trail_ICET -= snail_trail_ICET[-1,:] #set common origin \n",
    "# HD_map -= snail_trail_ICET[0,:]\n",
    "## HD_map[:,:2] -= snail_trail_ICET[0,:2] #test\n",
    "rotation_correction_ICET = R_tf(np.array([0, -0.15, -0.59])).numpy()\n",
    "snail_trail_ICET = snail_trail_ICET.dot(rotation_correction_ICET)\n",
    "snail_trail_ICET_points_obj = Points(snail_trail_ICET, c = 'red', r = 5, alpha = 1).legend(\"ICET\")\n",
    "disp.append(snail_trail_ICET_points_obj)\n",
    "\n",
    "snail_trail_NDT -= snail_trail_NDT[-1,:] #set common origin \n",
    "snail_trail_NDT = snail_trail_NDT.dot(rotation_correction_ICET)\n",
    "snail_trail_NDT_points_obj = Points(snail_trail_NDT, c = 'green', r = 5, alpha = 1).legend(\"NDT\")\n",
    "disp.append(snail_trail_NDT_points_obj)\n",
    "\n",
    "#snail trail for ground truth\n",
    "gt = ground_truth_ENU[20:]\n",
    "gt = gt-gt[0]\n",
    "gt_points_obj = Points(gt, c = 'blue', r = 3, alpha = 1).legend(\"GPS/INS Baseline\")\n",
    "disp.append(gt_points_obj)\n",
    "         \n",
    "\n",
    "# rotation_correction_HD_map = R_tf(np.array([0, -0.15, -0.59 + np.pi])).numpy()\n",
    "# HD_map = HD_map.dot(rotation_correction_HD_map)\n",
    "HD_map_temp = HD_map.copy()\n",
    "HD_map_temp[:,2] -= 6.5 #1.5\n",
    "HD_map_temp = HD_map_temp.dot(R_tf(np.array([0, 0.05, 0])).numpy()) #old\n",
    "# HD_map_temp = HD_map_temp.dot(R_tf(np.array([0.025, 0.1, 0])).numpy()) #test\n",
    "HD_map_temp = HD_map_temp[HD_map_temp[:,0] > -15 ] #crop\n",
    "HD_map_temp = HD_map_temp[HD_map_temp[:,0] < 100 ] \n",
    "HD_map_temp = HD_map_temp[HD_map_temp[:,1] > -15 ] \n",
    "HD_map_temp = HD_map_temp[HD_map_temp[:,1] < 150 ] \n",
    "\n",
    "#rainbow by z height\n",
    "# zheight = 100*(np.sin(0.25*HD_map_temp[:,2])+3)\n",
    "# cname = np. array([zheight, 100*(np.sin(0.25*HD_map_temp[:,2]+256)+1), 128*np.ones(len(zheight))]).T.tolist()\n",
    "# points_object = Points(HD_map_temp, c = cname, r = 1.0, alpha = 0.02)\n",
    "# disp.append(points_object)\n",
    "\n",
    "disp.append(Points(HD_map_temp, c = \"black\", r = 0.25, alpha = 0.03))\n",
    "\n",
    "lb = LegendBox([snail_trail_NDT_points_obj, snail_trail_ICET_points_obj, gt_points_obj], width=0.15, height=0.15, markers='s').font(\"Kanopus\")\n",
    "\n",
    "plt2.show(disp, lb, \"LeddarTech PixSet\", axes = axlabel)\n",
    "# plt2.show(disp, lb, \"LeddarTech PixSet\")\n",
    "ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snail_trail_ICET[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae68414",
   "metadata": {},
   "source": [
    "# Using Ouster Sample Dataset and Ouster-SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import R_tf\n",
    "fn1 = \"/media/derm/06EF-127D3/Ouster/csv/pcap_out_000320.csv\"\n",
    "df1 = pd.read_csv(fn1, sep=',', skiprows=[0])\n",
    "pc1 = df1.values[:,8:11]*0.001 #1st return\n",
    "# pc1 = df1.values[:,11:14]*0.001 #2nd return\n",
    "# print(pc1)\n",
    "fn2 = \"/media/derm/06EF-127D3/Ouster/csv/pcap_out_000321.csv\"\n",
    "df2 = pd.read_csv(fn2, sep=',', skiprows=[0])\n",
    "pc2 = df2.values[:,8:11]*0.001\n",
    "\n",
    "pc1 = pc1[pc1[:,2] > -1.75] #ignore ground plane\n",
    "pc2 = pc2[pc2[:,2] > -1.75] #ignore ground plane\n",
    "\n",
    "# T = np.array([0.124,0.,0.]) #ground truth transform for scans 0,1\n",
    "# pc2 += T\n",
    "# T = np.array([1.577,0.,0.]) #120, 125\n",
    "# rot = R_tf(np.array([0.,0.,-0.133])).numpy()\n",
    "# pc2 = (pc2 + T).dot(rot)\n",
    "T = np.array([0,0.,0.]) #120, 125\n",
    "rot = R_tf(np.array([0.,0.,0.])).numpy()\n",
    "pc2 = (pc2 + T).dot(rot)\n",
    "\n",
    "\n",
    "signal_miss_idx = np.where(pc1 == np.array([0., 0., 0.]))\n",
    "print(np.shape(signal_miss_idx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "# #color by z height\n",
    "# # zheight = (15*(pc1[:,2]+3)) #was this\n",
    "# # cname = np.array([zheight, 80*np.ones(len(zheight)), 80*np.ones(len(zheight))]).T.tolist()\n",
    "# zheight = 100*(np.sin(0.5*pc1[:,2])+1) #test\n",
    "# cname = np.array([zheight, 100*(np.sin(0.5*pc1[:,2]+256)+1), 128*np.ones(len(zheight))]).T.tolist()\n",
    "# print(zheight)\n",
    "# points_object1 = Points(pc1, c = cname, r = 5, alpha = 0.5)\n",
    "# disp.append(points_object1)\n",
    "\n",
    "#constant color\n",
    "disp.append(Points(pc1, c = 'red', r = 2.5, alpha = 1)) \n",
    "disp.append(Points(pc2, c = 'blue', r = 2.5, alpha = 1)) \n",
    "plt2.show(disp, \"Fig Ouster\")\n",
    "ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79800047",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_init = tf.constant([0.5, 0., 0., 0., 0., 0.])\n",
    "it = ICET(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 5, \n",
    "           draw = True, group = 2, RM = False, DNN_filter = False, x0 = x_init)\n",
    "ViewInteractiveWidget(it.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "x_hist = np.loadtxt(\"ouster_ICET_estimates.txt\")\n",
    "pred_stds = np.loadtxt(\"ouster_ICET_pred_stds.txt\")\n",
    "print(pred_stds[0])\n",
    "\n",
    "ax[0].plot(x_hist[:,0])\n",
    "ax[0].plot(x_hist[:,0]+ 2*pred_stds[:,0], c = 'k', ls = '--')\n",
    "ax[0].plot(x_hist[:,0]- 2*pred_stds[:,0], c = 'k', ls = '--')\n",
    "ax[1].plot(x_hist[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in raw PCAP files directly from Ouster Sample dataset\n",
    "#  need to use ouster-sdk (not as good as velodyne)\n",
    "from ouster import pcap\n",
    "from ouster.pcap import _pcap\n",
    "from ouster import client\n",
    "from ouster.client import _client\n",
    "\n",
    "pcap_path = \"/media/derm/06EF-127D3/Ouster/OS-1-128_v2.3.0_1024x10_20220419_160551-000.pcap\"\n",
    "metadata_path = '/media/derm/06EF-127D3/Ouster/OS-1-128_v2.3.0_1024x10_20220419_160551.json'\n",
    "\n",
    "\n",
    "\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = client.SensorInfo(f.read())\n",
    "\n",
    "source = pcap.Pcap(pcap_path, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab8c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pcap_to_csv(source, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "def pcap_to_csv(source: client.PacketSource,\n",
    "                metadata: client.SensorInfo,\n",
    "                num: int = 0,\n",
    "                csv_dir: str = \".\",\n",
    "                csv_base: str = \"pcap_out\",\n",
    "                csv_ext: str = \"csv\") -> None:\n",
    "    \"\"\"Write scans from a pcap to csv files (one per lidar scan).\n",
    "\n",
    "    The number of saved lines per csv file is always H x W, which corresponds to\n",
    "    a full 2D image representation of a lidar scan.\n",
    "\n",
    "    Each line in a csv file is (for LEGACY profile):\n",
    "\n",
    "        TIMESTAMP, RANGE (mm), SIGNAL, NEAR_IR, REFLECTIVITY, X (mm), Y (mm), Z (mm)\n",
    "\n",
    "    If ``csv_ext`` ends in ``.gz``, the file is automatically saved in\n",
    "    compressed gzip format. :func:`.numpy.loadtxt` can be used to read gzipped\n",
    "    files transparently back to :class:`.numpy.ndarray`.\n",
    "\n",
    "    Args:\n",
    "        source: PacketSource from pcap\n",
    "        metadata: associated SensorInfo for PacketSource\n",
    "        num: number of scans to save from pcap to csv files\n",
    "        csv_dir: path to the directory where csv files will be saved\n",
    "        csv_base: string to use as the base of the filename for pcap output\n",
    "        csv_ext: file extension to use, \"csv\" by default\n",
    "    \"\"\"\n",
    "\n",
    "    dual = False\n",
    "    if metadata.format.udp_profile_lidar == client.UDPProfileLidar.PROFILE_LIDAR_RNG19_RFL8_SIG16_NIR16_DUAL:\n",
    "        dual = True\n",
    "        print(\"Note: You've selected to convert a dual returns pcap to CSV. Each row \"\n",
    "              \"will represent a single pixel, so that both returns for that pixel will \"\n",
    "              \"be on a single row. As this is an example we provide for getting \"\n",
    "              \"started, we realize that you may have conversion needs which are not met \"\n",
    "              \"by this function. You can find the source code on the Python SDK \"\n",
    "              \"documentation website to modify it for your own needs.\")\n",
    "\n",
    "    # ensure that base csv_dir exists\n",
    "    if not os.path.exists(csv_dir):\n",
    "        os.makedirs(csv_dir)\n",
    "\n",
    "    # construct csv header and data format\n",
    "    def get_fields_info(scan: client.LidarScan) -> Tuple[str, List[str]]:\n",
    "        field_names = 'TIMESTAMP (ns)'\n",
    "        field_fmts = ['%d']\n",
    "        for chan_field in scan.fields:\n",
    "            field_names += f', {chan_field}'\n",
    "            if chan_field in [client.ChanField.RANGE, client.ChanField.RANGE2]:\n",
    "                field_names += ' (mm)'\n",
    "            field_fmts.append('%d')\n",
    "        field_names += ', X (mm), Y (mm), Z (mm)'\n",
    "        field_fmts.extend(3 * ['%d'])\n",
    "        if dual:\n",
    "            field_names += ', X2 (mm), Y2 (mm), Z2 (mm)'\n",
    "            field_fmts.extend(3 * ['%d'])\n",
    "        return field_names, field_fmts\n",
    "\n",
    "    field_names: str = ''\n",
    "    field_fmts: List[str] = []\n",
    "\n",
    "    # [doc-stag-pcap-to-csv]\n",
    "    from itertools import islice\n",
    "    # precompute xyzlut to save computation in a loop\n",
    "    xyzlut = client.XYZLut(metadata)\n",
    "\n",
    "    # create an iterator of LidarScans from pcap and bound it if num is specified\n",
    "    scans = iter(client.Scans(source))\n",
    "    if num:\n",
    "        scans = islice(scans, num)\n",
    "\n",
    "    for idx, scan in enumerate(scans):\n",
    "\n",
    "        # initialize the field names for csv header\n",
    "        if not field_names or not field_fmts:\n",
    "            field_names, field_fmts = get_fields_info(scan)\n",
    "\n",
    "        # copy per-column timestamps for each channel\n",
    "        timestamps = np.tile(scan.timestamp, (scan.h, 1))\n",
    "\n",
    "        # grab channel data\n",
    "        fields_values = [scan.field(ch) for ch in scan.fields]\n",
    "\n",
    "        # use integer mm to avoid loss of precision casting timestamps\n",
    "        xyz = (xyzlut(scan.field(client.ChanField.RANGE)) * 1000).astype(\n",
    "            np.int64)\n",
    "\n",
    "        if dual:\n",
    "            xyz2 = (xyzlut(scan.field(client.ChanField.RANGE2)) * 1000).astype(\n",
    "                np.int64)\n",
    "\n",
    "            # get all data as one H x W x num fields int64 array for savetxt()\n",
    "            frame = np.dstack((timestamps, *fields_values, xyz, xyz2))\n",
    "\n",
    "        else:\n",
    "            # get all data as one H x W x num fields int64 array for savetxt()\n",
    "            frame = np.dstack((timestamps, *fields_values, xyz))\n",
    "\n",
    "        # not necessary, but output points in \"image\" vs. staggered order\n",
    "        frame = client.destagger(metadata, frame)\n",
    "\n",
    "        # write csv out to file\n",
    "        csv_path = os.path.join(csv_dir, f'{csv_base}_{idx:06d}.{csv_ext}')\n",
    "        print(f'write frame #{idx}, to file: {csv_path}')\n",
    "\n",
    "        header = '\\n'.join([f'frame num: {idx}', field_names])\n",
    "\n",
    "        np.savetxt(csv_path,\n",
    "                   frame.reshape(-1, frame.shape[2]),\n",
    "                   fmt=field_fmts,\n",
    "                   delimiter=',',\n",
    "                   header=header)\n",
    "\n",
    "    # [doc-etag-pcap-to-csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_proj(metadata: client.SensorInfo,\n",
    "             scan: client.LidarScan) -> np.ndarray:\n",
    "    \"\"\"Computes a point cloud from a scan as numpy array.\n",
    "\n",
    "    This is a reference implementation that follows the calculations from\n",
    "    `Section 3.1.2`_ of the Software User Manual exactly. Output is a point\n",
    "    cloud in the *sensor frame* with points arranged in column-major order,\n",
    "    with coordinates in meters.\n",
    "\n",
    "    Args:\n",
    "        metadata: Sensor metadata associated with the scan\n",
    "        scan: A frame of lidar data\n",
    "\n",
    "    Returns:\n",
    "        A H x W x 3 array of point coordinates\n",
    "\n",
    "    .. _Section 3.1.2: https://data.ouster.io/downloads/software-user-manual/software-user-manual-v2p0.pdf#a\n",
    "    \"\"\"\n",
    "#     https://static.ouster.dev/sdk-docs/_modules/ouster/sdk/examples/reference.html#xyz_proj\n",
    "\n",
    "    # use homogeneous coordinates for convenient transformation\n",
    "    xyz = np.zeros((scan.w * scan.h, 4))\n",
    "\n",
    "    # iterate over each measurement channel/row and measurement block/column\n",
    "    for u, v in product(range(scan.h), range(scan.w)):\n",
    "\n",
    "        r = scan.field(client.ChanField.RANGE)[u, v]\n",
    "        n = metadata.lidar_origin_to_beam_origin_mm\n",
    "\n",
    "        # scans are always a full frame, so the measurement id is also the index\n",
    "        assert scan.measurement_id[v] == v\n",
    "\n",
    "        theta_encoder = 2.0 * pi * (1.0 - v / scan.w)\n",
    "        theta_azimuth = -2.0 * pi * (metadata.beam_azimuth_angles[u] / 360.0)\n",
    "        phi = 2.0 * pi * (metadata.beam_altitude_angles[u] / 360.0)\n",
    "\n",
    "        # zero ranges represent no return; avoid applying offsets to these\n",
    "        if r == 0.0:\n",
    "            continue\n",
    "\n",
    "        # compute point coordinates in the lidar frame\n",
    "        x = (r - n) * cos(theta_encoder +\n",
    "                          theta_azimuth) * cos(phi) + n * cos(theta_encoder)\n",
    "        y = (r - n) * sin(theta_encoder +\n",
    "                          theta_azimuth) * cos(phi) + n * sin(theta_encoder)\n",
    "        z = (r - n) * sin(phi)\n",
    "\n",
    "        # insert into xyz; point order is row-major to match input scan\n",
    "        xyz[u * scan.w + v] = [x, y, z, 1]\n",
    "\n",
    "    # transform from lidar to sensor frame and scale to meters\n",
    "    xyz_sensor = xyz @ metadata.lidar_to_sensor_transform.T\n",
    "    return xyz_sensor[:, :3].reshape(scan.h, scan.w, 3) * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suggested method of reading pcap files Ouster unit\n",
    "for packet in source:\n",
    "    if isinstance(packet, client.LidarPacket):\n",
    "        # Now we can process the LidarPacket. In this case, we access\n",
    "        # the measurement ids, timestamps, and ranges\n",
    "        measurement_ids = packet.measurement_id\n",
    "        timestamps = packet.timestamp\n",
    "        ranges = packet.field(client.ChanField.RANGE)\n",
    "        print(f'  encoder counts = {measurement_ids.shape}')\n",
    "        print(f'  timestamps = {timestamps.shape}')\n",
    "        print(f'  ranges = {ranges.shape}')\n",
    "\n",
    "    elif isinstance(packet, client.ImuPacket):\n",
    "        # and access ImuPacket content\n",
    "        print(f'  acceleration = {packet.accel}')\n",
    "        print(f'  angular_velocity = {packet.angular_vel}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ab77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for packet in source:\n",
    "#     print(packet)\n",
    "    if isinstance(packet, client.LidarPacket):\n",
    "        test = packet\n",
    "        print(\"Done\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "fn1 = prefix + '%08d.pkl' %(idx)\n",
    "print(fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae037e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
