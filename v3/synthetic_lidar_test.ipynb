{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KITTI-CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ground truth transformation\n",
    "fpl = np.loadtxt(\"/home/derm/KITTICARLA/dataset/Town01/generated/full_poses_lidar.txt\") #full poses lidar\n",
    "print(np.shape(fpl))\n",
    "\n",
    "#plot pose at arbitrary point in drive NEED TO MULTIPLY THIS BY 100??!\n",
    "idx = 1900 #1050 for town1\n",
    "\n",
    "#create rotation vector\n",
    "R = np.array([[fpl[:,0], fpl[:,1], fpl[:,2]],\n",
    "              [fpl[:,4], fpl[:,5], fpl[:,6]],\n",
    "              [fpl[:,8], fpl[:,9], fpl[:,10]]]).T\n",
    "# R = np.transpose(R, (0,2,1))\n",
    "# print(np.shape(R))\n",
    "# print(R[-3])\n",
    "\n",
    "angs = R2Euler(R) #convert to euler angles (for use with ICET)\n",
    "# print(angs.T)\n",
    "\n",
    "T = np.array([fpl[:,3], fpl[:,7], fpl[:,11]]).T #get translation vector\n",
    "print(T[idx*100])\n",
    "\n",
    "#plot results\n",
    "fig, ax = plt.subplots(3,1)\n",
    "ax[0].plot(T[:,0], T[:,1])\n",
    "ax[0].plot(T[idx*100,0], T[idx*100,1], 'rx')\n",
    "ax[0].set_aspect(\"equal\")\n",
    "ax[0].set_title(\"ENU trajectory\")\n",
    "\n",
    "ax[1].set_title(\"yaw angle (rad)\")\n",
    "ax[1].plot(angs[2,:])\n",
    "ax[1].plot(idx*100, angs[2,idx*100], 'rx')\n",
    "\n",
    "#TODO: get change in angles between subsequent transformations, fixangs greater than 2pi\n",
    "vel = np.diff(T.T)\n",
    "print(np.shape(vel))\n",
    "ax[2].set_title(\"vel\")\n",
    "ax[2].plot(np.sqrt(vel[0,:]**2 + vel[1,:]**2))\n",
    "ax[2].plot(idx*100, vel[0,idx*100], 'rx')\n",
    "\n",
    "#sanity check for consistant timesteps...\n",
    "# dt = np.diff(fpl[:,12])\n",
    "# bad = dt[abs(dt[:] - 0.001) > 0.00001]\n",
    "# print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "skip = 5\n",
    "noise_scale = 0.01\n",
    "plt1 = Plotter(N = 1, axes = 7, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "s1_fn = '/home/derm/KITTICARLA/dataset/Town01/generated/frames/frame_%04d.ply' %(idx)\n",
    "s2_fn = '/home/derm/KITTICARLA/dataset/Town01/generated/frames/frame_%04d.ply' %(idx+skip)\n",
    "\n",
    "dat1 = trimesh.load(s1_fn)\n",
    "dat2 = trimesh.load(s2_fn)\n",
    "\n",
    "c1 = dat1.vertices\n",
    "# c1 += true_traj[(idx)*100]\n",
    "c1 = c1[c1[:,2] > -1.5]\n",
    "c1 = c1.dot(R[(idx)*100])\n",
    "# mesh = Mesh(dat1).c(\"gray\").alpha(1) #draw ignored points on ground plane\n",
    "# disp.append(mesh)\n",
    "\n",
    "c2 = dat2.vertices\n",
    "# c2 += true_traj[(idx+skip)*100]\n",
    "c2 = c2[c2[:,2] > -1.5] #ground + sidewalk\n",
    "c2 = c2.dot(R[(idx+skip)*100])\n",
    "# c2 = c2 + (vel[:,(idx+skip)*100] + vel[:,(idx)*100])*50*(skip) #transform c2 to overlay with c1 #was this\n",
    "# correction = np.sum(vel[:,((idx-1)*100):((idx-1+skip)*100)], axis = 1) #test1\n",
    "# c2 = c2 + correction\n",
    "# print(correction)\n",
    "\n",
    "\n",
    "#display overal trajectory via \"poses_lidar.ply\" ~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "fn = \"/home/derm/KITTICARLA/dataset/Town01/generated/poses_lidar.ply\"\n",
    "datposes = trimesh.load(fn)\n",
    "true_traj = datposes.vertices\n",
    "# print(true_traj)\n",
    "disp.append(Points(true_traj - [0, 0, 1.65], alpha = 0.3))\n",
    "\n",
    "#true location (for viz)\n",
    "c1 += true_traj[(idx)*100]\n",
    "c2 += true_traj[(idx+skip)*100]\n",
    "#center at 0 (for training data)\n",
    "# c2 += true_traj[(idx+skip)*100] - true_traj[(idx)*100]\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "c1 += noise_scale*np.random.randn(np.shape(c1)[0],3)\n",
    "c2 += noise_scale*np.random.randn(np.shape(c2)[0],3)\n",
    "\n",
    "disp.append(Points(c1, c = 'red', r = 2))\n",
    "disp.append(Points(c2, c = 'blue', r = 2))\n",
    "\n",
    "disp.append(Points(np.array([[0.,0.,0.]]), c = 'purple', r =10))\n",
    "plt1.show(disp, \"surface sampling test\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2Euler(mat):\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms3d.euler import mat2euler, euler2mat\n",
    "print(euler2mat(0,0,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/TIERS/forest01_optitrack.csv'\n",
    "# filename = 'C:/TIERS/forest02_optitrack.csv'\n",
    "\n",
    "data = np.loadtxt(filename, delimiter=\",\", usecols = range(11))\n",
    "# [timestamp, pose.position.x,  pose.position.y,  pose.position.z, \n",
    "#   roll, pitch, yaw, pose.orientation.x, pose.orientation.y, pose.orientation.z, \n",
    "#   pose.orientation.w ]\n",
    "\n",
    "# print(np.diff(data, axis = 0))\n",
    "gt = data[:,1:4]\n",
    "# print(gt)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gt[:,0], gt[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODD\n",
    "import h5py\n",
    "\n",
    "# filename = 'C:/CODD/data/m1v7p7s769.hdf5'\n",
    "# filename = 'C:/CODD/data/m5v10p6s31.hdf5' #turn on country road\n",
    "# filename = 'C:/CODD/data/m2v7p3s333.hdf5' #complex geometries\n",
    "filename = 'C:/CODD/data/m10v11p6s30.hdf5' #wide road, traffic and palm trees\n",
    "\n",
    "vidx = 0\n",
    "\n",
    "with h5py.File(filename, 'r') as hf:\n",
    "#     pcls = hf['point_cloud'][:]\n",
    "    #[frames, vehicles, points_per_cloud, 4]\n",
    "    pcls = hf['point_cloud'][:, vidx ,: , :3]\n",
    "    #[frames, points_per_cloud, rgb]\n",
    "    \n",
    "#     pose = hf['lidar_pose'][:]\n",
    "    #[frames, vehicles, (x,y,z, rotx, roty, rotz)]\n",
    "    pose = hf['lidar_pose'][:, vidx, :]\n",
    "    \n",
    "    vbb = hf['vehicle_boundingbox'][:, vidx, :]\n",
    "    \n",
    "print(np.shape(pcls))\n",
    "print(np.shape(pose))\n",
    "print(np.shape(vbb))\n",
    "\n",
    "#these are the same\n",
    "# print(pose[1,:])\n",
    "# print(vbb[1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "component = 0 #fwd translation \n",
    "# component = 5 #yaw\n",
    "\n",
    "vel = np.diff(pose, axis = 0)\n",
    "\n",
    "vf = np.sqrt(vel[:,0]**2 + vel[:,1]**2 ) # if plotting forward translation\n",
    "# vf = vel[:,4]#*np.pi/180 #for yaw\n",
    "\n",
    "# #test\n",
    "# component = 3\n",
    "# vf = -vel[:,5] \n",
    "# vf = vf*0\n",
    "# vf = vel[:,2]\n",
    "\n",
    "ax[0].plot(vf, label = 'Ground Truth Translation')\n",
    "# ax.plot(np.diff(pose, axis = 0)[:,4])  \n",
    "# ax.scatter(pose[:,0], pose[:,1])  \n",
    "print(np.shape(vf))\n",
    "\n",
    "estimates = np.loadtxt('ICET_estimates_CODD_v6.txt') #123\n",
    "pred_stds = np.loadtxt('ICET_pred_stds_CODD_v6.txt')\n",
    "estimates[:,3:] = estimates[:,3:]*180/np.pi \n",
    "pred_stds[:,3:] = pred_stds[:,3:]*180/np.pi \n",
    "\n",
    "# estimates = np.loadtxt('ICET_estimates_CODD_v4.txt') #20\n",
    "# pred_stds = np.loadtxt('ICET_pred_stds_CODD_v4.txt')\n",
    "# vf = vf[:23]\n",
    "\n",
    "# print(estimates[:,0])\n",
    "ax[0].plot(estimates[:,component], label = \"ICET Estimated Translation\")\n",
    "# ax[0].plot(estimates[:,0] + pred_stds[:,0], color = [0,0,0], alpha = 0.1)\n",
    "# ax[0].plot(estimates[:,0] - pred_stds[:,0], color = [0,0,0], alpha = 0.1)\n",
    "ax[0].fill_between(np.linspace(0,123,124), \n",
    "                   vf - 2*pred_stds[:,component], vf + 2*pred_stds[:,component], \n",
    "                   color = [0,0,0], alpha = 0.2, label = 'Predicted 2Ïƒ Error Bound')\n",
    "ax[0].set_xlabel(\"frame\")\n",
    "ax[0].set_ylabel(\"forward translation per frame (m)\")\n",
    "# ax[0].set_ylabel(\"change in yaw per frame (deg)\")\n",
    "ax[0].legend(loc = 'lower right')\n",
    "# ax[0].set_tile(\"Simple Outlier Rejection\")\n",
    "\n",
    "ferr = vf - estimates[:,0]\n",
    "# ax[1].plot(abs(ferr))\n",
    "# ax[1].plot(pred_stds[:,0])\n",
    "ax[1].scatter(abs(ferr), pred_stds[:,0])\n",
    "ax[1].set_xlabel(\"forward errror (m)\")\n",
    "ax[1].set_ylabel(\"predicted standard deviation of errror (m)\")\n",
    "ax[1].set_title(\"Predicted vs Actual std of error in CODD dataset\")\n",
    "\n",
    "#correlation between higher predicted std of error and actual higher std of error\n",
    "print(\"correlation: \\n\", np.corrcoef(abs(ferr), pred_stds[:,0]))\n",
    "# print(np.sum(ferr))\n",
    "# print(np.sum(vf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot absolute trajectory\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "true_cum = np.cumsum(vf)\n",
    "ax2.plot(true_cum)\n",
    "\n",
    "est_cum = np.cumsum(estimates[:,5])\n",
    "ax2.plot(est_cum)\n",
    "\n",
    "print(est_cum, true_cum)\n",
    "\n",
    "# ax2.plot(vf)\n",
    "# ax2.plot(estimates[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aiodrive - CMU RI\n",
    "import pandas as pd\n",
    "# test = pd.read_pickle(r'C:/aiodrive/control/000000.pkl')\n",
    "# print(test[0])\n",
    "# print(len(test))\n",
    "test = pd.read_pickle(r'C:/aiodrive/velocorr/000000.pkl')\n",
    "print(test[0])\n",
    "# print(test[10])\n",
    "# dat = open(r'C:/aiodrive/lidar_velodyne/000001.bin').read_bytes()\n",
    "# print(dat)\n",
    "gps_i = np.loadtxt('C:/aiodrive/gps/000000.txt')\n",
    "print(gps_i)\n",
    "gps_i = np.loadtxt('C:/aiodrive/gps/000001.txt')\n",
    "print(gps_i)\n",
    "gps_i = np.loadtxt('C:/aiodrive/gps/000002.txt')\n",
    "print(gps_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SynLiDAR\n",
    "import glob\n",
    "\n",
    "def read_points(path):\n",
    "    scan = np.fromfile(path, dtype=np.float32)\n",
    "    scan = scan.reshape((-1, 4))  # [x,y,z,intensity]\n",
    "    return scan\n",
    "\n",
    "def read_label(path):\n",
    "    label = np.fromfile(path, dtype=np.uint32)\n",
    "    label = label.reshape((-1))\n",
    "    return label\n",
    "\n",
    "f_path = \"C:/SynLiDAR/01/velodyne/000007.bin\"\n",
    "\n",
    "scan = read_points(f_path)\n",
    "# print(np.shape(scan))\n",
    "\n",
    "label_path = f_path.replace('velodyne', 'labels').replace('bin', 'label')\n",
    "labels = read_label(label_path)\n",
    "\n",
    "assert scan.shape[0] == labels.shape[0]\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
