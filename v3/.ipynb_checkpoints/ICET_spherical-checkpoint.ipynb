{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.31410828 -0.00153609  0.09991124 -0.00620458  0.00421205  0.01244162], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.33431602  0.00695762  0.05746645 -0.00567841  0.00349628  0.0138566 ], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34085846 -0.0063442   0.02839667 -0.00417265  0.0029643   0.01407214], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34080637 -0.0074435   0.00955635 -0.00288681  0.00245076  0.01413573], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3411951  -0.00805545  0.00306188 -0.00260942  0.0022355   0.01418984], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3427948  -0.0112745   0.00202577 -0.00269312  0.00242362  0.01419091], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3434888  -0.01408371 -0.00178519 -0.00258752  0.00253043  0.01416827], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34443748 -0.01737556 -0.00741063 -0.00240817  0.00275299  0.01412222], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3443934  -0.01725774 -0.01102356 -0.00249238  0.00346886  0.01409075], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34454763 -0.01723238 -0.01242729 -0.00250928  0.00391234  0.01406707], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34471405 -0.01745864 -0.0128724  -0.00251829  0.00404155  0.01406602], shape=(6,), dtype=float32)\n",
      "\n",
      " ---identified moving objects---\n",
      "pred_stds: \n",
      " tf.Tensor([0.00165539 0.00200249 0.00698845 0.00086046 0.00049221 0.00012146], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from ICET_spherical import ICET\n",
    "\n",
    "# init KITTI dataset -----------------------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "idx = 0\n",
    "# drive = '0093'\n",
    "# idx = 220\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(idx) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "c1 = velo1[:,:3]\n",
    "c1 = c1[c1[:,2] > -1.5] #ignore ground plane\n",
    "velo2 = dataset.get_velo(idx+1) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "c2 = velo2[:,:3]\n",
    "c2 = c2[c2[:,2] > -1.5] #ignore ground plane\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# ## load custom point cloud geneated in matlab------------------------------------------\n",
    "# c1 = np.loadtxt(\"scene1_scan1.txt\", dtype = float)\n",
    "# # c2 = c1 + np.array([2.0, 0.2, 0])\n",
    "# c2 = c1 + np.array([0.1, 0., 0.])\n",
    "\n",
    "# # c1 = c1[c1[:,2] > -1.5] #ignore ground plane\n",
    "# # c2 = c2[c2[:,2] > -1.5] #ignore ground plane\n",
    "# ## ------------------------------------------------------------------------------------\n",
    "\n",
    "# #single distinct cluster---------------------------------------------------------------\n",
    "# c1 = np.random.randn(3000,3)*tf.constant([0.04,0.3,0.3]) + tf.constant([6.,0.,0.])\n",
    "# c2 = np.random.randn(3000,3)*tf.constant([0.04,0.3,0.3]) + tf.constant([6.,0.,0.]) - np.array([0., 0.25, 0.0])\n",
    "# # # c2 = c1 - np.array([0.1, 0.3, 0.0])\n",
    "# # -------------------------------------------------------------------------------------\n",
    "\n",
    "# D = True\n",
    "D = False\n",
    "X = tf.constant([0., 0., 0., 0., 0., 0.])\n",
    "it1 = ICET(cloud1 = c1, cloud2 = c2,  fid = 50, draw = False, x0 = X, niter = 12, group= 2, RM = True)\n",
    "# it2 = ICET(cloud1 = it1.cloud1_static, cloud2 = c2, fid = 50, niter = 20, draw = True, group = 2, RM = False)\n",
    "\n",
    "if D:\n",
    "    ViewInteractiveWidget(it2.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015AA5A2FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015AA5A2FE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([-0.02386692  0.00629028 -0.00421011], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process points from ICET to feed to DNN\n",
    "\n",
    "#Get ragged tensor containing all points from each scan inside each sufficient voxel\n",
    "in1 = it1.inside1\n",
    "npts1 = it1.npts1\n",
    "in2 = it1.inside2\n",
    "npts2 = it1.npts2\n",
    "corr = it1.corr #indices of bins that have enough points from scan1 and scan2\n",
    "\n",
    "# print(tf.shape(in2.to_tensor()))\n",
    "\n",
    "#get indices of rag with >= 25 elements\n",
    "ncells = tf.shape(corr)[0].numpy() #num of voxels with sufficent number of points\n",
    "# print(tf.gather(npts2, corr))\n",
    "enough1 = tf.gather(in1, corr)\n",
    "enough2 = tf.gather(in2, corr)\n",
    "print(tf.shape(enough2.to_tensor())[0].numpy())\n",
    "# print(npts2)\n",
    "# print(corr)\n",
    "\n",
    "#init array to store indices\n",
    "idx1 = np.zeros([ncells ,25])\n",
    "idx2 = np.zeros([ncells ,25])\n",
    "\n",
    "#loop through each element of ragged tensor\n",
    "for i in range(ncells):\n",
    "    idx1[i,:] = tf.random.shuffle(enough1[i])[:25].numpy() #shuffle order and take first 25 elements\n",
    "    idx2[i,:] = tf.random.shuffle(enough2[i])[:25].numpy() #shuffle order and take first 25 elements\n",
    "\n",
    "idx1 = tf.cast(tf.convert_to_tensor(idx1), tf.int32)\n",
    "idx2 = tf.cast(tf.convert_to_tensor(idx2), tf.int32)\n",
    "\n",
    "# print(it1.cloud1_tensor)\n",
    "from1 = tf.gather(it1.cloud1_tensor, idx1)\n",
    "# from2 = tf.gather(it1.cloud2_tensor_OG, idx2)\n",
    "from2 = tf.gather(it1.cloud2_tensor, idx2)\n",
    "# print(from1)\n",
    "\n",
    "x_test = tf.concat((from1, from2), axis = 1)\n",
    "# np.savetxt('perspective_shift/ICET_KITTI_frame0.txt', tf.reshape(from1, [-1, 3]).numpy())\n",
    "# np.savetxt('perspective_shift/ICET_KITTI_frame1.txt', tf.reshape(from2, [-1, 3]).numpy())\n",
    "\n",
    "model = tf.keras.models.load_model(\"perspective_shift/KITTInet.kmod\")\n",
    "from_DNN = model.predict(x_test)\n",
    "# print(from_DNN)\n",
    "# print(np.shape(from_DNN))\n",
    "print(tf.math.reduce_mean(from_DNN, axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0.05482213 -0.1017012   0.06880612], shape=(3,), dtype=float32)\n",
      "tf.Tensor([ 0.01979446  0.00055659 -0.04462598], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 3.52298431e-02 -1.02506220e-01  1.09857924e-01]\n",
      " [ 4.30989303e-02  4.57911491e-02  4.35838103e-02]\n",
      " [ 5.02229780e-02 -1.50410831e-03 -7.54863471e-02]\n",
      " [ 9.62308701e-03  7.29096904e-02  1.67206917e-02]\n",
      " [-2.64909118e-04 -8.56456161e-02  2.23617256e-03]\n",
      " [-1.39686853e-01  5.63878566e-03  2.29388922e-02]\n",
      " [-1.55692212e-02  1.21321119e-01 -3.05570476e-03]\n",
      " [-6.67665377e-02  4.98737469e-02 -2.56096292e-03]\n",
      " [-7.30866119e-02  5.65661490e-02  1.27329621e-02]\n",
      " [-8.09199456e-03 -2.80454941e-03 -5.53010125e-03]\n",
      " [ 9.58209857e-04  5.37143722e-02  1.26236565e-02]\n",
      " [-1.84007846e-02  4.95290309e-02 -1.66862845e-01]\n",
      " [ 3.39099839e-02  1.64972544e-02 -1.45345125e-02]\n",
      " [ 3.71243060e-02  1.47517443e-01 -2.13619843e-02]\n",
      " [ 2.53607389e-02 -2.68967561e-02  3.58064175e-02]\n",
      " [ 1.49561707e-02  2.16856953e-02 -5.25067262e-02]\n",
      " [ 1.07891284e-01 -2.31563859e-03 -5.46252877e-02]\n",
      " [ 2.12103754e-01 -4.09865916e-01 -2.66802143e-02]\n",
      " [-6.58834353e-02  1.16082914e-01 -5.80850914e-02]\n",
      " [ 6.47154003e-02  6.25984371e-02  6.59504905e-03]\n",
      " [-1.52361602e-01  8.65029171e-03 -7.25224987e-03]\n",
      " [ 3.09034079e-01 -3.49287763e-02 -7.90654495e-03]\n",
      " [-4.48118895e-04 -5.05222306e-02  2.90898755e-02]\n",
      " [-1.51384175e-01  4.63446751e-02  5.12209199e-02]\n",
      " [-1.51650086e-02  1.32935280e-02 -1.96441002e-02]\n",
      " [-1.83731467e-02 -3.48253585e-02  1.79151725e-03]\n",
      " [-1.76901683e-01  4.58318479e-02  3.09163518e-02]\n",
      " [-6.07159510e-02 -4.20267321e-02  7.31911324e-03]\n",
      " [-8.65333825e-02  5.51697798e-03 -4.65551317e-02]\n",
      " [ 2.29309872e-02  5.54452315e-02  5.81657775e-02]\n",
      " [ 2.73484319e-01  1.08843729e-01 -1.85294598e-01]\n",
      " [ 8.14632699e-03  3.56526047e-01  1.05209298e-01]\n",
      " [ 1.32796988e-01 -4.30528931e-02  5.58952875e-02]\n",
      " [ 1.71020553e-01  5.09165585e-01  1.34473994e-01]\n",
      " [-2.54368752e-01 -3.42587680e-02  1.34204060e-01]\n",
      " [-9.11398977e-02 -1.64647400e-03 -1.36012863e-02]\n",
      " [ 1.19589344e-01 -1.13506898e-01  9.38030928e-02]\n",
      " [-4.66852002e-02  2.84857042e-02 -2.32794285e-02]\n",
      " [-5.25895730e-02  1.06746145e-02  2.21068375e-02]\n",
      " [-2.79955208e-01 -2.10717708e-01 -1.15311161e-01]\n",
      " [ 8.63793045e-02  5.65440804e-02 -3.04760449e-02]\n",
      " [ 1.12076424e-01 -5.77345602e-02  5.57535663e-02]\n",
      " [-1.78788677e-02 -2.37035990e-01 -6.56582415e-02]\n",
      " [-1.04344398e-01  7.12894183e-03 -3.13822404e-02]\n",
      " [-7.61951357e-02 -4.47829068e-02  5.38640395e-02]\n",
      " [ 2.45378375e-01  2.79694080e-01 -1.88867580e-02]\n",
      " [-5.26546463e-02  8.20400193e-03 -5.24849743e-02]\n",
      " [ 2.56086528e-01  6.04632869e-02 -4.75337915e-03]\n",
      " [-7.73902237e-02  1.00598007e-01  1.63410008e-02]\n",
      " [-6.54984832e-01  8.73161554e-02  3.34869549e-02]\n",
      " [ 7.85364434e-02 -1.07837662e-01 -6.73804581e-02]\n",
      " [-8.43801424e-02  9.61496606e-02  5.06375059e-02]\n",
      " [-5.54739079e-03  4.33951057e-02  5.64453751e-02]\n",
      " [-3.42777252e-01  1.35207459e-01 -6.52594119e-02]\n",
      " [-6.00144744e-01 -2.32419968e-02 -3.17430729e-03]\n",
      " [ 2.70450562e-02  1.65801898e-01  4.26483899e-03]\n",
      " [-1.36825487e-01  8.14648867e-02 -3.33331786e-02]\n",
      " [-5.67754507e-01 -5.92588782e-01  3.75341773e-02]\n",
      " [-7.25667477e-02 -1.51059106e-02 -1.70458555e-01]\n",
      " [ 1.76426262e-01  2.36933842e-01 -8.50552097e-02]\n",
      " [-1.28789961e-01  1.35468677e-01 -3.81103866e-02]\n",
      " [-3.20912838e-01  8.14385861e-02 -1.34159066e-02]\n",
      " [-2.17036903e-01  1.01807579e-01  8.11497495e-03]\n",
      " [ 3.07614058e-01 -7.88619295e-02  8.95168409e-02]\n",
      " [-4.81926441e-01 -1.25319600e-01  6.80248663e-02]\n",
      " [-1.45975605e-01  4.07779738e-02  1.35371899e-02]\n",
      " [ 1.45554096e-01  2.06319895e-03  3.80216204e-02]\n",
      " [ 4.42430750e-02 -1.24853671e-01  5.32329865e-02]\n",
      " [ 8.79675299e-02  1.37032762e-01  6.72589689e-02]\n",
      " [-5.94258681e-02 -2.84217000e-02  9.79468878e-03]\n",
      " [ 6.24406300e-02  5.83151542e-03  4.26113382e-02]\n",
      " [-2.39645448e-02  4.13252302e-02  5.46151511e-02]\n",
      " [-1.09467536e-01  1.51312649e-02 -8.67788792e-02]\n",
      " [ 3.06359172e-01  2.95747574e-02  3.18763740e-02]\n",
      " [-9.97405797e-02 -1.22928157e-01 -5.59009910e-02]\n",
      " [ 2.17289880e-01  1.50905505e-01 -1.08775549e-01]\n",
      " [-4.56164837e-01  4.09353040e-02 -1.03435116e-02]\n",
      " [-3.22134435e-01  7.19691217e-02  8.67460221e-02]\n",
      " [-2.89544284e-01 -2.20484063e-02  1.21655576e-01]\n",
      " [-6.17505535e-02  9.01086815e-03  1.11621115e-02]\n",
      " [-5.16221952e-03  2.56210193e-02 -1.60122178e-02]\n",
      " [-2.47524958e-03 -2.69963481e-02 -4.67846580e-02]\n",
      " [ 9.06023085e-02 -9.97095183e-03  1.64417159e-02]\n",
      " [-4.21105176e-02 -7.26472065e-02 -3.39271091e-02]\n",
      " [ 1.48150744e-03 -2.58114338e-02 -2.58611739e-02]\n",
      " [-9.92532969e-02 -7.08792582e-02  1.09679308e-02]\n",
      " [-2.52900068e-02  7.89892823e-02 -5.29559217e-02]\n",
      " [ 2.93206070e-02  3.65337580e-02  3.01384777e-02]\n",
      " [ 1.48277998e-01  4.70225513e-02  1.35833127e-02]\n",
      " [ 4.42317098e-01  9.26052481e-02  4.17589210e-03]\n",
      " [-9.61307064e-03  5.34869134e-02 -1.96167119e-02]\n",
      " [ 1.49242263e-02 -1.39829367e-02  1.44663574e-02]\n",
      " [-2.71872338e-02 -5.32588968e-03 -4.30106185e-03]\n",
      " [-1.57730076e-02  1.09189004e-02 -4.77278158e-02]\n",
      " [-1.23765916e-02 -3.19305025e-02  1.61222238e-02]\n",
      " [ 3.40772048e-02 -1.88228358e-02 -1.45527143e-02]\n",
      " [ 1.66944750e-02 -6.31506890e-02  9.51988436e-03]], shape=(97, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#compare per cell translation estimates between ICET and DNN on converged results\n",
    "dnnsoln = tf.convert_to_tensor(from_DNN)\n",
    "# n = 0 #cell idx\n",
    "# print(dnnsoln[n])\n",
    "# print(it1.residuals[n])\n",
    "print(dnnsoln - icetsoln)\n",
    "\n",
    "# print(tf.math.reduce_mean(it1.residuals, axis = 0))\n",
    "# print(tf.math.reduce_mean(dnnsoln, axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify outlier cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "nbins = 25\n",
    "nstd = 2\n",
    "\n",
    "# print(it.dx_i[:,0])\n",
    "# print(tf.math.reduce_sum(it.dx_i, axis = 0))\n",
    "# print(it.W)\n",
    "# print(it.H)\n",
    "# print(it.residuals[:,0])\n",
    "\n",
    "component = it1.residuals_full[:,1]\n",
    "print(tf.shape(component))\n",
    "# print(component)\n",
    "\n",
    "print(\"\\n before:\")\n",
    "mu = tf.math.reduce_mean(component)\n",
    "print(\"mean\", mu)\n",
    "sigma = tf.math.reduce_std(component)\n",
    "print(\"standard deviation\", sigma)\n",
    "bad_idx = tf.where( tf.math.abs(component) > mu + nstd*sigma )\n",
    "# print(\"bad idx\", bad_idx)\n",
    "good_idx = tf.where( tf.math.abs(component) < mu + nstd*sigma )\n",
    "# print(tf.gather(component, bad_idx))\n",
    "# ax.hist(it.dx_i[:,0], nbins);\n",
    "ax[0].hist(component, nbins);\n",
    "ax[0].set_xlabel(\"y_i - y0_i (forward translation error)\")\n",
    "ax[0].set_ylabel(\"frequency\")\n",
    "ax[0].set_title(\"All Distributions\")\n",
    "\n",
    "#test to make sure outliers are being removed correctly\n",
    "component = it1.residuals[:,1]\n",
    "print(tf.shape(component))\n",
    "# print(component)\n",
    "\n",
    "print(\"\\n after:\")\n",
    "mu = tf.math.reduce_mean(component)\n",
    "print(\"mean\", mu)\n",
    "sigma = tf.math.reduce_std(component)\n",
    "print(\"standard deviation\", sigma)\n",
    "\n",
    "ax[1].hist(component, nbins);\n",
    "ax[1].set_xlabel(\"y_i - y0_i (forward translation error)\")\n",
    "ax[1].set_ylabel(\"frequency\")\n",
    "ax[1].set_title(\"Best Fitting Distributions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "# print(it.residuals_full[:,0])\n",
    "edges = tf.linspace(-1.,1.,30)\n",
    "# print(edges)\n",
    "print(edges)\n",
    "\n",
    "bins_soln = tfp.stats.find_bins(it.residuals_full[:,0], edges)\n",
    "# print(bins_soln)\n",
    "\n",
    "good_idx = tf.where(bins_soln == 14)\n",
    "bad_idx = tf.where(bins_soln == 14)\n",
    "# print(bad_idx)\n",
    "# print(good_idx)\n",
    "# print(tf.gather(it.residuals_full[:,0], good_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[5, 6, 7, 8]])\n",
    "b = tf.constant([[8, 7, 10]])\n",
    "print(tf.sets.difference(a,b).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Useful Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import get_cluster\n",
    "\n",
    "#index of spike that each of the points from cloud 1 is occupying\n",
    "print(it.bins_spike)\n",
    "\n",
    "occupied_spikes, idxs = tf.unique(it.bins_spike)\n",
    "print(\"\\n occupied_spikes \\n\", occupied_spikes)\n",
    "temp =  tf.where(it.bins_spike == occupied_spikes[:,None])\n",
    "rag = tf.RaggedTensor.from_value_rowids(temp[:,1], temp[:,0])\n",
    "idx_by_rag = tf.gather(it.cloud1_tensor_spherical[:,0], rag)\n",
    "\n",
    "# rads = idx_by_rag[50,:] #single element from ragged tensor\n",
    "rads = tf.transpose(idx_by_rag.to_tensor()[:3,:])\n",
    "# rads = tf.transpose(idx_by_rag.to_tensor())\n",
    "# print(rads) #starts out unordered\n",
    "\n",
    "# #_________________________________________________________________\n",
    "fig, ax = plt.subplots(2,1)\n",
    "nbins = 25\n",
    "ax[0].hist(rads.numpy(), nbins, histtype = 'step');\n",
    "yax = tf.ones(tf.shape(rads), tf.float32) #plots everything on top of eachother\n",
    "yax = yax * tf.cast(tf.linspace(1, 0, tf.shape(rads)[1]), tf.float32)\n",
    "# print(tf.linspace(0, 1, tf.shape(rads)[1])[:,None] )\n",
    "ax[1].plot(rads,yax, 'b.', markersize = 3)\n",
    "# #_________________________________________________________________\n",
    "\"\"\n",
    "bounds = get_cluster(rads)\n",
    "print(\"\\n Bounds \\n\", bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([1,2])\n",
    "b = np.ones([3,2])\n",
    "print(np.append(b, a, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_r = bounds[6,:]\n",
    "print(edges_r)\n",
    "pts = tf.cast(tf.convert_to_tensor(c1[:,1]), tf.float64)\n",
    "print(pts)\n",
    "\n",
    "bins_r = tfp.stats.find_bins(pts, edges_r)\n",
    "print(bins_r)\n",
    "#get rid of NaNs\n",
    "nonnan = 1 - tf.cast(tf.math.is_nan(bins_r), tf.float32)\n",
    "idxnonan = tf.where(nonnan == 1)\n",
    "print(tf.gather(bins_r, idxnonan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33398169 -0.00806366 -0.01034651]]\n",
      "[[ 0.36177183  0.0056728   0.00114252  0.000432   -0.00459209 -0.01451318]]\n",
      "0.110133\n"
     ]
    }
   ],
   "source": [
    "#get true transformation between frames\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "idx = 0\n",
    "poses0 = dataset.oxts[idx] #<- ID of 1st scan\n",
    "poses1 = dataset.oxts[idx+1] #<- ID of 2nd scan\n",
    "lat0 = poses0.packet.lat\n",
    "lon0 = poses0.packet.lon\n",
    "alt0 = poses0.packet.alt\n",
    "lat1 = poses1.packet.lat\n",
    "lon1 = poses1.packet.lon\n",
    "alt1 = poses1.packet.alt\n",
    "\n",
    "# print(lat0)\n",
    "# print(lon0)\n",
    "\n",
    "dx_oxts, dy_oxts = lat_lon_grid_deltas(np.array([lon0,lon1]), np.array([lat0, lat1]))\n",
    "# print(dx_oxts, dy_oxts) \n",
    "dx_oxts = dx_oxts[0,0].magnitude\n",
    "dy_oxts = dy_oxts[0,0].magnitude\n",
    "dz_oxts = (alt0-alt1)\n",
    "droll_oxts = (poses0.packet.roll - poses1.packet.roll)\n",
    "dpitch_oxts = (poses0.packet.pitch - poses1.packet.pitch)\n",
    "dyaw_oxts = (poses0.packet.yaw - poses1.packet.yaw)\n",
    "\n",
    "rot = poses1.T_w_imu[:3,:3] #trying this\n",
    "\n",
    "dxyz_oxts = np.array([[dx_oxts, dy_oxts, dz_oxts]])\n",
    "dxyz_lidar = dxyz_oxts.dot(rot)\n",
    "print(dxyz_lidar)\n",
    "\n",
    "# dt = 0.10\n",
    "dt = 0.1037 #mean time between lidar samples\n",
    "from_vel = np.array([[poses1.packet.vf*dt, poses1.packet.vl*dt, poses1.packet.vu*dt, -poses1.packet.wf*dt, -poses1.packet.wl*dt, -poses1.packet.wu*dt]])\n",
    "print(from_vel)\n",
    "\n",
    "# print(poses1.packet.vel_accuracy)\n",
    "print((dataset.timestamps[idx+1] - dataset.timestamps[idx]).microseconds/(10e5))\n",
    "\n",
    "# # print(np.shape(dataset.timestamps)[0])\n",
    "# # tvec = np.zeros(np.shape(dataset.timestamps)[0])\n",
    "# tvec = np.zeros(149)\n",
    "# # for i in range(np.shape(dataset.timestamps)[0] - 1):\n",
    "# for i in range(149):\n",
    "# #     print((dataset.timestamps[i+1] - dataset.timestamps[i]).microseconds/(10e5))\n",
    "#     tvec[i] = (dataset.timestamps[i+1] - dataset.timestamps[i]).microseconds/(10e5)\n",
    "# print(tvec)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1,2,3,4]])\n",
    "test = np.append(test,np.array([[0,2,3,4]]),axis = 0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test batch rotation matrix conversions\n",
    "from utils import R_tf\n",
    "\n",
    "print(R_tf(tf.Variable([[0., 0., 1.]])), \"\\n\")\n",
    "\n",
    "angs = tf.Variable([[0., 0., 1.], [0., 0., 1.]])\n",
    "# angs = tf.Variable([[0., 0., 1.]])\n",
    "print(angs)\n",
    "\n",
    "rots = R_tf(angs) \n",
    "print(rots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad tensors to get them to the same length\n",
    "#to fix bug in get_U_and_L()\n",
    "\n",
    "t1 = tf.ones([8,3], tf.int32)\n",
    "print(t1)\n",
    "t2 = tf.ones([7,3], tf.int32)\n",
    "print(t2)\n",
    "\n",
    "bofa = tf.sets.intersection(t1, t2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test- workaround for in place tensor operations\n",
    "indices = tf.cast(tf.constant([1, 2, 3, 5]), tf.int32)[:,None]\n",
    "print(\"indices\", indices)\n",
    "updates = tf.ones(tf.shape(indices))\n",
    "print(\"updates\", updates)\n",
    "shape = tf.constant([7, 1])\n",
    "print(\"shape\", shape)\n",
    "\n",
    "b = tf.scatter_nd(indices, updates, shape)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results of ICET estimates on KITTI lidar point clouds vs GPS/INS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "font = {'fontname':'Times New Roman'}\n",
    "\n",
    "#v8 is the best so far...\n",
    "ICET_estimates = np.loadtxt(\"ICET_estimates_v8.txt\")\n",
    "OXTS_baseline = np.loadtxt(\"OXTS_baseline_v8.txt\")\n",
    "# ICET_estimates = np.loadtxt(\"ICET_estimates_v10.txt\")\n",
    "# OXTS_baseline = np.loadtxt(\"OXTS_baseline_v10.txt\")\n",
    "\n",
    "\n",
    "# vf_from_matlab = np.loadtxt(\"vf.txt\")\n",
    "# vf_from_matlab = np.append(vf_from_matlab, 0)\n",
    "# # print(vf_from_matlab)\n",
    "# OXTS_baseline[:,0] = vf_from_matlab\n",
    "\n",
    "# OXTS_baseline = np.loadtxt(\"OXTS_baseline_gps.txt\")\n",
    "\n",
    "# OXTS_baseline[:,3:] = OXTS_baseline[:,3:]/0.1*0.1037\n",
    "OXTS_baseline = OXTS_baseline/0.1*0.1037\n",
    "\n",
    "# ICET_estimates[:,0] = ICET_estimates[:,0]/tvec*0.1\n",
    "\n",
    "#fix sign errors\n",
    "ICET_estimates[:,1] = -ICET_estimates[:,1]\n",
    "ICET_estimates[:,3:] = -ICET_estimates[:,3:]\n",
    "style1 = 'b-'\n",
    "style2 = 'r-'\n",
    "\n",
    "fig, ax = plt.subplots(3,2, constrained_layout = True)\n",
    "ax[0,0].plot(ICET_estimates[:,0], style1, label = 'ICET')\n",
    "# ax[0,0].plot(OXTS_baseline[:,0], style2, label = 'GPS/INS Baseline')\n",
    "ax[0,0].plot(np.sqrt(OXTS_baseline[:,0]**2 + OXTS_baseline[:,1]**2), style2, label = 'GPS/INS Baseline')\n",
    "ax[0,0].set_title(\"change in x per frame\", **font)\n",
    "ax[0,0].set_ylabel(\"dx (m)\", **font)\n",
    "ax[0,0].legend(loc = 'upper left')\n",
    "ax[0,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "ax[1,0].plot(ICET_estimates[:,1], style1, lw = 1)\n",
    "ax[1,0].plot(-OXTS_baseline[:,1], style2, lw = 1)\n",
    "# ax[1,0].plot(np.arange(n//2, np.shape(ICET_estimates)[0] - n//2 ), moving_avg(OXTS_baseline[:,1], n),  style2, lw = 1)\n",
    "ax[1,0].set_title(\"change in y per frame\", **font)\n",
    "ax[1,0].set_ylabel(\"dy (m)\", **font)\n",
    "ax[1,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[2,0].plot(ICET_estimates[:,2], style1, lw = 1)\n",
    "ax[2,0].plot(OXTS_baseline[:,2], style2, lw = 1)\n",
    "# ax[2,0].plot(np.arange(n//2, np.shape(ICET_estimates)[0] - n//2 ), moving_avg(OXTS_baseline[:,2], n),  style2, lw = 1)\n",
    "ax[2,0].set_title(\"change in z per frame\", **font)\n",
    "ax[2,0].set_ylabel(\"dz (m)\", **font)\n",
    "ax[2,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "ax[0,1].plot(ICET_estimates[:,3], style1, lw = 1)\n",
    "ax[0,1].plot(OXTS_baseline[:,3], style2, lw = 1)\n",
    "ax[0,1].set_title(\"change in roll per frame\", **font)\n",
    "ax[0,1].set_ylabel(\"droll (rad)\", **font)\n",
    "ax[0,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[1,1].plot(ICET_estimates[:,4], style1, lw = 1)\n",
    "ax[1,1].plot(OXTS_baseline[:,4], style2, lw = 1)\n",
    "ax[1,1].set_title(\"change in pitch per frame\", **font)\n",
    "ax[1,1].set_ylabel(\"dpitch (rad)\", **font)\n",
    "ax[1,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[2,1].plot(ICET_estimates[:,5], style1, lw = 1)\n",
    "ax[2,1].plot(OXTS_baseline[:,5], style2, lw = 1)\n",
    "ax[2,1].set_title(\"change in yaw per frame\", **font)\n",
    "ax[2,1].set_ylabel(\"dyaw (rad)\", **font)\n",
    "ax[2,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "# fig.tight_layout(h_pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error between ICET and absolute position\n",
    "plt.rc('font',family='Times New Roman')\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "\n",
    "ICET_pred_stds = np.loadtxt(\"ICET_pred_stds_v8.txt\")\n",
    "# ICET_pred_stds = (2*np.sqrt(ICET_pred_stds))**2\n",
    "# ICET_pred_stds = np.sqrt(2*(ICET_pred_stds**2))\n",
    "\n",
    "\n",
    "#which component to look at\n",
    "# c = 5 #yaw\n",
    "c = 0 # x (forward movement)\n",
    "\n",
    "diffx = OXTS_baseline[:,c] - ICET_estimates[:,c]\n",
    "\n",
    "print(abs(diffx))\n",
    "print(\"correlation coefficient \\n\", np.corrcoef(abs(diffx), ICET_pred_stds[:,0]))\n",
    "\n",
    "#flip sign when looking at yaw\n",
    "if c ==5:\n",
    "    diffx = -diffx \n",
    "    \n",
    "cum_err = np.zeros(np.shape(ICET_pred_stds))\n",
    "cum_diffx = np.zeros(np.shape(diffx))\n",
    "\n",
    "for i in range(np.shape(ICET_pred_stds)[0]):\n",
    "    cum_err[i,:] = np.sum(ICET_pred_stds[:i,:]**2, axis = 0)\n",
    "    #add in baseline OXTS 1-sigma errors\n",
    "#     cum_err[i,:] += np.sqrt(2)*np.array([0.05,0.05,0.1,0.0005,0.0005,0.001])**2\n",
    "    cum_err[i,:] += np.sqrt(2)*np.array([0.08,0.08,0.1,0.0005,0.0005,0.001745])**2\n",
    "    cum_err[i,:] = np.sqrt(cum_err[i,:]) \n",
    "    \n",
    "for j in range(np.shape(diffx)[0]):\n",
    "    cum_diffx[j] = np.sum(diffx[:j]) \n",
    "\n",
    "# # #old (error for each individual timestep)------------------------\n",
    "ax3.plot(diffx, label = 'GPS/INS - ICET')\n",
    "ax3.fill_between(np.linspace(0,150,np.shape(ICET_pred_stds)[0]), -2*ICET_pred_stds[:,c], 2*ICET_pred_stds[:,c], \n",
    "                 color = (0,0,1,0.2), label = 'ICET Predicted 2σ Error Bounds')\n",
    "# # #-------------------------------------------------------------------\n",
    "\n",
    "# #new (accumulated differences in error)--------------------------\n",
    "# # ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx_with_ground, label = 'GPS/INS - ICET')\n",
    "# ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx, label = 'GPS/INS - ICET')\n",
    "# ax3.fill_between(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), -2*cum_err[:,c], 2*cum_err[:,c], \n",
    "#                  color = (0,0,1,0.2), label = 'Predicted 2σ Error Bounds')\n",
    "# # --------------------------------------------------------------------\n",
    "\n",
    "ax3.legend(loc = 'lower left')\n",
    "ax3.set_title(\"Predicted vs Actual Error in x\")\n",
    "ax3.set_xlabel(\"time (s)\", **font)\n",
    "ax3.set_ylabel(\"GPS/INS Baseline x - Odometry Estimate x (m)\", **font)\n",
    "# ax3.set_ylim([-0.07,0.07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test where points are inside spherical cell...\n",
    "# print(it.cloud1_tensor_spherical)\n",
    "maxtheta = tf.constant([[0.2],[0.7]])\n",
    "maxr = tf.constant([[0.5],[2.]])\n",
    "\n",
    "ans1 = tf.greater(it.cloud1_tensor_spherical[:,1], maxtheta)\n",
    "# print(ans1)\n",
    "ans2 = tf.less(it.cloud1_tensor_spherical[:,0], maxr)\n",
    "# print(ans2)\n",
    "combined = tf.Variable([ans1, ans2])\n",
    "# print(combined)\n",
    "ans3 = tf.math.reduce_all(combined, axis = 1)\n",
    "\n",
    "print(ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate each element of an n*1 vector 3 times\n",
    "t = tf.linspace(0,5,6)[:,None]\n",
    "print(t)\n",
    "\n",
    "test  = tf.tile(t, [3,1])\n",
    "# print(test)\n",
    "test2 = tf.reshape(tf.transpose(tf.reshape(test, [3,-1])), [-1,1])\n",
    "print(test2)\n",
    "test3 = tf.reshape(tf.transpose(tf.reshape(test, [3,-1])), [-1,3])\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate each element of an n*3 vector 3 times\n",
    "t = tf.linspace(1,5,5)\n",
    "t = tf.transpose(tf.Variable([t, 2*t, 3*t]))\n",
    "print(t)\n",
    "\n",
    "test  = tf.tile(t, [4,1])\n",
    "# print(test)\n",
    "\n",
    "test = tf.reshape(tf.transpose(test), [3, 4, -1])\n",
    "# print(test)\n",
    "\n",
    "test = tf.transpose(test, [2,1,0])\n",
    "# print(test)\n",
    "\n",
    "test = tf.reshape(test, [-1,3])\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MC sim to compare performance estimation in \"realistic\" scenes with flat vs curved surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "c1_OG = np.loadtxt(\"scene2_scan1.txt\", dtype = float) #thin cylinders\n",
    "c2_OG = np.loadtxt(\"scene2_scan2.txt\", dtype = float)\n",
    "# c1_OG = np.loadtxt(\"scene3_scan1.txt\", dtype = float) #rectangles\n",
    "# c2_OG = np.loadtxt(\"scene3_scan2.txt\", dtype = float)\n",
    "# c1 = np.loadtxt(\"scene4_scan1.txt\", dtype = float) #cylinders\n",
    "# c2 = np.loadtxt(\"scene4_scan2.txt\", dtype = float)\n",
    "\n",
    "xvec = np.zeros([epochs, 6])\n",
    "pred_stds = np.zeros([epochs, 6])\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"\\n -------------- Epoch\", i, \"--------------------\")\n",
    "    #add noise (if not generated when point clouds were created)\n",
    "    c1 = c1_OG + 0.02*np.random.randn(np.shape(c1_OG)[0], 3)\n",
    "    c2 = c2_OG + 0.02*np.random.randn(np.shape(c2_OG)[0], 3)  \n",
    "\n",
    "    it = ICET(cloud1 = c1, cloud2 = c2, fid = 70, niter = 20, draw = False, group = 2, RM = True)\n",
    "    xvec[i] = it.X\n",
    "    pred_stds[i] = it.pred_stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_soln_err = np.array([-0.5, 0, 0, 0, 0, 0,]) - np.mean(xvec, axis = 0)\n",
    "\n",
    "print(\"Smaller Clylindrical features, no occlusion, no outlier rejection, n=10:\\n\")\n",
    "# print(\"Rectangular features, no occlusion, no outlier rejection, n=50:\\n\")\n",
    "\n",
    "print(\"mean solution error: \\n\", mean_soln_err)\n",
    "soln_std = np.std(xvec, axis = 0)\n",
    "print(\"\\n experimentally determined std: \\n\", soln_std)\n",
    "mean_pred_std = np.mean(pred_stds, axis = 0)\n",
    "print(\"\\n predicted std: \\n\", mean_pred_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "nbins = 10\n",
    "ax.hist(xvec[:,0], nbins)\n",
    "# ax.set_title(\"Clylindrical features, no occlusion, no outlier rejection, n=50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
