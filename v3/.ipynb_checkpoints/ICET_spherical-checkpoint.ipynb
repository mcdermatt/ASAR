{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3262136   0.01210751 -0.04107135  0.00583877  0.00923016  0.01366654], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34012377  0.01607612 -0.04202338  0.00416007  0.00952097  0.01430645], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34119904  0.01409199 -0.04767205  0.00347816  0.00987983  0.01422459], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34124714  0.01331836 -0.05010424  0.00342606  0.01006268  0.01419187], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34132358  0.01307106 -0.0512622   0.00335676  0.01011535  0.01418361], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3413794   0.01301072 -0.05127696  0.00331319  0.01009191  0.01418316], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34136912  0.01302353 -0.051625    0.00330863  0.01007996  0.01418143], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138262  0.01302139 -0.05156136  0.00330608  0.01007179  0.01418241], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.3413817   0.01302121 -0.0515581   0.00330588  0.01007182  0.0141823 ], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138086  0.01302085 -0.05155848  0.00330599  0.01007175  0.01418243], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138158  0.01302166 -0.05155934  0.00330585  0.01007185  0.01418232], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138212  0.01302301 -0.05155841  0.00330592  0.01007178  0.01418237], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138048  0.01302225 -0.051558    0.00330586  0.01007184  0.01418232], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138122  0.01302154 -0.05155908  0.00330583  0.01007181  0.01418232], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138143  0.01302199 -0.05155837  0.00330573  0.01007186  0.01418238], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138137  0.0130216  -0.05155889  0.00330581  0.01007186  0.01418235], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138015  0.01302176 -0.05155855  0.00330588  0.01007179  0.01418236], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138194  0.01302257 -0.05155814  0.00330579  0.01007175  0.01418247], shape=(6,), dtype=float32)\n",
      "\n",
      " estimated solution vector X: \n",
      " tf.Tensor([ 0.34138122  0.01302197 -0.05155864  0.00330595  0.01007183  0.01418231], shape=(6,), dtype=float32)\n",
      "pred_stds: \n",
      " tf.Tensor(\n",
      "[7.9116854e-04 9.0027764e-04 2.0921477e-03 2.7314902e-04 3.0526507e-04\n",
      " 6.0835806e-05], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from ICET_spherical import ICET\n",
    "\n",
    "# init KITTI dataset -----------------------------------------------------------------\n",
    "basedir = 'C:/kitti/'\n",
    "date = '2011_09_26'\n",
    "drive = '0005'\n",
    "idx = 0\n",
    "# drive = '0093'\n",
    "# idx = 220\n",
    "dataset = pykitti.raw(basedir, date, drive)\n",
    "velo1 = dataset.get_velo(idx) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "c1 = velo1[:,:3]\n",
    "velo2 = dataset.get_velo(idx+1) # Each scan is a Nx4 array of [x,y,z,reflectance]\n",
    "c2 = velo2[:,:3]\n",
    "# c1 = c1[c1[:,2] > -1.5] #ignore ground plane\n",
    "# c2 = c2[c2[:,2] > -1.5] #ignore ground plane\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# ## load custom point cloud geneated in matlab------------------------------------------\n",
    "# c1 = np.loadtxt(\"scene1_scan1.txt\", dtype = float)\n",
    "# # c2 = c1 + np.array([2.0, 0.2, 0])\n",
    "# c2 = c1 + np.array([0.1, 0., 0.])\n",
    "\n",
    "# # c1 = c1[c1[:,2] > -1.5] #ignore ground plane\n",
    "# # c2 = c2[c2[:,2] > -1.5] #ignore ground plane\n",
    "# ## ------------------------------------------------------------------------------------\n",
    "\n",
    "# #single distinct cluster---------------------------------------------------------------\n",
    "# c1 = np.random.randn(3000,3)*tf.constant([0.04,0.3,0.3]) + tf.constant([6.,0.,0.])\n",
    "# c2 = np.random.randn(3000,3)*tf.constant([0.04,0.3,0.3]) + tf.constant([6.,0.,0.]) - np.array([0., 0.25, 0.0])\n",
    "# # # c2 = c1 - np.array([0.1, 0.3, 0.0])\n",
    "# # -------------------------------------------------------------------------------------\n",
    "\n",
    "# D = True\n",
    "D = False\n",
    "X = tf.constant([0., 0., 0., 0., 0., 0.])\n",
    "it1 = ICET(cloud1 = c1, cloud2 = c2,  fid = 50, draw = False, x0 = X, niter = 20, group= 2, RM = False)\n",
    "# it2 = ICET(cloud1 = it1.cloud1_static, cloud2 = c2, fid = 50, niter = 20, draw = True, group = 2, RM = False)\n",
    "\n",
    "if D:\n",
    "    ViewInteractiveWidget(it2.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B57B86828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015B57B86828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([-0.00037409  0.01331765 -0.00745325], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process points from ICET to feed to DNN\n",
    "\n",
    "#Get ragged tensor containing all points from each scan inside each sufficient voxel\n",
    "in1 = it1.inside1\n",
    "npts1 = it1.npts1\n",
    "in2 = it1.inside2\n",
    "npts2 = it1.npts2\n",
    "corr = it1.corr #indices of bins that have enough points from scan1 and scan2\n",
    "\n",
    "# print(tf.shape(in2.to_tensor()))\n",
    "\n",
    "#get indices of rag with >= 25 elements\n",
    "ncells = tf.shape(corr)[0].numpy() #num of voxels with sufficent number of points\n",
    "# print(tf.gather(npts2, corr))\n",
    "enough1 = tf.gather(in1, corr)\n",
    "enough2 = tf.gather(in2, corr)\n",
    "print(tf.shape(enough2.to_tensor())[0].numpy())\n",
    "# print(npts2)\n",
    "# print(corr)\n",
    "\n",
    "#init array to store indices\n",
    "idx1 = np.zeros([ncells ,25])\n",
    "idx2 = np.zeros([ncells ,25])\n",
    "\n",
    "#loop through each element of ragged tensor\n",
    "for i in range(ncells):\n",
    "    idx1[i,:] = tf.random.shuffle(enough1[i])[:25].numpy() #shuffle order and take first 25 elements\n",
    "    idx2[i,:] = tf.random.shuffle(enough2[i])[:25].numpy() #shuffle order and take first 25 elements\n",
    "\n",
    "idx1 = tf.cast(tf.convert_to_tensor(idx1), tf.int32)\n",
    "idx2 = tf.cast(tf.convert_to_tensor(idx2), tf.int32)\n",
    "\n",
    "# print(it1.cloud1_tensor)\n",
    "from1 = tf.gather(it1.cloud1_tensor, idx1)\n",
    "# from2 = tf.gather(it1.cloud2_tensor_OG, idx2)\n",
    "from2 = tf.gather(it1.cloud2_tensor, idx2)\n",
    "# print(from1)\n",
    "\n",
    "x_test = tf.concat((from1, from2), axis = 1)\n",
    "# np.savetxt('perspective_shift/ICET_KITTI_frame0.txt', tf.reshape(from1, [-1, 3]).numpy())\n",
    "# np.savetxt('perspective_shift/ICET_KITTI_frame1.txt', tf.reshape(from2, [-1, 3]).numpy())\n",
    "\n",
    "model = tf.keras.models.load_model(\"perspective_shift/KITTInet.kmod\")\n",
    "from_DNN = model.predict(x_test)\n",
    "# print(from_DNN)\n",
    "# print(np.shape(from_DNN))\n",
    "print(tf.math.reduce_mean(from_DNN, axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify compact directions where ICET and DNN disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([109   3   3], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 1  3 10 13 15 16 31 35 35 44 46 46 47 47 53 54 55 56 56 57 59 59 60 61\n",
      " 63 66 70 72 73 77 78 79 80 82 83 89 99], shape=(37,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#compare per cell translation estimates between ICET and DNN on converged results\n",
    "dnnsoln = tf.convert_to_tensor(from_DNN)\n",
    "# n = 0 #cell idx\n",
    "# print(dnnsoln[n])\n",
    "# print(it1.residuals[n])\n",
    "\n",
    "# icetsoln = tf.gather(it1.residuals_full, it1.corr)\n",
    "icetsoln = tf.gather(it1.residuals, it1.corr) #test\n",
    "\n",
    "#align differences between solutions with the principal axis of ICET scan1\n",
    "L = it1.L #only from \"mu1_enough\", \"sigma1_enough\" -> why it's too small rn???\n",
    "U = it1.U\n",
    "print(tf.shape(U))\n",
    "# print(U)\n",
    "\n",
    "# print(it1.enough1) #voxel IDs from scan1 with enough points\n",
    "# print(it1.corr)    # voxel IDs from BOTH with enough points\n",
    "\n",
    "#TODO: \n",
    "#  1) get IDX of elements that are in both enough1 and corr\n",
    "#  2) use this to index U and L to get U_i and L_i\n",
    "both = tf.sets.intersection(it1.enough1[None,:], it1.corr[None,:]).values\n",
    "ans = tf.where(it1.enough1[:,None] == both)[:,0]\n",
    "# print(ans)\n",
    "\n",
    "#project into frame of principal axis of distribution from scan1, prune extended axis\n",
    "LUT = tf.matmul(L, tf.transpose(U, [0,2,1]))\n",
    "it_compact = tf.matmul(LUT, icetsoln[:,:,None])\n",
    "dnn_compact = tf.matmul(LUT, dnnsoln[:,:,None])\n",
    "# print(it_compact)\n",
    "# print(dnn_compact)\n",
    "\n",
    "#find where the largest difference in residuals are\n",
    "thresh = 0.1\n",
    "#be careful- not sure what this index corresponds to (may not be voxel ID)\n",
    "problem_voxels = tf.where(tf.math.abs(it_compact - dnn_compact) > thresh)[:,0]\n",
    "print(problem_voxels)\n",
    "\n",
    "\n",
    "#remove extended axis\n",
    "# print(dnnsoln - icetsoln)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify outlier cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "nbins = 25\n",
    "nstd = 2\n",
    "\n",
    "# print(it.dx_i[:,0])\n",
    "# print(tf.math.reduce_sum(it.dx_i, axis = 0))\n",
    "# print(it.W)\n",
    "# print(it.H)\n",
    "# print(it.residuals[:,0])\n",
    "\n",
    "component = it1.residuals_full[:,1]\n",
    "print(tf.shape(component))\n",
    "# print(component)\n",
    "\n",
    "print(\"\\n before:\")\n",
    "mu = tf.math.reduce_mean(component)\n",
    "print(\"mean\", mu)\n",
    "sigma = tf.math.reduce_std(component)\n",
    "print(\"standard deviation\", sigma)\n",
    "bad_idx = tf.where( tf.math.abs(component) > mu + nstd*sigma )\n",
    "# print(\"bad idx\", bad_idx)\n",
    "good_idx = tf.where( tf.math.abs(component) < mu + nstd*sigma )\n",
    "# print(tf.gather(component, bad_idx))\n",
    "# ax.hist(it.dx_i[:,0], nbins);\n",
    "ax[0].hist(component, nbins);\n",
    "ax[0].set_xlabel(\"y_i - y0_i (forward translation error)\")\n",
    "ax[0].set_ylabel(\"frequency\")\n",
    "ax[0].set_title(\"All Distributions\")\n",
    "\n",
    "#test to make sure outliers are being removed correctly\n",
    "component = it1.residuals[:,1]\n",
    "print(tf.shape(component))\n",
    "# print(component)\n",
    "\n",
    "print(\"\\n after:\")\n",
    "mu = tf.math.reduce_mean(component)\n",
    "print(\"mean\", mu)\n",
    "sigma = tf.math.reduce_std(component)\n",
    "print(\"standard deviation\", sigma)\n",
    "\n",
    "ax[1].hist(component, nbins);\n",
    "ax[1].set_xlabel(\"y_i - y0_i (forward translation error)\")\n",
    "ax[1].set_ylabel(\"frequency\")\n",
    "ax[1].set_title(\"Best Fitting Distributions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "# print(it.residuals_full[:,0])\n",
    "edges = tf.linspace(-1.,1.,30)\n",
    "# print(edges)\n",
    "print(edges)\n",
    "\n",
    "bins_soln = tfp.stats.find_bins(it.residuals_full[:,0], edges)\n",
    "# print(bins_soln)\n",
    "\n",
    "good_idx = tf.where(bins_soln == 14)\n",
    "bad_idx = tf.where(bins_soln == 14)\n",
    "# print(bad_idx)\n",
    "# print(good_idx)\n",
    "# print(tf.gather(it.residuals_full[:,0], good_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[5, 6, 7, 8]])\n",
    "b = tf.constant([[8, 7, 10]])\n",
    "print(tf.sets.difference(a,b).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Useful Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import get_cluster\n",
    "\n",
    "#index of spike that each of the points from cloud 1 is occupying\n",
    "print(it.bins_spike)\n",
    "\n",
    "occupied_spikes, idxs = tf.unique(it.bins_spike)\n",
    "print(\"\\n occupied_spikes \\n\", occupied_spikes)\n",
    "temp =  tf.where(it.bins_spike == occupied_spikes[:,None])\n",
    "rag = tf.RaggedTensor.from_value_rowids(temp[:,1], temp[:,0])\n",
    "idx_by_rag = tf.gather(it.cloud1_tensor_spherical[:,0], rag)\n",
    "\n",
    "# rads = idx_by_rag[50,:] #single element from ragged tensor\n",
    "rads = tf.transpose(idx_by_rag.to_tensor()[:3,:])\n",
    "# rads = tf.transpose(idx_by_rag.to_tensor())\n",
    "# print(rads) #starts out unordered\n",
    "\n",
    "# #_________________________________________________________________\n",
    "fig, ax = plt.subplots(2,1)\n",
    "nbins = 25\n",
    "ax[0].hist(rads.numpy(), nbins, histtype = 'step');\n",
    "yax = tf.ones(tf.shape(rads), tf.float32) #plots everything on top of eachother\n",
    "yax = yax * tf.cast(tf.linspace(1, 0, tf.shape(rads)[1]), tf.float32)\n",
    "# print(tf.linspace(0, 1, tf.shape(rads)[1])[:,None] )\n",
    "ax[1].plot(rads,yax, 'b.', markersize = 3)\n",
    "# #_________________________________________________________________\n",
    "\"\"\n",
    "bounds = get_cluster(rads)\n",
    "print(\"\\n Bounds \\n\", bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([1,2])\n",
    "b = np.ones([3,2])\n",
    "print(np.append(b, a, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_r = bounds[6,:]\n",
    "print(edges_r)\n",
    "pts = tf.cast(tf.convert_to_tensor(c1[:,1]), tf.float64)\n",
    "print(pts)\n",
    "\n",
    "bins_r = tfp.stats.find_bins(pts, edges_r)\n",
    "print(bins_r)\n",
    "#get rid of NaNs\n",
    "nonnan = 1 - tf.cast(tf.math.is_nan(bins_r), tf.float32)\n",
    "idxnonan = tf.where(nonnan == 1)\n",
    "print(tf.gather(bins_r, idxnonan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33398169 -0.00806366 -0.01034651]]\n",
      "[[ 0.36177183  0.0056728   0.00114252  0.000432   -0.00459209 -0.01451318]]\n",
      "0.110133\n"
     ]
    }
   ],
   "source": [
    "#get true transformation between frames\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "idx = 0\n",
    "poses0 = dataset.oxts[idx] #<- ID of 1st scan\n",
    "poses1 = dataset.oxts[idx+1] #<- ID of 2nd scan\n",
    "lat0 = poses0.packet.lat\n",
    "lon0 = poses0.packet.lon\n",
    "alt0 = poses0.packet.alt\n",
    "lat1 = poses1.packet.lat\n",
    "lon1 = poses1.packet.lon\n",
    "alt1 = poses1.packet.alt\n",
    "\n",
    "# print(lat0)\n",
    "# print(lon0)\n",
    "\n",
    "dx_oxts, dy_oxts = lat_lon_grid_deltas(np.array([lon0,lon1]), np.array([lat0, lat1]))\n",
    "# print(dx_oxts, dy_oxts) \n",
    "dx_oxts = dx_oxts[0,0].magnitude\n",
    "dy_oxts = dy_oxts[0,0].magnitude\n",
    "dz_oxts = (alt0-alt1)\n",
    "droll_oxts = (poses0.packet.roll - poses1.packet.roll)\n",
    "dpitch_oxts = (poses0.packet.pitch - poses1.packet.pitch)\n",
    "dyaw_oxts = (poses0.packet.yaw - poses1.packet.yaw)\n",
    "\n",
    "rot = poses1.T_w_imu[:3,:3] #trying this\n",
    "\n",
    "dxyz_oxts = np.array([[dx_oxts, dy_oxts, dz_oxts]])\n",
    "dxyz_lidar = dxyz_oxts.dot(rot)\n",
    "print(dxyz_lidar)\n",
    "\n",
    "# dt = 0.10\n",
    "dt = 0.1037 #mean time between lidar samples\n",
    "from_vel = np.array([[poses1.packet.vf*dt, poses1.packet.vl*dt, poses1.packet.vu*dt, -poses1.packet.wf*dt, -poses1.packet.wl*dt, -poses1.packet.wu*dt]])\n",
    "print(from_vel)\n",
    "\n",
    "# print(poses1.packet.vel_accuracy)\n",
    "print((dataset.timestamps[idx+1] - dataset.timestamps[idx]).microseconds/(10e5))\n",
    "\n",
    "# # print(np.shape(dataset.timestamps)[0])\n",
    "# # tvec = np.zeros(np.shape(dataset.timestamps)[0])\n",
    "# tvec = np.zeros(149)\n",
    "# # for i in range(np.shape(dataset.timestamps)[0] - 1):\n",
    "# for i in range(149):\n",
    "# #     print((dataset.timestamps[i+1] - dataset.timestamps[i]).microseconds/(10e5))\n",
    "#     tvec[i] = (dataset.timestamps[i+1] - dataset.timestamps[i]).microseconds/(10e5)\n",
    "# print(tvec)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1,2,3,4]])\n",
    "test = np.append(test,np.array([[0,2,3,4]]),axis = 0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test batch rotation matrix conversions\n",
    "from utils import R_tf\n",
    "\n",
    "print(R_tf(tf.Variable([[0., 0., 1.]])), \"\\n\")\n",
    "\n",
    "angs = tf.Variable([[0., 0., 1.], [0., 0., 1.]])\n",
    "# angs = tf.Variable([[0., 0., 1.]])\n",
    "print(angs)\n",
    "\n",
    "rots = R_tf(angs) \n",
    "print(rots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad tensors to get them to the same length\n",
    "#to fix bug in get_U_and_L()\n",
    "\n",
    "t1 = tf.ones([8,3], tf.int32)\n",
    "print(t1)\n",
    "t2 = tf.ones([7,3], tf.int32)\n",
    "print(t2)\n",
    "\n",
    "bofa = tf.sets.intersection(t1, t2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test- workaround for in place tensor operations\n",
    "indices = tf.cast(tf.constant([1, 2, 3, 5]), tf.int32)[:,None]\n",
    "print(\"indices\", indices)\n",
    "updates = tf.ones(tf.shape(indices))\n",
    "print(\"updates\", updates)\n",
    "shape = tf.constant([7, 1])\n",
    "print(\"shape\", shape)\n",
    "\n",
    "b = tf.scatter_nd(indices, updates, shape)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results of ICET estimates on KITTI lidar point clouds vs GPS/INS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "font = {'fontname':'Times New Roman'}\n",
    "\n",
    "#v8 is the best so far...\n",
    "ICET_estimates = np.loadtxt(\"ICET_estimates_v8.txt\")\n",
    "OXTS_baseline = np.loadtxt(\"OXTS_baseline_v8.txt\")\n",
    "# ICET_estimates = np.loadtxt(\"ICET_estimates_v10.txt\")\n",
    "# OXTS_baseline = np.loadtxt(\"OXTS_baseline_v10.txt\")\n",
    "\n",
    "\n",
    "# vf_from_matlab = np.loadtxt(\"vf.txt\")\n",
    "# vf_from_matlab = np.append(vf_from_matlab, 0)\n",
    "# # print(vf_from_matlab)\n",
    "# OXTS_baseline[:,0] = vf_from_matlab\n",
    "\n",
    "# OXTS_baseline = np.loadtxt(\"OXTS_baseline_gps.txt\")\n",
    "\n",
    "# OXTS_baseline[:,3:] = OXTS_baseline[:,3:]/0.1*0.1037\n",
    "OXTS_baseline = OXTS_baseline/0.1*0.1037\n",
    "\n",
    "# ICET_estimates[:,0] = ICET_estimates[:,0]/tvec*0.1\n",
    "\n",
    "#fix sign errors\n",
    "ICET_estimates[:,1] = -ICET_estimates[:,1]\n",
    "ICET_estimates[:,3:] = -ICET_estimates[:,3:]\n",
    "style1 = 'b-'\n",
    "style2 = 'r-'\n",
    "\n",
    "fig, ax = plt.subplots(3,2, constrained_layout = True)\n",
    "ax[0,0].plot(ICET_estimates[:,0], style1, label = 'ICET')\n",
    "# ax[0,0].plot(OXTS_baseline[:,0], style2, label = 'GPS/INS Baseline')\n",
    "ax[0,0].plot(np.sqrt(OXTS_baseline[:,0]**2 + OXTS_baseline[:,1]**2), style2, label = 'GPS/INS Baseline')\n",
    "ax[0,0].set_title(\"change in x per frame\", **font)\n",
    "ax[0,0].set_ylabel(\"dx (m)\", **font)\n",
    "ax[0,0].legend(loc = 'upper left')\n",
    "ax[0,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "ax[1,0].plot(ICET_estimates[:,1], style1, lw = 1)\n",
    "ax[1,0].plot(-OXTS_baseline[:,1], style2, lw = 1)\n",
    "# ax[1,0].plot(np.arange(n//2, np.shape(ICET_estimates)[0] - n//2 ), moving_avg(OXTS_baseline[:,1], n),  style2, lw = 1)\n",
    "ax[1,0].set_title(\"change in y per frame\", **font)\n",
    "ax[1,0].set_ylabel(\"dy (m)\", **font)\n",
    "ax[1,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[2,0].plot(ICET_estimates[:,2], style1, lw = 1)\n",
    "ax[2,0].plot(OXTS_baseline[:,2], style2, lw = 1)\n",
    "# ax[2,0].plot(np.arange(n//2, np.shape(ICET_estimates)[0] - n//2 ), moving_avg(OXTS_baseline[:,2], n),  style2, lw = 1)\n",
    "ax[2,0].set_title(\"change in z per frame\", **font)\n",
    "ax[2,0].set_ylabel(\"dz (m)\", **font)\n",
    "ax[2,0].set_xlabel(\"frame\", **font)\n",
    "\n",
    "ax[0,1].plot(ICET_estimates[:,3], style1, lw = 1)\n",
    "ax[0,1].plot(OXTS_baseline[:,3], style2, lw = 1)\n",
    "ax[0,1].set_title(\"change in roll per frame\", **font)\n",
    "ax[0,1].set_ylabel(\"droll (rad)\", **font)\n",
    "ax[0,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[1,1].plot(ICET_estimates[:,4], style1, lw = 1)\n",
    "ax[1,1].plot(OXTS_baseline[:,4], style2, lw = 1)\n",
    "ax[1,1].set_title(\"change in pitch per frame\", **font)\n",
    "ax[1,1].set_ylabel(\"dpitch (rad)\", **font)\n",
    "ax[1,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "\n",
    "ax[2,1].plot(ICET_estimates[:,5], style1, lw = 1)\n",
    "ax[2,1].plot(OXTS_baseline[:,5], style2, lw = 1)\n",
    "ax[2,1].set_title(\"change in yaw per frame\", **font)\n",
    "ax[2,1].set_ylabel(\"dyaw (rad)\", **font)\n",
    "ax[2,1].set_xlabel(\"frame\", **font)\n",
    "\n",
    "# fig.tight_layout(h_pad = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error between ICET and absolute position\n",
    "plt.rc('font',family='Times New Roman')\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "\n",
    "ICET_pred_stds = np.loadtxt(\"ICET_pred_stds_v8.txt\")\n",
    "# ICET_pred_stds = (2*np.sqrt(ICET_pred_stds))**2\n",
    "# ICET_pred_stds = np.sqrt(2*(ICET_pred_stds**2))\n",
    "\n",
    "\n",
    "#which component to look at\n",
    "# c = 5 #yaw\n",
    "c = 0 # x (forward movement)\n",
    "\n",
    "diffx = OXTS_baseline[:,c] - ICET_estimates[:,c]\n",
    "\n",
    "print(abs(diffx))\n",
    "print(\"correlation coefficient \\n\", np.corrcoef(abs(diffx), ICET_pred_stds[:,0]))\n",
    "\n",
    "#flip sign when looking at yaw\n",
    "if c ==5:\n",
    "    diffx = -diffx \n",
    "    \n",
    "cum_err = np.zeros(np.shape(ICET_pred_stds))\n",
    "cum_diffx = np.zeros(np.shape(diffx))\n",
    "\n",
    "for i in range(np.shape(ICET_pred_stds)[0]):\n",
    "    cum_err[i,:] = np.sum(ICET_pred_stds[:i,:]**2, axis = 0)\n",
    "    #add in baseline OXTS 1-sigma errors\n",
    "#     cum_err[i,:] += np.sqrt(2)*np.array([0.05,0.05,0.1,0.0005,0.0005,0.001])**2\n",
    "    cum_err[i,:] += np.sqrt(2)*np.array([0.08,0.08,0.1,0.0005,0.0005,0.001745])**2\n",
    "    cum_err[i,:] = np.sqrt(cum_err[i,:]) \n",
    "    \n",
    "for j in range(np.shape(diffx)[0]):\n",
    "    cum_diffx[j] = np.sum(diffx[:j]) \n",
    "\n",
    "# # #old (error for each individual timestep)------------------------\n",
    "ax3.plot(diffx, label = 'GPS/INS - ICET')\n",
    "ax3.fill_between(np.linspace(0,150,np.shape(ICET_pred_stds)[0]), -2*ICET_pred_stds[:,c], 2*ICET_pred_stds[:,c], \n",
    "                 color = (0,0,1,0.2), label = 'ICET Predicted 2σ Error Bounds')\n",
    "# # #-------------------------------------------------------------------\n",
    "\n",
    "# #new (accumulated differences in error)--------------------------\n",
    "# # ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx_with_ground, label = 'GPS/INS - ICET')\n",
    "# ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx, label = 'GPS/INS - ICET')\n",
    "# ax3.fill_between(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), -2*cum_err[:,c], 2*cum_err[:,c], \n",
    "#                  color = (0,0,1,0.2), label = 'Predicted 2σ Error Bounds')\n",
    "# # --------------------------------------------------------------------\n",
    "\n",
    "ax3.legend(loc = 'lower left')\n",
    "ax3.set_title(\"Predicted vs Actual Error in x\")\n",
    "ax3.set_xlabel(\"time (s)\", **font)\n",
    "ax3.set_ylabel(\"GPS/INS Baseline x - Odometry Estimate x (m)\", **font)\n",
    "# ax3.set_ylim([-0.07,0.07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test where points are inside spherical cell...\n",
    "# print(it.cloud1_tensor_spherical)\n",
    "maxtheta = tf.constant([[0.2],[0.7]])\n",
    "maxr = tf.constant([[0.5],[2.]])\n",
    "\n",
    "ans1 = tf.greater(it.cloud1_tensor_spherical[:,1], maxtheta)\n",
    "# print(ans1)\n",
    "ans2 = tf.less(it.cloud1_tensor_spherical[:,0], maxr)\n",
    "# print(ans2)\n",
    "combined = tf.Variable([ans1, ans2])\n",
    "# print(combined)\n",
    "ans3 = tf.math.reduce_all(combined, axis = 1)\n",
    "\n",
    "print(ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate each element of an n*1 vector 3 times\n",
    "t = tf.linspace(0,5,6)[:,None]\n",
    "print(t)\n",
    "\n",
    "test  = tf.tile(t, [3,1])\n",
    "# print(test)\n",
    "test2 = tf.reshape(tf.transpose(tf.reshape(test, [3,-1])), [-1,1])\n",
    "print(test2)\n",
    "test3 = tf.reshape(tf.transpose(tf.reshape(test, [3,-1])), [-1,3])\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate each element of an n*3 vector 3 times\n",
    "t = tf.linspace(1,5,5)\n",
    "t = tf.transpose(tf.Variable([t, 2*t, 3*t]))\n",
    "print(t)\n",
    "\n",
    "test  = tf.tile(t, [4,1])\n",
    "# print(test)\n",
    "\n",
    "test = tf.reshape(tf.transpose(test), [3, 4, -1])\n",
    "# print(test)\n",
    "\n",
    "test = tf.transpose(test, [2,1,0])\n",
    "# print(test)\n",
    "\n",
    "test = tf.reshape(test, [-1,3])\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MC sim to compare performance estimation in \"realistic\" scenes with flat vs curved surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "c1_OG = np.loadtxt(\"scene2_scan1.txt\", dtype = float) #thin cylinders\n",
    "c2_OG = np.loadtxt(\"scene2_scan2.txt\", dtype = float)\n",
    "# c1_OG = np.loadtxt(\"scene3_scan1.txt\", dtype = float) #rectangles\n",
    "# c2_OG = np.loadtxt(\"scene3_scan2.txt\", dtype = float)\n",
    "# c1 = np.loadtxt(\"scene4_scan1.txt\", dtype = float) #cylinders\n",
    "# c2 = np.loadtxt(\"scene4_scan2.txt\", dtype = float)\n",
    "\n",
    "xvec = np.zeros([epochs, 6])\n",
    "pred_stds = np.zeros([epochs, 6])\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"\\n -------------- Epoch\", i, \"--------------------\")\n",
    "    #add noise (if not generated when point clouds were created)\n",
    "    c1 = c1_OG + 0.02*np.random.randn(np.shape(c1_OG)[0], 3)\n",
    "    c2 = c2_OG + 0.02*np.random.randn(np.shape(c2_OG)[0], 3)  \n",
    "\n",
    "    it = ICET(cloud1 = c1, cloud2 = c2, fid = 70, niter = 20, draw = False, group = 2, RM = True)\n",
    "    xvec[i] = it.X\n",
    "    pred_stds[i] = it.pred_stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_soln_err = np.array([-0.5, 0, 0, 0, 0, 0,]) - np.mean(xvec, axis = 0)\n",
    "\n",
    "print(\"Smaller Clylindrical features, no occlusion, no outlier rejection, n=10:\\n\")\n",
    "# print(\"Rectangular features, no occlusion, no outlier rejection, n=50:\\n\")\n",
    "\n",
    "print(\"mean solution error: \\n\", mean_soln_err)\n",
    "soln_std = np.std(xvec, axis = 0)\n",
    "print(\"\\n experimentally determined std: \\n\", soln_std)\n",
    "mean_pred_std = np.mean(pred_stds, axis = 0)\n",
    "print(\"\\n predicted std: \\n\", mean_pred_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "nbins = 10\n",
    "ax.hist(xvec[:,0], nbins)\n",
    "# ax.set_title(\"Clylindrical features, no occlusion, no outlier rejection, n=50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
