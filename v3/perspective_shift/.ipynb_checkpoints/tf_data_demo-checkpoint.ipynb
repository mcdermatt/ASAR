{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup - rememeber to switch to tensorflow 2.3 kernel...\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(tf.__version__)\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load individual data numpy files\n",
    "#-------------------------------------------------------------------\n",
    "# d1_1 = np.load('C:/Users/Derm/Desktop/big/pshift/test1_scan1.npy')\n",
    "# d2_1 = np.load('C:/Users/Derm/Desktop/big/pshift/test1_scan2.npy')\n",
    "# y1 = np.load('C:/Users/Derm/Desktop/big/pshift/test1_ground_truth.npy')\n",
    "\n",
    "# d1_2 = np.load('C:/Users/Derm/Desktop/big/pshift/test2_scan1.npy')\n",
    "# d2_2 = np.load('C:/Users/Derm/Desktop/big/pshift/test2_scan2.npy')\n",
    "# y2 = np.load('C:/Users/Derm/Desktop/big/pshift/test2_ground_truth.npy')\n",
    "\n",
    "d1_1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v1_scan1.npy\")\n",
    "d2_1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v1_scan2.npy\")\n",
    "gt_1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v1_ground_truth.npy\")\n",
    "# d1_1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v3_scan1.npy\")\n",
    "# d2_1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v3_scan2.npy\")\n",
    "# gt_1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v3_ground_truth.npy\")\n",
    "\n",
    "d1_2 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_scan1.npy\")\n",
    "d2_2 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_scan2.npy\")\n",
    "gt_2 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_ground_truth.npy\")\n",
    "# d1_2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_scan1.txt\")\n",
    "# d2_2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_scan2.txt\")\n",
    "# gt_2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_ground_truth.txt\")\n",
    "\n",
    "d1 = np.append(d1_1, d1_2, axis = 0)\n",
    "d2 = np.append(d2_1, d2_2, axis = 0)\n",
    "gt = np.append(gt_1, gt_2, axis = 0)\n",
    "\n",
    "# #TODO: loop through all files in testing folder \n",
    "# #combine scans 1 and 2 from both files\n",
    "#-------------------------------------------------------------------\n",
    "#single big file\n",
    "# d1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/scan1_300k_50_samples.npy\")\n",
    "# d2 = np.load(\"C:/Users/Derm/Desktop/big/pshift/scan2_300k_50_samples.npy\")\n",
    "# gt = np.load(\"C:/Users/Derm/Desktop/big/pshift/ground_truth_300k_50_samples.npy\")\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "#reshape but don't convert to tensor\n",
    "points_per_sample = 50          #poitns sammpled from each voxel\n",
    "tsplit = 0.95                   #this fraction goes into training\n",
    "\n",
    "scan1 = np.reshape(d1, [-1, points_per_sample, 3])\n",
    "scan2 = np.reshape(d2, [-1, points_per_sample, 3])\n",
    "ntrain = int(tsplit*tf.shape(scan1)[0].numpy())\n",
    "\n",
    "x_train = np.append(scan1[:ntrain], scan2[:ntrain], axis = 1)\n",
    "x_test = np.append(scan1[ntrain:], scan2[ntrain:], axis = 1)\n",
    "# print(np.shape(x_train))\n",
    "# print(np.shape(x_test))\n",
    "\n",
    "y_train = gt[:ntrain]\n",
    "y_test = gt[ntrain:]\n",
    "# print(np.shape(y_train))\n",
    "# print(np.shape(y_test))\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train network\n",
    "from network import Net\n",
    "\n",
    "runLen = 300\n",
    "\n",
    "def scheduler(epoch, learning_rate):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3\n",
    "    if epoch < part1:\n",
    "        learning_rate = 0.002\n",
    "        return learning_rate\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        learning_rate = 0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part2:\n",
    "        learning_rate = 0.00025\n",
    "        return learning_rate\n",
    "\n",
    "model = Net()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002),\n",
    "              loss = tf.keras.losses.MeanAbsoluteError()) #was MeanSquaredError()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\"FordNetCP.kmod\", monitor = 'val_loss', save_best_only = True) \n",
    "\n",
    "log_dir = \"runs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "trace = model.fit(x = x_train, y = y_train, batch_size = 512, epochs=runLen, verbose=1, \n",
    "                  validation_split = 0.2, shuffle=True, callbacks = [cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save stuff\n",
    "# np.save(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_scan1\", d1_2)\n",
    "# np.save(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_scan2\", d2_2)\n",
    "# np.save(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v2_ground_truth\", gt_2)\n",
    "\n",
    "# d1_2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v1_scan1.txt\")\n",
    "# d2_2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v1_scan2.txt\")\n",
    "# gt_2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_Ford_v1_ground_truth.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-creation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
