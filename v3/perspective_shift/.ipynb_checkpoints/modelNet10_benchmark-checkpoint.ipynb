{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup - rememeber to switch to tensorflow 2.3 kernel...\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "import trimesh\n",
    "import time\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "%matplotlib notebook\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bottom-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took  0.014003753662109375 seconds\n"
     ]
    }
   ],
   "source": [
    "#load OFF file from ModelNet10 dir\n",
    "start = time.time()\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/sofa/train/sofa_0370.off'\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0320.off'\n",
    "\n",
    "\n",
    "M = trimesh.load(fn)\n",
    "test = trimesh.sample.sample_surface(M, 100)\n",
    "print(\"took \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acknowledged-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79defde05c4d40cb8dde1c79e8bbb2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use Vedo to plot OG and subsampled surfaces\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "\n",
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "# disp.append(Points(M.vertices, c = 'blue', r = 4))\n",
    "disp.append(Points(test[0], c = 'red', r = 5))\n",
    "toilet = Mesh(M).c(\"gray\").alpha(0.2)\n",
    "disp.append(toilet)\n",
    "\n",
    "plt1.show(disp, \"surface sampling test\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expected-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rotation matrix used to transform point clouds\n",
    "def R_tf(angs):\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat\n",
    "\n",
    "# determine euler angles from rotation matrix\n",
    "def R2Euler(mat):\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "answering-joshua",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "#generate toy dataset using all of the toilets in the ModelNet10 repository\n",
    "numMeshes = 100 #344\n",
    "ptsPerCloud = 256 #was 25 in OG method \n",
    "iterPerMesh = 100 #100  #number of times to sample clouds from each mesh\n",
    "\n",
    "#init vector to store sampled point clouds\n",
    "x = np.zeros([numMeshes*iterPerMesh, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y = np.zeros([numMeshes*iterPerMesh, 6]) #rotation and translation\n",
    "# y = np.zeros([numMeshes*iterPerMesh, 3]) #if only considering translations\n",
    "\n",
    "#scale trans and rotation params so outputs are equally weighted\n",
    "trans_scale = 10.0 #2.0\n",
    "rot_scale = 0.2 #0.2\n",
    "\n",
    "for i in range(numMeshes):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_%04d.off' %(i+1) #loop through file names\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_%04d.off' %(i+1) #loop through file names\n",
    "#     'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #debug -> only use single toilet model\n",
    "    M = trimesh.load(fn)\n",
    "\n",
    "    #more efficient to sample all points at once and then just use some for each frame\n",
    "    sam1 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get keyframe scan\n",
    "    sam2 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get new scan\n",
    "#     sam2 = sam1 + 0.01*np.random.randn(np.shape(sam1)[0], 3) #copy point locations and add some noise\n",
    "    \n",
    "    for j in range(iterPerMesh):\n",
    "        #rotate keyframe\n",
    "        angs1 = 1*tf.random.normal([3])\n",
    "        rot1 = R_tf(angs1)\n",
    "        #rotate scan 2 relative to keyframe\n",
    "        angs2 = rot_scale*tf.random.normal([3])\n",
    "#         rot2 = R_tf(angs1 + angs2) #was this (wrong??)\n",
    "        angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "        rot2 = tf.matmul(R_tf(angs1), R_tf(angs2)) #test\n",
    "        \n",
    "        # randomly grow/shrink each point cloud before translation\n",
    "        scale = 1. + 0.2*tf.random.normal([1])[0]\n",
    "\n",
    "        x[i*iterPerMesh + j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())*scale           \n",
    "            \n",
    "        trans = trans_scale*tf.random.normal([3])\n",
    "        #was this (incorrect for large angle deviation?)\n",
    "#         sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy()).dot(rot2.numpy())*scale \n",
    "        sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot2.numpy())*scale \n",
    "        x[i*iterPerMesh + j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "        #save transformation as y\n",
    "        y[i*iterPerMesh + j,:3] = trans.numpy()/trans_scale\n",
    "        y[i*iterPerMesh + j,3:] = angs2.numpy()/rot_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "necessary-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test sets, save to file\n",
    "split = 0.9\n",
    "x_train = x[:int(split*np.shape(x)[0])]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train', x_train)\n",
    "x_test = x[int(split*np.shape(x)[0]):]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test', x_test)\n",
    "y_train = y[:int(split*np.shape(y)[0])]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train', y_train)\n",
    "y_test = y[int(split*np.shape(y)[0]):]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "chronic-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9000  512    3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([9000    6], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "print(tf.shape(x_train))\n",
    "print(tf.shape(y_train))\n",
    "\n",
    "# print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-receptor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 512, 3)]          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_327 (Bat (None, 512, 3)            12        \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_328 (Bat (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 512, 512)          33280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose_31 (Te [(None, 512, 2)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 127, 4)            68        \n",
      "_________________________________________________________________\n",
      "batch_normalization_329 (Bat (None, 127, 4)            16        \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 62, 2)             34        \n",
      "_________________________________________________________________\n",
      "batch_normalization_330 (Bat (None, 62, 2)             8         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 30, 2)             14        \n",
      "_________________________________________________________________\n",
      "batch_normalization_331 (Bat (None, 30, 2)             8         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 1024)              62464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_332 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_333 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_334 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Mul_31 (TensorFl [(None, 6)]               0         \n",
      "=================================================================\n",
      "Total params: 761,254\n",
      "Trainable params: 757,520\n",
      "Non-trainable params: 3,734\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAC68363A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EAC68363A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  2/254 [..............................] - ETA: 45s - loss: 1.8854WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_train_batch_end` time: 0.3229s). Check your callbacks.\n",
      "254/254 [==============================] - ETA: 0s - loss: 0.6538WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EACFB04B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001EACFB04B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB4BC8A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB4BC8A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "254/254 [==============================] - 8s 33ms/step - loss: 0.6538 - val_loss: 0.4179\n",
      "Epoch 2/15\n",
      "253/254 [============================>.] - ETA: 0s - loss: 0.2104WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001E9C5860EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001E9C5860EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "254/254 [==============================] - 8s 33ms/step - loss: 0.2106 - val_loss: 0.2292\n",
      "Epoch 3/15\n",
      "253/254 [============================>.] - ETA: 0s - loss: 0.1828WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAAD586AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAAD586AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "254/254 [==============================] - 8s 31ms/step - loss: 0.1830 - val_loss: 0.1818\n",
      "Epoch 4/15\n",
      "253/254 [============================>.] - ETA: 0s - loss: 0.1775WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001E9C594D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001E9C594D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "254/254 [==============================] - 8s 31ms/step - loss: 0.1776 - val_loss: 0.1516\n",
      "Epoch 5/15\n",
      "253/254 [============================>.] - ETA: 0s - loss: 0.1658WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB5684288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB5684288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "254/254 [==============================] - 8s 33ms/step - loss: 0.1660 - val_loss: 0.1313\n",
      "Epoch 6/15\n",
      "254/254 [==============================] - 6s 23ms/step - loss: 0.1562 - val_loss: 0.1402\n",
      "Epoch 7/15\n",
      "253/254 [============================>.] - ETA: 0s - loss: 0.1527WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB41FE558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB41FE558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "254/254 [==============================] - 8s 31ms/step - loss: 0.1527 - val_loss: 0.1114\n",
      "Epoch 8/15\n",
      "254/254 [==============================] - 6s 22ms/step - loss: 0.1494 - val_loss: 0.1210\n",
      "Epoch 9/15\n",
      "254/254 [==============================] - 6s 23ms/step - loss: 0.1537 - val_loss: 0.1437\n",
      "Epoch 10/15\n",
      "254/254 [==============================] - 6s 22ms/step - loss: 0.1483 - val_loss: 0.1206\n",
      "Epoch 11/15\n",
      "254/254 [==============================] - 6s 23ms/step - loss: 0.1440 - val_loss: 0.1445\n",
      "Epoch 12/15\n",
      "115/254 [============>.................] - ETA: 2s - loss: 0.1616"
     ]
    }
   ],
   "source": [
    "#train network\n",
    "from network import Net\n",
    "np.random.seed(1337)\n",
    "runLen =  15 #30\n",
    "\n",
    "def scheduler(epoch, learning_rate):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "    if epoch < part1:\n",
    "        learning_rate = 0.01\n",
    "        return learning_rate\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        learning_rate = 0.005 #0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part2:\n",
    "        learning_rate = 0.00025 #0.00025\n",
    "        return learning_rate\n",
    "\n",
    "model = Net()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = tf.keras.losses.MeanAbsoluteError()) #was MeanAbsoluteError()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\"DermNet_ModelNet_benchmark_cp.kmod\", monitor = 'val_loss', save_best_only = True) \n",
    "\n",
    "log_dir = \"runs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "trace = model.fit(x = x_train, y = y_train, batch_size = 32, epochs=runLen, verbose=1, \n",
    "                  validation_split = 0.1, shuffle=True, callbacks = [cp, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Loss Plots\n",
    "from matplotlib import pyplot as plt\n",
    "fig0, ax0 = plt.subplots()\n",
    "ax0.plot(trace.history['loss'], '-')\n",
    "ax0.plot(trace.history['val_loss'], '-')\n",
    "ax0.legend(['train', 'val'], loc='upper left')\n",
    "ax0.set_xlabel('iteration')\n",
    "ax0.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "identical-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001EAB877D798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001EAB877D798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "#look at errors at never-before-seen test data generated from similar objects in ModelNet10\n",
    "guess = model.predict(x_train[:4])\n",
    "error = y_train[:4] - guess\n",
    "# print(guess)\n",
    "# print(y_train[:4])\n",
    "# print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "paperback-component",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1 512   3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Generate special test data for this visualization (evenly sampled)\n",
    "#  (doing this so we can draw the underlying model from which points were sampled)\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #0310 looks best\n",
    "M = trimesh.load(fn)\n",
    "\n",
    "n_tests = 1 #number of test samples to generate\n",
    "#init vector to store sampled point clouds\n",
    "x_test2 = np.zeros([n_tests, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y_test2 = np.zeros([n_tests, 6]) #rotation and translation\n",
    "\n",
    "sam1 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get keyframe scan\n",
    "sam2 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get new scan\n",
    "\n",
    "for j in range(n_tests):\n",
    "    angs1 = 1.0*tf.random.normal([3])    #rotate keyframe\n",
    "    rot1 = R_tf(angs1)\n",
    "    angs2 = rot_scale*tf.random.normal([3])     #rotate scan 2 relative to keyframe\n",
    "    rot2 = R_tf(angs2)\n",
    "#     rot_combined = R_tf(angs1 + angs2) #was this\n",
    "    rot_combined = tf.matmul(R_tf(angs1), R_tf(angs2))\n",
    "    \n",
    "    x_test2[j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())         \n",
    "\n",
    "    trans = trans_scale*tf.random.normal([3])\n",
    "    sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot_combined.numpy()) #transform scan\n",
    "    x_test2[j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "    #save transformation as y\n",
    "    y_test2[j,:3] = trans.numpy()/trans_scale\n",
    "    y_test2[j,3:] = angs2.numpy()/rot_scale\n",
    "print(tf.shape(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "normal-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ground truth: [ -9.07065034  -1.0239663  -12.91771054   0.24293718  -0.17147462\n",
      "  -0.05055048]\n",
      "\n",
      " estimate from DNN after 1 iteration: [-11.275255    -4.350907   -17.140577    -0.10297392  -0.15280984\n",
      "   0.4939334 ]\n",
      "\n",
      " estimate from DNN after 5 iterations:  [ -7.0188427    3.3856637  -10.069113     1.2571203    0.18172494\n",
      "  -1.2023576 ]\n",
      "------- \n",
      " Final Error: [-2.05180764 -4.40963005 -2.84859776 -1.01418307 -0.35319956  1.15180717]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8a5e91532343c788c3c86abed39b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=568, layout=Layout(height='auto', width='100%'), width=1706)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize network performance on evenly sampled data\n",
    "t = 0 #test number to draw\n",
    "niter = 5 #number of iterations to run network for\n",
    "\n",
    "plt2 = Plotter(N = 3, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp1 = [] #before estimated transformation (drawn on left)\n",
    "disp2 = [] #after 1 transformation (drawn in center)\n",
    "disp3 = [] #after niter transformations\n",
    "\n",
    "#draw first viz (untransformed set of scans)-------------------\n",
    "scan1 = Mesh(M).c(\"red\").alpha(0.1)#.rotate(90, axis = (0,0,1))\n",
    "scan1.applyTransform(rot1.numpy().T)\n",
    "disp1.append(scan1)\n",
    "disp1.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "\n",
    "scan2 = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2.applyTransform(rot_combined.numpy().T)\n",
    "# scan2.pos(y_test2[t,0], y_test2[t,1], y_test2[t,2])\n",
    "scan2.pos(y_test2[t,0]*trans_scale, y_test2[t,1]*trans_scale, y_test2[t,2]*trans_scale)\n",
    "disp1.append(scan2)\n",
    "disp1.append(Points(x_test2[0,ptsPerCloud:], c = 'blue', r = 5))\n",
    "\n",
    "#FOR DEBUG - draw ground truth transformation in green so I can be sure which order is correct\n",
    "correct = (x_test2[0,ptsPerCloud:] - y_test2[0,:3]*trans_scale).dot(R_tf(y_test2[0,3:]*rot_scale).numpy().T)\n",
    "temp = Points(correct, c = 'green', r = 5)\n",
    "disp1.append(temp)\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "#draw esatimated soln after 1 iteration ------------------------\n",
    "ans_cum = model.predict(x_test2)[t]\n",
    "ans_cum[:3] = ans_cum[:3]*trans_scale\n",
    "ans_cum[3:] = ans_cum[3:]*rot_scale\n",
    "\n",
    "scan2_transformed = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "soln_est_rot = R_tf(ans_cum[3:])\n",
    "scan2_transformed.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T)) #test\n",
    "scan2_transformed.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                      y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                      y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp2.append(scan2_transformed)\n",
    "\n",
    "\n",
    "disp2.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T))\n",
    "\n",
    "#add points\n",
    "scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "disp2.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "disp2.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "# disp2.append(Points((x_test2[0,ptsPerCloud:]).dot(soln_est_rot.numpy().T) - ans[:3], c = 'blue', r = 5))\n",
    "gt = y_test2[t].copy()\n",
    "gt[:3] = gt[:3]*trans_scale\n",
    "gt[3:] = gt[3:]*rot_scale\n",
    "print(\"\\n ground truth:\", gt)\n",
    "print(\"\\n estimate from DNN after 1 iteration:\", ans_cum)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "# draw estiamted soln after n interations-------------------------\n",
    "for i in range(niter):\n",
    "    #replace initial scan2 with transformed pc2 as input to network\n",
    "    inlayer = tf.concat([x_test2[0][:ptsPerCloud], scan2_pts_transformed], axis = 0)[None, :, :]\n",
    "    ans_i = model.predict(inlayer)[0]\n",
    "    ans_i[:3] = ans_i[:3]*trans_scale\n",
    "    ans_i[3:] = ans_i[3:]*rot_scale\n",
    "    \n",
    "#     soln_est_rot = R_tf(ans_cum[3:]) #wrong?\n",
    "    soln_est_rot = tf.matmul(R_tf(ans_i[3:]), soln_est_rot)\n",
    "#     ans_cum = ans_cum + ans_i\n",
    "    ans_cum[:3] = ans_cum[:3] + ans_i[:3]\n",
    "#     ans_cum[3:] = ans_cum[3:].dot(ans_i[3:]) #wrong\n",
    "    ans_cum[3:] = R2Euler(soln_est_rot)[:,0]\n",
    "#     print(R2Euler(soln_est_rot))\n",
    "    scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "    \n",
    "print(\"\\n estimate from DNN after\", niter, \"iterations: \", ans_cum) \n",
    "\n",
    "disp3.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T))\n",
    "scan2_transformed_again = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed_again.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T)) #test\n",
    "scan2_transformed_again.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                            y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                            y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp3.append(scan2_transformed_again)\n",
    "disp3.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "disp3.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "\n",
    "print(\"------- \\n Final Error:\", gt - ans_cum)\n",
    "# #---------------------------------------------------------------\n",
    "\n",
    "    \n",
    "plt2.show(disp1, \"initial transformation\", at = 0)\n",
    "plt2.show(disp2, \"after 1 iteration\", at = 1)\n",
    "plt2.show(disp3, \"after 5 iterations\", at = 2)\n",
    "ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "composed-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB497EE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001EAB497EE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark.kmod\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"DermNet_ModelNet_benchmark.kmod\") #256 pts per cloud, MAE =~ 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "embedded-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.5886282  -0.75547487  0.28770593]\n",
      " [-0.03155808 -0.3770966  -0.9256362 ]\n",
      " [ 0.8077877   0.5357761  -0.24581096]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.5879922  -0.76723665  0.2561503 ]\n",
      " [ 0.02447033 -0.29966033 -0.9537321 ]\n",
      " [ 0.80849636  0.5670551  -0.1574234 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Can't just add euler angles in 3D...\n",
    "a = tf.constant([[1., 2., 3.]])\n",
    "A = R_tf(a)\n",
    "b = tf.constant([[0.3, 0.2, 0.1]])\n",
    "B = R_tf(b)\n",
    "print(tf.matmul(A, B))\n",
    "print(R_tf(a + b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "delayed-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41198224  0.05872664  0.9092974 ]\n",
      " [-0.6812427  -0.6428728   0.35017547]\n",
      " [ 0.6051272  -0.76371837 -0.22484507]]\n",
      "[[ 0.41198224  0.05872662  0.9092975 ]\n",
      " [-0.6812428  -0.6428728   0.35017556]\n",
      " [ 0.6051273  -0.7637183  -0.22484513]]\n"
     ]
    }
   ],
   "source": [
    "print(A.numpy().T)\n",
    "print(np.linalg.pinv(A.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "quiet-absorption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 0.41198224, -0.6812427 ,  0.6051272 ],\n",
       "       [ 0.05872664, -0.6428728 , -0.76371837],\n",
       "       [ 0.9092974 ,  0.35017547, -0.22484507]], dtype=float32)>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(R_tf(tf.constant([0.,0.,0.])), R_tf(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-northern",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
