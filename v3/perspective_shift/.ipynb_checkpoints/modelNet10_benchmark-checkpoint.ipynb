{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Derm\\anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup - rememeber to switch to tensorflow 2.3 kernel...\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "import trimesh\n",
    "import time\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "%matplotlib notebook\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bottom-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took  0.028012514114379883 seconds\n"
     ]
    }
   ],
   "source": [
    "#load OFF file from ModelNet10 dir\n",
    "start = time.time()\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/sofa/train/sofa_0370.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0320.off'\n",
    "\n",
    "\n",
    "M = trimesh.load(fn)\n",
    "test = trimesh.sample.sample_surface(M, 100)\n",
    "print(\"took \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963c0cad7cc04fdc952df94ce13a4aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use Vedo to plot OG and subsampled surfaces\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "\n",
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "# disp.append(Points(M.vertices, c = 'blue', r = 4))\n",
    "disp.append(Points(test[0], c = 'red', r = 5))\n",
    "toilet = Mesh(M).c(\"gray\").alpha(0.2)\n",
    "disp.append(toilet)\n",
    "\n",
    "plt1.show(disp, \"surface sampling test\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expected-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rotation matrix used to transform point clouds\n",
    "def R_tf(angs):\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat\n",
    "\n",
    "# determine euler angles from rotation matrix\n",
    "def R2Euler(mat):\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "answering-joshua",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "#generate toy dataset using all of the toilets in the ModelNet10 repository\n",
    "numMeshes = 300 #344\n",
    "ptsPerCloud = 256 #was 25 in OG method \n",
    "iterPerMesh = 200 #100  #number of times to sample clouds from each mesh\n",
    "\n",
    "#init vector to store sampled point clouds\n",
    "x = np.zeros([numMeshes*iterPerMesh, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y = np.zeros([numMeshes*iterPerMesh, 6]) #rotation and translation\n",
    "# y = np.zeros([numMeshes*iterPerMesh, 3]) #if only considering translations\n",
    "\n",
    "#scale trans and rotation params so outputs are equally weighted\n",
    "trans_scale = 10.0 #2.0\n",
    "rot_scale = 0.05 #0.2\n",
    "\n",
    "for i in range(numMeshes):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_%04d.off' %(i+1) #loop through file names\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0059.off'\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #debug -> only use single toilet model\n",
    "    M = trimesh.load(fn)\n",
    "\n",
    "    #more efficient to sample all points at once and then just use some for each frame\n",
    "    sam1 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get keyframe scan\n",
    "    sam2 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get new scan\n",
    "#     sam2 = sam1 + 0.01*np.random.randn(np.shape(sam1)[0], 3) #copy point locations and add some noise\n",
    "    \n",
    "    for j in range(iterPerMesh):\n",
    "        #rotate keyframe\n",
    "        angs1 = 0.5*tf.random.normal([3])\n",
    "        rot1 = R_tf(angs1)\n",
    "        #rotate scan 2 relative to keyframe\n",
    "        angs2 = rot_scale*tf.random.normal([3])\n",
    "#         rot2 = R_tf(angs1 + angs2) #was this (wrong??)\n",
    "        angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "#         rot2 = tf.matmul(R_tf(angs1), R_tf(angs2)) #was this (wrong??)\n",
    "        rot2 = tf.matmul(R_tf(angs2), R_tf(angs1)) #test\n",
    "\n",
    "        \n",
    "        # randomly grow/shrink each point cloud before translation\n",
    "        scale = 1. + 0.2*tf.random.normal([1])[0]\n",
    "\n",
    "        x[i*iterPerMesh + j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())*scale           \n",
    "            \n",
    "        trans = trans_scale*tf.random.normal([3])\n",
    "        #was this (incorrect for large angle deviation?)\n",
    "#         sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy()).dot(rot2.numpy())*scale \n",
    "        sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot2.numpy())*scale \n",
    "        x[i*iterPerMesh + j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "        #save transformation as y\n",
    "        y[i*iterPerMesh + j,:3] = trans.numpy()/trans_scale\n",
    "        y[i*iterPerMesh + j,3:] = angs2.numpy()/rot_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "necessary-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test sets, save to file\n",
    "split = 0.9\n",
    "x_train = x[:int(split*np.shape(x)[0])]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train', x_train)\n",
    "x_test = x[int(split*np.shape(x)[0]):]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test', x_test)\n",
    "y_train = y[:int(split*np.shape(y)[0])]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train', y_train)\n",
    "y_test = y[int(split*np.shape(y)[0]):]\n",
    "np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "chronic-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([54000   512     3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([54000     6], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "print(tf.shape(x_train))\n",
    "print(tf.shape(y_train))\n",
    "\n",
    "# print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "after-receptor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        [(None, 512, 3)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims_33 (T [(None, 512, 3, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 512, 1, 64)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_360 (Bat (None, 512, 1, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 512, 1, 64)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_361 (Bat (None, 512, 1, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 512, 1, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_362 (Bat (None, 512, 1, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 512, 1, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_363 (Bat (None, 512, 1, 512)       2048      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_32 (Tens [(None, 512, 512)]        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose_35 (Te [(None, 512, 2)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 127, 4)            68        \n",
      "_________________________________________________________________\n",
      "batch_normalization_364 (Bat (None, 127, 4)            16        \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 127, 64)           320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_365 (Bat (None, 127, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 62, 2)             514       \n",
      "_________________________________________________________________\n",
      "batch_normalization_366 (Bat (None, 62, 2)             8         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 62, 64)            192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_367 (Bat (None, 62, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 30, 2)             386       \n",
      "_________________________________________________________________\n",
      "batch_normalization_368 (Bat (None, 30, 2)             8         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 30, 64)            192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_369 (Bat (None, 30, 64)            256       \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "batch_normalization_370 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_371 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Mul_35 (TensorFl [(None, 6)]               0         \n",
      "=================================================================\n",
      "Total params: 594,222\n",
      "Trainable params: 591,646\n",
      "Non-trainable params: 2,576\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FA13351288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001FA13351288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.2913WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FA12E21948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FA12E21948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1449AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1449AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 45s 118ms/step - loss: 0.2913 - val_loss: 0.4201\n",
      "Epoch 2/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1381WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA17693A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA17693A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 47s 124ms/step - loss: 0.1381 - val_loss: 0.1203\n",
      "Epoch 3/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1186WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1056AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1056AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 45s 117ms/step - loss: 0.1186 - val_loss: 0.0968\n",
      "Epoch 4/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1085WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FAA55F03A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FAA55F03A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 48s 127ms/step - loss: 0.1085 - val_loss: 0.0856\n",
      "Epoch 5/15\n",
      "380/380 [==============================] - 41s 107ms/step - loss: 0.1011 - val_loss: 0.1051\n",
      "Epoch 6/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0956WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FAA4B8CAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FAA4B8CAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 47s 124ms/step - loss: 0.0956 - val_loss: 0.0841\n",
      "Epoch 7/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0944WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1271F168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1271F168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 45s 119ms/step - loss: 0.0944 - val_loss: 0.0811\n",
      "Epoch 8/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0914WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1449A288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA1449A288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 44s 116ms/step - loss: 0.0914 - val_loss: 0.0794\n",
      "Epoch 9/15\n",
      "380/380 [==============================] - 41s 107ms/step - loss: 0.0891 - val_loss: 0.0906\n",
      "Epoch 10/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0857WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA2C1E6048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA2C1E6048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 44s 117ms/step - loss: 0.0857 - val_loss: 0.0760\n",
      "Epoch 11/15\n",
      "380/380 [==============================] - 40s 106ms/step - loss: 0.0894 - val_loss: 0.0835\n",
      "Epoch 12/15\n",
      "380/380 [==============================] - 40s 106ms/step - loss: 0.0858 - val_loss: 0.0808\n",
      "Epoch 13/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0803WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA29E68288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA29E68288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 43s 114ms/step - loss: 0.0803 - val_loss: 0.0731\n",
      "Epoch 14/15\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.0814WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FAA5E36C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FAA5E36C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n",
      "380/380 [==============================] - 44s 115ms/step - loss: 0.0814 - val_loss: 0.0719\n",
      "Epoch 15/15\n",
      "380/380 [==============================] - 40s 105ms/step - loss: 0.0800 - val_loss: 0.0867\n"
     ]
    }
   ],
   "source": [
    "#train network\n",
    "from network import Net #mine\n",
    "# from pcrnet import Network as Net #PCR-Net baseline\n",
    "np.random.seed(1337)\n",
    "runLen =  15 #30\n",
    "\n",
    "def scheduler(epoch, learning_rate):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "    if epoch < part1:\n",
    "        learning_rate = 0.01\n",
    "        return learning_rate\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        learning_rate = 0.005 #0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part2:\n",
    "        learning_rate = 0.00025 #0.00025\n",
    "        return learning_rate\n",
    "\n",
    "model = Net()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = tf.keras.losses.MeanAbsoluteError()) #was MeanAbsoluteError()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\"DermNet_ModelNet_benchmark_cp.kmod\", monitor = 'val_loss', save_best_only = True) \n",
    "\n",
    "log_dir = \"runs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "trace = model.fit(x = x_train, y = y_train, batch_size = 128, epochs=runLen, verbose=1, \n",
    "                  validation_split = 0.1, shuffle=True, callbacks = [cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "minute-police",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network Loss Plots\n",
    "from matplotlib import pyplot as plt\n",
    "fig0, ax0 = plt.subplots()\n",
    "ax0.plot(trace.history['loss'], '-')\n",
    "ax0.plot(trace.history['val_loss'], '-')\n",
    "ax0.legend(['train', 'val'], loc='upper left')\n",
    "ax0.set_xlabel('iteration')\n",
    "ax0.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "wound-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-5.58008181  4.2474526   1.54906792], shape=(3,), dtype=float64)\n",
      "tf.Tensor([-5.92326622  3.40196312  1.40976369], shape=(3,), dtype=float64)\n",
      "tf.Tensor([0.3431844  0.84548947 0.13930423], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#temp- get center location of each point cloud to make sure net isn't just matching centroids\n",
    "idx = int(np.floor(100*np.random.randn()))\n",
    "mu1 = tf.math.reduce_mean(x_train[idx, :ptsPerCloud, :], axis = 0)\n",
    "mu2 = tf.math.reduce_mean(x_train[idx, ptsPerCloud:, :], axis = 0) - (y_train[idx,:3]*trans_scale)\n",
    "print(mu1)\n",
    "print(mu2)\n",
    "center_error = mu1 - mu2\n",
    "print(center_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "identical-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FA12DADAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FA12DADAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "#look at errors at never-before-seen test data generated from similar objects in ModelNet10\n",
    "guess = model.predict(x_train[:4])\n",
    "error = y_train[:4] - guess\n",
    "# print(guess)\n",
    "# print(y_train[:4])\n",
    "# print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "paperback-component",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1 512   3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Generate special test data for this visualization (evenly sampled)\n",
    "#  (doing this so we can draw the underlying model from which points were sampled)\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0310.off' #0310 looks best\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0199.off' \n",
    "\n",
    "M = trimesh.load(fn)\n",
    "\n",
    "n_tests = 1 #number of test samples to generate\n",
    "#init vector to store sampled point clouds\n",
    "x_test2 = np.zeros([n_tests, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y_test2 = np.zeros([n_tests, 6]) #rotation and translation\n",
    "\n",
    "sam1 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get keyframe scan\n",
    "sam2 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get new scan\n",
    "\n",
    "for j in range(n_tests):\n",
    "    angs1 = 0.5*tf.random.normal([3])    #rotate keyframe\n",
    "    rot1 = R_tf(angs1)\n",
    "    angs2 = rot_scale*tf.random.normal([3])     #rotate scan 2 relative to keyframe\n",
    "    angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "    rot2 = R_tf(angs2)\n",
    "    #     rot_combined = R_tf(angs1 + angs2) #was this\n",
    "    rot_combined = tf.matmul(R_tf(angs1), R_tf(angs2))\n",
    "    \n",
    "    x_test2[j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())         \n",
    "\n",
    "    trans = trans_scale*tf.random.normal([3])\n",
    "    #was this\n",
    "    sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot_combined.numpy()) #transform scan\n",
    "    #DEBUG\n",
    "#     sam2_j = (sam2[j*ptsPerCloud:(j+1)*ptsPerCloud]+trans.numpy()).dot(rot_combined.numpy()) #transform scan\n",
    "    x_test2[j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "    #save transformation as y\n",
    "    y_test2[j,:3] = trans.numpy()/trans_scale\n",
    "    y_test2[j,3:] = angs2.numpy()/rot_scale\n",
    "print(tf.shape(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "normal-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FA12DADAF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " ground truth: [ -2.93450415 -11.67715192  -7.66426742   0.           0.\n",
      "   0.        ]\n",
      "\n",
      " estimate from DNN after 1 iteration: [-2.1420038e+00 -8.5850754e+00 -5.8727903e+00  1.1023683e-04\n",
      " -2.3872717e-05  4.5969526e-05]\n",
      "------- \n",
      " Final Error: [-7.24967837e-01 -1.86784196e+00 -3.77005935e-01  5.32448641e-04\n",
      " -4.34882037e-04  3.08492221e-04]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fbea89231e4e65bb7c3429c3e703b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=568, layout=Layout(height='auto', width='100%'), width=1706)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize network performance on evenly sampled data\n",
    "t = 0 #test number to draw\n",
    "niter = 5 #number of iterations to run network for\n",
    "\n",
    "plt2 = Plotter(N = 3, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp1 = [] #before estimated transformation (drawn on left)\n",
    "disp2 = [] #after 1 transformation (drawn in center)\n",
    "disp3 = [] #after niter transformations\n",
    "\n",
    "#draw first viz (untransformed set of scans)-------------------\n",
    "scan1 = Mesh(M).c(\"red\").alpha(0.1)#.rotate(90, axis = (0,0,1))\n",
    "scan1.applyTransform(rot1.numpy().T)\n",
    "disp1.append(scan1)\n",
    "disp1.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "\n",
    "scan2 = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2.applyTransform(rot_combined.numpy().T)\n",
    "# scan2.pos(y_test2[t,0], y_test2[t,1], y_test2[t,2])\n",
    "scan2.pos(y_test2[t,0]*trans_scale, y_test2[t,1]*trans_scale, y_test2[t,2]*trans_scale)\n",
    "disp1.append(scan2)\n",
    "disp1.append(Points(x_test2[0,ptsPerCloud:], c = 'blue', r = 5))\n",
    "\n",
    "#FOR DEBUG - draw ground truth transformation in green so I can be sure which order is correct\n",
    "# correct = (x_test2[0,ptsPerCloud:] - y_test2[0,:3]*trans_scale).dot(R_tf(y_test2[0,3:]*rot_scale).numpy().T)\n",
    "# temp = Points(correct, c = 'green', r = 5)\n",
    "# disp1.append(temp)\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "#draw esatimated soln after 1 iteration ------------------------\n",
    "ans_cum = model.predict(x_test2)[t]\n",
    "ans_cum[:3] = ans_cum[:3]*trans_scale\n",
    "ans_cum[3:] = ans_cum[3:]*rot_scale\n",
    "\n",
    "#draw meshes\n",
    "soln_est_rot = R_tf(ans_cum[3:])\n",
    "scan2_transformed = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T))\n",
    "scan2_transformed.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                      y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                      y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp2.append(scan2_transformed)\n",
    "disp2.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T)) #draw keyframe\n",
    "\n",
    "#add points\n",
    "scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "# scan2_pts_transformed = (x_test2[0,ptsPerCloud:]).dot(soln_est_rot.numpy().T) - ans_cum[:3]\n",
    "disp2.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "\n",
    "disp2.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "gt = y_test2[t].copy()\n",
    "gt[:3] = gt[:3]*trans_scale\n",
    "gt[3:] = gt[3:]*rot_scale\n",
    "print(\"\\n ground truth:\", gt)\n",
    "print(\"\\n estimate from DNN after 1 iteration:\", ans_cum)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "# draw estiamted soln after n interations-------------------------\n",
    "#TODO: need to figure out more compat way of representing sequential 6DOF transforms\n",
    "for i in range(niter):\n",
    "    #replace initial scan2 with transformed pc2 as input to network\n",
    "    inlayer = tf.concat([x_test2[0][:ptsPerCloud], scan2_pts_transformed], axis = 0)[None, :, :]\n",
    "    ans_i = model.predict(inlayer)[0]\n",
    "    ans_i[:3] = ans_i[:3]*trans_scale\n",
    "    ans_i[3:] = ans_i[3:]*rot_scale\n",
    "    \n",
    "#     soln_est_rot = tf.matmul(R_tf(ans_i[3:]), soln_est_rot)\n",
    "    soln_est_rot = R_tf(ans_i[3:]) #test\n",
    "    ans_cum[:3] = ans_cum[:3] + ans_i[:3]\n",
    "#     ans_cum[3:] = R2Euler(soln_est_rot)[:,0]\n",
    "    ans_cum[3:] = R2Euler(tf.matmul(R_tf(ans_i[3:]), soln_est_rot))[:,0]\n",
    "    scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "    \n",
    "# print(\"\\n estimate from DNN after\", niter, \"iterations: \", ans_cum) \n",
    "\n",
    "scan2_transformed_again = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed_again.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T)) #test\n",
    "scan2_transformed_again.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                            y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                            y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp3.append(scan2_transformed_again)\n",
    "disp3.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "disp3.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "disp3.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T)) #keyframe\n",
    "\n",
    "print(\"------- \\n Final Error:\", gt - ans_cum)\n",
    "# #---------------------------------------------------------------\n",
    "\n",
    "    \n",
    "plt2.show(disp1, \"initial transformation\", at = 0)\n",
    "plt2.show(disp2, \"after 1 iteration\", at = 1)\n",
    "plt2.show(disp3, \"after 5 iterations\", at = 2)\n",
    "ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "tested-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.1264965  -0.90080355  1.40520944]]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(x_test2[:ptsPerCloud], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "composed-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA99647678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001FA99647678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_trans_only.kmod\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"DermNet_ModelNet_benchmark.kmod\") #256 pts per cloud, MAE =~ 0.31\n",
    "# model.save(\"DermNet_ModelNet_benchmark.h5\") #allows viz with Netron\n",
    "\n",
    "\n",
    "# model.save(\"DermNet_ModelNet_trans_only.kmod\") #256 pts per cloud, MAE = 0.0719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't just add euler angles in 3D...\n",
    "a = tf.constant([[1., 2., 3.]])\n",
    "A = R_tf(a)\n",
    "b = tf.constant([[0.3, 0.2, 0.1]])\n",
    "B = R_tf(b)\n",
    "print(tf.matmul(A, B))\n",
    "print(R_tf(a + b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.numpy().T)\n",
    "print(np.linalg.pinv(A.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(R_tf(tf.constant([0.,0.,0.])), R_tf(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-smoke",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
