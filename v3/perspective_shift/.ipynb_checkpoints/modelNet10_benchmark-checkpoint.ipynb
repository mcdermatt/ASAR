{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup - rememeber to switch to tensorflow 2.3 kernel...\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "import trimesh\n",
    "import time\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "%matplotlib notebook\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bottom-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took  0.01599884033203125 seconds\n"
     ]
    }
   ],
   "source": [
    "#load OFF file from ModelNet10 dir\n",
    "start = time.time()\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/sofa/train/sofa_0370.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0320.off'\n",
    "\n",
    "\n",
    "M = trimesh.load(fn)\n",
    "test = trimesh.sample.sample_surface(M, 100)\n",
    "print(\"took \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4882cb74a64a5aa9341010d6093dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use Vedo to plot OG and subsampled surfaces\n",
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "# disp.append(Points(M.vertices, c = 'blue', r = 4))\n",
    "disp.append(Points(test[0], c = 'red', r = 5))\n",
    "toilet = Mesh(M).c(\"gray\").alpha(0.2)\n",
    "disp.append(toilet)\n",
    "\n",
    "# disp.append(Points(x_train[50,:,:].numpy(), c = 'blue', r = 5)) #test drawing unknown point cloud\n",
    "\n",
    "plt1.show(disp, \"surface sampling test\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expected-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rotation matrix used to transform point clouds\n",
    "def R_tf(angs):\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat\n",
    "\n",
    "# determine euler angles from rotation matrix\n",
    "def R2Euler(mat):\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "answering-joshua",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#generate toy dataset using all of the toilets in the ModelNet10 repository\n",
    "numMeshes = 20 #300 #344\n",
    "ptsPerCloud = 100 #was 25 in OG method \n",
    "iterPerMesh = 100 #number of times to sample clouds from each mesh\n",
    "\n",
    "#init vector to store sampled point clouds\n",
    "x = np.zeros([numMeshes*iterPerMesh, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y = np.zeros([numMeshes*iterPerMesh, 6]) #rotation and translation\n",
    "# y = np.zeros([numMeshes*iterPerMesh, 3]) #if only considering translations\n",
    "\n",
    "#scale trans and rotation params so outputs are equally weighted\n",
    "trans_scale = 10.0 #2.0\n",
    "rot_scale = 0.2 #0.2\n",
    "\n",
    "for i in range(numMeshes):\n",
    "    if i % 2 == 0:\n",
    "        print(i)\n",
    "    fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_%04d.off' %(i+1) #loop through file names\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0059.off'\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #debug -> only use single toilet model\n",
    "    M = trimesh.load(fn)\n",
    "\n",
    "    #more efficient to sample all points at once and then just use some for each frame\n",
    "    sam1 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get keyframe scan\n",
    "    sam2 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get new scan\n",
    "#     sam2 = sam1 + 0.01*np.random.randn(np.shape(sam1)[0], 3) #copy point locations and add some noise\n",
    "    \n",
    "    for j in range(iterPerMesh):\n",
    "        #rotate keyframe\n",
    "        angs1 = 0.5*tf.random.normal([3])\n",
    "        rot1 = R_tf(angs1)\n",
    "        #rotate scan 2 relative to keyframe\n",
    "        angs2 = rot_scale*tf.random.normal([3])\n",
    "#         rot2 = R_tf(angs1 + angs2) #was this (wrong??)\n",
    "        angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "#         rot2 = tf.matmul(R_tf(angs1), R_tf(angs2)) #was this (wrong??)\n",
    "        rot2 = tf.matmul(R_tf(angs2), R_tf(angs1)) #test\n",
    "\n",
    "        \n",
    "        # randomly grow/shrink each point cloud before translation\n",
    "        scale = 1. + 0.2*tf.random.normal([1])[0]\n",
    "\n",
    "        x[i*iterPerMesh + j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())*scale           \n",
    "            \n",
    "        trans = trans_scale*tf.random.normal([3])\n",
    "        #was this (incorrect for large angle deviation?)\n",
    "#         sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy()).dot(rot2.numpy())*scale \n",
    "        sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot2.numpy())*scale \n",
    "        x[i*iterPerMesh + j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "        #save transformation as y\n",
    "        y[i*iterPerMesh + j,:3] = trans.numpy()/trans_scale\n",
    "        y[i*iterPerMesh + j,3:] = angs2.numpy()/rot_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "necessary-ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "#split into train and test sets, save to file\n",
    "split = 0.9\n",
    "x_train = x[:int(split*np.shape(x)[0])]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train', x_train)\n",
    "x_test = x[int(split*np.shape(x)[0]):]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test', x_test)\n",
    "y_train = y[:int(split*np.shape(y)[0])]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train', y_train)\n",
    "y_test = y[int(split*np.shape(y)[0]):]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test', y_test)\n",
    "\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from memory\n",
    "numMeshes = 300 #344\n",
    "ptsPerCloud = 256 #50 #was 25 in OG method \n",
    "iterPerMesh = 200 #100  #number of times to sample clouds from each mesh\n",
    "trans_scale = 10.0 #2.0\n",
    "rot_scale = 0.2 #0.2\n",
    "\n",
    "x_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train.npy')\n",
    "y_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train.npy')\n",
    "x_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test.npy')\n",
    "y_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test.npy')\n",
    "\n",
    "# x_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train_trans_only.npy')\n",
    "# y_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train_trans_only.npy')\n",
    "# x_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test_trans_only.npy')\n",
    "# y_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test_trans_only.npy')\n",
    "\n",
    "#limit ptsPerCloud of loaded data -----------------------------------\n",
    "halflen = np.shape(x_train)[1]//2\n",
    "x_train = np.concatenate((x_train[:,:ptsPerCloud,:], x_train[:,halflen:(halflen + ptsPerCloud),:]), axis = 1)\n",
    "halflen = np.shape(x_test)[1]//2\n",
    "x_test = np.concatenate((x_test[:,:ptsPerCloud,:], x_test[:,halflen:(halflen + ptsPerCloud),:]), axis = 1)\n",
    "print(np.shape(x_train)) #starts out at 256 per cloud\n",
    "print(np.shape(y_train)) \n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))\n",
    "#---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-match",
   "metadata": {},
   "source": [
    "### Load Lidar Data (Alternate Option) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on data generated from KITTI dataset\n",
    "#(from drive 005 snippet)\n",
    "# d1 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_scan1_50_shifted.txt\")\n",
    "# d2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_scan2_50_shifted.txt\")\n",
    "# gt = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_ground_truth_50_shifted.txt\")\n",
    "\n",
    "# #full urban drive (much larger)\n",
    "# d1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_FULL_scan1_to400.npy\")\n",
    "# d2 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_FULL_scan2_to400.npy\")\n",
    "# gt = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_FULL_ground_truth_to400.npy\")\n",
    "\n",
    "# toy data set generated in MatLab\n",
    "d1 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/scan1_1k.txt\")\n",
    "d2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/scan2_1k.txt\")\n",
    "gt = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ground_truth_1k.txt\")\n",
    "\n",
    "points_per_sample = 50  #num pts per scan - defined in MatLab script\n",
    "scan1 = tf.reshape(tf.convert_to_tensor(d1), [-1, points_per_sample, 3])\n",
    "scan2 = tf.reshape(tf.convert_to_tensor(d2), [-1, points_per_sample, 3])\n",
    "gt = tf.convert_to_tensor(gt)\n",
    "\n",
    "#split data into training and validation sets\n",
    "tsplit = 0.95 #this fraction goes into training\n",
    "ntrain = int(tsplit*tf.shape(scan1)[0].numpy())\n",
    "x_train = tf.concat((scan1[:ntrain], scan2[:ntrain]), axis = 1)\n",
    "x_test = tf.concat((scan1[ntrain:], scan2[ntrain:]), axis = 1)\n",
    "y_train = gt[:ntrain]\n",
    "y_test = gt[ntrain:]\n",
    "\n",
    "print(tf.shape(y_train))\n",
    "y_train = tf.concat((y_train, tf.zeros(tf.shape(y_train), dtype = tf.double)), axis = 1)\n",
    "# y_train = tf.concat((y_train, tf.zeros(tf.shape(y_train), dtype = tf.float32)), axis = 1)\n",
    "print(tf.shape(y_train))\n",
    "print(tf.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "print(tf.shape(x_train))\n",
    "print(tf.shape(y_train))\n",
    "\n",
    "#TEST\n",
    "#just translation case ------------\n",
    "# y_train = y_train[:,:3]\n",
    "# print(tf.shape(y_train))\n",
    "#----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e02c9",
   "metadata": {},
   "source": [
    "## Create TF dataset to augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8f65b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 200, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>\n",
      "(200, 3)\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 200, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "def augment(points, gt):\n",
    "    print(np.shape(points))\n",
    "    # jitter points\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points in first point cloud\n",
    "    points = tf.concat([tf.random.shuffle(points[:256]), tf.random.shuffle(points[256:])], axis = 0)\n",
    "#     print(test)\n",
    "    return points, gt\n",
    "\n",
    "NUM_POINTS = 256\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(len(x_train)).map(augment).batch(BATCH_SIZE)\n",
    "print(train_dataset)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.shuffle(len(x_test)).map(augment).batch(BATCH_SIZE)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36bc46",
   "metadata": {},
   "source": [
    "# Train Network\n",
    "\n",
    "| MAE      | Batch Size     |    Epochs | Train Dataset | Notes | Filename|\n",
    "| ----------- | ----------- | --------- | --------   | | |\n",
    "| 0.055  | 64 |  30   | toilet 69, 5k samles | 50 pts per scan    | - |\n",
    "| 0.067  | 16 |  30   | toilet 69, 1800 samles | 512 pts per scan    | - |\n",
    "| 0.11  | 64 |  30   | 20 toilets, 100 PCs each |Constant dataset tf.data.map(augment)| - |\n",
    "| 0.065  | 64 |  30   | 20 toilets, 100 PCs each |Using tf.data.map(augment)| - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "after-receptor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " tf.expand_dims_6 (TFOpLambd  (None, 200, 3, 1)        0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 200, 1, 64)        256       \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 200, 1, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 200, 1, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 200, 1, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 200, 1, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 200, 1, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 200, 1, 128)       8320      \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 200, 1, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 2, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1024)              263168    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 6)                 1542      \n",
      "                                                                 \n",
      " tf.math.multiply_6 (TFOpLam  (None, 6)                0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,264,582\n",
      "Trainable params: 2,257,286\n",
      "Non-trainable params: 7,296\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.5328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 4s 109ms/step - loss: 1.5328 - val_loss: 0.6617 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.7027 - val_loss: 0.7140 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4242 - val_loss: 0.8679 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.2919 - val_loss: 0.9839 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.2789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 87ms/step - loss: 0.2771 - val_loss: 0.6266 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 91ms/step - loss: 0.2471 - val_loss: 0.3614 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.2487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 101ms/step - loss: 0.2498 - val_loss: 0.3083 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.2240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 84ms/step - loss: 0.2246 - val_loss: 0.3044 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.2029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 92ms/step - loss: 0.2035 - val_loss: 0.2424 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.2044 - val_loss: 0.3031 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 100ms/step - loss: 0.1743 - val_loss: 0.1986 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.1653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 102ms/step - loss: 0.1651 - val_loss: 0.1675 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.1585"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 88ms/step - loss: 0.1584 - val_loss: 0.1312 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.1516 - val_loss: 0.1370 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.1442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 103ms/step - loss: 0.1435 - val_loss: 0.1129 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 0.1517 - val_loss: 0.1143 - lr: 5.0000e-04\n",
      "Epoch 17/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.1447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 91ms/step - loss: 0.1468 - val_loss: 0.1050 - lr: 5.0000e-04\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.1365 - val_loss: 0.1158 - lr: 5.0000e-04\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.1442 - val_loss: 0.1070 - lr: 5.0000e-04\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 100ms/step - loss: 0.1430 - val_loss: 0.0942 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.1260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 97ms/step - loss: 0.1259 - val_loss: 0.0719 - lr: 5.0000e-05\n",
      "Epoch 22/30\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.1176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 86ms/step - loss: 0.1190 - val_loss: 0.0666 - lr: 5.0000e-05\n",
      "Epoch 23/30\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.1097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 94ms/step - loss: 0.1107 - val_loss: 0.0644 - lr: 5.0000e-05\n",
      "Epoch 24/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.1069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 99ms/step - loss: 0.1101 - val_loss: 0.0630 - lr: 5.0000e-05\n",
      "Epoch 25/30\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.1125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 95ms/step - loss: 0.1128 - val_loss: 0.0628 - lr: 5.0000e-05\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.1139 - val_loss: 0.0634 - lr: 5.0000e-05\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.1091 - val_loss: 0.0638 - lr: 5.0000e-05\n",
      "Epoch 28/30\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.1091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 97ms/step - loss: 0.1097 - val_loss: 0.0619 - lr: 5.0000e-05\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 1s 15ms/step - loss: 0.1123 - val_loss: 0.0630 - lr: 5.0000e-05\n",
      "Epoch 30/30\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.1123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "29/29 [==============================] - 2s 88ms/step - loss: 0.1129 - val_loss: 0.0612 - lr: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from network import Net #mine\n",
    "# from network import PCRnet as Net #PCR-Net baseline\n",
    "np.random.seed(1337)\n",
    "runLen =  30\n",
    "\n",
    "def scheduler(epoch, learning_rate):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "    if epoch < part1:\n",
    "        learning_rate = 0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        learning_rate = 0.0005 #0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part2:\n",
    "        learning_rate = 0.00005 #0.00025\n",
    "        return learning_rate\n",
    "\n",
    "model = Net()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = tf.keras.losses.MeanAbsoluteError()) #was MeanAbsoluteError()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\"DermNet_ModelNet_benchmark_cp.kmod\", monitor = 'val_loss', save_best_only = True) \n",
    "\n",
    "log_dir = \"runs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#was this\n",
    "# trace = model.fit(x = x_train, y = y_train, batch_size = 64, epochs=runLen, verbose=1, \n",
    "#                   validation_split = 0.1, shuffle=True, callbacks = [cp,scheduler])\n",
    "#best BS = 512??\n",
    "\n",
    "#using TF.dataset.augmen\n",
    "trace = model.fit(train_dataset, epochs=runLen, validation_data = val_dataset, \n",
    "                  verbose=1, callbacks = [cp,scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "minute-police",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Absolute Error')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network Loss Plots\n",
    "from matplotlib import pyplot as plt\n",
    "fig0, ax0 = plt.subplots()\n",
    "ax0.plot(trace.history['loss'], '-')\n",
    "ax0.plot(trace.history['val_loss'], '-')\n",
    "ax0.legend(['train', 'val'], loc='upper left')\n",
    "ax0.set_xlabel('iteration')\n",
    "ax0.set_ylabel('Mean Absolute Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "orange-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.07833534 -0.75580972 -4.1484359 ], shape=(3,), dtype=float64)\n",
      "tf.Tensor([-0.69656208 -0.81059129 -3.77331856], shape=(3,), dtype=float64)\n",
      "tf.Tensor([ 0.61822674  0.05478157 -0.37511734], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#temp- get center location of each point cloud to make sure net isn't just matching centroids\n",
    "idx = int(np.floor(100*np.random.randn()))\n",
    "mu1 = tf.math.reduce_mean(x_train[idx, :ptsPerCloud, :], axis = 0)\n",
    "mu2 = tf.math.reduce_mean(x_train[idx, ptsPerCloud:, :], axis = 0) - (y_train[idx,:3]*trans_scale)\n",
    "print(mu1)\n",
    "print(mu2)\n",
    "center_error = mu1 - mu2\n",
    "print(center_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "identical-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "[[ 8.8630414e-01  3.7944728e-01 -4.8318721e-02 -6.2199222e-04\n",
      "   1.8169298e-03  8.9697354e-03]\n",
      " [-2.8563768e-01 -1.1546829e+00  1.9337322e+00 -5.6677662e-02\n",
      "  -1.2197019e-02 -3.4217939e-03]\n",
      " [-1.6258678e+00 -4.4306409e-01 -1.0471096e+00 -5.4730740e-03\n",
      "  -1.9031925e-02  1.1517245e-02]\n",
      " [-4.8903877e-01  6.8988878e-01  2.6858859e+00 -5.0131299e-02\n",
      "   3.9929260e-02  1.3483118e-01]]\n",
      "[[ 1.0393157   0.24978371  0.05293555  0.          0.          0.        ]\n",
      " [-0.30825162 -1.02497351  1.95604157  0.          0.          0.        ]\n",
      " [-1.68946934 -0.32829732 -1.02210927  0.          0.          0.        ]\n",
      " [-0.79820514  1.01362717  3.24297667  0.          0.          0.        ]]\n",
      "[[ 0.15301156 -0.12966357  0.10125427  0.00062199 -0.00181693 -0.00896974]\n",
      " [-0.02261394  0.12970936  0.02230942  0.05667766  0.01219702  0.00342179]\n",
      " [-0.06360149  0.11476678  0.02500033  0.00547307  0.01903193 -0.01151725]\n",
      " [-0.30916637  0.3237384   0.55709076  0.0501313  -0.03992926 -0.13483118]]\n"
     ]
    }
   ],
   "source": [
    "#look at errors at never-before-seen test data generated from similar objects in ModelNet10\n",
    "guess = model.predict(x_train[:4])\n",
    "error = y_train[:4] - guess\n",
    "print(guess)\n",
    "print(y_train[:4])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "paperback-component",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1 200   3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Generate special test data for this visualization (evenly sampled)\n",
    "#  (doing this so we can draw the underlying model from which points were sampled)\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0310.off' #0310 looks best\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #simple shape\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0250.off' \n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/sofa/train/sofa_0250.off' \n",
    "\n",
    "M = trimesh.load(fn)\n",
    "\n",
    "n_tests = 1 #number of test samples to generate\n",
    "#init vector to store sampled point clouds\n",
    "x_test2 = np.zeros([n_tests, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y_test2 = np.zeros([n_tests, 6]) #rotation and translation\n",
    "\n",
    "sam1 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get keyframe scan\n",
    "sam2 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get new scan\n",
    "\n",
    "for j in range(n_tests):\n",
    "    angs1 = 0.5*tf.random.normal([3])    #rotate keyframe\n",
    "    rot1 = R_tf(angs1)\n",
    "    angs2 = rot_scale*tf.random.normal([3])     #rotate scan 2 relative to keyframe\n",
    "    angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "    rot2 = R_tf(angs2)\n",
    "    #     rot_combined = R_tf(angs1 + angs2) #was this\n",
    "    rot_combined = tf.matmul(R_tf(angs1), R_tf(angs2))\n",
    "    \n",
    "    x_test2[j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())         \n",
    "\n",
    "    trans = trans_scale*tf.random.normal([3])\n",
    "    #was this\n",
    "    sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot_combined.numpy()) #transform scan\n",
    "    #DEBUG\n",
    "#     sam2_j = (sam2[j*ptsPerCloud:(j+1)*ptsPerCloud]+trans.numpy()).dot(rot_combined.numpy()) #transform scan\n",
    "    x_test2[j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "    #save transformation as y\n",
    "    y_test2[j,:3] = trans.numpy()/trans_scale\n",
    "    y_test2[j,3:] = angs2.numpy()/rot_scale\n",
    "print(tf.shape(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "normal-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "\n",
      " ground truth: [ -5.78190804 -31.26205921   7.48254061   0.           0.\n",
      "   0.        ]\n",
      "\n",
      " estimate from DNN after 1 iteration: [-5.17527294e+00 -2.54875679e+01  4.76249647e+00 -1.79752409e-02\n",
      "  1.16390325e-02  1.09621501e-02]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "------- \n",
      " Final Error: [-0.74964857 -0.00310802 -1.42528105  0.00389347  0.00249721  0.00488784]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0647e1236344b390526474598f22b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=568, layout=Layout(height='auto', width='100%'), width=1706)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize network performance on evenly sampled data\n",
    "t = 0 #test number to draw\n",
    "niter = 5 #number of iterations to run network for\n",
    "\n",
    "plt2 = Plotter(N = 3, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp1 = [] #before estimated transformation (drawn on left)\n",
    "disp2 = [] #after 1 transformation (drawn in center)\n",
    "disp3 = [] #after niter transformations\n",
    "\n",
    "#draw first viz (untransformed set of scans)-------------------\n",
    "scan1 = Mesh(M).c(\"red\").alpha(0.1)#.rotate(90, axis = (0,0,1))\n",
    "scan1.applyTransform(rot1.numpy().T)\n",
    "disp1.append(scan1)\n",
    "disp1.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "\n",
    "scan2 = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2.applyTransform(rot_combined.numpy().T)\n",
    "# scan2.pos(y_test2[t,0], y_test2[t,1], y_test2[t,2])\n",
    "scan2.pos(y_test2[t,0]*trans_scale, y_test2[t,1]*trans_scale, y_test2[t,2]*trans_scale)\n",
    "disp1.append(scan2)\n",
    "disp1.append(Points(x_test2[0,ptsPerCloud:], c = 'blue', r = 5))\n",
    "\n",
    "#FOR DEBUG - draw ground truth transformation in green so I can be sure which order is correct\n",
    "# correct = (x_test2[0,ptsPerCloud:] - y_test2[0,:3]*trans_scale).dot(R_tf(y_test2[0,3:]*rot_scale).numpy().T)\n",
    "# temp = Points(correct, c = 'green', r = 5)\n",
    "# disp1.append(temp)\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "#draw esatimated soln after 1 iteration ------------------------\n",
    "ans_cum = model.predict(x_test2)[t]\n",
    "ans_cum[:3] = ans_cum[:3]*trans_scale\n",
    "ans_cum[3:] = ans_cum[3:]*rot_scale\n",
    "\n",
    "#draw meshes\n",
    "soln_est_rot = R_tf(ans_cum[3:])\n",
    "scan2_transformed = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T))\n",
    "scan2_transformed.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                      y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                      y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp2.append(scan2_transformed)\n",
    "disp2.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T)) #draw keyframe\n",
    "\n",
    "#add points\n",
    "scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "# scan2_pts_transformed = (x_test2[0,ptsPerCloud:]).dot(soln_est_rot.numpy().T) - ans_cum[:3]\n",
    "disp2.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "\n",
    "disp2.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "gt = y_test2[t].copy()\n",
    "gt[:3] = gt[:3]*trans_scale\n",
    "gt[3:] = gt[3:]*rot_scale\n",
    "print(\"\\n ground truth:\", gt)\n",
    "print(\"\\n estimate from DNN after 1 iteration:\", ans_cum)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "# draw estiamted soln after n interations-------------------------\n",
    "#TODO: need to figure out more compat way of representing sequential 6DOF transforms\n",
    "for i in range(niter):\n",
    "    #replace initial scan2 with transformed pc2 as input to network\n",
    "    inlayer = tf.concat([x_test2[0][:ptsPerCloud], scan2_pts_transformed], axis = 0)[None, :, :]\n",
    "    ans_i = model.predict(inlayer)[0]\n",
    "    ans_i[:3] = ans_i[:3]*trans_scale\n",
    "    ans_i[3:] = ans_i[3:]*rot_scale\n",
    "    \n",
    "#     soln_est_rot = tf.matmul(R_tf(ans_i[3:]), soln_est_rot)\n",
    "    soln_est_rot = R_tf(ans_i[3:]) #test\n",
    "    ans_cum[:3] = ans_cum[:3] + ans_i[:3]\n",
    "#     ans_cum[3:] = R2Euler(soln_est_rot)[:,0]\n",
    "    ans_cum[3:] = R2Euler(tf.matmul(R_tf(ans_i[3:]), soln_est_rot))[:,0]\n",
    "    scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "    \n",
    "# print(\"\\n estimate from DNN after\", niter, \"iterations: \", ans_cum) \n",
    "\n",
    "scan2_transformed_again = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed_again.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T)) #test\n",
    "scan2_transformed_again.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                            y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                            y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp3.append(scan2_transformed_again)\n",
    "disp3.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "disp3.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "disp3.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T)) #keyframe\n",
    "\n",
    "print(\"------- \\n Final Error:\", gt - ans_cum)\n",
    "# #---------------------------------------------------------------\n",
    "\n",
    "    \n",
    "plt2.show(disp1, \"initial transformation\", at = 0)\n",
    "plt2.show(disp2, \"after 1 iteration\", at = 1)\n",
    "plt2.show(disp3, \"after 5 iterations\", at = 2)\n",
    "ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(x_test2[:ptsPerCloud], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"DermNet_ModelNet_benchmark.kmod\") #256 pts per cloud, MAE =~ 0.3177\n",
    "# model.save(\"DermNet_ModelNet_benchmark.h5\") #allows viz with Netron\n",
    "# model = tf.keras.models.load_model(\"DermNet_ModelNet_benchmark.kmod\")\n",
    "\n",
    "# model.save(\"DermNet_ModelNet_trans_only.kmod\") #256 pts per cloud, MAE = 0.0308\n",
    "# model = tf.keras.models.load_model(\"DermNet_ModelNet_trans_only.kmod\")\n",
    "model.save(\"PCRnet_trans_only.kmod\") #256 pts per cloud, MAE = 0.071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't just add euler angles in 3D...\n",
    "a = tf.constant([[1., 2., 3.]])\n",
    "A = R_tf(a)\n",
    "b = tf.constant([[0.3, 0.2, 0.1]])\n",
    "B = R_tf(b)\n",
    "print(tf.matmul(A, B))\n",
    "print(R_tf(a + b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.numpy().T)\n",
    "print(np.linalg.pinv(A.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(R_tf(tf.constant([0.,0.,0.])), R_tf(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-smoke",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
