{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "#setup - rememeber to switch to tensorflow 2.3 kernel...\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "import trimesh\n",
    "import time\n",
    "from vedo import *\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "\n",
    "#need to have these two lines to work on my ancient 1060 3gb\n",
    "#  https://stackoverflow.com/questions/43990046/tensorflow-blas-gemm-launch-failed\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "%matplotlib notebook\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bottom-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took  0.021000385284423828 seconds\n"
     ]
    }
   ],
   "source": [
    "#load OFF file from ModelNet10 dir\n",
    "start = time.time()\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/sofa/train/sofa_0370.off'\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0320.off'\n",
    "\n",
    "\n",
    "M = trimesh.load(fn)\n",
    "test = trimesh.sample.sample_surface(M, 100)\n",
    "print(\"took \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a754723e2546deb4fa1717ff29f2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=960, layout=Layout(height='auto', width='100%'), width=960)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use Vedo to plot OG and subsampled surfaces\n",
    "plt1 = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp = []\n",
    "\n",
    "# disp.append(Points(M.vertices, c = 'blue', r = 4))\n",
    "disp.append(Points(test[0], c = 'red', r = 5))\n",
    "toilet = Mesh(M).c(\"gray\").alpha(0.2)\n",
    "disp.append(toilet)\n",
    "\n",
    "# disp.append(Points(x_train[50,:,:].numpy(), c = 'blue', r = 5)) #test drawing unknown point cloud\n",
    "\n",
    "plt1.show(disp, \"surface sampling test\")\n",
    "ViewInteractiveWidget(plt1.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expected-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rotation matrix used to transform point clouds\n",
    "def R_tf(angs):\n",
    "    if len(tf.shape(angs)) == 1:\n",
    "        angs = angs[None,:]\n",
    "    phi = angs[:,0]\n",
    "    theta = angs[:,1]\n",
    "    psi = angs[:,2]\n",
    "    mat = tf.Variable([[cos(theta)*cos(psi), sin(psi)*cos(phi) + sin(phi)*sin(theta)*cos(psi), sin(phi)*sin(psi) - sin(theta)*cos(phi)*cos(psi)],\n",
    "                       [-sin(psi)*cos(theta), cos(phi)*cos(psi) - sin(phi)*sin(theta)*sin(psi), sin(phi)*cos(psi) + sin(theta)*sin(psi)*cos(phi)],\n",
    "                       [sin(theta), -sin(phi)*cos(theta), cos(phi)*cos(theta)]\n",
    "                        ])\n",
    "    mat = tf.transpose(mat, [2, 0, 1])\n",
    "    mat = tf.squeeze(mat)\n",
    "    return mat\n",
    "\n",
    "# determine euler angles from rotation matrix\n",
    "def R2Euler(mat):\n",
    "    if len( tf.shape(mat) ) == 2:\n",
    "        mat = mat[None, :, :]\n",
    "    R_sum = np.sqrt(( mat[:,0,0]**2 + mat[:,0,1]**2 + mat[:,1,2]**2 + mat[:,2,2]**2 ) / 2)\n",
    "    phi = np.arctan2(-mat[:,1,2],mat[:,2,2])\n",
    "    theta = np.arctan2(mat[:,0,2], R_sum)\n",
    "    psi = np.arctan2(-mat[:,0,1], mat[:,0,0])\n",
    "    angs = np.array([phi, theta, psi])\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-joshua",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate toy dataset using all of the toilets in the ModelNet10 repository\n",
    "numMeshes = 20 #300 #344\n",
    "ptsPerCloud = 100 #was 25 in OG method \n",
    "iterPerMesh = 100 #number of times to sample clouds from each mesh\n",
    "\n",
    "#init vector to store sampled point clouds\n",
    "x = np.zeros([numMeshes*iterPerMesh, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y = np.zeros([numMeshes*iterPerMesh, 6]) #rotation and translation\n",
    "# y = np.zeros([numMeshes*iterPerMesh, 3]) #if only considering translations\n",
    "\n",
    "#scale trans and rotation params so outputs are equally weighted\n",
    "trans_scale = 10.0 #2.0\n",
    "rot_scale = 0.2 #0.2\n",
    "\n",
    "for i in range(numMeshes):\n",
    "    if i % 2 == 0:\n",
    "        print(i)\n",
    "    fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_%04d.off' %(i+1) #loop through file names\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0059.off'\n",
    "#     fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #debug -> only use single toilet model\n",
    "    M = trimesh.load(fn)\n",
    "\n",
    "    #more efficient to sample all points at once and then just use some for each frame\n",
    "    sam1 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get keyframe scan\n",
    "    sam2 = trimesh.sample.sample_surface(M, iterPerMesh*ptsPerCloud)[0] #get new scan\n",
    "#     sam2 = sam1 + 0.01*np.random.randn(np.shape(sam1)[0], 3) #copy point locations and add some noise\n",
    "    \n",
    "    for j in range(iterPerMesh):\n",
    "        #rotate keyframe\n",
    "        angs1 = 0.5*tf.random.normal([3])\n",
    "        rot1 = R_tf(angs1)\n",
    "        #rotate scan 2 relative to keyframe\n",
    "        angs2 = rot_scale*tf.random.normal([3])\n",
    "#         rot2 = R_tf(angs1 + angs2) #was this (wrong??)\n",
    "        angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "#         rot2 = tf.matmul(R_tf(angs1), R_tf(angs2)) #was this (wrong??)\n",
    "        rot2 = tf.matmul(R_tf(angs2), R_tf(angs1)) #test\n",
    "\n",
    "        \n",
    "        # randomly grow/shrink each point cloud before translation\n",
    "        scale = 1. + 0.2*tf.random.normal([1])[0]\n",
    "\n",
    "        x[i*iterPerMesh + j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())*scale           \n",
    "            \n",
    "        trans = trans_scale*tf.random.normal([3])\n",
    "        #was this (incorrect for large angle deviation?)\n",
    "#         sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy()).dot(rot2.numpy())*scale \n",
    "        sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot2.numpy())*scale \n",
    "        x[i*iterPerMesh + j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "        #save transformation as y\n",
    "        y[i*iterPerMesh + j,:3] = trans.numpy()/trans_scale\n",
    "        y[i*iterPerMesh + j,3:] = angs2.numpy()/rot_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test sets, save to file\n",
    "split = 0.9\n",
    "x_train = x[:int(split*np.shape(x)[0])]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train', x_train)\n",
    "x_test = x[int(split*np.shape(x)[0]):]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test', x_test)\n",
    "y_train = y[:int(split*np.shape(y)[0])]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train', y_train)\n",
    "y_test = y[int(split*np.shape(y)[0]):]\n",
    "# np.save('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test', y_test)\n",
    "\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boring-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 512, 3)\n",
      "(54000, 6)\n",
      "(6000, 512, 3)\n",
      "(6000, 6)\n"
     ]
    }
   ],
   "source": [
    "#load data from memory\n",
    "numMeshes = 300 #344\n",
    "ptsPerCloud = 256 #50 #was 25 in OG method \n",
    "iterPerMesh = 200 #100  #number of times to sample clouds from each mesh\n",
    "trans_scale = 10.0 #2.0\n",
    "rot_scale = 0.2 #0.2\n",
    "\n",
    "# x_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train.npy')\n",
    "# y_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train.npy')\n",
    "# x_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test.npy')\n",
    "# y_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test.npy')\n",
    "\n",
    "x_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_train_trans_only.npy')\n",
    "y_train = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_train_trans_only.npy')\n",
    "x_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/x_test_trans_only.npy')\n",
    "y_test = np.load('C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/y_test_trans_only.npy')\n",
    "\n",
    "#limit ptsPerCloud of loaded data -----------------------------------\n",
    "halflen = np.shape(x_train)[1]//2\n",
    "x_train = np.concatenate((x_train[:,:ptsPerCloud,:], x_train[:,halflen:(halflen + ptsPerCloud),:]), axis = 1)\n",
    "halflen = np.shape(x_test)[1]//2\n",
    "x_test = np.concatenate((x_test[:,:ptsPerCloud,:], x_test[:,halflen:(halflen + ptsPerCloud),:]), axis = 1)\n",
    "print(np.shape(x_train)) #starts out at 256 per cloud\n",
    "print(np.shape(y_train)) \n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))\n",
    "#---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-match",
   "metadata": {},
   "source": [
    "### Load Lidar Data (Alternate Option) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on data generated from KITTI dataset\n",
    "#(from drive 005 snippet)\n",
    "# d1 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_scan1_50_shifted.txt\")\n",
    "# d2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_scan2_50_shifted.txt\")\n",
    "# gt = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_ground_truth_50_shifted.txt\")\n",
    "\n",
    "# #full urban drive (much larger)\n",
    "# d1 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_FULL_scan1_to400.npy\")\n",
    "# d2 = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_FULL_scan2_to400.npy\")\n",
    "# gt = np.load(\"C:/Users/Derm/Desktop/big/pshift/ICET_KITTI_FULL_ground_truth_to400.npy\")\n",
    "\n",
    "# toy data set generated in MatLab\n",
    "d1 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/scan1_1k.txt\")\n",
    "d2 = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/scan2_1k.txt\")\n",
    "gt = np.loadtxt(\"C:/Users/Derm/Desktop/big/pshift/ground_truth_1k.txt\")\n",
    "\n",
    "points_per_sample = 50  #num pts per scan - defined in MatLab script\n",
    "scan1 = tf.reshape(tf.convert_to_tensor(d1), [-1, points_per_sample, 3])\n",
    "scan2 = tf.reshape(tf.convert_to_tensor(d2), [-1, points_per_sample, 3])\n",
    "gt = tf.convert_to_tensor(gt)\n",
    "\n",
    "#split data into training and validation sets\n",
    "tsplit = 0.95 #this fraction goes into training\n",
    "ntrain = int(tsplit*tf.shape(scan1)[0].numpy())\n",
    "x_train = tf.concat((scan1[:ntrain], scan2[:ntrain]), axis = 1)\n",
    "x_test = tf.concat((scan1[ntrain:], scan2[ntrain:]), axis = 1)\n",
    "y_train = gt[:ntrain]\n",
    "y_test = gt[ntrain:]\n",
    "\n",
    "print(tf.shape(y_train))\n",
    "y_train = tf.concat((y_train, tf.zeros(tf.shape(y_train), dtype = tf.double)), axis = 1)\n",
    "# y_train = tf.concat((y_train, tf.zeros(tf.shape(y_train), dtype = tf.float32)), axis = 1)\n",
    "print(tf.shape(y_train))\n",
    "print(tf.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "print(tf.shape(x_train))\n",
    "print(tf.shape(y_train))\n",
    "\n",
    "#TEST\n",
    "#just translation case ------------\n",
    "# y_train = y_train[:,:3]\n",
    "# print(tf.shape(y_train))\n",
    "#----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393b363",
   "metadata": {},
   "source": [
    "## Create TF dataset to augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcdd0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 512, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>\n",
      "(512, 3)\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 512, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "def augment(points, gt):\n",
    "    print(np.shape(points))\n",
    "    # jitter points\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points in first point cloud\n",
    "    points = tf.concat([tf.random.shuffle(points[:256]), tf.random.shuffle(points[256:])], axis = 0)\n",
    "#     print(test)\n",
    "    return points, gt\n",
    "\n",
    "NUM_POINTS = 256\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(len(x_train)).map(augment).batch(BATCH_SIZE)\n",
    "print(train_dataset)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.shuffle(len(x_test)).map(augment).batch(BATCH_SIZE)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14034a12",
   "metadata": {},
   "source": [
    "# Train Network\n",
    "\n",
    "| MAE      | Batch Size     |    Epochs | Train Dataset | Notes | Network|\n",
    "| ----------- | ----------- | --------- | --------   | | |\n",
    "| 0.055  | 64 |  30   | toilet 69, 5k samles | 50 pts per scan    | Net |\n",
    "| 0.067  | 16 |  30   | toilet 69, 1800 samles | 512 pts per scan    | Net |\n",
    "| 0.11  | 64 |  30   | 20 toilets, 100 PCs each |no augmentation between epochs| Net |\n",
    "| 0.065  | 64 |  30   | 20 toilets, 100 PCs each |Using tf.data.map(augment)| Net |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "after-receptor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 3)]          0         \n",
      "                                                                 \n",
      " tf.expand_dims_1 (TFOpLambd  (None, 512, 3, 1)        0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 512, 1, 64)        256       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512, 1, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 512, 1, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512, 1, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 512, 1, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512, 1, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 512, 1, 128)       8320      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512, 1, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 512, 1, 1024)      132096    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 512, 1, 1024)     4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 1, 1024)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      " tf.math.multiply_1 (TFOpLam  (None, 6)                0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,235,782\n",
      "Trainable params: 4,226,438\n",
      "Non-trainable params: 9,344\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.3741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 19s 164ms/step - loss: 0.3741 - val_loss: 0.8355 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.1471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 168ms/step - loss: 0.1471 - val_loss: 0.5688 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.1238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 19s 177ms/step - loss: 0.1238 - val_loss: 0.3157 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.1140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 163ms/step - loss: 0.1140 - val_loss: 0.2341 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.1038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 17s 163ms/step - loss: 0.1038 - val_loss: 0.2049 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 17s 160ms/step - loss: 0.0997 - val_loss: 0.1773 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 164ms/step - loss: 0.0940 - val_loss: 0.1646 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 163ms/step - loss: 0.0873 - val_loss: 0.1343 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "106/106 [==============================] - 15s 143ms/step - loss: 0.0839 - val_loss: 0.1532 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "106/106 [==============================] - 16s 151ms/step - loss: 0.0834 - val_loss: 0.1473 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 167ms/step - loss: 0.0697 - val_loss: 0.1136 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0680"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 163ms/step - loss: 0.0680 - val_loss: 0.0762 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "106/106 [==============================] - 16s 149ms/step - loss: 0.0646 - val_loss: 0.0819 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "106/106 [==============================] - 15s 141ms/step - loss: 0.0681 - val_loss: 0.1026 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "106/106 [==============================] - 15s 141ms/step - loss: 0.0650 - val_loss: 0.0993 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "106/106 [==============================] - 15s 142ms/step - loss: 0.0670 - val_loss: 0.1216 - lr: 5.0000e-04\n",
      "Epoch 17/30\n",
      "106/106 [==============================] - 15s 141ms/step - loss: 0.0667 - val_loss: 0.1000 - lr: 5.0000e-04\n",
      "Epoch 18/30\n",
      "106/106 [==============================] - 15s 143ms/step - loss: 0.0635 - val_loss: 0.0980 - lr: 5.0000e-04\n",
      "Epoch 19/30\n",
      "106/106 [==============================] - 16s 149ms/step - loss: 0.0646 - val_loss: 0.1195 - lr: 5.0000e-04\n",
      "Epoch 20/30\n",
      "106/106 [==============================] - 15s 145ms/step - loss: 0.0651 - val_loss: 0.0879 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 17s 163ms/step - loss: 0.0537 - val_loss: 0.0648 - lr: 5.0000e-05\n",
      "Epoch 22/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 169ms/step - loss: 0.0515 - val_loss: 0.0630 - lr: 5.0000e-05\n",
      "Epoch 23/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 18s 165ms/step - loss: 0.0516 - val_loss: 0.0620 - lr: 5.0000e-05\n",
      "Epoch 24/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 17s 163ms/step - loss: 0.0518 - val_loss: 0.0618 - lr: 5.0000e-05\n",
      "Epoch 25/30\n",
      "106/106 [==============================] - 15s 142ms/step - loss: 0.0524 - val_loss: 0.0632 - lr: 5.0000e-05\n",
      "Epoch 26/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DermNet_ModelNet_benchmark_cp.kmod\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 17s 164ms/step - loss: 0.0515 - val_loss: 0.0568 - lr: 5.0000e-05\n",
      "Epoch 27/30\n",
      "106/106 [==============================] - 15s 142ms/step - loss: 0.0509 - val_loss: 0.0581 - lr: 5.0000e-05\n",
      "Epoch 28/30\n",
      "106/106 [==============================] - 15s 144ms/step - loss: 0.0513 - val_loss: 0.0600 - lr: 5.0000e-05\n",
      "Epoch 29/30\n",
      "106/106 [==============================] - 15s 143ms/step - loss: 0.0509 - val_loss: 0.0604 - lr: 5.0000e-05\n",
      "Epoch 30/30\n",
      "106/106 [==============================] - 15s 141ms/step - loss: 0.0503 - val_loss: 0.0617 - lr: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from network import Net #mine\n",
    "# from network import PointNet as Net #uses builtin PointNetConv2Layer\n",
    "# from network import PCRnet as Net #PCR-Net baseline\n",
    "np.random.seed(1337)\n",
    "runLen =  30\n",
    "\n",
    "def scheduler(epoch, learning_rate):\n",
    "    part1 = runLen//3\n",
    "    part2 = 2*runLen//3 #net2\n",
    "    if epoch < part1:\n",
    "        learning_rate = 0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part1 and epoch < part2:\n",
    "        learning_rate = 0.0005 #0.001\n",
    "        return learning_rate\n",
    "    if epoch >= part2:\n",
    "        learning_rate = 0.00005 #0.00025\n",
    "        return learning_rate\n",
    "\n",
    "model = Net()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = tf.keras.losses.MeanAbsoluteError()) #was MeanAbsoluteError()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\"DermNet_ModelNet_benchmark_cp.kmod\", monitor = 'val_loss', save_best_only = True) \n",
    "\n",
    "log_dir = \"runs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#was this\n",
    "# trace = model.fit(x = x_train, y = y_train, batch_size = 64, epochs=runLen, verbose=1, \n",
    "#                   validation_split = 0.1, shuffle=True, callbacks = [cp,scheduler])\n",
    "#best BS = 512??\n",
    "\n",
    "#using TF.dataset.augmen\n",
    "trace = model.fit(train_dataset, epochs=runLen, validation_data = val_dataset, \n",
    "                  verbose=1, callbacks = [cp,scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minute-police",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Absolute Error')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network Loss Plots\n",
    "from matplotlib import pyplot as plt\n",
    "fig0, ax0 = plt.subplots()\n",
    "ax0.plot(trace.history['loss'], '-')\n",
    "ax0.plot(trace.history['val_loss'], '-')\n",
    "ax0.legend(['train', 'val'], loc='upper left')\n",
    "ax0.set_xlabel('iteration')\n",
    "ax0.set_ylabel('Mean Absolute Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "orange-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-5.58008181  4.2474526   1.54906792], shape=(3,), dtype=float64)\n",
      "tf.Tensor([-5.92326622  3.40196312  1.40976369], shape=(3,), dtype=float64)\n",
      "tf.Tensor([0.3431844  0.84548947 0.13930423], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#temp- get center location of each point cloud to make sure net isn't just matching centroids\n",
    "idx = int(np.floor(100*np.random.randn()))\n",
    "mu1 = tf.math.reduce_mean(x_train[idx, :ptsPerCloud, :], axis = 0)\n",
    "mu2 = tf.math.reduce_mean(x_train[idx, ptsPerCloud:, :], axis = 0) - (y_train[idx,:3]*trans_scale)\n",
    "print(mu1)\n",
    "print(mu2)\n",
    "center_error = mu1 - mu2\n",
    "print(center_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "identical-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 330ms/step\n",
      "[[ 3.6034173e-01  3.0419078e-01  1.0271007e+00  2.4722498e-03\n",
      "   4.7277391e-04 -5.4686680e-05]\n",
      " [-1.1673863e+00 -3.8995641e-01  8.6279565e-01 -8.7316288e-04\n",
      "   3.9807092e-03  1.8857124e-03]\n",
      " [ 3.0340341e-01 -6.6184324e-01 -7.5254649e-01 -3.8316869e-03\n",
      "   7.1171962e-04 -3.3546514e-03]\n",
      " [-1.7223639e+00 -2.3635265e-01  7.6726502e-01 -1.8547336e-03\n",
      "  -6.0966506e-04 -4.3083318e-03]]\n",
      "[[ 0.42244235  0.30968952  1.08941162  0.          0.          0.        ]\n",
      " [-1.33839726 -0.4203828   0.93120605  0.          0.          0.        ]\n",
      " [ 0.30679035 -0.72255397 -0.76323378  0.          0.          0.        ]\n",
      " [-1.82219815 -0.24048337  0.81757659  0.          0.          0.        ]]\n",
      "[[ 6.21006191e-02  5.49873710e-03  6.23109341e-02 -2.47224979e-03\n",
      "  -4.72773914e-04  5.46866795e-05]\n",
      " [-1.71010971e-01 -3.04263830e-02  6.84103966e-02  8.73162877e-04\n",
      "  -3.98070924e-03 -1.88571238e-03]\n",
      " [ 3.38694453e-03 -6.07107282e-02 -1.06872916e-02  3.83168692e-03\n",
      "  -7.11719622e-04  3.35465139e-03]\n",
      " [-9.98342037e-02 -4.13072109e-03  5.03115654e-02  1.85473356e-03\n",
      "   6.09665061e-04  4.30833176e-03]]\n"
     ]
    }
   ],
   "source": [
    "#look at errors at never-before-seen test data generated from similar objects in ModelNet10\n",
    "guess = model.predict(x_train[:4])\n",
    "error = y_train[:4] - guess\n",
    "print(guess)\n",
    "print(y_train[:4])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "paperback-component",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1 512   3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Generate special test data for this visualization (evenly sampled)\n",
    "#  (doing this so we can draw the underlying model from which points were sampled)\n",
    "fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0310.off' #0310 looks best\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/toilet/train/toilet_0069.off' #simple shape\n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/bed/train/bed_0250.off' \n",
    "# fn = 'C:/Users/Derm/Desktop/big/ModelNet10/sofa/train/sofa_0250.off' \n",
    "\n",
    "M = trimesh.load(fn)\n",
    "\n",
    "n_tests = 1 #number of test samples to generate\n",
    "#init vector to store sampled point clouds\n",
    "x_test2 = np.zeros([n_tests, ptsPerCloud*2, 3])\n",
    "#init vector to store transformations \n",
    "y_test2 = np.zeros([n_tests, 6]) #rotation and translation\n",
    "\n",
    "sam1 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get keyframe scan\n",
    "sam2 = trimesh.sample.sample_surface(M, n_tests*ptsPerCloud)[0] #get new scan\n",
    "\n",
    "for j in range(n_tests):\n",
    "    angs1 = 0.5*tf.random.normal([3])    #rotate keyframe\n",
    "    rot1 = R_tf(angs1)\n",
    "    angs2 = rot_scale*tf.random.normal([3])     #rotate scan 2 relative to keyframe\n",
    "    angs2 = tf.zeros([3]) # ~~~~~~~~~~~~~~~ zero out rotation (for debug) ~~~~~~~~~~~~~~~~~~~~~~\n",
    "    rot2 = R_tf(angs2)\n",
    "    #     rot_combined = R_tf(angs1 + angs2) #was this\n",
    "    rot_combined = tf.matmul(R_tf(angs1), R_tf(angs2))\n",
    "    \n",
    "    x_test2[j, :ptsPerCloud, :] = sam1[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot1.numpy())         \n",
    "\n",
    "    trans = trans_scale*tf.random.normal([3])\n",
    "    #was this\n",
    "    sam2_j = trans + sam2[j*ptsPerCloud:(j+1)*ptsPerCloud].dot(rot_combined.numpy()) #transform scan\n",
    "    #DEBUG\n",
    "#     sam2_j = (sam2[j*ptsPerCloud:(j+1)*ptsPerCloud]+trans.numpy()).dot(rot_combined.numpy()) #transform scan\n",
    "    x_test2[j, ptsPerCloud:, :] = sam2_j\n",
    "\n",
    "    #save transformation as y\n",
    "    y_test2[j,:3] = trans.numpy()/trans_scale\n",
    "    y_test2[j,3:] = angs2.numpy()/rot_scale\n",
    "print(tf.shape(x_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "normal-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 217ms/step\n",
      "\n",
      " ground truth: [-2.1549806   1.45327911 -4.80816305  0.          0.          0.        ]\n",
      "\n",
      " estimate from DNN after 1 iteration: [-2.0803771e+00  1.5713584e+00 -5.0467405e+00  4.4693239e-04\n",
      "  3.3477109e-04  3.0394053e-04]\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "------- \n",
      " Final Error: [-3.58687460e-01 -2.96856552e-01  2.32818246e-01 -1.20052195e-04\n",
      " -1.14664545e-04 -6.01415930e-04]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6687e0ab8d647a0869ac9095c473e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=568, layout=Layout(height='auto', width='100%'), width=1706)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize network performance on evenly sampled data\n",
    "t = 0 #test number to draw\n",
    "niter = 5 #number of iterations to run network for\n",
    "\n",
    "plt2 = Plotter(N = 3, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp1 = [] #before estimated transformation (drawn on left)\n",
    "disp2 = [] #after 1 transformation (drawn in center)\n",
    "disp3 = [] #after niter transformations\n",
    "\n",
    "#draw first viz (untransformed set of scans)-------------------\n",
    "scan1 = Mesh(M).c(\"red\").alpha(0.1)#.rotate(90, axis = (0,0,1))\n",
    "scan1.applyTransform(rot1.numpy().T)\n",
    "disp1.append(scan1)\n",
    "disp1.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "\n",
    "scan2 = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2.applyTransform(rot_combined.numpy().T)\n",
    "# scan2.pos(y_test2[t,0], y_test2[t,1], y_test2[t,2])\n",
    "scan2.pos(y_test2[t,0]*trans_scale, y_test2[t,1]*trans_scale, y_test2[t,2]*trans_scale)\n",
    "disp1.append(scan2)\n",
    "disp1.append(Points(x_test2[0,ptsPerCloud:], c = 'blue', r = 5))\n",
    "\n",
    "#FOR DEBUG - draw ground truth transformation in green so I can be sure which order is correct\n",
    "# correct = (x_test2[0,ptsPerCloud:] - y_test2[0,:3]*trans_scale).dot(R_tf(y_test2[0,3:]*rot_scale).numpy().T)\n",
    "# temp = Points(correct, c = 'green', r = 5)\n",
    "# disp1.append(temp)\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "#draw esatimated soln after 1 iteration ------------------------\n",
    "ans_cum = model.predict(x_test2)[t]\n",
    "ans_cum[:3] = ans_cum[:3]*trans_scale\n",
    "ans_cum[3:] = ans_cum[3:]*rot_scale\n",
    "\n",
    "#draw meshes\n",
    "soln_est_rot = R_tf(ans_cum[3:])\n",
    "scan2_transformed = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T))\n",
    "scan2_transformed.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                      y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                      y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp2.append(scan2_transformed)\n",
    "disp2.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T)) #draw keyframe\n",
    "\n",
    "#add points\n",
    "scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "# scan2_pts_transformed = (x_test2[0,ptsPerCloud:]).dot(soln_est_rot.numpy().T) - ans_cum[:3]\n",
    "disp2.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "\n",
    "disp2.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "gt = y_test2[t].copy()\n",
    "gt[:3] = gt[:3]*trans_scale\n",
    "gt[3:] = gt[3:]*rot_scale\n",
    "print(\"\\n ground truth:\", gt)\n",
    "print(\"\\n estimate from DNN after 1 iteration:\", ans_cum)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "# draw estiamted soln after n interations-------------------------\n",
    "#TODO: need to figure out more compat way of representing sequential 6DOF transforms\n",
    "for i in range(niter):\n",
    "    #replace initial scan2 with transformed pc2 as input to network\n",
    "    inlayer = tf.concat([x_test2[0][:ptsPerCloud], scan2_pts_transformed], axis = 0)[None, :, :]\n",
    "    ans_i = model.predict(inlayer)[0]\n",
    "    ans_i[:3] = ans_i[:3]*trans_scale\n",
    "    ans_i[3:] = ans_i[3:]*rot_scale\n",
    "    \n",
    "#     soln_est_rot = tf.matmul(R_tf(ans_i[3:]), soln_est_rot)\n",
    "    soln_est_rot = R_tf(ans_i[3:]) #test\n",
    "    ans_cum[:3] = ans_cum[:3] + ans_i[:3]\n",
    "#     ans_cum[3:] = R2Euler(soln_est_rot)[:,0]\n",
    "    ans_cum[3:] = R2Euler(tf.matmul(R_tf(ans_i[3:]), soln_est_rot))[:,0]\n",
    "    scan2_pts_transformed = (x_test2[0,ptsPerCloud:] - ans_cum[:3]).dot(soln_est_rot.numpy().T)\n",
    "    \n",
    "# print(\"\\n estimate from DNN after\", niter, \"iterations: \", ans_cum) \n",
    "\n",
    "scan2_transformed_again = Mesh(M).c(\"blue\").alpha(0.1)\n",
    "scan2_transformed_again.applyTransform(soln_est_rot.numpy().dot(rot_combined.numpy().T)) #test\n",
    "scan2_transformed_again.pos(y_test2[t,0]*trans_scale - ans_cum[0], \n",
    "                            y_test2[t,1]*trans_scale - ans_cum[1], \n",
    "                            y_test2[t,2]*trans_scale - ans_cum[2])\n",
    "disp3.append(scan2_transformed_again)\n",
    "disp3.append(Points(scan2_pts_transformed, c = 'blue', r = 5))\n",
    "disp3.append(Points(x_test2[0,:ptsPerCloud], c = 'red', r = 5))\n",
    "disp3.append(Mesh(M).c(\"red\").alpha(0.1).applyTransform(rot1.numpy().T)) #keyframe\n",
    "\n",
    "print(\"------- \\n Final Error:\", gt - ans_cum)\n",
    "# #---------------------------------------------------------------\n",
    "\n",
    "    \n",
    "plt2.show(disp1, \"initial transformation\", at = 0)\n",
    "plt2.show(disp2, \"after 1 iteration\", at = 1)\n",
    "plt2.show(disp3, \"after 5 iterations\", at = 2)\n",
    "ViewInteractiveWidget(plt2.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(x_test2[:ptsPerCloud], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"DermNet_ModelNet_benchmark.kmod\") #256 pts per cloud, MAE =~ 0.3177\n",
    "# model.save(\"DermNet_ModelNet_benchmark.h5\") #allows viz with Netron\n",
    "# model = tf.keras.models.load_model(\"DermNet_ModelNet_benchmark.kmod\")\n",
    "\n",
    "# model.save(\"DermNet_ModelNet_trans_only.kmod\") #256 pts per cloud, MAE = 0.0308\n",
    "# model = tf.keras.models.load_model(\"DermNet_ModelNet_trans_only.kmod\")\n",
    "# model.save(\"PCRnet_trans_only.kmod\") #256 pts per cloud, MAE = 0.071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't just add euler angles in 3D...\n",
    "a = tf.constant([[1., 2., 3.]])\n",
    "A = R_tf(a)\n",
    "b = tf.constant([[0.3, 0.2, 0.1]])\n",
    "B = R_tf(b)\n",
    "print(tf.matmul(A, B))\n",
    "print(R_tf(a + b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.numpy().T)\n",
    "print(np.linalg.pinv(A.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(R_tf(tf.constant([0.,0.,0.])), R_tf(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-smoke",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
