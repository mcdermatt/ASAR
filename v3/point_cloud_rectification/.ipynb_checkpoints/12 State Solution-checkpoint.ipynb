{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d618048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:20:09.886935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 21:20:10.531104: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-30 21:20:11.673132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-30 21:20:11.673227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-30 21:20:11.673234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-04-30 21:20:13.160451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.278425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.278757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:20:13.616399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 21:20:13.617785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.617948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.618075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.617736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.617998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.618199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.618331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "from ICET_spherical import ICET\n",
    "from utils import *\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from pioneer.das.api.platform import Platform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cf3de",
   "metadata": {},
   "source": [
    "# Goal: Simultaneously Estimate Translation, Rotation, and Distortion\n",
    "\n",
    "## $\\mathbf{A} = [\\hat{X}_{ij}, \\hat{m}_{ij}] = \n",
    "\\begin{bmatrix}\n",
    "% x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a9028",
   "metadata": {},
   "source": [
    "We can use newton-raphson to find A\n",
    "\n",
    "<!-- ## $y_i = \\mathbf{h}(y_j, \\hat{X}_{ij}, \\hat{m}_{ij}) + \\mathbf{H}_m \\delta m + \\mathbf{H}_x \\delta x + \\text{H.O.T.}$ -->\n",
    "\n",
    "## $y_i = \\mathbf{h}(y_j, \\hat{A}_{ij}) + \\mathbf{H}_A \\delta A + \\text{H.O.T.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62668f7e",
   "metadata": {},
   "source": [
    "## $\\mathbf{H}_A \\in \\mathbb{R}^{4N \\times 12} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb30f3c",
   "metadata": {},
   "source": [
    "\n",
    "### $\\mathbf{H}_A = [H_X, H_m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf4dfc",
   "metadata": {},
   "source": [
    "# Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1645f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load point cloud\n",
    "# # no distortion\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case1/raw_frame_0.npy\")\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #actual motion\n",
    "# m_hat = np.array([-3., 0., 0., 0., 0., 0.1]) #test wrap around\n",
    "\n",
    "# movement in x\n",
    "old_cloud =  np.load(\"sample_data/paper_figures/case2/raw_frame_3.npy\") \n",
    "m_hat = np.array([3, 0, 0., 0., 0., 0])\n",
    "# m_hat = np.array([3, 0, 0., 0., 0., -0.2]) #FOR DEBUG-- deform just a little\n",
    "gt =  np.load(\"sample_data/paper_figures/case2/base_vel_2.npy\")\n",
    "\n",
    "# # movement in x, y, & yaw\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case3/raw_frame_1.npy\") \n",
    "# # m_hat = np.array([3, -1, 0., 0., 0., -1])\n",
    "# m_hat = np.array([3, -1, 0., 0., 0., -0.86]) #FOR DEBUG-- deform a little extra\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #FOR DEBUG-- no deformation\n",
    "# gt =  np.load(\"sample_data/paper_figures/case3/base_vel_2.npy\")\n",
    "# # print(gt) \n",
    "\n",
    "# period_lidar = 1\n",
    "# t_scale = (2*np.pi)/(-m_hat[-1] + (2*np.pi/period_lidar))\n",
    "# print(t_scale)\n",
    "# m_hat = m_hat*t_scale\n",
    "# # m_hat[-1] = m_hat[-1]*t_scaled\n",
    "# print(m_hat)\n",
    "\n",
    "#downsample\n",
    "old_cloud = old_cloud[::5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b92149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30295131384d038934e49442456706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from remove_motion_basic import linear_correction_old as lc \n",
    "\n",
    "#apply ground truth distortion according to m_hat\n",
    "new_cloud = lc(old_cloud, m_hat) \n",
    "#set ground truth transform between clouds\n",
    "# X_gt = np.array([0, 0., 0.0, 0.0, 0.0, 0.0])\n",
    "# X_gt = np.array([1.5, 0.5, 0.03, 0.03, 0.03, 0.25])\n",
    "# X_gt = np.array([1.5, -3, 0.1, 0.2, 0.03, -0.15])\n",
    "X_gt = np.array([-1.5, 0., 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "# add noise\n",
    "old_cloud += 0.01*np.random.randn(np.shape(old_cloud)[0], 3)\n",
    "\n",
    "# #for fig: mess up both again to show that relative distortion remains constant\n",
    "# new_cloud = lc(new_cloud, -m_hat)\n",
    "# old_cloud = lc(old_cloud, -m_hat)\n",
    "\n",
    "#remove ground plane\n",
    "old_cloud = old_cloud[old_cloud[:,2] > -1] \n",
    "new_cloud = new_cloud[new_cloud[:,2] > -1] \n",
    "\n",
    "# Rotate + Translate new point cloud\n",
    "trans = X_gt[:3]\n",
    "rot = R_tf(X_gt[3:]).numpy()\n",
    "new_cloud = (new_cloud @ rot) + trans\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(old_cloud, c = \"#CB2314\")) \n",
    "disp.append(Points(new_cloud, c = \"#2c7c94\")) \n",
    "plt.show(disp, \"raw point clouds\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734cdf9",
   "metadata": {},
   "source": [
    "### Attempt to solve with basic 6 state solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3c124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:20:28.690962: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-30 21:20:30.402328: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~Iteration  0 ~~~~~~~~~~\n",
      "took 0.03403830528259277 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (75, 6)\n",
      "H_m \n",
      " (300, 6)\n",
      "took 0.00986170768737793 sec to get H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:20:31.978535: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x72b4730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_hat:  [ 0.00746424  0.04021354  0.06130894 -0.01878214  0.00531771  0.01718472]\n",
      "~~~~~~~~~~~Iteration  1 ~~~~~~~~~~\n",
      "took 0.01360774040222168 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (73, 6)\n",
      "H_m \n",
      " (292, 6)\n",
      "took 0.003005504608154297 sec to get H\n",
      "m_hat:  [-0.00302407  0.04816992  0.06140573 -0.02203067  0.02073113  0.02273943]\n",
      "~~~~~~~~~~~Iteration  2 ~~~~~~~~~~\n",
      "took 0.013400793075561523 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.0028777122497558594 sec to get H\n",
      "m_hat:  [-0.02556884  0.03712575  0.06151301 -0.03500357  0.03180126  0.02549559]\n",
      "~~~~~~~~~~~Iteration  3 ~~~~~~~~~~\n",
      "took 0.013161182403564453 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.0016872882843017578 sec to get H\n",
      "m_hat:  [-0.04295301  0.03784451  0.06164558 -0.03897972  0.04276758  0.02608056]\n",
      "~~~~~~~~~~~Iteration  4 ~~~~~~~~~~\n",
      "took 0.013776302337646484 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.002126932144165039 sec to get H\n",
      "m_hat:  [-0.0498055   0.02994547  0.06171985 -0.04628553  0.05166     0.02614224]\n",
      "~~~~~~~~~~~Iteration  5 ~~~~~~~~~~\n",
      "took 0.013179779052734375 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.003318309783935547 sec to get H\n",
      "m_hat:  [-0.063012    0.02594139  0.0618406  -0.05151389  0.06075044  0.02689983]\n",
      "~~~~~~~~~~~Iteration  6 ~~~~~~~~~~\n",
      "took 0.013988494873046875 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.0016689300537109375 sec to get H\n",
      "m_hat:  [-0.06930792  0.02091471  0.06190061 -0.05737752  0.06659967  0.02716866]\n",
      "~~~~~~~~~~~Iteration  7 ~~~~~~~~~~\n",
      "took 0.013788461685180664 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.001798391342163086 sec to get H\n",
      "m_hat:  [-0.09043939  0.01624506  0.06212544 -0.06274912  0.07901326  0.02717113]\n",
      "~~~~~~~~~~~Iteration  8 ~~~~~~~~~~\n",
      "took 0.01350545883178711 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (74, 6)\n",
      "H_m \n",
      " (296, 6)\n",
      "took 0.0018360614776611328 sec to get H\n",
      "m_hat:  [-0.11500765  0.00572351  0.06240812 -0.0705441   0.09331992  0.02651069]\n",
      "~~~~~~~~~~~Iteration  9 ~~~~~~~~~~\n",
      "took 0.013544321060180664 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (73, 6)\n",
      "H_m \n",
      " (292, 6)\n",
      "took 0.0018393993377685547 sec to get H\n",
      "m_hat:  [-0.15550563 -0.0057474   0.06296677 -0.07783365  0.11467524  0.02546082]\n",
      "~~~~~~~~~~~Iteration  10 ~~~~~~~~~~\n",
      "took 0.01392674446105957 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (71, 6)\n",
      "H_m \n",
      " (284, 6)\n",
      "took 0.0036127567291259766 sec to get H\n",
      "m_hat:  [-0.24588948 -0.01540604  0.06449164 -0.08140069  0.16098952  0.02389319]\n",
      "~~~~~~~~~~~Iteration  11 ~~~~~~~~~~\n",
      "took 0.012981891632080078 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (67, 6)\n",
      "H_m \n",
      " (268, 6)\n",
      "took 0.0033745765686035156 sec to get H\n",
      "m_hat:  [-0.51695645 -0.02405863  0.5862745  -0.07695501  0.25066659  0.01690995]\n",
      "~~~~~~~~~~~Iteration  12 ~~~~~~~~~~\n",
      "took 0.013720512390136719 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (55, 6)\n",
      "H_m \n",
      " (220, 6)\n",
      "took 0.0030221939086914062 sec to get H\n",
      "m_hat:  [-1.50956523 -0.03453414  0.62860173 -0.05706915  0.50061214  0.00763496]\n",
      "~~~~~~~~~~~Iteration  13 ~~~~~~~~~~\n",
      "took 0.013703584671020508 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (38, 6)\n",
      "H_m \n",
      " (152, 6)\n",
      "took 0.002777576446533203 sec to get H\n",
      "m_hat:  [-1.49275696 -0.01303264  0.67145187 -0.03271527  0.51214492  0.0047439 ]\n",
      "~~~~~~~~~~~Iteration  14 ~~~~~~~~~~\n",
      "took 0.014321565628051758 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (34, 6)\n",
      "H_m \n",
      " (136, 6)\n",
      "took 0.003168344497680664 sec to get H\n",
      "m_hat:  [-1.49308681 -0.00613464  0.67140889 -0.01606023  0.51008314  0.00212509]\n",
      "~~~~~~~~~~~Iteration  15 ~~~~~~~~~~\n",
      "took 0.013158559799194336 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (36, 6)\n",
      "H_m \n",
      " (144, 6)\n",
      "took 0.0029382705688476562 sec to get H\n",
      "m_hat:  [-1.49279952e+00 -6.37824228e-03  6.71402395e-01 -8.42784997e-03\n",
      "  5.11891842e-01  5.43441623e-04]\n",
      "~~~~~~~~~~~Iteration  16 ~~~~~~~~~~\n",
      "took 0.014133691787719727 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (36, 6)\n",
      "H_m \n",
      " (144, 6)\n",
      "took 0.0016269683837890625 sec to get H\n",
      "m_hat:  [-1.49237478e+00 -5.40342694e-03  6.71390772e-01 -4.69127856e-03\n",
      "  5.14699697e-01 -5.41017507e-05]\n",
      "~~~~~~~~~~~Iteration  17 ~~~~~~~~~~\n",
      "took 0.013640642166137695 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (36, 6)\n",
      "H_m \n",
      " (144, 6)\n",
      "took 0.0018160343170166016 sec to get H\n",
      "m_hat:  [-1.49180412e+00 -5.75429946e-03  6.71385407e-01 -3.88503517e-03\n",
      "  5.18452406e-01 -1.41786077e-04]\n",
      "~~~~~~~~~~~Iteration  18 ~~~~~~~~~~\n",
      "took 0.013708829879760742 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (36, 6)\n",
      "H_m \n",
      " (144, 6)\n",
      "took 0.0015552043914794922 sec to get H\n",
      "m_hat:  [-1.49143469e+00 -5.12063410e-03  6.71378493e-01 -3.24801775e-03\n",
      "  5.20935118e-01 -1.63366334e-04]\n",
      "~~~~~~~~~~~Iteration  19 ~~~~~~~~~~\n",
      "took 0.013069629669189453 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (36, 6)\n",
      "H_m \n",
      " (144, 6)\n",
      "took 0.0015757083892822266 sec to get H\n",
      "m_hat:  [-1.49107063e+00 -5.12545509e-03  6.71374977e-01 -3.13417939e-03\n",
      "  5.23364127e-01 -1.93425905e-04]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985beae9065b4b8ca71bb605aa5610a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linear_corrector import LC\n",
    "pc1 = old_cloud\n",
    "pc2  = new_cloud\n",
    "m_hat0 = np.array([0, 0, 0, 0, 0, 0.])\n",
    "dc = LC(cloud1 = pc2, cloud2 = pc1, fid = 50, niter = 20, draw = True, m_hat0 = m_hat0,  mnp = 25, RM = False)\n",
    "ViewInteractiveWidget(dc.plt.window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b7545ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##DEBUG: make sure that correspondeces between old and new cloud are good\n",
    "# pc1_theta = dc.c2s(pc1)[:,1]\n",
    "# pc2_theta = dc.c2s(pc2)[:,1]\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(pc1_theta)\n",
    "# ax.plot(pc2_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "467e0506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ iteration  0 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [0. 0. 0. 0. 0. 0.] \n",
      " [0. 0. 0. 0. 0. 0.]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 1.32669e+00  3.43000e-03  2.87700e-02 -9.70000e-04  3.71000e-03\n",
      " -1.13000e-03] \n",
      " [-2.66862e+00 -3.20000e-03 -6.54600e-02 -3.40000e-04  7.99000e-03\n",
      " -8.70000e-04]\n",
      "~~~~ iteration  1 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.3267e+00 -3.4000e-03 -2.8800e-02  1.0000e-03 -3.7000e-03  1.1000e-03] \n",
      " [ 2.6686e+00  3.2000e-03  6.5500e-02 -3.0000e-04  8.0000e-03 -9.0000e-04]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 0.15818 -0.00155 -0.0154   0.0009  -0.00264  0.00105] \n",
      " [-0.29733  0.00189  0.03588  0.0006  -0.0061   0.00083]\n",
      "~~~~ iteration  2 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.4849e+00 -1.9000e-03 -1.3400e-02  1.0000e-04 -1.1000e-03  1.0000e-04] \n",
      " [ 2.9659e+00  1.3000e-03  2.9600e-02  3.0000e-04  1.9000e-03 -0.0000e+00]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 1.393e-02 -1.470e-03 -8.640e-03  1.200e-04 -6.200e-04  9.000e-05] \n",
      " [-3.122e-02  7.300e-04  1.925e-02 -3.000e-05 -1.140e-03  5.000e-05]\n",
      "~~~~ iteration  3 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.4988e+00 -4.0000e-04 -4.7000e-03 -0.0000e+00 -4.0000e-04 -0.0000e+00] \n",
      " [2.9972e+00 6.0000e-04 1.0300e-02 2.0000e-04 7.0000e-04 0.0000e+00]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 1.23e-03 -1.80e-04 -3.30e-03  3.00e-05 -2.70e-04  0.00e+00] \n",
      " [-2.89e-03  9.00e-05  7.15e-03 -6.00e-05 -4.80e-04  0.00e+00]\n",
      "~~~~ iteration  4 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.5e+00 -2.0e-04 -1.4e-03 -1.0e-04 -2.0e-04 -0.0e+00] \n",
      " [3.0001e+00 5.0000e-04 3.2000e-03 2.0000e-04 3.0000e-04 0.0000e+00]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 8.00e-05 -1.00e-05 -1.19e-03  1.00e-05 -9.00e-05 -0.00e+00] \n",
      " [-2.20e-04 -1.00e-05  2.51e-03 -3.00e-05 -1.60e-04 -0.00e+00]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aa7d5be4694ddf8d0645113ae9b7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_hat = np.array([0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "skip = 1 #50\n",
    "y_i = new_cloud[::skip] #baseline\n",
    "y_j = old_cloud[::skip] #distorted cloud\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(y_i[:,:3], c = \"#2c7c94 \", alpha = 0.5, r=5.5))\n",
    "\n",
    "runlen = 5\n",
    "for count in range(runlen):\n",
    "    \n",
    "    print(\"~~~~ iteration \", count, \"~~~~~~~~~~~\")\n",
    "    print(\"A_hat = \\n\", np.round(A_hat[:6],4), \"\\n\", np.round(A_hat[6:],4)) \n",
    "    \n",
    "    #decompose A_hat into X_hat and m_hat\n",
    "    X_hat = A_hat[:6] \n",
    "    m_hat = A_hat[6:]     \n",
    "#     X_hat = np.array([0, 0, 0, 0, 0, 0.]) #for debug\n",
    "#     m_hat = np.array([0, 0, 0, 0, 0, 0.]) #for debug\n",
    "#     m_hat = 0.1*m_hat\n",
    "    \n",
    "    #apply last estimate of distortion correction\n",
    "#     print(\"m_hat\", m_hat)\n",
    "    y_j_undistort = lc(y_j, m_hat)\n",
    "\n",
    "    #apply last rigid transform\n",
    "    rot = R_tf(X_hat[3:]).numpy()\n",
    "    trans = X_hat[:3]\n",
    "    y_j_undistort = (y_j_undistort @ rot) + trans\n",
    "    \n",
    "#     print(\"rot: \\n\", rot,\"\\n trans: \\n\", trans)  \n",
    "#     print(\"\\n y_i \\n\",np.shape(y_i), \"\\n\", y_i[:3])\n",
    "#     print(\"y_j_undistort \\n\",np.shape(y_j_undistort), \"\\n\", y_j_undistort[:3])\n",
    "\n",
    "    \n",
    "    #get H = [H_X, H_m]\n",
    "    #get jacobain of distortion correction function\n",
    "    H_m = dc.get_H_m(y_j_undistort, m_hat) \n",
    "#     print(\"\\n H_m:\", np.shape(H_m), \"\\n\", H_m[:10])\n",
    "    \n",
    "    #get jacobian of rigid transform function \n",
    "    H_x = jacobian_tf(tf.transpose(tf.convert_to_tensor(y_j_undistort, tf.float32)), tf.convert_to_tensor(X_hat[3:], tf.float32)) # shape = [num of corr * 3, 6]\n",
    "    #need to append on a row of zeros since we are working with homogeneous coordinates!\n",
    "    H_x = tf.reshape(H_x, (tf.shape(H_x)[0]//3, 3, 6)) # -> need shape [#corr//4, 4, 6]\n",
    "#     print(\"\\n H_x:\", np.shape(H_x), \"\\n\", H_x[0])\n",
    "    H_x = tf.concat([H_x, tf.zeros([len(H_x),1,6])], axis = 1)\n",
    "    H_x = tf.reshape(H_x, (-1, 6))\n",
    "#     print(\"\\n H_x:\", np.shape(H_x), \"\\n\", H_x[:10])\n",
    "    H_x = H_x.numpy()\n",
    "        \n",
    "    #delta_A =  ((H^T*H)^-1)(H^T)(yi - yj_undistort)\n",
    "    residual = (np.append(y_i, np.ones([len(y_i),1]), axis = 1) -\n",
    "                np.append(y_j_undistort, np.ones([len(y_i),1]), axis = 1)).flatten()\n",
    "#     print(\"residual\", np.shape(residual), \"\\n\", residual)\n",
    "    \n",
    "    H = np.append(H_x, H_m, axis = 1)\n",
    "#     print(\"H: \\n\", np.shape(H))\n",
    "    \n",
    "    delta_A = np.linalg.pinv(H.T @ H) @ H.T @ residual\n",
    "    print(\"\\n delta_A \\n\", np.round(delta_A[:6], 5), \"\\n\", np.round(delta_A[6:], 5))\n",
    "    #augment rigid transform components\n",
    "    A_hat[:6] -=   delta_A[:6]\n",
    "    #augment distortion components\n",
    "    A_hat[6:9] -= delta_A[6:9]\n",
    "    A_hat[9:] += delta_A[9:]\n",
    "\n",
    "    #plot updated cloud2\n",
    "#     color = [0.5 + count/(runlen*2), 1 - (count+1)/runlen, (count+1)/runlen]\n",
    "#     disp.append(Points(y_j_undistort[:,:3], c = color, r=3.5))\n",
    "    disp.append(Points(y_j_undistort[:,:3], c = \"#a65852 \", alpha = (count+1)/(runlen+1), r=3.5))\n",
    "\n",
    "    \n",
    "plt.show(disp, \"12 State Solution\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbbc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
