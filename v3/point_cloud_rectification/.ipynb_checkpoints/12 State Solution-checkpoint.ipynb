{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d618048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 13:27:24.831878: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 13:27:24.936224: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-27 13:27:25.355111: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-07-27 13:27:25.355166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-07-27 13:27:25.355170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-27 13:27:25.839121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:25.861721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:25.861892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 13:27:26.079115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 13:27:26.079864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:26.080076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:26.080219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:26.435878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:26.436042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:26.436168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-27 13:27:26.436254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 8*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "from ICET_spherical import ICET\n",
    "from utils import *\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "# from pioneer.das.api.platform import Platform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "# from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "from matplotlib import pyplot as plt\n",
    "import nbconvert\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cf3de",
   "metadata": {},
   "source": [
    "# Goal: Simultaneously Estimate Translation, Rotation, and Distortion\n",
    "\n",
    "## $\\mathbf{A} = [\\hat{X}_{ij}, \\hat{m}_{ij}] = \n",
    "\\begin{bmatrix}\n",
    "% x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a9028",
   "metadata": {},
   "source": [
    "We can use newton-raphson to find A\n",
    "\n",
    "<!-- ## $y_i = \\mathbf{h}(y_j, \\hat{X}_{ij}, \\hat{m}_{ij}) + \\mathbf{H}_m \\delta m + \\mathbf{H}_x \\delta x + \\text{H.O.T.}$ -->\n",
    "\n",
    "## $y_i = \\mathbf{h}(y_j, \\hat{A}_{ij}) + \\mathbf{H}_A \\delta A + \\text{H.O.T.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62668f7e",
   "metadata": {},
   "source": [
    "## $\\mathbf{H}_A \\in \\mathbb{R}^{4N \\times 12} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb30f3c",
   "metadata": {},
   "source": [
    "\n",
    "### $\\mathbf{H}_A = [H_X, H_m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20903173",
   "metadata": {},
   "source": [
    "# Problem:  what if distortion correction and rigid transform both work equally well?\n",
    "\n",
    "(ex: there are not enough features on one side to completely enclose the vehicle)\n",
    "\n",
    "### IT MAKES LIFE WAY EASIER IF I SUPPRESS ANGULAR COMPONENT OF MOTION PROFILE??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf4dfc",
   "metadata": {},
   "source": [
    "### Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1645f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load point cloud\n",
    "# # no distortion\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case1/raw_frame_0.npy\")\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #actual motion\n",
    "# m_hat = np.array([-3., 0., 0., 0., 0., 0.1]) #test wrap around\n",
    "\n",
    "# movement in x\n",
    "old_cloud =  np.load(\"sample_data/paper_figures/case2/raw_frame_3.npy\") \n",
    "# m_hat = np.array([3, 0, 0., 0., 0., 0])\n",
    "# m_hat = np.array([0, 0, 0., 0., 0., 0])\n",
    "m_hat = np.array([0.25, 0, 0., 0., 0.1, -0.1]) #FOR DEBUG-- deform just a little\n",
    "gt =  np.load(\"sample_data/paper_figures/case2/base_vel_2.npy\")\n",
    "\n",
    "# # movement in x, y, & yaw\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case3/raw_frame_1.npy\") \n",
    "# # m_hat = np.array([3, -1, 0., 0., 0., -1])\n",
    "# # m_hat = np.array([3, -1, 0., 0., 0., -0.86]) #FOR DEBUG-- deform a little extra\n",
    "# m_hat = np.array([3., -1., 0., 0., 0., -0.5]) #FOR DEBUG\n",
    "# gt =  np.load(\"sample_data/paper_figures/case3/base_vel_3.npy\")\n",
    "# print(gt) \n",
    "\n",
    "# period_lidar = 1\n",
    "# t_scale = (2*np.pi)/(-m_hat[-1] + (2*np.pi/period_lidar))\n",
    "# print(t_scale)\n",
    "# m_hat = m_hat*t_scale\n",
    "# # m_hat[-1] = m_hat[-1]*t_scaled\n",
    "# print(m_hat)\n",
    "\n",
    "#downsample\n",
    "# old_cloud = old_cloud[::5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b92149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325e54477a9d429e89590275c4e61122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#apply ground truth distortion according to m_hat\n",
    "try:\n",
    "    new_cloud = dc.apply_motion_profile(old_cloud, m_hat, period_lidar=1)\n",
    "except:\n",
    "    from remove_motion_basic import linear_correction_old as lc #old method (straight from ROS node) \n",
    "    print(\"using backup\")\n",
    "    new_cloud = lc(old_cloud, m_hat) \n",
    "\n",
    "# load new cloud from seprate file\n",
    "# # transOnlyBox GIF (on VICET github repo)\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case2/raw_frame_2.npy\") \n",
    "# new_cloud = np.load(\"sample_data/paper_figures/case2/raw_frame_3.npy\")\n",
    "# #transAndRotateBox GIF\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case2/raw_frame_1.npy\") \n",
    "# new_cloud = np.load(\"sample_data/paper_figures/case3/raw_frame_1.npy\") \n",
    "#test\n",
    "old_cloud =  np.load(\"sample_data/test1/raw_frame_5.npy\") \n",
    "new_cloud = np.load(\"sample_data/test1/raw_frame_7.npy\")\n",
    "# old_cloud =  np.load(\"sample_data/test2/raw_frame_22.npy\") \n",
    "# new_cloud = np.load(\"sample_data/test2/raw_frame_23.npy\")\n",
    "old_cloud = old_cloud[old_cloud[:,0]<1000]\n",
    "new_cloud = new_cloud[new_cloud[:,0]<1000]\n",
    "old_cloud = old_cloud[old_cloud[:,0]>-1000]\n",
    "new_cloud = new_cloud[new_cloud[:,0]>-1000]\n",
    "# old_cloud = old_cloud[~np.isinf(old_cloud[:,0])]\n",
    "\n",
    "#add some extra distortion\n",
    "m_hat = np.array([5, 0, 0.0, 0.0, 0., 0])\n",
    "new_cloud = dc.apply_motion_profile(new_cloud, m_hat, period_lidar=1)\n",
    "\n",
    "# #downsample (for debug)\n",
    "# old_cloud = old_cloud[::5,:]\n",
    "# new_cloud = new_cloud[::5,:]\n",
    "\n",
    "#test-- flip to match rotation direction of Newer College Dataset\n",
    "new_cloud = np.flip(new_cloud, axis =0)\n",
    "old_cloud = np.flip(old_cloud, axis =0)\n",
    "\n",
    "#set ground truth RIGID transform between clouds\n",
    "# X_gt = np.array([0, 0., 0.0, 0.0, 0.0, 0.0])\n",
    "# X_gt = np.array([1.5, 0.5, 0.03, 0.03, 0.03, 0.0625])\n",
    "# X_gt = np.array([1.5, -3, 0.1, 0.2, 0.03, -0.15]) #test\n",
    "# X_gt = np.array([1., 1., 0.0, 0., 0., -0.3]) #rotate and trans GIF\n",
    "# X_gt = np.array([-1.5, 0., 0.0, 0., 0., 0.]) #trans only GIF\n",
    "X_gt = np.array([-2.5,0., 0.0, 0.0, 0.0, 0.0]) #simulated  town scene\n",
    "\n",
    "# add noise\n",
    "# old_cloud += 0.01*np.random.randn(np.shape(old_cloud)[0], 3)\n",
    "\n",
    "#remove ground plane\n",
    "old_cloud = old_cloud[old_cloud[:,2] > -1] \n",
    "new_cloud = new_cloud[new_cloud[:,2] > -1] \n",
    "\n",
    "# Rotate + Translate new point cloud\n",
    "trans = X_gt[:3]\n",
    "rot = R_tf(X_gt[3:]).numpy()\n",
    "new_cloud = (new_cloud @ rot) + trans\n",
    "# old_cloud = (old_cloud @ rot) + trans\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "\n",
    "# #COLOR new_cloud POINTS BY ORDER IN CLOUD ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# color = 255*np.linspace(0,1,len(new_cloud))\n",
    "# cname = np.array([255-color//2, color, 255-color]).T.tolist()\n",
    "# disp.append(Points(new_cloud, c = cname, r = 3, alpha = 1))\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "disp.append(Points(old_cloud, c = \"#2c7c94\", alpha = 0.5)) #blue \n",
    "disp.append(Points(new_cloud, c = \"#CB2314\", alpha = 0.5)) #red\n",
    "plt.show(disp, \"raw point clouds\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b14aab",
   "metadata": {},
   "source": [
    "# Run toy problem again with 12-State ICET (VICET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "734604ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_corrector import LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30cbbc70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual X, m: \n",
      " [-2.5  0.   0.   0.   0.   0. ] \n",
      " [5. 0. 0. 0. 0. 0.]\n",
      "A0:\n",
      " [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "~~~~~~~~~~~Iteration  0 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.593 -0.144 -0.003 -0.    -0.    -0.009] \n",
      " [ 0.03   0.202  0.002 -0.     0.     0.008]\n",
      "~~~~~~~~~~~Iteration  1 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.667 -0.266 -0.004  0.    -0.001 -0.019] \n",
      " [ 0.05   0.367  0.003 -0.001  0.001  0.018]\n",
      "~~~~~~~~~~~Iteration  2 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.751 -0.293 -0.002  0.    -0.001 -0.021] \n",
      " [ 0.084  0.373  0.003 -0.001  0.002  0.024]\n",
      "~~~~~~~~~~~Iteration  3 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.821 -0.322 -0.     0.    -0.002 -0.027] \n",
      " [ 0.111  0.374  0.002 -0.     0.002  0.033]\n",
      "~~~~~~~~~~~Iteration  4 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.86  -0.405 -0.003  0.001 -0.003 -0.039] \n",
      " [0.118 0.472 0.015 0.001 0.004 0.048]\n",
      "~~~~~~~~~~~Iteration  5 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.907 -0.429 -0.002  0.001 -0.004 -0.045] \n",
      " [0.135 0.486 0.016 0.001 0.004 0.057]\n",
      "~~~~~~~~~~~Iteration  6 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.947 -0.421  0.004  0.001 -0.005 -0.049] \n",
      " [0.153 0.448 0.013 0.001 0.004 0.062]\n",
      "~~~~~~~~~~~Iteration  7 ~~~~~~~~~~\n",
      "A: \n",
      " [ 0.98  -0.407  0.001 -0.    -0.006 -0.053] \n",
      " [0.167 0.392 0.04  0.006 0.005 0.071]\n",
      "~~~~~~~~~~~Iteration  8 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.014 -0.374  0.006 -0.001 -0.007 -0.059] \n",
      " [0.178 0.293 0.043 0.008 0.004 0.085]\n",
      "~~~~~~~~~~~Iteration  9 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.039 -0.335  0.013 -0.001 -0.007 -0.066] \n",
      " [0.186 0.186 0.038 0.008 0.004 0.099]\n",
      "~~~~~~~~~~~Iteration  10 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.066 -0.296  0.019 -0.001 -0.008 -0.073] \n",
      " [0.194 0.085 0.03  0.008 0.004 0.116]\n",
      "~~~~~~~~~~~Iteration  11 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.093 -0.247  0.029 -0.001 -0.008 -0.084] \n",
      " [ 0.194 -0.072  0.014  0.008  0.004  0.141]\n",
      "~~~~~~~~~~~Iteration  12 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.405 -0.191  0.047 -0.001 -0.007 -0.083] \n",
      " [-0.569 -0.177 -0.033  0.004  0.003  0.144]\n",
      "~~~~~~~~~~~Iteration  13 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.688 -0.148  0.063 -0.    -0.005 -0.079] \n",
      " [-1.242 -0.226 -0.074  0.002  0.001  0.141]\n",
      "~~~~~~~~~~~Iteration  14 ~~~~~~~~~~\n",
      "A: \n",
      " [ 1.928 -0.12   0.073 -0.    -0.005 -0.075] \n",
      " [-1.796 -0.227 -0.097 -0.     0.     0.136]\n",
      "~~~~~~~~~~~Iteration  15 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.141 -0.097  0.079  0.    -0.004 -0.07 ] \n",
      " [-2.275 -0.216 -0.111 -0.001 -0.     0.129]\n",
      "~~~~~~~~~~~Iteration  16 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.321 -0.076  0.083  0.    -0.004 -0.065] \n",
      " [-2.671 -0.208 -0.119 -0.001 -0.001  0.123]\n",
      "~~~~~~~~~~~Iteration  17 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.48  -0.06   0.086  0.    -0.004 -0.061] \n",
      " [-3.011 -0.193 -0.126 -0.002 -0.001  0.117]\n",
      "~~~~~~~~~~~Iteration  18 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.627 -0.047  0.089  0.001 -0.004 -0.057] \n",
      " [-3.323 -0.174 -0.132 -0.003 -0.001  0.111]\n",
      "~~~~~~~~~~~Iteration  19 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.754 -0.036  0.092  0.001 -0.003 -0.053] \n",
      " [-3.588 -0.161 -0.138 -0.003 -0.001  0.106]\n",
      "~~~~~~~~~~~Iteration  20 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.86  -0.029  0.096  0.001 -0.003 -0.049] \n",
      " [-3.806 -0.144 -0.148 -0.004 -0.002  0.101]\n",
      "~~~~~~~~~~~Iteration  21 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.95  -0.024  0.1    0.001 -0.003 -0.046] \n",
      " [-3.993 -0.13  -0.159 -0.006 -0.002  0.096]\n",
      "~~~~~~~~~~~Iteration  22 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.969 -0.019  0.098  0.001 -0.003 -0.046] \n",
      " [-3.987 -0.127 -0.15  -0.005 -0.002  0.095]\n",
      "~~~~~~~~~~~Iteration  23 ~~~~~~~~~~\n",
      "A: \n",
      " [ 2.986 -0.014  0.096  0.001 -0.003 -0.046] \n",
      " [-3.982 -0.124 -0.141 -0.004 -0.001  0.094]\n",
      "~~~~~~~~~~~Iteration  24 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.057 -0.01   0.1    0.001 -0.003 -0.043] \n",
      " [-4.143 -0.117 -0.156 -0.006 -0.002  0.09 ]\n",
      "~~~~~~~~~~~Iteration  25 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.069 -0.007  0.1    0.001 -0.003 -0.043] \n",
      " [-4.139 -0.114 -0.152 -0.006 -0.002  0.089]\n",
      "~~~~~~~~~~~Iteration  26 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.079 -0.005  0.099  0.001 -0.003 -0.042] \n",
      " [-4.136 -0.111 -0.148 -0.005 -0.002  0.087]\n",
      "~~~~~~~~~~~Iteration  27 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.088 -0.004  0.097  0.001 -0.003 -0.042] \n",
      " [-4.133 -0.109 -0.143 -0.005 -0.001  0.086]\n",
      "~~~~~~~~~~~Iteration  28 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.096 -0.003  0.096  0.001 -0.003 -0.041] \n",
      " [-4.131 -0.105 -0.141 -0.005 -0.001  0.085]\n",
      "~~~~~~~~~~~Iteration  29 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.103 -0.004  0.096  0.001 -0.003 -0.041] \n",
      " [-4.129 -0.1   -0.14  -0.005 -0.001  0.084]\n",
      "~~~~~~~~~~~Iteration  30 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.107 -0.003  0.094  0.001 -0.003 -0.04 ] \n",
      " [-4.128 -0.098 -0.133 -0.005 -0.001  0.083]\n",
      "~~~~~~~~~~~Iteration  31 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.159 -0.001  0.097  0.001 -0.003 -0.038] \n",
      " [-4.269 -0.094 -0.144 -0.006 -0.002  0.08 ]\n",
      "~~~~~~~~~~~Iteration  32 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.163 -0.001  0.096  0.001 -0.003 -0.038] \n",
      " [-4.267 -0.091 -0.142 -0.006 -0.002  0.078]\n",
      "~~~~~~~~~~~Iteration  33 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.166 -0.     0.095  0.002 -0.003 -0.037] \n",
      " [-4.267 -0.089 -0.141 -0.006 -0.002  0.077]\n",
      "~~~~~~~~~~~Iteration  34 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.168  0.     0.094  0.002 -0.003 -0.037] \n",
      " [-4.266 -0.09  -0.137 -0.006 -0.002  0.077]\n",
      "~~~~~~~~~~~Iteration  35 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.213  0.002  0.096  0.002 -0.002 -0.035] \n",
      " [-4.388 -0.087 -0.145 -0.007 -0.002  0.074]\n",
      "~~~~~~~~~~~Iteration  36 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.217  0.003  0.095  0.002 -0.002 -0.035] \n",
      " [-4.387 -0.088 -0.144 -0.007 -0.002  0.073]\n",
      "~~~~~~~~~~~Iteration  37 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.22   0.004  0.093  0.002 -0.003 -0.034] \n",
      " [-4.386 -0.087 -0.14  -0.007 -0.002  0.072]\n",
      "~~~~~~~~~~~Iteration  38 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.222  0.004  0.092  0.002 -0.003 -0.034] \n",
      " [-4.386 -0.087 -0.139 -0.007 -0.002  0.071]\n",
      "~~~~~~~~~~~Iteration  39 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.223  0.003  0.092  0.002 -0.003 -0.034] \n",
      " [-4.386 -0.086 -0.138 -0.007 -0.002  0.071]\n",
      "~~~~~~~~~~~Iteration  40 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.225  0.004  0.091  0.002 -0.003 -0.033] \n",
      " [-4.385 -0.085 -0.137 -0.008 -0.002  0.07 ]\n",
      "~~~~~~~~~~~Iteration  41 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227  0.005  0.089  0.002 -0.003 -0.033] \n",
      " [-4.385 -0.086 -0.132 -0.007 -0.001  0.069]\n",
      "~~~~~~~~~~~Iteration  42 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227  0.002  0.088  0.002 -0.003 -0.033] \n",
      " [-4.385 -0.082 -0.131 -0.007 -0.001  0.069]\n",
      "~~~~~~~~~~~Iteration  43 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227  0.002  0.087  0.002 -0.003 -0.033] \n",
      " [-4.385 -0.081 -0.128 -0.007 -0.001  0.068]\n",
      "~~~~~~~~~~~Iteration  44 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227  0.002  0.087  0.003 -0.003 -0.033] \n",
      " [-4.385 -0.079 -0.128 -0.007 -0.001  0.068]\n",
      "~~~~~~~~~~~Iteration  45 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227 -0.001  0.086  0.003 -0.003 -0.033] \n",
      " [-4.386 -0.076 -0.125 -0.007 -0.001  0.068]\n",
      "~~~~~~~~~~~Iteration  46 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.228 -0.001  0.085  0.003 -0.003 -0.033] \n",
      " [-4.385 -0.076 -0.124 -0.007 -0.001  0.067]\n",
      "~~~~~~~~~~~Iteration  47 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227 -0.003  0.084  0.003 -0.003 -0.033] \n",
      " [-4.386 -0.073 -0.124 -0.007 -0.001  0.067]\n",
      "~~~~~~~~~~~Iteration  48 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.227 -0.003  0.083  0.003 -0.003 -0.032] \n",
      " [-4.386 -0.071 -0.123 -0.008 -0.001  0.066]\n",
      "~~~~~~~~~~~Iteration  49 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.228 -0.004  0.083  0.003 -0.003 -0.032] \n",
      " [-4.386 -0.068 -0.122 -0.008 -0.001  0.065]\n",
      "~~~~~~~~~~~Iteration  50 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.229 -0.005  0.082  0.003 -0.003 -0.032] \n",
      " [-4.386 -0.068 -0.12  -0.008 -0.001  0.065]\n",
      "~~~~~~~~~~~Iteration  51 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.265 -0.004  0.083  0.003 -0.003 -0.03 ] \n",
      " [-4.492 -0.067 -0.126 -0.009 -0.002  0.063]\n",
      "~~~~~~~~~~~Iteration  52 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.267 -0.004  0.081  0.003 -0.003 -0.03 ] \n",
      " [-4.492 -0.068 -0.122 -0.008 -0.001  0.062]\n",
      "~~~~~~~~~~~Iteration  53 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.267 -0.003  0.08   0.003 -0.003 -0.03 ] \n",
      " [-4.492 -0.068 -0.119 -0.008 -0.001  0.062]\n",
      "~~~~~~~~~~~Iteration  54 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.268 -0.005  0.079  0.003 -0.003 -0.03 ] \n",
      " [-4.492 -0.065 -0.119 -0.008 -0.001  0.061]\n",
      "~~~~~~~~~~~Iteration  55 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.268 -0.007  0.078  0.003 -0.003 -0.03 ] \n",
      " [-4.493 -0.061 -0.117 -0.008 -0.001  0.061]\n",
      "~~~~~~~~~~~Iteration  56 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.268 -0.008  0.077  0.003 -0.003 -0.03 ] \n",
      " [-4.493 -0.059 -0.114 -0.008 -0.001  0.061]\n",
      "~~~~~~~~~~~Iteration  57 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.268 -0.01   0.077  0.003 -0.003 -0.03 ] \n",
      " [-4.493 -0.057 -0.113 -0.008 -0.001  0.06 ]\n",
      "~~~~~~~~~~~Iteration  58 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.268 -0.011  0.076  0.003 -0.003 -0.029] \n",
      " [-4.493 -0.055 -0.112 -0.008 -0.001  0.06 ]\n",
      "~~~~~~~~~~~Iteration  59 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.301 -0.009  0.077  0.003 -0.002 -0.028] \n",
      " [-4.587 -0.057 -0.116 -0.009 -0.002  0.058]\n",
      "~~~~~~~~~~~Iteration  60 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.332 -0.01   0.075  0.003 -0.003 -0.026] \n",
      " [-4.67  -0.042 -0.111 -0.008 -0.001  0.056]\n",
      "~~~~~~~~~~~Iteration  61 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.362 -0.013  0.074  0.003 -0.003 -0.024] \n",
      " [-4.746 -0.023 -0.106 -0.008 -0.001  0.054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~Iteration  62 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.389 -0.015  0.073  0.003 -0.002 -0.023] \n",
      " [-4.812 -0.003 -0.104 -0.007 -0.001  0.051]\n",
      "~~~~~~~~~~~Iteration  63 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.413 -0.016  0.073  0.003 -0.002 -0.021] \n",
      " [-4.87   0.009 -0.102 -0.007 -0.001  0.049]\n",
      "~~~~~~~~~~~Iteration  64 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.433 -0.016  0.072  0.003 -0.002 -0.02 ] \n",
      " [-4.918  0.018 -0.098 -0.006 -0.001  0.048]\n",
      "~~~~~~~~~~~Iteration  65 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.437 -0.014  0.071  0.003 -0.003 -0.019] \n",
      " [-4.917  0.019 -0.096 -0.007 -0.     0.047]\n",
      "~~~~~~~~~~~Iteration  66 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.439 -0.013  0.071  0.003 -0.003 -0.019] \n",
      " [-4.916  0.019 -0.095 -0.007  0.     0.047]\n",
      "~~~~~~~~~~~Iteration  67 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.441 -0.011  0.07   0.003 -0.003 -0.019] \n",
      " [-4.915  0.02  -0.095 -0.007  0.001  0.046]\n",
      "~~~~~~~~~~~Iteration  68 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.442 -0.011  0.07   0.003 -0.003 -0.019] \n",
      " [-4.915  0.02  -0.097 -0.007  0.001  0.046]\n",
      "~~~~~~~~~~~Iteration  69 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.443 -0.01   0.069  0.003 -0.003 -0.018] \n",
      " [-4.915  0.02  -0.097 -0.008  0.002  0.045]\n",
      "~~~~~~~~~~~Iteration  70 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.445 -0.009  0.068  0.003 -0.003 -0.018] \n",
      " [-4.914  0.02  -0.099 -0.008  0.002  0.045]\n",
      "~~~~~~~~~~~Iteration  71 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.446 -0.008  0.068  0.003 -0.003 -0.018] \n",
      " [-4.914  0.021 -0.101 -0.009  0.003  0.044]\n",
      "~~~~~~~~~~~Iteration  72 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.447 -0.008  0.068  0.004 -0.003 -0.018] \n",
      " [-4.913  0.021 -0.103 -0.009  0.003  0.044]\n",
      "~~~~~~~~~~~Iteration  73 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.447 -0.007  0.067  0.004 -0.003 -0.018] \n",
      " [-4.913  0.021 -0.104 -0.01   0.004  0.044]\n",
      "~~~~~~~~~~~Iteration  74 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.448 -0.006  0.066  0.004 -0.003 -0.017] \n",
      " [-4.913  0.021 -0.106 -0.01   0.004  0.043]\n",
      "~~~~~~~~~~~Iteration  75 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.448 -0.006  0.066  0.004 -0.003 -0.017] \n",
      " [-4.913  0.021 -0.108 -0.011  0.005  0.043]\n",
      "~~~~~~~~~~~Iteration  76 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.448 -0.007  0.065  0.004 -0.003 -0.017] \n",
      " [-4.913  0.021 -0.11  -0.011  0.005  0.043]\n",
      "~~~~~~~~~~~Iteration  77 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.449 -0.007  0.065  0.004 -0.003 -0.017] \n",
      " [-4.913  0.021 -0.114 -0.012  0.006  0.043]\n",
      "~~~~~~~~~~~Iteration  78 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.449 -0.008  0.065  0.005 -0.003 -0.017] \n",
      " [-4.912  0.022 -0.12  -0.013  0.006  0.043]\n",
      "~~~~~~~~~~~Iteration  79 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.449 -0.008  0.066  0.005 -0.003 -0.017] \n",
      " [-4.912  0.025 -0.125 -0.014  0.007  0.042]\n",
      "~~~~~~~~~~~Iteration  80 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.448 -0.009  0.066  0.005 -0.003 -0.017] \n",
      " [-4.912  0.027 -0.131 -0.015  0.007  0.042]\n",
      "~~~~~~~~~~~Iteration  81 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.447 -0.011  0.066  0.006 -0.003 -0.017] \n",
      " [-4.912  0.03  -0.138 -0.016  0.007  0.042]\n",
      "~~~~~~~~~~~Iteration  82 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.447 -0.011  0.066  0.006 -0.003 -0.017] \n",
      " [-4.912  0.032 -0.143 -0.017  0.008  0.042]\n",
      "~~~~~~~~~~~Iteration  83 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.446 -0.013  0.067  0.006 -0.003 -0.017] \n",
      " [-4.913  0.032 -0.15  -0.018  0.008  0.042]\n",
      "~~~~~~~~~~~Iteration  84 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.445 -0.014  0.068  0.007 -0.003 -0.017] \n",
      " [-4.913  0.034 -0.157 -0.019  0.008  0.042]\n",
      "~~~~~~~~~~~Iteration  85 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.444 -0.015  0.068  0.007 -0.003 -0.017] \n",
      " [-4.913  0.034 -0.164 -0.02   0.009  0.042]\n",
      "~~~~~~~~~~~Iteration  86 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.461 -0.016  0.069  0.007 -0.003 -0.016] \n",
      " [-4.969  0.038 -0.172 -0.021  0.009  0.041]\n",
      "~~~~~~~~~~~Iteration  87 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.478 -0.017  0.07   0.008 -0.003 -0.016] \n",
      " [-5.02   0.043 -0.178 -0.022  0.009  0.04 ]\n",
      "~~~~~~~~~~~Iteration  88 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.491 -0.018  0.07   0.008 -0.003 -0.015] \n",
      " [-5.063  0.048 -0.183 -0.023  0.009  0.039]\n",
      "~~~~~~~~~~~Iteration  89 ~~~~~~~~~~\n",
      "A: \n",
      " [ 3.505 -0.018  0.07   0.009 -0.003 -0.015] \n",
      " [-5.103  0.051 -0.188 -0.024  0.01   0.038]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51be640f0647407386608b117e1d61b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "A0 = np.array([0.5, 0., 0, 0, 0, 0.0,\n",
    "               0, 0.0, 0, 0, 0, 0])\n",
    "print(\"actual X, m: \\n\", X_gt, \"\\n\", m_hat )\n",
    "# new_cloud=new_cloud[:-200]#get rid of points at end\n",
    "\n",
    "dc = LC(cloud1 = old_cloud, cloud2 = new_cloud, fid = 85, niter = 90, \n",
    "        draw = True, mnp = 25, RM = False, solver = '12_state', \n",
    "        max_buffer = 5.5, A0 = A0)\n",
    "# dc = LC(cloud1 = new_cloud, cloud2 = old_cloud, fid = 60, niter = 180, \n",
    "#         draw = True, mnp = 25, RM = False, solver = '12_state', \n",
    "#         max_buffer = 2.5, A0 = A0)\n",
    "\n",
    "#NOTE: if sensor is  spinning in the wrong direction, correction factor will get PC's to align BUT\n",
    "#      motion distortion and rigid  transform values will be incorrect\n",
    "\n",
    "# new_cloud_flipped = np.flip(new_cloud, axis = 0)\n",
    "# old_cloud_flipped = np.flip(old_cloud, axis = 0)\n",
    "# dc = LC(cloud1 = old_cloud_flipped, cloud2 = new_cloud_flipped, fid = 50, niter = 105, \n",
    "#         draw = True, mnp = 25, RM = False, solver = '12_state', \n",
    "#         max_buffer = 3.5, A0 = A0)\n",
    "\n",
    "\n",
    "ViewInteractiveWidget(dc.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389e9b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737bb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0734cdf9",
   "metadata": {},
   "source": [
    "### Attempt to solve with basic 6 state solution (Impossible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from linear_corrector import LC\n",
    "pc1 = old_cloud\n",
    "pc2  = new_cloud\n",
    "m_hat0 = np.array([0, 0, 0, 0, 0, 0.])\n",
    "dc = LC(cloud1 = pc2, cloud2 = pc1, fid = 50, niter = 20, draw = True, \n",
    "        m_hat0 = m_hat0,  mnp = 25, RM = False, solver='6_state')\n",
    "ViewInteractiveWidget(dc.plt.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab35f8",
   "metadata": {},
   "source": [
    "### Run Newton-Raphson with a priori correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e0506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_hat = np.array([0., 0, 0, 0, 0, 0, \n",
    "                  0, 0, 0, 0, 0, 0])\n",
    "skip = 1 #50\n",
    "y_i = new_cloud[::skip] #baseline\n",
    "y_j = old_cloud[::skip] #distorted cloud\n",
    "\n",
    "print(\"num corr total:\", len(y_i))\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(y_i[:,:3], c = \"#a65852 \", alpha = 0.5, r=5.5)) #\n",
    "\n",
    "runlen = 20\n",
    "for count in range(runlen):\n",
    "    \n",
    "    print(\"~~~~ iteration \", count, \"~~~~~~~~~~~\")\n",
    "#     print(\"A_hat = \\n\", np.round(A_hat[:6],4), \"\\n\", np.round(A_hat[6:],4)) \n",
    "    print(\"A_hat = \\n\", A_hat[:6], \"\\n\", A_hat[6:]) \n",
    "\n",
    "    #decompose A_hat into X_hat and m_hat\n",
    "    X_hat = A_hat[:6] \n",
    "    m_hat = A_hat[6:]\n",
    "    \n",
    "    #apply last estimate of distortion correction\n",
    "    y_j_undistort = lc(y_j, m_hat)\n",
    "    #apply last rigid transform\n",
    "    rot = R_tf(X_hat[3:]).numpy()\n",
    "    trans = X_hat[:3]\n",
    "    y_j_undistort = (y_j_undistort @ rot) + trans\n",
    "\n",
    "#     print(\"rot: \\n\", rot,\"\\n trans: \\n\", trans)  \n",
    "#     print(\"\\n y_i \\n\",np.shape(y_i), \"\\n\", y_i[:3])\n",
    "#     print(\"y_j_undistort \\n\",np.shape(y_j_undistort), \"\\n\", y_j_undistort[:3])\n",
    "    \n",
    "    #get jacobain of distortion correction function, [H_X, H_m]\n",
    "    H_m = dc.get_H_m(y_j_undistort, m_hat) \n",
    "#     print(\"\\n H_m:\", np.shape(H_m), \"\\n\", H_m[:10])\n",
    "    \n",
    "    #get jacobian of rigid transform function \n",
    "    H_x = jacobian_tf(tf.transpose(tf.convert_to_tensor(y_j_undistort, tf.float32)), tf.convert_to_tensor(X_hat[3:], tf.float32)) # shape = [num of corr * 3, 6]\n",
    "    #need to append on a row of zeros since we are working with homogeneous coordinates!\n",
    "    H_x = tf.reshape(H_x, (tf.shape(H_x)[0]//3, 3, 6)) # -> need shape [#corr//4, 4, 6]\n",
    "#     print(\"\\n H_x before:\", np.shape(H_x), \"\\n\", H_x[0])\n",
    "    H_x = tf.concat([H_x, tf.zeros([len(H_x),1,6])], axis = 1)\n",
    "    H_x = tf.reshape(H_x, (-1, 6))\n",
    "#     print(\"\\n H_x after:\", np.shape(H_x), \"\\n\", H_x[:10])\n",
    "    H_x = H_x.numpy()\n",
    "        \n",
    "    #delta_A =  ((H^T*H)^-1)(H^T)(yi - yj_undistort)\n",
    "    residual = (np.append(y_i, np.ones([len(y_i),1]), axis = 1) -\n",
    "                np.append(y_j_undistort, np.ones([len(y_i),1]), axis = 1)).flatten()\n",
    "#     print(\"residual\", np.shape(residual), \"\\n\", residual)\n",
    "    \n",
    "    H = np.append(H_x, H_m, axis = 1)\n",
    "    print(\"H: \\n\", np.shape(H))\n",
    "\n",
    "    print(\"pinv(HTH): \\n\", np.shape(np.linalg.pinv(H.T @ H)))\n",
    "    print(\"pinv(HTH) @ H.T: \\n\", np.shape(np.linalg.pinv(H.T @ H) @ H.T))\n",
    "    \n",
    "    delta_A = np.linalg.pinv(H.T @ H) @ H.T @ residual\n",
    "    print(\"\\n delta_A \\n\", np.round(delta_A[:6], 5), \"\\n\", np.round(delta_A[6:], 5))\n",
    "    #augment rigid transform components\n",
    "    A_hat[:6] -=   delta_A[:6]\n",
    "    #augment distortion components\n",
    "    A_hat[6:9] -= delta_A[6:9]\n",
    "    A_hat[9:] += delta_A[9:]\n",
    "\n",
    "    #plot updated cloud2\n",
    "#     color = [0.5 + count/(runlen*2), 1 - (count+1)/runlen, (count+1)/runlen]\n",
    "#     disp.append(Points(y_j_undistort[:,:3], c = color, r=3.5))\n",
    "    disp.append(Points(y_j_undistort[:,:3], c = \"#2c7c94 \", alpha = (count+1)/(runlen+1), r=3.5))\n",
    "\n",
    "    \n",
    "plt.show(disp, \"12 State Solution\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "a = dc.A\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5eec56",
   "metadata": {},
   "source": [
    "### Run rigid ICET (for debugging predicted standard deviations of error in rigid states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df017ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_guess = tf.constant([0.1*np.random.randn(),0.1*np.random.randn(),0.,0.,0.,0.])\n",
    "it = ICET(cloud1 = new_cloud, cloud2 = old_cloud, fid = 50, niter = 10, \n",
    "       draw = True, group = 2, RM = False, DNN_filter = False, x0 = initial_guess)\n",
    "ViewInteractiveWidget(it.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n  VICET error bounds: \\n\", dc.pred_stds[:6].numpy())\n",
    "print(\"\\n  ICET error bounds: \\n\", it.pred_stds.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086cb94",
   "metadata": {},
   "source": [
    "### New scan is being undistorted to match reference scan but pitch/roll are being compensated by a combination of rotation and translation states (should be rotation only!!!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider covariance of states\n",
    "# print(dc.Q)\n",
    "trans_y = dc.Q[1,:]\n",
    "print(trans_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1265e02",
   "metadata": {},
   "source": [
    "# Run 12-State on Ford Campus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf4ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test registration on single scan pair\n",
    "\n",
    "i = 2500 #990\n",
    "\n",
    "ground_truth = np.loadtxt(\"../spherical_paper/FORD_results/truth_body_frame.txt\") # [0, v_xandy, v_vertical, r, p, y]\n",
    "gt = (ground_truth[i,:] + ground_truth[i+1,:])/20 #avg between pts\n",
    "print(\"gt: \\n\", gt[0], gt[1])\n",
    "\n",
    "fn1 = '/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/Scan%04d.mat' %(i+75)\n",
    "fn2 = '/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/Scan%04d.mat' %(i+76)\n",
    "dat1 = mat4py.loadmat(fn1)\n",
    "SCAN1 = dat1['SCAN']\n",
    "pc1 = np.transpose(np.array(SCAN1['XYZ']))\n",
    "dat2 = mat4py.loadmat(fn2)\n",
    "SCAN2 = dat2['SCAN']\n",
    "pc2 = np.transpose(np.array(SCAN2['XYZ']))\n",
    "\n",
    "#flip order in which points appear in each cloud (so scanner spins ccw in stead of cw)\n",
    "pc1 = np.flip(pc1, axis = 0)\n",
    "pc2 = np.flip(pc2, axis = 0)\n",
    "#test: try just flipping sign on y values....\n",
    "# pc1[:,1] = -pc1[:,1]\n",
    "# pc2[:,1] = -pc2[:,1]\n",
    "\n",
    "#need to rotate point clouds so the scan starts aligned with +x axis\n",
    "rot = R_tf(np.array([0,0,-np.pi/2])).numpy()\n",
    "pc1 = pc1 @ rot\n",
    "pc2 = pc2 @ rot\n",
    "\n",
    "A0 = np.array([gt[1], 0, 0, 0, 0, 0,\n",
    "               0, 0, 0, 0, 0, 0])\n",
    "# A0 = np.array([0., 0, 0, 0, 0, 0,\n",
    "#                0, 0, 0, 0, 0, 0])\n",
    "\n",
    "#run 12 State Rigid Transform + Distortion Correction\n",
    "dc = LC(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 15, A0 = A0,\n",
    "    draw = True, mnp = 50, RM = False, solver = '12_state', \n",
    "        max_buffer = 0.5)\n",
    "ViewInteractiveWidget(dc.plt.window)\n",
    "\n",
    "# #just run ICET (for debug)\n",
    "# it = ICET(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 10, \n",
    "#            draw = True, group = 2, RM = True, DNN_filter = False)\n",
    "# ViewInteractiveWidget(it.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ground truth data and rigid transform ICET results\n",
    "# estimates = np.loadtxt(\"../results/Ford_full_estimates_v10.txt\") #was this\n",
    "# pred_stds = np.loadtxt(\"../results/Ford_full_pred_stds_v10.txt\")\n",
    "estimates = np.loadtxt(\"../Ford_full_estimates_v12.txt\") #test 5/8/23\n",
    "pred_stds = np.loadtxt(\"../Ford_full_pred_stds_v12.txt\")\n",
    "\n",
    "ground_truth = np.loadtxt(\"../spherical_paper/FORD_results/truth_body_frame.txt\") # [0, v_xandy, v_vertical, r, p, y]\n",
    "LOAM = np.loadtxt(\"../spherical_paper/FORD_results/LOAM.txt\")\n",
    "# LOAM = np.loadtxt(\"../spherical_paper/FORD_results/LOAM_v2.txt\")\n",
    "ICP = np.loadtxt(\"../spherical_paper/FORD_results/ICP.txt\")\n",
    "# NDT = np.loadtxt(\"../spherical_paper/FORD_results/NDT_cart_v2.txt\") #very bad\n",
    "runlen = np.shape(estimates)[0]\n",
    "estimates = estimates[1:,:]\n",
    "pred_stds = pred_stds[1:,:]\n",
    "vf = (ground_truth[:runlen-1,1]/10 + ground_truth[1:runlen,1]/10)/2 #v5\n",
    "\n",
    "#plot ground truth vs raw ICET estimates\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(vf, label = 'Ground Truth Translation')\n",
    "# print(estimates[:,0])\n",
    "ax.plot(LOAM[:,1], label = \"LOAM\")\n",
    "ax.plot(estimates[:,1], label = \"ICET (rigid) Estimated Translation\") #was this\n",
    "#NOTE-- adjust linspace here when shifting\n",
    "ax.fill_between(np.linspace(0,runlen-2,runlen-1),\n",
    "                   vf - 2*pred_stds[:,1], vf + 2*pred_stds[:,1], \n",
    "                   color = [0,0,0], alpha = 0.2, label = 'ICET (rigid) Predicted 2σ Error Bound')\n",
    "ax.set_xlabel(\"frame\")\n",
    "ax.set_ylabel(\"forward translation per frame (m)\")\n",
    "ax.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e65728",
   "metadata": {},
   "source": [
    "## Full Ford Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ad150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_corrector import LC\n",
    "import mat4py\n",
    "\n",
    "start_idx = 0 #990 #start on this scan\n",
    "runlen = 3680 #250\n",
    "m_hat_history = np.zeros([runlen, 6])\n",
    "X_hat_history = np.zeros([runlen, 6])\n",
    "X_hat_history_ICET = np.zeros([runlen, 6])\n",
    "seed_hist = np.zeros([runlen, 6])\n",
    "\n",
    "A0 = np.array([0., 0, 0, 0, 0, 0,\n",
    "               0., 0, 0, 0, 0, 0])\n",
    "\n",
    "for i in range(runlen):\n",
    "    print(\"---------------------------------- SCAN IDX\", i + start_idx,\"-------------------------------------\")\n",
    "\n",
    "    #load point clouds\n",
    "    fn1 = '/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/Scan%04d.mat' %(i+start_idx+75)\n",
    "    fn2 = '/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/Scan%04d.mat' %(i+start_idx+76)\n",
    "    dat1 = mat4py.loadmat(fn1)\n",
    "    SCAN1 = dat1['SCAN']\n",
    "    pc1 = np.transpose(np.array(SCAN1['XYZ']))\n",
    "    dat2 = mat4py.loadmat(fn2)\n",
    "    SCAN2 = dat2['SCAN']\n",
    "    pc2 = np.transpose(np.array(SCAN2['XYZ']))\n",
    "\n",
    "    #align point clouds using ground truth\n",
    "    ground_truth = np.loadtxt(\"/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/FORD_DS1_truth.txt\")/10\n",
    "    ground_truth = tf.cast(tf.convert_to_tensor(ground_truth), tf.float32)\n",
    "    gt = (ground_truth[i+start_idx,:] + ground_truth[i+start_idx+1,:])/2 #avg between pts\n",
    "        \n",
    "    #flip order in which points appear in each cloud (so scanner spins ccw in stead of cw)\n",
    "    pc1 = np.flip(pc1, axis = 0)\n",
    "    pc2 = np.flip(pc2, axis = 0)\n",
    "    #need to rotate point clouds so the scan starts aligned with +x axis\n",
    "    rot = R_tf(np.array([0,0,-np.pi/2])).numpy()\n",
    "    pc1 = pc1 @ rot\n",
    "    pc2 = pc2 @ rot\n",
    "\n",
    "#     #apply \"ground truth\" transform to point clouds\n",
    "#     trans = np.array([gt[1], gt[0], gt[2]])\n",
    "#     trans[0] += 0.01 #add noise to x\n",
    "#     rot = R_tf(-gt[3:]).numpy().T\n",
    "#     pc2_transformed =  (pc2 @ rot) + trans \n",
    "    \n",
    "#     print(\"\\n trans, rot GT: \\n\", trans, -gt[3:].numpy())\n",
    "\n",
    "    \n",
    "#     #apply output of ICET to raw point clouds ~~~~~~~~~~~~~~~~~~~\n",
    "#     #align point clouds using ICET output, seed ICET input with ground truth to ensure convergence\n",
    "#     it = ICET(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 10, \n",
    "#            draw = False, group = 2, RM = True, DNN_filter = False, x0 = gt)\n",
    "#     #ViewInteractiveWidget(it.plt.window)\n",
    "#     gt = it.X\n",
    "#     trans = it.X[:3].numpy()\n",
    "#     rot = R_tf(-it.X[3:]).numpy().T\n",
    "#     pc2_transformed =  (pc2 @ rot) + trans \n",
    "#     print(\"\\n trans, rot it.X \\n\", trans, -it.X[3:].numpy())\n",
    "#     #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "#     #run 12 State Rigid Transform + Distortion Correction\n",
    "#     dc = LC(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 25, \n",
    "#         draw = False, mnp = 25, RM = True, solver = '12_state', max_buffer = 1.0)\n",
    "    \n",
    "    noise = 0.05*np.random.randn()\n",
    "#     run 6 State Rigid Transform ONLY\n",
    "    x0 = tf.constant([gt[1].numpy()+noise, 0, 0, 0, 0, 0], tf.float32)\n",
    "    it = ICET(cloud1 = pc1, cloud2 = pc2, fid = 70, niter = 10, x0 = x0,\n",
    "           draw = False, group = 2, RM = True, DNN_filter = False)\n",
    "    seed_hist[i,0] = gt[1].numpy()+noise\n",
    "    \n",
    "#     #seed initial alignments close to GT solution\n",
    "#     A0 = np.array([gt[1]+noise, 0, 0, 0, 0, 0,\n",
    "#                    0,           0, 0, 0, 0, 0])\n",
    "    #seed initial alignments close to ICET solution\n",
    "    A0 = np.array([it.X[0], it.X[1], it.X[2], it.X[3], it.X[4], it.X[5],\n",
    "                   0., 0., 0., 0., 0., 0.])\n",
    "#     A0[:6] = np.array([it.X[0], it.X[1], it.X[2], it.X[3], it.X[4], it.X[5]])\n",
    "#     run 12 State Rigid Transform + Distortion Correction\n",
    "    dc = LC(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 5, A0 = A0,\n",
    "        draw = False, mnp = 50, RM = False, solver = '12_state', max_buffer = 0.3)\n",
    "#     if A0[6] < 0.05:\n",
    "#         A0[6:] = dc.A[6:] #test feeding last distortion bounds as input for next iter\n",
    "#     else:\n",
    "#         A0[6:] = np.array([0., 0., 0., 0., 0., 0.]) #zero out if they get too big\n",
    "        \n",
    "#     #zero out initial estimates (assume rigid ICET got us most of the way there)\n",
    "#     A0 = np.array([0., 0, 0, 0, 0, 0,\n",
    "#                    0, 0, 0, 0, 0, 0])\n",
    "#     #run 12 State on STATIC portions of clouds ONLY\n",
    "#     dc = LC(cloud1 = it.cloud1_static, cloud2 = it.cloud2_static, fid = 50, niter = 10, A0 = A0,\n",
    "#         draw = False, mnp = 50, RM = False, solver = '12_state', max_buffer = 0.3)\n",
    "    \n",
    "    X_hat_history[i,:] = dc.A[:6] #when feeding output of rigid ICET as x0\n",
    "#     X_hat_history[i,:] = dc.A[:6] + it.X #when using \"static PC\" output\n",
    "    m_hat_history[i,:] = dc.A[6:]\n",
    "    X_hat_history_ICET[i,:] = it.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79346168",
   "metadata": {},
   "source": [
    "### plot bounds for forward movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502c190",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_stds = np.loadtxt(\"../results/Ford_full_pred_stds_v10.txt\")\n",
    "pred_stds = pred_stds[(start_idx):(start_idx+runlen),:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ground_truth = np.loadtxt(\"/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/FORD_DS1_truth.txt\")/10\n",
    "ground_truth = tf.cast(tf.convert_to_tensor(ground_truth), tf.float32)\n",
    "# gt = (ground_truth[i+start_idx,:] + ground_truth[i+start_idx+1,:])/2 #avg between pts\n",
    "vf = (ground_truth[(start_idx+1):(start_idx+runlen+1),1] + ground_truth[start_idx:(start_idx+runlen),1])/2 #works best(?)\n",
    "# vf = ground_truth[(start_idx+1):(start_idx+runlen+1),1] #test\n",
    "\n",
    "ax.plot(vf, 'k--', label = 'Ground Truth Translation')\n",
    "# ax.plot(estimates[start_idx:(start_idx+runlen),1], label = \"ICET Estimated Translation (rigid)\") #old rigid\n",
    "\n",
    "# ax.plot(X_hat_history[1:,0], alpha = 0.8, label = \"ICET Registration (12 State)\")\n",
    "# ax.plot(X_hat_history_ICET[:,0], alpha = 0.8, label = \"ICET Registration (6 State)\") #same params as 12 state\n",
    "ax.plot(estimates[start_idx:(start_idx+runlen),1], alpha = 0.8, label = \"ICET\")#\"ICET Registration (tuned 6 State)\") #old full run optimized ICET\n",
    "# ax.plot(seed_hist[:,0], 'k.', alpha = 0.3, label = \"ICET initial seed\" )\n",
    "# ax.plot(LOAM[1:,1], alpha = 0.5, label = \"LOAM\")\n",
    "ax.plot(ICP[1:,1], 'g', alpha = 0.35, label = \"ICP\")\n",
    "# ax.plot(NDT[1:,1], 'g--', alpha = 0.8, label = \"NDT\")\n",
    "\n",
    "# ax.fill_between(np.linspace(0,runlen-1,runlen),\n",
    "#                    vf - 2*pred_stds[:,1], vf + 2*pred_stds[:,1], \n",
    "#                    color = [0,0,0], alpha = 0.2, label = 'ICET Predicted 2σ Error Bound')\n",
    "\n",
    "# ax.fill_between(np.linspace(0,runlen-1,runlen),\n",
    "#                    vf - m_hat_history[:,0], vf + m_hat_history[:,0], \n",
    "#                    color = [1,0,0], alpha = 0.3, label = 'Distortion Bounds (12 State)')\n",
    "\n",
    "# plot distortion bounds w.r.t. gt\n",
    "# ax.fill_between(np.linspace(0,runlen-2,runlen-1),\n",
    "#                    vf[:-1] - abs(m_hat_history[1:,0])-2*abs(pred_stds[1:,1]), \n",
    "#                    vf[:-1] + abs(m_hat_history[1:,0]) + 2*abs(pred_stds[1:,1]), \n",
    "#                    color = [1,0,0], alpha = 0.3, label = 'Distortion Bounds')\n",
    "ax.fill_between(np.linspace(0,runlen-3,runlen-2),\n",
    "                   vf[:-2] - abs(m_hat_history[2:,0])-2*abs(pred_stds[2:,1]), \n",
    "                   vf[:-2] + abs(m_hat_history[2:,0]) + 2*abs(pred_stds[2:,1]), \n",
    "                   color = [1,0,0], alpha = 0.5, label = '2σ + Distortion Bounds')\n",
    "\n",
    "# # plot distortion bounds w.r.t. 12-State ICET Estimaes\n",
    "# ax.fill_between(np.linspace(0,runlen-1,runlen),\n",
    "#                    X_hat_history[:,0] - abs(m_hat_history[:,0])-2*abs(pred_stds[:,1]), \n",
    "#                    X_hat_history[:,0] + abs(m_hat_history[:,0]) + 2*abs(pred_stds[:,1]), \n",
    "#                    color = [1,0,0], alpha = 0.3, label = '2σ + 2*Distortion Bounds (12 State)')\n",
    "\n",
    "ax.set_title(\"Ford Campus Dataset: 12-state ICET\")\n",
    "ax.set_xlabel(\"frame index\")\n",
    "ax.set_ylabel(\"forward translation per frame (m)\")\n",
    "ax.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c54216",
   "metadata": {},
   "source": [
    "### plot bounds for yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f380c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_stds = np.loadtxt(\"../results/Ford_full_pred_stds_v10.txt\")\n",
    "pred_stds = pred_stds[(start_idx):(start_idx+runlen),:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ground_truth = np.loadtxt(\"/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/FORD_DS1_truth.txt\")/10\n",
    "ground_truth = tf.cast(tf.convert_to_tensor(ground_truth), tf.float32)\n",
    "# gt = (ground_truth[i+start_idx,:] + ground_truth[i+start_idx+1,:])/2 #avg between pts\n",
    "# vf = (ground_truth[(start_idx+1):(start_idx+runlen+1),5] + ground_truth[start_idx:(start_idx+runlen),5])/2 #works best(?)\n",
    "vf = ground_truth[(start_idx+1):(start_idx+runlen+1),5] #test\n",
    "\n",
    "ax.plot(vf, 'k--', label = 'Ground Truth Yaw')\n",
    "# ax.plot(estimates[start_idx:(start_idx+runlen),1], label = \"ICET Estimated Translation (rigid)\") #old rigid\n",
    "\n",
    "# ax.plot(X_hat_history[1:,0], alpha = 0.8, label = \"ICET Registration (12 State)\")\n",
    "# ax.plot(X_hat_history_ICET[:,0], alpha = 0.8, label = \"ICET Registration (6 State)\") #same params as 12 state\n",
    "ax.plot(estimates[start_idx:(start_idx+runlen),5], alpha = 0.8, label = \"ICET\")#\"ICET Registration (tuned 6 State)\") #old full run optimized ICET\n",
    "# ax.plot(seed_hist[:,0], 'k.', alpha = 0.3, label = \"ICET initial seed\" )\n",
    "# ax.plot(LOAM[1:,1], alpha = 0.5, label = \"LOAM\")\n",
    "# ax.plot(ICP[1:,1], 'g', alpha = 0.35, label = \"ICP\")\n",
    "# ax.plot(NDT[1:,1], 'g--', alpha = 0.8, label = \"NDT\")\n",
    "\n",
    "# ax.fill_between(np.linspace(0,runlen-1,runlen),\n",
    "#                    vf - 2*pred_stds[:,1], vf + 2*pred_stds[:,1], \n",
    "#                    color = [0,0,0], alpha = 0.2, label = 'ICET Predicted 2σ Error Bound')\n",
    "\n",
    "# ax.fill_between(np.linspace(0,runlen-1,runlen),\n",
    "#                    vf - m_hat_history[:,0], vf + m_hat_history[:,0], \n",
    "#                    color = [1,0,0], alpha = 0.3, label = 'Distortion Bounds (12 State)')\n",
    "\n",
    "# plot distortion bounds w.r.t. gt\n",
    "ax.fill_between(np.linspace(0,runlen-2,runlen-1),\n",
    "                   vf[:-1] - abs(m_hat_history[1:,5])-2*abs(pred_stds[1:,5]), \n",
    "                   vf[:-1] + abs(m_hat_history[1:,5]) + 2*abs(pred_stds[1:,5]), \n",
    "                   color = [1,0,0], alpha = 0.3, label = 'Distortion Bounds')\n",
    "# ax.fill_between(np.linspace(0,runlen-3,runlen-2),\n",
    "#                    vf[:-2] - abs(m_hat_history[2:,5])-2*abs(pred_stds[2:,5]), \n",
    "#                    vf[:-2] + abs(m_hat_history[2:,5]) + 2*abs(pred_stds[2:,5]), \n",
    "#                    color = [1,0,0], alpha = 0.3, label = '2σ + Distortion Bounds')\n",
    "\n",
    "# # plot distortion bounds w.r.t. 12-State ICET Estimaes\n",
    "# ax.fill_between(np.linspace(0,runlen-1,runlen),\n",
    "#                    X_hat_history[:,0] - abs(m_hat_history[:,0])-2*abs(pred_stds[:,1]), \n",
    "#                    X_hat_history[:,0] + abs(m_hat_history[:,0]) + 2*abs(pred_stds[:,1]), \n",
    "#                    color = [1,0,0], alpha = 0.3, label = '2σ + 2*Distortion Bounds (12 State)')\n",
    "\n",
    "ax.set_title(\"Ford Campus Dataset: 12-state ICET\")\n",
    "ax.set_xlabel(\"frame index\")\n",
    "ax.set_ylabel(\"yaw per frame (rad)\")\n",
    "ax.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"sample_data/Ford_m_hat_history_12_state_ICET_990\",  m_hat_history) #250 frames\n",
    "# np.save(\"sample_data/Ford_X_hat_history_12_state_ICET_990\",  X_hat_history) #250 frames\n",
    "# np.save(\"sample_data/Ford_12_state_seed_values_990\", seed_hist) #250 frames\n",
    "\n",
    "# np.save(\"sample_data/Ford_m_hat_history_12_state_ICET_full\",  m_hat_history) \n",
    "# np.save(\"sample_data/Ford_X_hat_history_12_state_ICET_full\",  X_hat_history) \n",
    "# np.save(\"sample_data/Ford_12_state_seed_values_full\", seed_hist)\n",
    "m_hat_history = np.load(\"sample_data/Ford_m_hat_history_12_state_ICET_full.npy\")\n",
    "X_hat_history = np.load(\"sample_data/Ford_X_hat_history_12_state_ICET_full.npy\")\n",
    "seed_hist = np.load(\"sample_data/Ford_12_state_seed_values_full.npy\")\n",
    "\n",
    "# np.save(\"sample_data/Ford_m_hat_history_12_state_ICET_full_v2\",  m_hat_history) \n",
    "# np.save(\"sample_data/Ford_X_hat_history_12_state_ICET_full_v2\",  X_hat_history) \n",
    "# np.save(\"sample_data/Ford_X_hat_history_6_state_ICET_full_v2\",  X_hat_history_ICET) \n",
    "# np.save(\"sample_data/Ford_12_state_seed_values_full_v2\", seed_hist)\n",
    "\n",
    "\n",
    "# start_idx = 0 #990 #start on this scan\n",
    "# runlen = 3680 #250\n",
    "\n",
    "#remove outliers from m_hat_history\n",
    "m_hat_history[abs(m_hat_history[:,0]) > 0.1] = 0.1 #fwd\n",
    "# m_hat_history[abs(m_hat_history[:,5]) > 0.02] = 0.0 #yaw\n",
    "# m_hat_history[:,5] = m_hat_history[:,5]/10 #yaw #DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97cf56",
   "metadata": {},
   "source": [
    "### Plot Cumulative error between ICET, LOAM, and Ground Truth for forward motion (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error between ICET and absolute position\n",
    "plt.rc('font',family='Times New Roman')\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "font = {'fontname':'Times New Roman'}\n",
    "\n",
    "c = 0 # x (forward movement)\n",
    "\n",
    "# #DEBUG: why is GT continuously 0.005m short for frames 2400-3000??? #~~~~~~~~~\n",
    "# vf = (ground_truth[(start_idx+1):(start_idx+runlen+1),1] + ground_truth[start_idx:(start_idx+runlen),1])/2 #works best(?)\n",
    "# vf = vf.numpy()\n",
    "# vf[2400:3000] += 0.005\n",
    "# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#works best(??) -- tuned 6-state ICET\n",
    "# diffx = vf - estimates[:len(vf),1] \n",
    "# diffx = (vf/0.999) - estimates[:len(vf),1]  # need to rescale timestamps\n",
    "diffx = vf - estimates[:len(vf),1]*(np.append(np.diff(ts_history),1)/100_000)  # need to rescale timestamps\n",
    "\n",
    "#  # 12-state ICET rigid transform\n",
    "# # vf = (ground_truth[(start_idx+2):(start_idx+runlen+2),1] + ground_truth[(start_idx+1):(start_idx+runlen+1),1])/2 #works best(?)\n",
    "# # vf = (ground_truth[(start_idx+1):(start_idx+runlen+1),1] + ground_truth[start_idx:(start_idx+runlen),1])/2 #works best(?)\n",
    "# vf = ground_truth[(start_idx):(start_idx+runlen),1]\n",
    "# diffx = vf - X_hat_history[:len(vf),0]\n",
    "\n",
    "\n",
    "# diffx_LOAM = vf - LOAM[len(vf),1]\n",
    "\n",
    "# diffx = ground_truth[:len(estimates),5] - estimates[:,5]\n",
    "\n",
    "cum_err = np.zeros(np.shape(pred_stds))\n",
    "cum_diffx = np.zeros(np.shape(diffx))\n",
    "\n",
    "for i in range(np.shape(pred_stds)[0]):\n",
    "    #include sensor noise calculated by ICET \n",
    "    cum_err[i,:] = np.sum(pred_stds[:i,:]**2, axis = 0)\n",
    "    #add in distortion bounds\n",
    "    cum_err[i,:] += np.sum(m_hat_history[:i,:]**2, axis = 0)\n",
    "    #add in baseline OXTS 1-sigma errors\n",
    "    cum_err[i,:] += np.sqrt(2)*np.array([0.05,0.05,0.1,0.0005,0.0005,0.001])**2\n",
    "#     cum_err[i,:] += np.sqrt(2)*np.array([0.08,0.08,0.1,0.0005,0.0005,0.001745])**2\n",
    "    cum_err[i,:] = np.sqrt(cum_err[i,:]) \n",
    "    \n",
    "for j in range(np.shape(diffx)[0]):\n",
    "    cum_diffx[j] = np.sum(diffx[:j]) \n",
    "\n",
    "# # error for each individual timestep --------------------------------\n",
    "# ax3.plot(diffx, label = 'GPS/INS - ICET (after bias reduction)')\n",
    "# # ax3.fill_between(np.linspace(0,len(pred_stds)-1,len(pred_stds)), -2*pred_stds[:,c], 2*pred_stds[:,c], \n",
    "# #                  color = (0.5,0.5,0.5,0.4), label = 'ICET Predicted 2σ Error Bounds')\n",
    "# ax3.fill_between(np.linspace(0,len(pred_stds)-1,len(pred_stds)), \n",
    "#                  -m_hat_history[:,0]  - 2*pred_stds[:,c], \n",
    "#                   m_hat_history[:,0] + 2*pred_stds[:,c], \n",
    "#                  color = (0.5,0.5,0.5,0.4), label = 'Predicted Error Bounds')\n",
    "# #-------------------------------------------------------------------\n",
    "\n",
    "# #new (accumulated differences in error)--------------------------\n",
    "# ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx_with_ground, label = 'GPS/INS - ICET')\n",
    "ax3.plot(np.linspace(0,len(pred_stds)-1,len(pred_stds)), cum_diffx, label = 'Cumulative Error in ICET Estimates')\n",
    "ax3.fill_between(np.linspace(0,len(pred_stds)-1,len(pred_stds)), \n",
    "                 -cum_err[:,1], \n",
    "                 cum_err[:,1], \n",
    "                 color = (0,0,1,0.2), label = 'Predicted Error Bounds')\n",
    "# # --------------------------------------------------------------------\n",
    "\n",
    "# ax3.legend(loc = 'lower left')\n",
    "ax3.legend(loc = 'upper left')\n",
    "ax3.set_title(\"Bounding Error in Forward Motion Estimates\")\n",
    "ax3.set_xlabel(\"scan index\", **font)\n",
    "ax3.set_ylabel(\"Ground Truth x - Odometry Estimate x (m)\", **font)\n",
    "# ax3.set_title(\"Predicted vs Actual Error in yaw\")\n",
    "# ax3.set_xlabel(\"time (s)\", **font)\n",
    "# ax3.set_ylabel(\"GPS/INS Baseline yaw - Odometry Estimate yaw (rad)\", **font)\n",
    "# ax3.set_ylim(-0.032,0.045)\n",
    "# ax3.set_ylim([-0.07,0.07])\n",
    "ax3.set_xlim([0,3678])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b65d6",
   "metadata": {},
   "source": [
    "### Repeat for yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8537b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error between ICET and absolute position\n",
    "plt.rc('font',family='Times New Roman')\n",
    "fig3, ax3 = plt.subplots(1,1)\n",
    "font = {'fontname':'Times New Roman'}\n",
    "\n",
    "# print(len(estimates), len(ground_truth), len(pred_stds))\n",
    "\n",
    "\n",
    "\n",
    "# diffx = ground_truth[:len(estimates), 5] - estimates[:,5] #was this\n",
    "\n",
    "#test\n",
    "# yaw_gt = (ground_truth[(start_idx+1):(start_idx+runlen+1),5] + ground_truth[start_idx:(start_idx+runlen),5])/2 #works best(?)\n",
    "yaw_gt = (ground_truth[(start_idx+2):(start_idx+runlen+2),5] + ground_truth[(start_idx+1):(start_idx+runlen+1),5])/2 #works best(?)\n",
    "# diffx = yaw_gt[:len(estimates)] - estimates[:len(yaw_gt),5]\n",
    "# diffx = (yaw_gt[:len(estimates)]/0.999) - estimates[:len(yaw_gt),5] #need to rescale time estimates\n",
    "diffx = yaw_gt[:len(estimates)] - estimates[:len(vf),5]*(np.append(np.diff(ts_history),1)/100_000)  # need to rescale timestamps\n",
    "\n",
    "# diffx_LOAM = vf - LOAM[len(vf),1]\n",
    "\n",
    "cum_err = np.zeros(np.shape(estimates))\n",
    "cum_diffx = np.zeros(len(estimates))\n",
    "\n",
    "for i in range(np.shape(estimates)[0]):\n",
    "    #include sensor noise calculated by ICET \n",
    "    cum_err[i,:] = 2*np.sum(pred_stds[:i,:]**2, axis = 0)\n",
    "    #add in distortion bounds\n",
    "    cum_err[i,:] += np.sum(m_hat_history[:i,:]**2, axis = 0)\n",
    "    #add in baseline OXTS 1-sigma errors\n",
    "    cum_err[i,:] += np.sqrt(2)*np.array([0.05,0.05,0.1,0.0005,0.0005,0.001])**2\n",
    "#     cum_err[i,:] += np.sqrt(2)*np.array([0.08,0.08,0.1,0.0005,0.0005,0.001745])**2\n",
    "    cum_err[i,:] = np.sqrt(cum_err[i,:]) \n",
    "    \n",
    "for j in range(np.shape(diffx)[0]):\n",
    "    cum_diffx[j] = np.sum(diffx[:j]) \n",
    "\n",
    "# print(np.shape(estimates))\n",
    "# print(np.shape(m_hat_history[0:len(estimates),:]))\n",
    "# print(len(np.linspace(0,len(estimates)-1,len(estimates))))\n",
    "    \n",
    "# # error for each individual timestep --------------------------------\n",
    "# ax3.plot(diffx, label = 'GPS/INS - ICET')\n",
    "# # ax3.fill_between(np.linspace(0,len(pred_stds)-1,len(pred_stds)), -2*pred_stds[:,c], 2*pred_stds[:,c], \n",
    "# #                  color = (0.5,0.5,0.5,0.4), label = 'ICET Predicted 2σ Error Bounds')\n",
    "# ax3.fill_between(np.linspace(0,len(estimates)-1,len(m_hat_history)), \n",
    "#                  -m_hat_history[:len(estimates),0]  - 2*pred_stds[:len(estimates),5], \n",
    "#                   m_hat_history[:len(estimates),0] + 2*pred_stds[:len(estimates),5], \n",
    "#                  color = (0.5,0.5,0.5,0.4), label = 'Predicted Error Bounds')\n",
    "# #-------------------------------------------------------------------\n",
    "\n",
    "# #new (accumulated differences in error)--------------------------\n",
    "# ax3.plot(np.linspace(0,15,np.shape(ICET_pred_stds)[0]), cum_diffx_with_ground, label = 'GPS/INS - ICET')\n",
    "ax3.plot(np.linspace(0,len(estimates)-1,len(estimates)), cum_diffx, label = 'Cumulative Error in ICET Estimates')\n",
    "ax3.fill_between(np.linspace(0,len(estimates)-1,len(estimates)), \n",
    "                 -cum_err[:,5], \n",
    "                 cum_err[:,5], \n",
    "                 color = (0,0,1,0.2), label = 'Predicted Error Bounds')\n",
    "# # --------------------------------------------------------------------\n",
    "\n",
    "ax3.legend(loc = 'upper left')\n",
    "ax3.set_title(\"Bounding Error in Azimuth Estimates\")\n",
    "ax3.set_xlabel(\"scan index\", **font)\n",
    "ax3.set_ylabel(\"Ground Truth Azimuth - Odometry Azimuth (rad)\", **font)\n",
    "ax3.set_xlim([0,3678])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287a63c",
   "metadata": {},
   "source": [
    "### Debug timestamps from Ford Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [framecount, curr_timestamp_sync, curr_timestamp_dc1394,  curr_timestamp_hosttime]\n",
    "ts_fn = \"/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/Timestamp.log\"\n",
    "ts = np.loadtxt(ts_fn, skiprows=1)\n",
    "# print(ts)\n",
    "\n",
    "print(np.shape(ts))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(np.diff(ts[:,1]))\n",
    "ax.plot(ts[:,1])\n",
    "# ax.plot(np.convolve(np.diff(ts[:,1]), np.ones(3)/3, mode='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DEBUG: run distortion correction just on \"static\" point clouds -- not helpful\n",
    "# it = ICET(cloud1 = pc1, cloud2 = pc2, fid = 50, niter = 10, \n",
    "#            draw = True, group = 2, RM = True, DNN_filter = False)\n",
    "# ViewInteractiveWidget(it.plt.window)\n",
    "# pc1_static = it.cloud1_static\n",
    "# pc2_static = it.cloud2_static\n",
    "\n",
    "# plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "# disp=[]\n",
    "# disp.append(Points(pc1_static, c = \"#CB2314\")) \n",
    "# disp.append(Points(pc2_static, c = \"#2c7c94\")) \n",
    "# plt.show(disp, \"raw point clouds\")\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(abs(pred_stds),axis = 0))\n",
    "print(np.mean(m_hat_history, axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dat1['SCAN']\n",
    "print(a.keys())\n",
    "print(a['timestamp_laser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8da612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_idx = 0 #990 #start on this scan\n",
    "runlen = 3680 #3680 #250\n",
    "\n",
    "ts_history = np.zeros(runlen)\n",
    "\n",
    "for i in range(runlen):\n",
    "    print(\"---------------------------------- SCAN IDX\", i + start_idx,\"-------------------------------------\")\n",
    "\n",
    "    #load point clouds\n",
    "    fn1 = '/media/derm/06EF-127D3/Ford/IJRR-Dataset-1/SCANS/Scan%04d.mat' %(i+start_idx+75)\n",
    "    dat1 = mat4py.loadmat(fn1)\n",
    "    SCAN1 = dat1['SCAN']\n",
    "\n",
    "    ts_history[i] = SCAN1['timestamp_laser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.diff(ts_history)))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.diff(ts_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"sample_data/ts_history.txt\", ts_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test making box and whisker plot in matplotlib\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# a = np.array([-1,-1,0,0,0,6])\n",
    "# ax.boxplot(a)\n",
    "\n",
    "sym = \"\" #hides flyers\n",
    "# sym = None #show flyers \n",
    "labels = [\"x\", \"y\", \"z\", \"φ\", \"θ\", \"ψ\"]\n",
    "\n",
    "x_err = (np.random.rand(10000) - 0.5) * 3\n",
    "y_err = np.random.randn(10) * 0.03\n",
    "z_err = np.random.randn(10) * 0.001\n",
    "phi_err = np.random.randn(10) * 0.005\n",
    "theta_err = np.random.randn(10) * 0.005\n",
    "psi_err = np.random.randn(100) * 0.13\n",
    "\n",
    "\n",
    "errs = np.array([x_err, y_err, z_err, phi_err, theta_err, psi_err]).T\n",
    "\n",
    "ax.set_title(\"\")\n",
    "ax.boxplot(errs, sym = sym, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa8bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
