{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5c1675",
   "metadata": {},
   "source": [
    "### Demo of Registering Distorted LIDAR Scans to HD Map Provided in Newer College Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe994a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 14:28:21.142931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 14:28:21.235632: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-09 14:28:21.622274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-06-09 14:28:21.622325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-06-09 14:28:21.622329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-09 14:28:22.064676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.090529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.090683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.204596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 14:28:22.205312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.205534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.205672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.570228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.570425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.570556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-09 14:28:22.570651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16384 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-06-09 14:28:22.581495: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 16.00G (17179869184 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-06-09 14:28:22.582358: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 14.40G (15461881856 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-06-09 14:28:22.583102: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 12.96G (13915693056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-06-09 14:28:22.583860: I tensorflow/stream_executor/cuda/cuda_driver.cc:733] failed to allocate 11.66G (12524123136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 16*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "from ICET_spherical import ICET\n",
    "from utils import R_tf\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from pioneer.das.api.platform import Platform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4ab0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load HD Map from .ply File\n",
    "import trimesh\n",
    "\n",
    "# pl = '/home/derm/Downloads/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply' #provided in Google Drive 03\n",
    "pl = '/media/derm/06EF-127D3/Newer College Dataset/new-college-29-01-2020-1cm-resolution-1stSection - mesh.ply'\n",
    "HD_map = trimesh.load(pl).vertices\n",
    "# print(type(HD_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf543e7",
   "metadata": {},
   "source": [
    "# Draw HD Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd48cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402461, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/vtkmodules/util/numpy_support.py:74: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  _vtk_np = {vtkConstants.VTK_BIT:numpy.bool,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837ed51196c240b190c3d327c8a84909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test drawing downsampled version of HD Map (laptop alert)\n",
    "show_nth = 10 #10\n",
    "submap = HD_map[::show_nth]\n",
    "# submap[:,2] += min(submap[:,2])\n",
    "print(np.shape(submap))\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4\n",
    "disp=[]\n",
    "# draw in red\n",
    "disp.append(Points(submap, c = \"#CB2314\", r = 2, alpha = 0.1))  \n",
    "\n",
    "## rainbow by z height\n",
    "# # zheight = 50*(np.sin(0.0625*submap[:,2])+1)#was this\n",
    "# zheight = 100*(np.sin(0.25*submap[:,2])+1) #test\n",
    "# print(zheight[::100], min(zheight), max(zheight))\n",
    "# # cname = np.array([zheight, 100*(np.sin(0.5*zheight+256)+1), 128*np.ones(len(zheight))]).T.tolist()\n",
    "# cname = np.array([zheight, zheight, zheight]).T.tolist()\n",
    "# # cname = np.array([64*np.ones(len(zheight)), 256 - zheight/2, 256 - zheight]).T.tolist()\n",
    "# disp.append(Points(submap, c = cname, r = 2, alpha = 0.1))\n",
    "\n",
    "plt.show(disp, \"HD Map\")\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb60d11",
   "metadata": {},
   "source": [
    "# Register scan using rigid ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cabd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 400\n",
    "# fn1 = \"/media/derm/06EF-127D3/Newer College Dataset/05_Quad_With_Dynamics/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "fn1 = \"/media/derm/06EF-127D3/Newer College Dataset/06_Dynamic_Spinning/point_clouds/frame_\" + str(idx) + \".npy\"\n",
    "\n",
    "# fn1 = \"/media/derm/06EF-127D3/Newer College Dataset/05_Quad_With_Dynamics/test/frame_\" + str(idx) + \".npy\" #test\n",
    "\n",
    "pc1 = np.load(fn1)\n",
    "\n",
    "#load ground truth\n",
    "# [sec,nsec,x,y,z,qx,qy,qz,qw]\n",
    "# fn_gt = \"/media/derm/06EF-127D3/Newer College Dataset/05_Quad_With_Dynamics/registered_poses.csv\"\n",
    "fn_gt = \"/media/derm/06EF-127D3/Newer College Dataset/06_Dynamic_Spinning/registered_poses.csv\"\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "# print(gt[idx, 2:])\n",
    "\n",
    "offset = 0#for debug \n",
    "rot = R.from_quat(gt[idx+offset,5:]).as_euler('xyz')\n",
    "# rot_m = R.from_quat(gt[idx+offset,5:]).as_matrix()\n",
    "# rot_m = R.from_quat(gt[idx,5:]).inv().as_matrix()\n",
    "rot_m = R.from_euler('xyz', [0, 0, rot[2]]).as_matrix()\n",
    "# rot_m = R.from_euler('xyz', [rot[0], rot[1], -rot[2] - np.pi/8 ]).as_matrix()\n",
    "# rot_m = R.from_quat(gt[idx,5:]).inv().as_matrix()\n",
    "# print(rot_m)\n",
    "\n",
    "initial_guess = tf.cast(tf.constant([gt[idx+offset,2], gt[idx+offset,3], gt[idx+offset,4], rot[0], rot[1], rot[2] ]), tf.float32)\n",
    "# pc1 = pc1 @ rot_m\n",
    "# rotcorr = R.from_euler('xyz', [0,0,np.pi/8]).as_matrix() #need to correct 45 degree offset??\n",
    "# pc1 = pc1 @ rotcorr\n",
    "# pc1 += initial_guess[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df51e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(gt)\n",
    "# # # ans = gt[:,0] - gt[0,0]\n",
    "# # # ans = np.where(np.diff(gt[:,0]) > 0.99 )\n",
    "# # # # print(ans)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# t = gt[:,0] + gt[:,1]/(1e9)\n",
    "# # ax.plot(np.diff(t)) #pretty interesting results for  dynamic spinning dataset\n",
    "# # ax.set_title(\"06- Dynamic Spinning Frame Length\")\n",
    "# # print(np.mean(np.diff(t[100:1100])))\n",
    "\n",
    "# ax.plot(np.diff(gt[:,2]))\n",
    "# len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380b272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Ground Truth Poses via code shamelessly taken from KitWare pyLiDAR-SLAM library\n",
    "\n",
    "#load ground truth .csv file\n",
    "# [sec,nsec,x,y,z,qx,qy,qz,qw]\n",
    "# fn_gt = \"/media/derm/06EF-127D3/Newer College Dataset/05_Quad_With_Dynamics/registered_poses.csv\"\n",
    "fn_gt = \"/media/derm/06EF-127D3/Newer College Dataset/06_Dynamic_Spinning/registered_poses.csv\"\n",
    "\n",
    "gt = np.loadtxt(fn_gt, delimiter=',',skiprows = 1)\n",
    "seconds = gt[:, 0]\n",
    "nano_seconds = gt[:, 1]\n",
    "xyz = gt[:, 2:5]\n",
    "qxyzw = gt[:, 5:]\n",
    "num_poses = qxyzw.shape[0]\n",
    "poses = np.eye(4, dtype=np.float64).reshape(1, 4, 4).repeat(num_poses, axis=0)\n",
    "poses[:, :3, :3] = R.from_quat(qxyzw).as_matrix()\n",
    "poses[:, :3, 3] = xyz\n",
    "T_CL = np.eye(4, dtype=np.float32)\n",
    "T_CL[:3, :3] = R.from_quat([0.0, 0.0, 0.924, 0.383]).as_matrix() #was this --1134.97 deg\n",
    "T_CL[:3, 3] = np.array([-0.084, -0.025, 0.050], dtype=np.float32) #was this\n",
    "# T_CL[:3, :3] = R.from_euler('xyz', [0,0, np.deg2rad(135)]).as_matrix() #as specified by paper (exactly 45 deg)\n",
    "# T_CL[:3, 3] = np.array([0.084, 0.025, -0.050], dtype=np.float32) #debugging possible sign errors\n",
    "poses = np.einsum(\"nij,jk->nik\", poses, T_CL)\n",
    "\n",
    "initial_pose = np.linalg.inv(poses[0]) \n",
    "\n",
    "poses_timestamps = seconds * 10e9 + nano_seconds\n",
    "poses = np.einsum(\"ij,njk->nik\", np.linalg.inv(poses[0]), poses) #try commenting out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1823d",
   "metadata": {},
   "source": [
    "## Regsiter Raw Clouds i, j, and HD Map centered on origin of i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4628f60a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff74df8c1704e0ca024ea3b1e19ba41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# idx = 2500 #2000 - 3000 is the running and swinging loop\n",
    "# skip = 5 #how many lidar frames between clouds\n",
    "# # (need to deal with how there are more LIDAR frames than ground truth poses)\n",
    "# offset = 11 #10 #11  #works best for 05 dataset\n",
    "# fn1 = \"/media/derm/06EF-127D3/Newer College Dataset/05_Quad_With_Dynamics/point_clouds/frame_\" + str(idx + offset) + \".npy\"\n",
    "# fn2 = \"/media/derm/06EF-127D3/Newer College Dataset/05_Quad_With_Dynamics/point_clouds/frame_\" + str(idx + skip + offset) + \".npy\"\n",
    "\n",
    "idx = 950 #1080 #950 #fast motion\n",
    "# idx = 116 #slow distortion, very accurate solution\n",
    "skip = 1 #how many lidar frames between clouds\n",
    "offset = 1 #2 #figured out through guess and check (brutal) #1 aligns end of scan (11:00), 2 aligns front (1:00)\n",
    "fn1 = \"/media/derm/06EF-127D3/Newer College Dataset/06_Dynamic_Spinning/point_clouds/frame_\" + str(idx + offset) + \".npy\"\n",
    "fn2 = \"/media/derm/06EF-127D3/Newer College Dataset/06_Dynamic_Spinning/point_clouds/frame_\" + str(idx + skip + offset) + \".npy\"\n",
    "\n",
    "pc1 = np.load(fn1)\n",
    "pc2 = np.load(fn2)\n",
    "\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "#apply homogeneous transform matrix\n",
    "scan1_mapframe = (poses[idx] @ np.append(pc1, np.ones([len(pc1),1]), axis=1).T).T  \n",
    "scan2_mapframe = (poses[idx+skip] @ np.append(pc2, np.ones([len(pc2),1]), axis=1).T).T\n",
    "submap_mapframe = (initial_pose @ np.append(submap, np.ones([len(submap),1]), axis =1).T).T\n",
    "\n",
    "#Rotate scans to align beginning of each scan with +X axis ----------\n",
    "#IMPORTANT: Need to do this for <06 Dynamic Spinning> but NOT for <05 Quad With Dynamics>\n",
    "#Need to do this before applying 12-State ICET since it relies on frame beginning at +X axis\n",
    "scan1_mapframe = (np.linalg.pinv(poses[idx]) @ scan1_mapframe.T).T\n",
    "scan2_mapframe = (np.linalg.pinv(poses[idx]) @ scan2_mapframe.T).T\n",
    "submap_mapframe = (np.linalg.pinv(poses[idx]) @ submap_mapframe.T).T\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#remove 4th column and center first scan about origin\n",
    "scan1_lidarframe = scan1_mapframe[:,:3] - poses[idx][:3,3]\n",
    "scan2_lidarframe = scan2_mapframe[:,:3] - poses[idx][:3,3]\n",
    "submap_lidarframe = submap_mapframe[:,:3] - poses[idx][:3,3]\n",
    "\n",
    "#COLOR SCAN1 POINTS BY ORDER IN CLOUD\n",
    "color = 255*np.linspace(0,1,len(scan1_lidarframe))\n",
    "cname = np.array([255-color//2, color, 255-color]).T.tolist()\n",
    "disp.append(Points(scan1_lidarframe, c = cname, r = 3, alpha = 1))\n",
    "\n",
    "# # DRAW SCANS 1, 2\n",
    "# disp.append(Points(scan1_lidarframe, c = '#a65852', r = 3)) #red\n",
    "# disp.append(Points(scan2_lidarframe, c = '#2c7c94', r = 3)) #blue\n",
    "\n",
    "disp.append(Points(submap_lidarframe, c = \"black\", r = 2, alpha = 0.05)) ##CB2314\n",
    "plt.show(disp, \"06 Dynamic Spinning Frame #\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd331b",
   "metadata": {},
   "source": [
    "## Run 12-State ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2adba926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 14:28:30.112606: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-09 14:28:30.496305: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2023-06-09 14:28:30.496331: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-06-09 14:28:30.496349: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at matmul_op_impl.h:627 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:BatchMatMulV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m max_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;66;03m#was 2.5\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#scan to submap\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m dc \u001b[38;5;241m=\u001b[39m \u001b[43mLC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloud1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubmap_lidarframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcloud2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscan1_lidarframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmnp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRM\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m12_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_buffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#scan to scan\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# dc = LC(cloud1 = scan1_lidarframe, cloud2 = scan2_lidarframe, fid = 50, niter = 10, \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         draw = True, mnp = 25, RM = False, solver = '12_state', \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         max_buffer = 2.5, A0 = A0)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ViewInteractiveWidget(dc\u001b[38;5;241m.\u001b[39mplt\u001b[38;5;241m.\u001b[39mwindow)\n",
      "File \u001b[0;32m~/ASAR/v3/point_cloud_rectification/linear_corrector.py:98\u001b[0m, in \u001b[0;36mLC.__init__\u001b[0;34m(self, cloud1, cloud2, fid, niter, draw, m_hat0, A0, group, RM, DNN_filter, cheat, mnp, solver, max_buffer)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, A0)\n\u001b[0;32m---> 98\u001b[0m \t\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_12_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mniter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_moving\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m \t\u001b[38;5;66;03m# self.disp.append(addons.LegendBox(self.disp))\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplt\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp, solver, resetcam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ASAR/v3/point_cloud_rectification/linear_corrector.py:158\u001b[0m, in \u001b[0;36mLC.solve_12_state\u001b[0;34m(self, niter, A0, remove_moving)\u001b[0m\n\u001b[1;32m    155\u001b[0m mu1_enough \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(mu1, enough1)\n\u001b[1;32m    156\u001b[0m sigma1_enough \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(sigma1, enough1)\n\u001b[0;32m--> 158\u001b[0m U, L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_U_and_L_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma1_enough\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu1_enough\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moccupied_spikes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# if self.draw:\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# \t# self.visualize_L(mu1_enough, U, L)\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# \tself.draw_ell(mu1_enough, sigma1_enough, pc = 1, alpha = self.alpha)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m#main loop\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(niter):\n",
      "File \u001b[0;32m~/ASAR/v3/point_cloud_rectification/linear_corrector.py:1874\u001b[0m, in \u001b[0;36mLC.get_U_and_L_cluster\u001b[0;34m(self, sigma1, mu1, occupied_spikes, bounds)\u001b[0m\n\u001b[1;32m   1871\u001b[0m axislen \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(tf\u001b[38;5;241m.\u001b[39mtranspose(axislen), (tf\u001b[38;5;241m.\u001b[39mshape(axislen)[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)) \u001b[38;5;66;03m#variance not std...?\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;66;03m# get projections of axis length in each direction\u001b[39;00m\n\u001b[0;32m-> 1874\u001b[0m rotated \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxislen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#new\u001b[39;00m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;66;03m# axislen_actual = 2*tf.math.sqrt(axislen) #theoretically correct\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m axislen_actual \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mtf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msqrt(axislen) \u001b[38;5;66;03m#was this (works with one edge extended detection criteria)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInternalError\u001b[0m: {{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:BatchMatMulV2]"
     ]
    }
   ],
   "source": [
    "from linear_corrector import LC\n",
    "A0 = np.array([0., 0, 0, 0, 0, 0,\n",
    "               0, 0, 0, 0, 0, 0])\n",
    "max_buffer = 0.5 #was 2.5\n",
    "\n",
    "#scan to submap\n",
    "dc = LC(cloud1 = submap_lidarframe, cloud2 = scan1_lidarframe, fid = 80, niter = 20, \n",
    "        draw = True, mnp = 25, RM = False, solver = '12_state', \n",
    "        max_buffer = max_buffer, A0 = A0)\n",
    "\n",
    "#scan to scan\n",
    "# dc = LC(cloud1 = scan1_lidarframe, cloud2 = scan2_lidarframe, fid = 50, niter = 10, \n",
    "#         draw = True, mnp = 25, RM = False, solver = '12_state', \n",
    "#         max_buffer = 2.5, A0 = A0)\n",
    "\n",
    "ViewInteractiveWidget(dc.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #debug is cloud wrapping around >>360deg???\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# y = dc.yaw_angs\n",
    "# test = (y + 2*np.pi)%(2*np.pi)\n",
    "# ax.plot(test, label=\"new\")\n",
    "\n",
    "\n",
    "# ax.plot(dc.yaw_angs, label = \"raw (causing bug??)\")\n",
    "# ax.set_title(\"yaw angles per beam, newer college dataset\")\n",
    "# ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673df8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug: try applying arbitrary motion profile scan to try and replicate discontinuity bug \n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4 (simple), 1(scale)\n",
    "disp=[]\n",
    "\n",
    "\n",
    "m_hat = np.array([10., 0., 0., 0., 0., 0.])\n",
    "\n",
    "scan1_distorted = dc.apply_motion_profile(scan1_lidarframe, m_hat)\n",
    "\n",
    "\n",
    "disp.append(Points(scan1_lidarframe, c = \"red\", r = 3, alpha = 0.2)) ##CB2314\n",
    "disp.append(Points(scan1_distorted, c = \"blue\", r = 3, alpha = 0.2)) ##CB2314\n",
    "disp.append(Points(submap_lidarframe, c = \"black\", r = 2, alpha = 0.05)) ##CB2314\n",
    "\n",
    "plt.show(disp, \"06 Dynamic Spinning Frame #\" + str(idx))\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f52a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG: shuffling points in cloud 2 at the beginning produces bug, however, need to randomize \n",
    "#       which points are selected when fitting guassian\n",
    "\n",
    "# print(dc.inside2.bounding_shape())\n",
    "test = dc.fit_gaussian(dc.cloud2_tensor, dc.inside2, tf.cast(dc.npts2, tf.float32))\n",
    "# print(test)\n",
    "# print(tf.shape(dc.cloud2_tensor))\n",
    "# print(dc.inside2[100])\n",
    "\n",
    "#GOAL: shuffle ragged tensor <inside2>\n",
    "digits = tf.ragged.constant([[1,2,3],[],[3,4],[4,5,6,7]])\n",
    "print(digits)\n",
    "a = tf.random.shuffle(tf.range(digits.shape[0]))\n",
    "b = tf.reshape(a, (digits.shape[0], 1))\n",
    "shuffledDigits = tf.gather_nd(digits, b)\n",
    "print(shuffledDigits)\n",
    "\n",
    "print(dc.inside2.bounding_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d24df",
   "metadata": {},
   "source": [
    "## Run Rigid (6-State) ICET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6beeac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = ICET(cloud1 = scan1_lidarframe, cloud2 = submap_lidarframe, fid = 50, niter = 25, \n",
    "           draw = True, group = 2, RM = False, DNN_filter = False)#, x0 = initial_guess)\n",
    "print(\"\\n predicted standard deviations of error: \\n\", it.pred_stds)\n",
    "ViewInteractiveWidget(it.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dc.cloud1_tensor_spherical\n",
    "print(test)\n",
    "\n",
    "# test2 = tf.gather(tf.)\n",
    "\n",
    "smaller = tf.where(test[:,1] < 0.5)\n",
    "print(smaller)\n",
    "bigger = tf.where(test[:,1] > 0.4)\n",
    "test2 = tf.sets.intersection(tf.transpose(smaller),tf.transpose(bigger))\n",
    "print(test2.values)\n",
    "\n",
    "print(tf.gather(test, test2.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b172395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#transform LIDAR scan to align with HD Map -- not what we want\n",
    "plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4\n",
    "disp=[]\n",
    "# draw in red\n",
    "disp.append(Points(submap, c = \"#CB2314\", r = 2, alpha = 0.1))  \n",
    "\n",
    "# #matt's attempt:\n",
    "# rot_m = R.from_quat(gt[idx,5:]).as_matrix()\n",
    "# newscan_mapframe = (pc1 @ rot_m) + gt[idx,2:5]\n",
    "# disp.append(Points(newscan_mapframe, c = 'blue',r = 2))\n",
    "\n",
    "#kitware code\n",
    "newscan_mapframe = (poses[idx] @ np.append(pc1, np.zeros([len(pc1),1]), axis=1).T).T\n",
    "print(newscan_mapframe)\n",
    "disp.append(Points(newscan_mapframe[:,:3], c = 'blue',r = 2))\n",
    "\n",
    "#draw trajectory of platform according to <gt>\n",
    "disp.append(Points(gt[2000:3000,2:5], r=3))#, alpha = 0.2))\n",
    "disp.append(Points(gt[idx+offset,2:5][None,:], r=10, c = 'red'))\n",
    "\n",
    "#draw arrows showing heading\n",
    "for i in range(50):\n",
    "    rot_m = R.from_quat(gt[i*20,5:]).as_matrix()\n",
    "    arrow_end = gt[i*20,2:5] + rot_m @ np.array([2.,0.,0.])\n",
    "    disp.append(Arrow(gt[i*20,2:5], arrow_end, c='red'))\n",
    "\n",
    "plt.show(disp, \"HD Map\")\n",
    "ViewInteractiveWidget(plt.window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5644d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "euls = np.zeros([len(gt), 3])\n",
    "\n",
    "for i in range(len(gt)):\n",
    "    euls[i, :] = R.from_quat(gt[i,5:]).as_euler('xyz')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(euls[:,2])\n",
    "\n",
    "# ax.plot(gt[:,2:4])\n",
    "# ax.plot(gt[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #transform HD Map to align with lidar frame\n",
    "# plt = Plotter(N = 1, axes = 1, bg = (1, 1, 1), interactive = True) #axes = 4\n",
    "# disp=[]\n",
    "\n",
    "# # rot_m = R.from_quat(gt[idx,5:]).as_matrix() #nope\n",
    "\n",
    "# rot = R.from_quat(gt[:,5:]).as_euler('xyz')\n",
    "# rot -= rot[0]\n",
    "# rot[:,2] = -rot[:,2]\n",
    "# # print(rot)\n",
    "# rot_m = R.from_euler('xyz', rot[idx]).as_matrix()\n",
    "\n",
    "# map_trans = (submap - gt[idx, 2:5]) @ rot_m\n",
    "# disp.append(Points(pc1, c = 'blue', r = 3))\n",
    "# # disp.append(Points(pc1[:(len(pc1)//2)], c = 'blue', r = 3))\n",
    "# # disp.append(Points(pc1[(len(pc1)//2):], c = 'blue', r = 3, alpha = 0.2))\n",
    "\n",
    "# #draw axis for world frame\n",
    "# disp.append(Arrow([0,0,0], [2,0,0], c = 'red'))\n",
    "# disp.append(Arrow([0,0,0], [0,2,0], c = 'green'))\n",
    "# disp.append(Arrow([0,0,0], [0,0,2], c = 'blue'))\n",
    "# #draw axis for world frame transformed by rot_m\n",
    "# disp.append(Arrow([0,0,0], [2,0,0] @ rot_m, c = 'red', alpha = 0.2))\n",
    "# disp.append(Arrow([0,0,0], [0,2,0] @ rot_m, c = 'green', alpha = 0.2))\n",
    "# disp.append(Arrow([0,0,0], [0,0,2] @ rot_m, c = 'blue', alpha = 0.2))\n",
    "\n",
    "\n",
    "# disp.append(Points(np.array([[0.,0.,0.]]), c = 'purple', r =10))\n",
    "\n",
    "# disp.append(Points(map_trans, c = 'red', r = 2, alpha = 0.2))\n",
    "# plt.show(disp, \"HD Map\")\n",
    "# ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb1683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newscan_mapframe = np.append(pc1, np.zeros([len(pc1),1]), axis=1)\n",
    "# newscan_mapframe = poses[1] @ newscan_mapframe.T\n",
    "# print(newscan_mapframe.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb206bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rot)\n",
    "# rot_m @ np.array([0.,0.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_trans = (submap - gt[idx, 2:5]) @ rot_m\n",
    "\n",
    "# it = ICET(cloud1 = pc1, cloud2 = map_trans, fid = 50, niter = 5, \n",
    "#            draw = True, group = 2, RM = False, DNN_filter = False)#, x0 = initial_guess)\n",
    "# print(\"\\n predicted standard deviations of error: \\n\", it.pred_stds)\n",
    "# ViewInteractiveWidget(it.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3367d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28285b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
