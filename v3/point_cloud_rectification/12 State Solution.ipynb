{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d618048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 18:39:43.362502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 18:39:43.988325: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-01 18:39:45.090556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-05-01 18:39:45.090651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-05-01 18:39:45.090658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-05-01 18:39:46.504063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:46.618793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:46.619181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 18:39:46.965613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 18:39:46.967194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:46.967438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:46.967618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:47.926823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:47.927066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:47.927250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-01 18:39:47.927376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "from ICET_spherical import ICET\n",
    "from utils import *\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from pioneer.das.api.platform import Platform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cf3de",
   "metadata": {},
   "source": [
    "# Goal: Simultaneously Estimate Translation, Rotation, and Distortion\n",
    "\n",
    "## $\\mathbf{A} = [\\hat{X}_{ij}, \\hat{m}_{ij}] = \n",
    "\\begin{bmatrix}\n",
    "% x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a9028",
   "metadata": {},
   "source": [
    "We can use newton-raphson to find A\n",
    "\n",
    "<!-- ## $y_i = \\mathbf{h}(y_j, \\hat{X}_{ij}, \\hat{m}_{ij}) + \\mathbf{H}_m \\delta m + \\mathbf{H}_x \\delta x + \\text{H.O.T.}$ -->\n",
    "\n",
    "## $y_i = \\mathbf{h}(y_j, \\hat{A}_{ij}) + \\mathbf{H}_A \\delta A + \\text{H.O.T.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62668f7e",
   "metadata": {},
   "source": [
    "## $\\mathbf{H}_A \\in \\mathbb{R}^{4N \\times 12} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb30f3c",
   "metadata": {},
   "source": [
    "\n",
    "### $\\mathbf{H}_A = [H_X, H_m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf4dfc",
   "metadata": {},
   "source": [
    "# Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1645f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load point cloud\n",
    "# # no distortion\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case1/raw_frame_0.npy\")\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #actual motion\n",
    "# m_hat = np.array([-3., 0., 0., 0., 0., 0.1]) #test wrap around\n",
    "\n",
    "# movement in x\n",
    "old_cloud =  np.load(\"sample_data/paper_figures/case2/raw_frame_3.npy\") \n",
    "# m_hat = np.array([3, 0, 0., 0., 0., 0])\n",
    "m_hat = np.array([0., 0, 0., 0., 0., 0.]) #FOR DEBUG-- deform just a little\n",
    "gt =  np.load(\"sample_data/paper_figures/case2/base_vel_2.npy\")\n",
    "\n",
    "# # movement in x, y, & yaw\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case3/raw_frame_1.npy\") \n",
    "# # m_hat = np.array([3, -1, 0., 0., 0., -1])\n",
    "# m_hat = np.array([3, -1, 0., 0., 0., -0.86]) #FOR DEBUG-- deform a little extra\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #FOR DEBUG-- no deformation\n",
    "# gt =  np.load(\"sample_data/paper_figures/case3/base_vel_2.npy\")\n",
    "# # print(gt) \n",
    "\n",
    "# period_lidar = 1\n",
    "# t_scale = (2*np.pi)/(-m_hat[-1] + (2*np.pi/period_lidar))\n",
    "# print(t_scale)\n",
    "# m_hat = m_hat*t_scale\n",
    "# # m_hat[-1] = m_hat[-1]*t_scaled\n",
    "# print(m_hat)\n",
    "\n",
    "#downsample\n",
    "old_cloud = old_cloud[::5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54b92149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40ecd0e329a4042b36b9fe7eeaba884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from remove_motion_basic import linear_correction_old as lc \n",
    "\n",
    "#apply ground truth distortion according to m_hat\n",
    "new_cloud = lc(old_cloud, m_hat) \n",
    "#set ground truth transform between clouds\n",
    "# X_gt = np.array([0, 0., 0.0, 0.0, 0.0, 0.0])\n",
    "# X_gt = np.array([1.5, 0.5, 0.03, 0.03, 0.03, 0.25])\n",
    "# X_gt = np.array([1.5, -3, 0.1, 0.2, 0.03, -0.15])\n",
    "X_gt = np.array([-1.5, 0., 0.0, 0.0, 0.0, 0.])\n",
    "\n",
    "# add noise\n",
    "old_cloud += 0.01*np.random.randn(np.shape(old_cloud)[0], 3)\n",
    "\n",
    "# #for fig: mess up both again to show that relative distortion remains constant\n",
    "# new_cloud = lc(new_cloud, -m_hat)\n",
    "# old_cloud = lc(old_cloud, -m_hat)\n",
    "\n",
    "# #remove ground plane\n",
    "# old_cloud = old_cloud[old_cloud[:,2] > -1] \n",
    "# new_cloud = new_cloud[new_cloud[:,2] > -1] \n",
    "\n",
    "# Rotate + Translate new point cloud\n",
    "trans = X_gt[:3]\n",
    "rot = R_tf(X_gt[3:]).numpy()\n",
    "new_cloud = (new_cloud @ rot) + trans\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(old_cloud, c = \"#CB2314\")) \n",
    "disp.append(Points(new_cloud, c = \"#2c7c94\")) \n",
    "plt.show(disp, \"raw point clouds\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734cdf9",
   "metadata": {},
   "source": [
    "### Attempt to solve with basic 6 state solution (Impossible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3c124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 18:40:05.775711: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~Iteration  0 ~~~~~~~~~~\n",
      "took 0.03040933609008789 sec  to apply motion profile\n",
      "took 0.013721227645874023 sec to get H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 18:40:07.574527: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x70ab6e0\n",
      "2023-05-01 18:40:08.140605: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_hat:  [ 4.82940972e-01  1.42090954e-03  3.49700276e-05 -1.21493533e-04\n",
      "  9.68047389e-05  1.40186399e-04]\n",
      "~~~~~~~~~~~Iteration  1 ~~~~~~~~~~\n",
      "took 0.018985986709594727 sec  to apply motion profile\n",
      "took 0.004053831100463867 sec to get H\n",
      "m_hat:  [ 4.99094158e-01 -1.97746092e-04  9.43179621e-05 -5.65188966e-05\n",
      " -6.09922427e-05  1.59819610e-05]\n",
      "~~~~~~~~~~~Iteration  2 ~~~~~~~~~~\n",
      "took 0.016367673873901367 sec  to apply motion profile\n",
      "took 0.0026197433471679688 sec to get H\n",
      "m_hat:  [ 4.99606162e-01 -3.06372851e-04  1.10191075e-04 -4.34136236e-05\n",
      " -7.52959240e-05  2.03397249e-05]\n",
      "~~~~~~~~~~~Iteration  3 ~~~~~~~~~~\n",
      "took 0.01752495765686035 sec  to apply motion profile\n",
      "took 0.0026700496673583984 sec to get H\n",
      "m_hat:  [ 4.99617219e-01 -3.02896311e-04  1.06964530e-04 -4.21107397e-05\n",
      " -7.74002692e-05  2.15623077e-05]\n",
      "~~~~~~~~~~~Iteration  4 ~~~~~~~~~~\n",
      "took 0.017733097076416016 sec  to apply motion profile\n",
      "took 0.002604961395263672 sec to get H\n",
      "m_hat:  [ 4.99617726e-01 -3.02791770e-04  1.06761450e-04 -4.21535733e-05\n",
      " -7.73661232e-05  2.17062097e-05]\n",
      "~~~~~~~~~~~Iteration  5 ~~~~~~~~~~\n",
      "took 0.016193628311157227 sec  to apply motion profile\n",
      "took 0.002605915069580078 sec to get H\n",
      "m_hat:  [ 4.99617666e-01 -3.02400906e-04  1.06745894e-04 -4.21734949e-05\n",
      " -7.73734864e-05  2.16794087e-05]\n",
      "~~~~~~~~~~~Iteration  6 ~~~~~~~~~~\n",
      "took 0.01640629768371582 sec  to apply motion profile\n",
      "took 0.0030214786529541016 sec to get H\n",
      "m_hat:  [ 4.99617666e-01 -3.02223489e-04  1.06781408e-04 -4.21556178e-05\n",
      " -7.73637439e-05  2.16633471e-05]\n",
      "~~~~~~~~~~~Iteration  7 ~~~~~~~~~~\n",
      "took 0.016704082489013672 sec  to apply motion profile\n",
      "took 0.00442814826965332 sec to get H\n",
      "m_hat:  [ 4.99617606e-01 -3.02136003e-04  1.06778491e-04 -4.21621153e-05\n",
      " -7.73704087e-05  2.16114677e-05]\n",
      "~~~~~~~~~~~Iteration  8 ~~~~~~~~~~\n",
      "took 0.01587200164794922 sec  to apply motion profile\n",
      "took 0.002613067626953125 sec to get H\n",
      "m_hat:  [ 4.99617815e-01 -3.02795524e-04  1.06772553e-04 -4.21683144e-05\n",
      " -7.73545326e-05  2.16613516e-05]\n",
      "~~~~~~~~~~~Iteration  9 ~~~~~~~~~~\n",
      "took 0.015086650848388672 sec  to apply motion profile\n",
      "took 0.0027132034301757812 sec to get H\n",
      "m_hat:  [ 4.99617964e-01 -3.02885950e-04  1.06783475e-04 -4.21639852e-05\n",
      " -7.73587381e-05  2.16709705e-05]\n",
      "~~~~~~~~~~~Iteration  10 ~~~~~~~~~~\n",
      "took 0.016500234603881836 sec  to apply motion profile\n",
      "took 0.0026361942291259766 sec to get H\n",
      "m_hat:  [ 4.99617845e-01 -3.02524597e-04  1.06747109e-04 -4.21708937e-05\n",
      " -7.73671491e-05  2.16254011e-05]\n",
      "~~~~~~~~~~~Iteration  11 ~~~~~~~~~~\n",
      "took 0.016243934631347656 sec  to apply motion profile\n",
      "took 0.002584695816040039 sec to get H\n",
      "m_hat:  [ 4.99617696e-01 -3.01576365e-04  1.06766864e-04 -4.21626319e-05\n",
      " -7.73646825e-05  2.17400138e-05]\n",
      "~~~~~~~~~~~Iteration  12 ~~~~~~~~~~\n",
      "took 0.01764202117919922 sec  to apply motion profile\n",
      "took 0.0026319026947021484 sec to get H\n",
      "m_hat:  [ 4.99617308e-01 -3.02463159e-04  1.06755222e-04 -4.21659861e-05\n",
      " -7.73630964e-05  2.16690623e-05]\n",
      "~~~~~~~~~~~Iteration  13 ~~~~~~~~~~\n",
      "took 0.01595926284790039 sec  to apply motion profile\n",
      "took 0.0026357173919677734 sec to get H\n",
      "m_hat:  [ 4.99617904e-01 -3.02861532e-04  1.06730986e-04 -4.21848199e-05\n",
      " -7.73546417e-05  2.16271528e-05]\n",
      "~~~~~~~~~~~Iteration  14 ~~~~~~~~~~\n",
      "took 0.014499187469482422 sec  to apply motion profile\n",
      "took 0.002647876739501953 sec to get H\n",
      "m_hat:  [ 4.99617934e-01 -3.02322151e-04  1.06748252e-04 -4.21660297e-05\n",
      " -7.73618231e-05  2.15935379e-05]\n",
      "~~~~~~~~~~~Iteration  15 ~~~~~~~~~~\n",
      "took 0.015579700469970703 sec  to apply motion profile\n",
      "took 0.0049877166748046875 sec to get H\n",
      "m_hat:  [ 4.99618202e-01 -3.02690780e-04  1.06752210e-04 -4.21762852e-05\n",
      " -7.73699430e-05  2.15611453e-05]\n",
      "~~~~~~~~~~~Iteration  16 ~~~~~~~~~~\n",
      "took 0.01616668701171875 sec  to apply motion profile\n",
      "took 0.002607583999633789 sec to get H\n",
      "m_hat:  [ 4.99617904e-01 -3.02902423e-04  1.06802596e-04 -4.21579243e-05\n",
      " -7.73783249e-05  2.16025182e-05]\n",
      "~~~~~~~~~~~Iteration  17 ~~~~~~~~~~\n",
      "took 0.015317678451538086 sec  to apply motion profile\n",
      "took 0.0025899410247802734 sec to get H\n",
      "m_hat:  [ 4.99618262e-01 -3.01922613e-04  1.06772190e-04 -4.21614677e-05\n",
      " -7.73712745e-05  2.15893670e-05]\n",
      "~~~~~~~~~~~Iteration  18 ~~~~~~~~~~\n",
      "took 0.017436504364013672 sec  to apply motion profile\n",
      "took 0.0030333995819091797 sec to get H\n",
      "m_hat:  [ 4.99618381e-01 -3.02564789e-04  1.06753316e-04 -4.21514051e-05\n",
      " -7.73674547e-05  2.16233730e-05]\n",
      "~~~~~~~~~~~Iteration  19 ~~~~~~~~~~\n",
      "took 0.017600536346435547 sec  to apply motion profile\n",
      "took 0.0027129650115966797 sec to get H\n",
      "m_hat:  [ 4.99617755e-01 -3.01747263e-04  1.06730557e-04 -4.21688492e-05\n",
      " -7.73659121e-05  2.16675944e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6478123090449aa7bd511cd2b424b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linear_corrector import LC\n",
    "pc1 = old_cloud\n",
    "pc2  = new_cloud\n",
    "m_hat0 = np.array([0, 0, 0, 0, 0, 0.])\n",
    "dc = LC(cloud1 = pc2, cloud2 = pc1, fid = 50, niter = 20, draw = True, m_hat0 = m_hat0,  mnp = 25, RM = False)\n",
    "ViewInteractiveWidget(dc.plt.window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b7545ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##DEBUG: make sure that correspondeces between old and new cloud are good\n",
    "# pc1_theta = dc.c2s(pc1)[:,1]\n",
    "# pc2_theta = dc.c2s(pc2)[:,1]\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(pc1_theta)\n",
    "# ax.plot(pc2_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "467e0506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ iteration  0 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [0. 0. 0. 0. 0. 0.] \n",
      " [0. 0. 0. 0. 0. 0.]\n",
      "\n",
      " H_x before: (6619, 3, 6) \n",
      " tf.Tensor(\n",
      "[[ -1.          -0.          -0.           0.           0.87334144\n",
      "   -0.04215542]\n",
      " [ -0.          -1.          -0.          -0.87334144   0.\n",
      "  -11.479416  ]\n",
      " [ -0.          -0.          -1.           0.04215542  11.479416\n",
      "    0.        ]], shape=(3, 6), dtype=float32)\n",
      "\n",
      " H_x after: (26476, 6) \n",
      " tf.Tensor(\n",
      "[[ -1.          -0.          -0.           0.           0.87334144\n",
      "   -0.04215542]\n",
      " [ -0.          -1.          -0.          -0.87334144   0.\n",
      "  -11.479416  ]\n",
      " [ -0.          -0.          -1.           0.04215542  11.479416\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [ -1.          -0.          -0.           0.           0.23845406\n",
      "   -0.06033108]\n",
      " [ -0.          -1.          -0.          -0.23845406   0.\n",
      "  -11.4531765 ]\n",
      " [ -0.          -0.          -1.           0.06033108  11.4531765\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [ -1.          -0.          -0.           0.          -0.44316432\n",
      "   -0.05804704]\n",
      " [ -0.          -1.          -0.           0.44316432   0.\n",
      "  -11.468705  ]], shape=(10, 6), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 6619 and the array at index 1 has size 6618",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     H_x \u001b[38;5;241m=\u001b[39m H_x\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#delta_A =  ((H^T*H)^-1)(H^T)(yi - yj_undistort)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     residual \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mappend(y_i, np\u001b[38;5;241m.\u001b[39mones([\u001b[38;5;28mlen\u001b[39m(y_i),\u001b[38;5;241m1\u001b[39m]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m---> 55\u001b[0m                 \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_j_undistort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     print(\"residual\", np.shape(residual), \"\\n\", residual)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     H \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(H_x, H_m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/numpy/lib/function_base.py:5392\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5390\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5391\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 6619 and the array at index 1 has size 6618"
     ]
    }
   ],
   "source": [
    "A_hat = np.array([0., 0, 0, 0, 0, 0, \n",
    "                  0, 0, 0, 0, 0, 0])\n",
    "skip = 1 #50\n",
    "y_i = new_cloud[::skip] #baseline\n",
    "y_j = old_cloud[::skip] #distorted cloud\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(y_i[:,:3], c = \"#2c7c94 \", alpha = 0.5, r=5.5))\n",
    "\n",
    "runlen = 5\n",
    "for count in range(runlen):\n",
    "    \n",
    "    print(\"~~~~ iteration \", count, \"~~~~~~~~~~~\")\n",
    "    print(\"A_hat = \\n\", np.round(A_hat[:6],4), \"\\n\", np.round(A_hat[6:],4)) \n",
    "    \n",
    "    #decompose A_hat into X_hat and m_hat\n",
    "    X_hat = A_hat[:6] \n",
    "    m_hat = A_hat[6:]\n",
    "#     X_hat = np.array([0, 0, 0, 0, 0, 0.]) #for debug\n",
    "#     m_hat = np.array([0, 0, 0, 0, 0, 0.]) #for debug\n",
    "#     m_hat = 0.1*m_hat\n",
    "    \n",
    "    #apply last estimate of distortion correction\n",
    "#     print(\"m_hat\", m_hat)\n",
    "    y_j_undistort = lc(y_j, m_hat)\n",
    "\n",
    "    #apply last rigid transform\n",
    "    rot = R_tf(X_hat[3:]).numpy()\n",
    "    trans = X_hat[:3]\n",
    "    y_j_undistort = (y_j_undistort @ rot) + trans\n",
    "    \n",
    "#     print(\"rot: \\n\", rot,\"\\n trans: \\n\", trans)  \n",
    "#     print(\"\\n y_i \\n\",np.shape(y_i), \"\\n\", y_i[:3])\n",
    "#     print(\"y_j_undistort \\n\",np.shape(y_j_undistort), \"\\n\", y_j_undistort[:3])\n",
    "\n",
    "    \n",
    "    #get H = [H_X, H_m]\n",
    "    #get jacobain of distortion correction function\n",
    "    H_m = dc.get_H_m(y_j_undistort, m_hat) \n",
    "#     print(\"\\n H_m:\", np.shape(H_m), \"\\n\", H_m[:10])\n",
    "    \n",
    "    #get jacobian of rigid transform function \n",
    "    H_x = jacobian_tf(tf.transpose(tf.convert_to_tensor(y_j_undistort, tf.float32)), tf.convert_to_tensor(X_hat[3:], tf.float32)) # shape = [num of corr * 3, 6]\n",
    "    #need to append on a row of zeros since we are working with homogeneous coordinates!\n",
    "    H_x = tf.reshape(H_x, (tf.shape(H_x)[0]//3, 3, 6)) # -> need shape [#corr//4, 4, 6]\n",
    "    print(\"\\n H_x before:\", np.shape(H_x), \"\\n\", H_x[0])\n",
    "    H_x = tf.concat([H_x, tf.zeros([len(H_x),1,6])], axis = 1)\n",
    "    H_x = tf.reshape(H_x, (-1, 6))\n",
    "    print(\"\\n H_x after:\", np.shape(H_x), \"\\n\", H_x[:10])\n",
    "    H_x = H_x.numpy()\n",
    "        \n",
    "    #delta_A =  ((H^T*H)^-1)(H^T)(yi - yj_undistort)\n",
    "    residual = (np.append(y_i, np.ones([len(y_i),1]), axis = 1) -\n",
    "                np.append(y_j_undistort, np.ones([len(y_i),1]), axis = 1)).flatten()\n",
    "#     print(\"residual\", np.shape(residual), \"\\n\", residual)\n",
    "    \n",
    "    H = np.append(H_x, H_m, axis = 1)\n",
    "    print(\"H: \\n\", np.shape(H))\n",
    "    \n",
    "    delta_A = np.linalg.pinv(H.T @ H) @ H.T @ residual\n",
    "    print(\"\\n delta_A \\n\", np.round(delta_A[:6], 5), \"\\n\", np.round(delta_A[6:], 5))\n",
    "    #augment rigid transform components\n",
    "    A_hat[:6] -=   delta_A[:6]\n",
    "    #augment distortion components\n",
    "    A_hat[6:9] -= delta_A[6:9]\n",
    "    A_hat[9:] += delta_A[9:]\n",
    "\n",
    "    #plot updated cloud2\n",
    "#     color = [0.5 + count/(runlen*2), 1 - (count+1)/runlen, (count+1)/runlen]\n",
    "#     disp.append(Points(y_j_undistort[:,:3], c = color, r=3.5))\n",
    "    disp.append(Points(y_j_undistort[:,:3], c = \"#a65852 \", alpha = (count+1)/(runlen+1), r=3.5))\n",
    "\n",
    "    \n",
    "plt.show(disp, \"12 State Solution\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b14aab",
   "metadata": {},
   "source": [
    "# Run again with voxel-based correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "30cbbc70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~Iteration  0 ~~~~~~~~~~\n",
      "tf.Tensor([281   3  12], shape=(3,), dtype=int32)\n",
      "LUT tf.Tensor([281   3   3], shape=(3,), dtype=int32)\n",
      "HTWH \n",
      " (281, 12, 12)\n",
      "HTW \n",
      " (281, 12, 3)\n",
      "\n",
      " residuals (281, 3, 1)\n",
      "\n",
      " delta_A before \n",
      " (281, 12, 1)\n",
      "\n",
      " delta_A after \n",
      " (12,)\n",
      "A: \n",
      " [-8.5761e+00 -5.2870e-01  3.2000e-03  0.0000e+00  0.0000e+00  0.0000e+00] \n",
      " [0. 0. 0. 0. 0. 0.]\n",
      "~~~~~~~~~~~Iteration  1 ~~~~~~~~~~\n",
      "tf.Tensor([82  3 12], shape=(3,), dtype=int32)\n",
      "LUT tf.Tensor([82  3  3], shape=(3,), dtype=int32)\n",
      "HTWH \n",
      " (82, 12, 12)\n",
      "HTW \n",
      " (82, 12, 3)\n",
      "\n",
      " residuals (82, 3, 1)\n",
      "\n",
      " delta_A before \n",
      " (82, 12, 1)\n",
      "\n",
      " delta_A after \n",
      " (12,)\n",
      "A: \n",
      " [-8.5929 -0.4643  0.0258  0.      0.      0.    ] \n",
      " [0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde224ba307b47b6a60f0bbb8d200d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linear_corrector import LC\n",
    "\n",
    "dc = LC(cloud1 = old_cloud, cloud2 = new_cloud, fid = 50, niter = 2, \n",
    "        draw = True, mnp = 25, RM = False, solver = '12_state', max_buffer = 2.)\n",
    "ViewInteractiveWidget(dc.plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
