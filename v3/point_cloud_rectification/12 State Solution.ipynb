{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d618048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:20:09.886935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 21:20:10.531104: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-30 21:20:11.673132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-30 21:20:11.673227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/derm/anaconda3/envs/py39/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-30 21:20:11.673234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-04-30 21:20:13.160451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.278425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.278757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 21:20:13.616399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 21:20:13.617785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.617948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:13.618075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.617736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.617998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.618199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-30 21:20:14.618331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "from vedo import *\n",
    "import os\n",
    "from ipyvtklink.viewer import ViewInteractiveWidget\n",
    "import pykitti\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#limit GPU memory ------------------------------------------------\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    memlim = 4*1024\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "from tensorflow.math import sin, cos, tan\n",
    "import tensorflow_probability as tfp\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "parent_directory = os.path.dirname(current)\n",
    "sys.path.append(parent_directory)\n",
    "from ICET_spherical import ICET\n",
    "from utils import *\n",
    "from metpy.calc import lat_lon_grid_deltas\n",
    "from pioneer.das.api.platform import Platform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pioneer.das.api.egomotion.imu_egomotion_provider import IMUEgomotionProvider as emp \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cf3de",
   "metadata": {},
   "source": [
    "# Goal: Simultaneously Estimate Translation, Rotation, and Distortion\n",
    "\n",
    "## $\\mathbf{A} = [\\hat{X}_{ij}, \\hat{m}_{ij}] = \n",
    "\\begin{bmatrix}\n",
    "% x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "x, ~ y, ~ z, ~ \\phi, ~ \\theta, ~ \\psi, ~ x^+, ~y^+, ~z^+, ~\\phi^+, ~\\theta^+, ~\\psi^+ \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a9028",
   "metadata": {},
   "source": [
    "We can use newton-raphson to find A\n",
    "\n",
    "<!-- ## $y_i = \\mathbf{h}(y_j, \\hat{X}_{ij}, \\hat{m}_{ij}) + \\mathbf{H}_m \\delta m + \\mathbf{H}_x \\delta x + \\text{H.O.T.}$ -->\n",
    "\n",
    "## $y_i = \\mathbf{h}(y_j, \\hat{A}_{ij}) + \\mathbf{H}_A \\delta A + \\text{H.O.T.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62668f7e",
   "metadata": {},
   "source": [
    "## $\\mathbf{H}_A \\in \\mathbb{R}^{4N \\times 12} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb30f3c",
   "metadata": {},
   "source": [
    "\n",
    "### $\\mathbf{H}_A = [H_X, H_m]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf4dfc",
   "metadata": {},
   "source": [
    "# Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1645f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load point cloud\n",
    "# # no distortion\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case1/raw_frame_0.npy\")\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #actual motion\n",
    "# m_hat = np.array([-3., 0., 0., 0., 0., 0.1]) #test wrap around\n",
    "\n",
    "# movement in x\n",
    "old_cloud =  np.load(\"sample_data/paper_figures/case2/raw_frame_3.npy\") \n",
    "m_hat = np.array([3, 0, 0., 0., 0., 0])\n",
    "# m_hat = np.array([3, 0, 0., 0., 0., -0.2]) #FOR DEBUG-- deform just a little\n",
    "gt =  np.load(\"sample_data/paper_figures/case2/base_vel_2.npy\")\n",
    "\n",
    "# # movement in x, y, & yaw\n",
    "# old_cloud =  np.load(\"sample_data/paper_figures/case3/raw_frame_1.npy\") \n",
    "# # m_hat = np.array([3, -1, 0., 0., 0., -1])\n",
    "# m_hat = np.array([3, -1, 0., 0., 0., -0.86]) #FOR DEBUG-- deform a little extra\n",
    "# # m_hat = np.array([0., 0., 0., 0., 0., 0.0]) #FOR DEBUG-- no deformation\n",
    "# gt =  np.load(\"sample_data/paper_figures/case3/base_vel_2.npy\")\n",
    "# # print(gt) \n",
    "\n",
    "# period_lidar = 1\n",
    "# t_scale = (2*np.pi)/(-m_hat[-1] + (2*np.pi/period_lidar))\n",
    "# print(t_scale)\n",
    "# m_hat = m_hat*t_scale\n",
    "# # m_hat[-1] = m_hat[-1]*t_scaled\n",
    "# print(m_hat)\n",
    "\n",
    "#downsample\n",
    "old_cloud = old_cloud[::5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b92149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a3232a721443c0a32c68236985fe13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from remove_motion_basic import linear_correction_old as lc \n",
    "\n",
    "#apply ground truth distortion according to m_hat\n",
    "new_cloud = lc(old_cloud, m_hat) \n",
    "#set ground truth transform between clouds\n",
    "# X_gt = np.array([0, 0., 0.0, 0.0, 0.0, 0.0])\n",
    "# X_gt = np.array([1.5, 0.5, 0.03, 0.03, 0.03, 0.25])\n",
    "# X_gt = np.array([1.5, -3, 0.1, 0.2, 0.03, -0.15])\n",
    "X_gt = np.array([-3, 0., 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "# add noise\n",
    "old_cloud += 0.01*np.random.randn(np.shape(old_cloud)[0], 3)\n",
    "\n",
    "# #for fig: mess up both again to show that relative distortion remains constant\n",
    "# new_cloud = lc(new_cloud, -m_hat)\n",
    "# old_cloud = lc(old_cloud, -m_hat)\n",
    "\n",
    "#remove ground plane\n",
    "old_cloud = old_cloud[old_cloud[:,2] > -1] \n",
    "new_cloud = new_cloud[new_cloud[:,2] > -1] \n",
    "\n",
    "# Rotate + Translate new point cloud\n",
    "trans = X_gt[:3]\n",
    "rot = R_tf(X_gt[3:]).numpy()\n",
    "new_cloud = (new_cloud @ rot) + trans\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(old_cloud, c = \"#CB2314\")) \n",
    "disp.append(Points(new_cloud, c = \"#2c7c94\")) \n",
    "plt.show(disp, \"raw point clouds\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734cdf9",
   "metadata": {},
   "source": [
    "### Attempt to solve with basic 6 state solution (Impossible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3c124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~Iteration  0 ~~~~~~~~~~\n",
      "took 0.017620086669921875 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (73, 6)\n",
      "H_m \n",
      " (292, 6)\n",
      "took 0.0018317699432373047 sec to get H\n",
      "m_hat:  [-0.20490022 -0.00844516 -0.26121098  0.00464209 -0.03701815 -0.00690006]\n",
      "~~~~~~~~~~~Iteration  1 ~~~~~~~~~~\n",
      "took 0.015044212341308594 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0018990039825439453 sec to get H\n",
      "m_hat:  [-0.22695127 -0.02058472 -0.37419638 -0.00845655 -0.02406741 -0.00726894]\n",
      "~~~~~~~~~~~Iteration  2 ~~~~~~~~~~\n",
      "took 0.014275074005126953 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0020647048950195312 sec to get H\n",
      "m_hat:  [-0.22258125 -0.0192147  -0.44036609 -0.00507331 -0.03048321 -0.00752197]\n",
      "~~~~~~~~~~~Iteration  3 ~~~~~~~~~~\n",
      "took 0.014877796173095703 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (78, 6)\n",
      "H_m \n",
      " (312, 6)\n",
      "took 0.0023348331451416016 sec to get H\n",
      "m_hat:  [-0.22706306 -0.02151241 -0.48967582 -0.00841068 -0.0295359  -0.0074128 ]\n",
      "~~~~~~~~~~~Iteration  4 ~~~~~~~~~~\n",
      "took 0.013814449310302734 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017423629760742188 sec to get H\n",
      "m_hat:  [-0.23186639 -0.02139676 -0.49619779 -0.00862125 -0.02904951 -0.00726725]\n",
      "~~~~~~~~~~~Iteration  5 ~~~~~~~~~~\n",
      "took 0.013402462005615234 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.001708984375 sec to get H\n",
      "m_hat:  [-0.23179412 -0.02109554 -0.50754219 -0.00838811 -0.02973413 -0.00723098]\n",
      "~~~~~~~~~~~Iteration  6 ~~~~~~~~~~\n",
      "took 0.012358903884887695 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0018358230590820312 sec to get H\n",
      "m_hat:  [-0.23011445 -0.0214512  -0.522901   -0.00864302 -0.03137508 -0.00724351]\n",
      "~~~~~~~~~~~Iteration  7 ~~~~~~~~~~\n",
      "took 0.01317453384399414 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.001710653305053711 sec to get H\n",
      "m_hat:  [-0.23108323 -0.02082882 -0.52847475 -0.00807771 -0.03123158 -0.00722574]\n",
      "~~~~~~~~~~~Iteration  8 ~~~~~~~~~~\n",
      "took 0.011995315551757812 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0018825531005859375 sec to get H\n",
      "m_hat:  [-0.23378687 -0.02025376 -0.53862834 -0.00768586 -0.03071435 -0.00708884]\n",
      "~~~~~~~~~~~Iteration  9 ~~~~~~~~~~\n",
      "took 0.011450529098510742 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0020427703857421875 sec to get H\n",
      "m_hat:  [-0.23588002 -0.02002    -0.57526404 -0.00730265 -0.02966875 -0.00701672]\n",
      "~~~~~~~~~~~Iteration  10 ~~~~~~~~~~\n",
      "took 0.014159679412841797 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017707347869873047 sec to get H\n",
      "m_hat:  [-0.23502962 -0.02024541 -0.60228813 -0.00757177 -0.03072126 -0.00697437]\n",
      "~~~~~~~~~~~Iteration  11 ~~~~~~~~~~\n",
      "took 0.013721227645874023 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017406940460205078 sec to get H\n",
      "m_hat:  [-0.23378934 -0.02021407 -0.59707344 -0.00795039 -0.03168771 -0.0069801 ]\n",
      "~~~~~~~~~~~Iteration  12 ~~~~~~~~~~\n",
      "took 0.013422250747680664 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0024106502532958984 sec to get H\n",
      "m_hat:  [-0.236277   -0.02056047 -0.61119419 -0.00837104 -0.03056465 -0.00690046]\n",
      "~~~~~~~~~~~Iteration  13 ~~~~~~~~~~\n",
      "took 0.013473272323608398 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017657279968261719 sec to get H\n",
      "m_hat:  [-0.23380849 -0.02019078 -0.60893637 -0.00799552 -0.03206705 -0.00696377]\n",
      "~~~~~~~~~~~Iteration  14 ~~~~~~~~~~\n",
      "took 0.01570296287536621 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017139911651611328 sec to get H\n",
      "m_hat:  [-0.23689693 -0.02049853 -0.6056397  -0.0085315  -0.03053485 -0.00688755]\n",
      "~~~~~~~~~~~Iteration  15 ~~~~~~~~~~\n",
      "took 0.014163017272949219 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0018494129180908203 sec to get H\n",
      "m_hat:  [-0.23353392 -0.02053498 -0.59732223 -0.0080534  -0.03222588 -0.00699758]\n",
      "~~~~~~~~~~~Iteration  16 ~~~~~~~~~~\n",
      "took 0.013010263442993164 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.001955270767211914 sec to get H\n",
      "m_hat:  [-0.23662728 -0.02099127 -0.61261803 -0.00866523 -0.030569   -0.00697478]\n",
      "~~~~~~~~~~~Iteration  17 ~~~~~~~~~~\n",
      "took 0.01361703872680664 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017333030700683594 sec to get H\n",
      "m_hat:  [-0.23357368 -0.02046198 -0.60949481 -0.00803623 -0.03228458 -0.00699895]\n",
      "~~~~~~~~~~~Iteration  18 ~~~~~~~~~~\n",
      "took 0.013805627822875977 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0016701221466064453 sec to get H\n",
      "m_hat:  [-0.23676887 -0.02061431 -0.61835665 -0.00856878 -0.03109219 -0.00690349]\n",
      "~~~~~~~~~~~Iteration  19 ~~~~~~~~~~\n",
      "took 0.01303243637084961 sec  to apply motion profile\n",
      "\n",
      " M \n",
      " (79, 6)\n",
      "H_m \n",
      " (316, 6)\n",
      "took 0.0017292499542236328 sec to get H\n",
      "m_hat:  [-0.23411202 -0.02030404 -0.61053586 -0.00819941 -0.03214448 -0.00695912]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2769e08ad634449eb620c15c31df5104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from linear_corrector import LC\n",
    "pc1 = old_cloud\n",
    "pc2  = new_cloud\n",
    "m_hat0 = np.array([0, 0, 0, 0, 0, 0.])\n",
    "dc = LC(cloud1 = pc2, cloud2 = pc1, fid = 50, niter = 20, draw = True, m_hat0 = m_hat0,  mnp = 25, RM = False)\n",
    "ViewInteractiveWidget(dc.plt.window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b7545ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##DEBUG: make sure that correspondeces between old and new cloud are good\n",
    "# pc1_theta = dc.c2s(pc1)[:,1]\n",
    "# pc2_theta = dc.c2s(pc2)[:,1]\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(pc1_theta)\n",
    "# ax.plot(pc2_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "467e0506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ iteration  0 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [0. 0. 0. 0. 0. 0.] \n",
      " [0. 0. 0. 0. 0. 0.]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 1.32669e+00  3.43000e-03  2.87700e-02 -9.70000e-04  3.71000e-03\n",
      " -1.13000e-03] \n",
      " [-2.66862e+00 -3.20000e-03 -6.54600e-02 -3.40000e-04  7.99000e-03\n",
      " -8.70000e-04]\n",
      "~~~~ iteration  1 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.3267e+00 -3.4000e-03 -2.8800e-02  1.0000e-03 -3.7000e-03  1.1000e-03] \n",
      " [ 2.6686e+00  3.2000e-03  6.5500e-02 -3.0000e-04  8.0000e-03 -9.0000e-04]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 0.15818 -0.00155 -0.0154   0.0009  -0.00264  0.00105] \n",
      " [-0.29733  0.00189  0.03588  0.0006  -0.0061   0.00083]\n",
      "~~~~ iteration  2 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.4849e+00 -1.9000e-03 -1.3400e-02  1.0000e-04 -1.1000e-03  1.0000e-04] \n",
      " [ 2.9659e+00  1.3000e-03  2.9600e-02  3.0000e-04  1.9000e-03 -0.0000e+00]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 1.393e-02 -1.470e-03 -8.640e-03  1.200e-04 -6.200e-04  9.000e-05] \n",
      " [-3.122e-02  7.300e-04  1.925e-02 -3.000e-05 -1.140e-03  5.000e-05]\n",
      "~~~~ iteration  3 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.4988e+00 -4.0000e-04 -4.7000e-03 -0.0000e+00 -4.0000e-04 -0.0000e+00] \n",
      " [2.9972e+00 6.0000e-04 1.0300e-02 2.0000e-04 7.0000e-04 0.0000e+00]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 1.23e-03 -1.80e-04 -3.30e-03  3.00e-05 -2.70e-04  0.00e+00] \n",
      " [-2.89e-03  9.00e-05  7.15e-03 -6.00e-05 -4.80e-04  0.00e+00]\n",
      "~~~~ iteration  4 ~~~~~~~~~~~\n",
      "A_hat = \n",
      " [-1.5e+00 -2.0e-04 -1.4e-03 -1.0e-04 -2.0e-04 -0.0e+00] \n",
      " [3.0001e+00 5.0000e-04 3.2000e-03 2.0000e-04 3.0000e-04 0.0000e+00]\n",
      "\n",
      " M \n",
      " (18074, 6)\n",
      "H_m \n",
      " (72296, 6)\n",
      "\n",
      " delta_A \n",
      " [ 8.00e-05 -1.00e-05 -1.19e-03  1.00e-05 -9.00e-05 -0.00e+00] \n",
      " [-2.20e-04 -1.00e-05  2.51e-03 -3.00e-05 -1.60e-04 -0.00e+00]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aa7d5be4694ddf8d0645113ae9b7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=1043, layout=Layout(height='auto', width='100%'), width=1280)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_hat = np.array([0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "skip = 1 #50\n",
    "y_i = new_cloud[::skip] #baseline\n",
    "y_j = old_cloud[::skip] #distorted cloud\n",
    "\n",
    "plt = Plotter(N = 1, axes = 4, bg = (1, 1, 1), interactive = True)\n",
    "disp=[]\n",
    "disp.append(Points(y_i[:,:3], c = \"#2c7c94 \", alpha = 0.5, r=5.5))\n",
    "\n",
    "runlen = 5\n",
    "for count in range(runlen):\n",
    "    \n",
    "    print(\"~~~~ iteration \", count, \"~~~~~~~~~~~\")\n",
    "    print(\"A_hat = \\n\", np.round(A_hat[:6],4), \"\\n\", np.round(A_hat[6:],4)) \n",
    "    \n",
    "    #decompose A_hat into X_hat and m_hat\n",
    "    X_hat = A_hat[:6] \n",
    "    m_hat = A_hat[6:]     \n",
    "#     X_hat = np.array([0, 0, 0, 0, 0, 0.]) #for debug\n",
    "#     m_hat = np.array([0, 0, 0, 0, 0, 0.]) #for debug\n",
    "#     m_hat = 0.1*m_hat\n",
    "    \n",
    "    #apply last estimate of distortion correction\n",
    "#     print(\"m_hat\", m_hat)\n",
    "    y_j_undistort = lc(y_j, m_hat)\n",
    "\n",
    "    #apply last rigid transform\n",
    "    rot = R_tf(X_hat[3:]).numpy()\n",
    "    trans = X_hat[:3]\n",
    "    y_j_undistort = (y_j_undistort @ rot) + trans\n",
    "    \n",
    "#     print(\"rot: \\n\", rot,\"\\n trans: \\n\", trans)  \n",
    "#     print(\"\\n y_i \\n\",np.shape(y_i), \"\\n\", y_i[:3])\n",
    "#     print(\"y_j_undistort \\n\",np.shape(y_j_undistort), \"\\n\", y_j_undistort[:3])\n",
    "\n",
    "    \n",
    "    #get H = [H_X, H_m]\n",
    "    #get jacobain of distortion correction function\n",
    "    H_m = dc.get_H_m(y_j_undistort, m_hat) \n",
    "#     print(\"\\n H_m:\", np.shape(H_m), \"\\n\", H_m[:10])\n",
    "    \n",
    "    #get jacobian of rigid transform function \n",
    "    H_x = jacobian_tf(tf.transpose(tf.convert_to_tensor(y_j_undistort, tf.float32)), tf.convert_to_tensor(X_hat[3:], tf.float32)) # shape = [num of corr * 3, 6]\n",
    "    #need to append on a row of zeros since we are working with homogeneous coordinates!\n",
    "    H_x = tf.reshape(H_x, (tf.shape(H_x)[0]//3, 3, 6)) # -> need shape [#corr//4, 4, 6]\n",
    "#     print(\"\\n H_x:\", np.shape(H_x), \"\\n\", H_x[0])\n",
    "    H_x = tf.concat([H_x, tf.zeros([len(H_x),1,6])], axis = 1)\n",
    "    H_x = tf.reshape(H_x, (-1, 6))\n",
    "#     print(\"\\n H_x:\", np.shape(H_x), \"\\n\", H_x[:10])\n",
    "    H_x = H_x.numpy()\n",
    "        \n",
    "    #delta_A =  ((H^T*H)^-1)(H^T)(yi - yj_undistort)\n",
    "    residual = (np.append(y_i, np.ones([len(y_i),1]), axis = 1) -\n",
    "                np.append(y_j_undistort, np.ones([len(y_i),1]), axis = 1)).flatten()\n",
    "#     print(\"residual\", np.shape(residual), \"\\n\", residual)\n",
    "    \n",
    "    H = np.append(H_x, H_m, axis = 1)\n",
    "#     print(\"H: \\n\", np.shape(H))\n",
    "    \n",
    "    delta_A = np.linalg.pinv(H.T @ H) @ H.T @ residual\n",
    "    print(\"\\n delta_A \\n\", np.round(delta_A[:6], 5), \"\\n\", np.round(delta_A[6:], 5))\n",
    "    #augment rigid transform components\n",
    "    A_hat[:6] -=   delta_A[:6]\n",
    "    #augment distortion components\n",
    "    A_hat[6:9] -= delta_A[6:9]\n",
    "    A_hat[9:] += delta_A[9:]\n",
    "\n",
    "    #plot updated cloud2\n",
    "#     color = [0.5 + count/(runlen*2), 1 - (count+1)/runlen, (count+1)/runlen]\n",
    "#     disp.append(Points(y_j_undistort[:,:3], c = color, r=3.5))\n",
    "    disp.append(Points(y_j_undistort[:,:3], c = \"#a65852 \", alpha = (count+1)/(runlen+1), r=3.5))\n",
    "\n",
    "    \n",
    "plt.show(disp, \"12 State Solution\")\n",
    "ViewInteractiveWidget(plt.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbbc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
